<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python高阶函数函数和装饰器一]]></title>
    <url>%2F2020%2F08%2F25%2Fpython%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0%E5%92%8C%E8%A3%85%E9%A5%B0%E5%99%A8%E4%B8%80%2F</url>
    <content type="text"><![CDATA[python 高阶函数和装饰器一 First Class Object 函数在python中是一等公民; 函数也是对象，可调用的对象; 函数可以作为普通变量、参数、返回值等; 高阶函数 数据概念y=g(f(x)); 在数学和计算机科学中，高阶函数应当是至少满足下面一个条件的函数; 接受一个多个函数作为参数;输出一个函数; 12345678910def counter(base): def inc(step=1): nonlocal base base = base + step return base return incfoo = counter(10)foo1 = counter(10)print(foo())print(foo1()) 自定义sort 函数 排序问题 仿照内建函数sorted, 请自行实现一个sort函数(不使用内建函数),能够为列表元素排序; 思路 内建函数sorted函数是一个返回一个新的列表， 可以设置升序或降序,也可以设置一个 排序的函数;自定义的sort函数也要实现这个功能; 新建一个列表, 遍历原列表，和新列表的值依次比较决定如何插入新列表中; 思考sorted 函数的实现原理，扩展到map、 filter函数的实现原理; 123456789101112131415def sort(iterable,key=lambda a,b:a&lt;b, reverse=False): ret = [] for x in iterable: for i,y in enumerate(ret): flag = key(x, y) if reverse else key(y,x) if flag: ret.insert(i,x) break else: ret.append(x) return retlst = [1,2,3,11,5,6,4,8,9]print(sort(lst,reverse=True))# 输出[1, 2, 3, 4, 5, 6, 8, 9, 11]]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 函数(三)]]></title>
    <url>%2F2020%2F08%2F19%2Fpython%E5%87%BD%E6%95%B0%E4%B8%89%2F</url>
    <content type="text"><![CDATA[python 函数(三) 变量名解析原则LEGB Local本地作用域、局部作用域的local命名空间。函数调时创建，调用结束消亡; Enclosing, Python2.2时引入了嵌套函数，实现了闭包，这个就是嵌套函数的外部函数的全名空间; Global，全局作用域，即一个模块的命名空间。模块被import 时创建，解释器退出时消亡; Build-in， 内置模块的命名空间，生命周期从python解释器启动时创建 到解释器退出时消亡。例如 print(open)，print 和open都是内置的变量; 所以一个名词的查找顺序就是LEGB; 函数执行流程12345678910111213141516171819202122def foo1(b,b1=3): print("foo1 called",b,b1)def foo2(c): foo3(c) print("foo2 called",c)def foo3(d): print("foo3 called", d)def main(): print("main called") foo1(100,101) foo2(200) print("main ending")main()main calledfoo1 called 100 101foo3 called 200foo2 called 200main ending 全局帧中生成foo1、foo2、foo3、main函数对象; main函数调用; main中查找内建函数print压栈，将常量字符串压栈，调用函数，弹出栈顶; main中全局查找函数foo1压栈，将常量100、101压栈，调用函数foo1，创建栈帧。print函数压栈，字符串和亦是b、b1压栈、调用函数，弹出栈顶，返回值。 main中全局查找foo2函数压栈，将常量200压栈，调用foo2，创建栈帧。foo3函数压栈，变量c引用压栈，调用foo3，创建栈帧。foo3完成print函数调用后返回。foo2恢复调用。执行print后，返回值。main中foo2调用结束弹出栈顶，继续执行print函数调用，弹出栈顶。main函数返回。 递归Recursion 函数直接或者间接调用自身就是 递归; 递归需要有边界条件、递归前进段、递归返回段; 递归一定要有边界操作; 当办界条件不满足的时候，递归前进; 当边界条件满足的时候，递归返回; 斐波那契数列Fibonacci number: 1,1,2,3,5,8,13,21,34,55,89,144,… 如果设F(n)为该数列的第n项(n∈N* )，那么这句话可以写成如下形式: F(n)=F(n-1)+F(n-2) F(0)=0, F(1)=1,F(n)=F(n-1)+F(n-2) 123456789pre = 0cur = 1print(pre,cur,end=' ')n = 10for i in range(n-1): pre, cur = cur,pre+cur print(cur,end=' ')#结果: 0 1 1 2 3 5 8 13 21 34 55 递归实现 F(0)=0,F(1)=1,F(n)=F(n-1)+F(n-2) 12345def fib(n): return 1 if n &lt; 2 else fib(n-1) + fib(n-2)for i in range(10): print(fib(i), end=' ')# 1 1 2 3 5 8 13 21 34 55 解析: fib(3) + fib(2)fib(3) 调用fib(3)、fib(2)、fib(1)fib(2) 调用fib2(2)、fib(1)fib(1) 是边界 递归要求 递归一定要有退出条件，递归调用一定要执行到这个退出条件。没有退出条件的递归调用，就是无限调用; 递归调用的深度不宜过深; Python 对递归调用的深度做了限制，以保护解释器; 超过递归深度限制，抛出RecurisonError: maxinum recursion depth exceeded超出最大深度; sys.getrecursionlimit() 123456In [1]: import sysIn [2]: print(sys.getrecursionlimit())3000In [4]: sys.setrecursionlimit(1000)In [5]: print(sys.getrecursionlimit())1000 优化改进 fib函数和循环的思想类似;参数n是边界条件，用n来计数;上一次的计算结果直接作为函数的实参;效率很高;和循环比较，性能相近。所以并不是递归一定是效率底下，但是递归有深度的限制;12345678910111213pre = 0cur = 1print(pre, cur)def fib(n, pre=0,cur=1): pre, cur = cur, pre + cur print(cur, end=' ') if n == 2 : return fib(n-1, pre, cur)fib(10)# 输出 1 2 3 5 8 13 21 34 55 间接递归如def foo1(): foo2() def foo2(): foo1() foo1() 间接递归，是通过别的函数调用了函数自身;但是，如果构成了循环递归调用是非常危险的，但是往往这种情况下代码复杂的情况下，还是可能发生这种调用。要用代码的规范来避免这种递归调用的发生。 递归总结 递归是一种很自然的表达，符合逻辑思维; 递归相对运行效率低，每一次调用函数都要开辟栈帧; 递归有深度限制，如果递归层次太深，函数反复压栈，栈内存很快就溢出了; 如果是有限次数的递归，可以使用递归调用，或者使用循环代替，循环代码稍微复杂一些，但是只要不是死trggsk以多次迭代直至算出结果； 绝大多数递归，都可以使用循环实现; 即使递归代码很简洁，但是能不用则不用递归。 递归练习 求n的阶乘 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def fac(n): if n == 1 : return 1 return n * fac(n-1)def fac1(n, p =1 ): if n == 1: return p p *= n print(p) fac1(n-1,p) return pdef fac2(n, p = None): if p is None: p = [1] if n == 1 : return p[0] p[0] *= n print(p[0]) fac2(n-1, p) return pn = 10print(fac(n))print(fac1(n))print(fac2(n))# 输出362880010907205040302401512006048001814400362880010109072050403024015120060480018144003628800[3628800] 将一个数逆序放入列表中，例如1234 =&gt; [4,3,2,1 1234567num = 1234def revert(num, target=[]): if num: target.append(num[len(num) -1]) # target.append(num[-1:]) revert(num[:len(num) -1]) return targetprint(revert(str(num))) 解决猴子吃桃问题 猴子第一天摘下苦干个桃子，当即吃了一半，还不过瘾，又多吃了一个，第二天早上又剩下的桃子吃掉一半，又多吃了一个。以后每天早上都各吃了前一天剩下的一半零一个。到第10天早上想吃时，只剩下一个桃子了。求第一天共摘多少个桃子。 12345def peach(days=10): if days == 1: return 1 return(peach(days-1)+1)*2print(peach()) 注意这里必须是10， 因为return(peach(days-1)+1)*2 立即拿不到结果，必须通过再一次进入函数时判断是不是到了最后一天。也就是当前使用的值是由下一次函数调用得到，所以要执行10次函数调用。 换种方式表达 12345def peatch(days=1): if days == 10: return 1 return(peatch(days+1)+1)*2print(peatch()) 匿名函数Python 借助Lambda表达式构建匿名函数 例12In [1]: (lambda x:x*2)((4,2))Out[1]: (4, 2, 4, 2) 使用lambda 关键字来定义匿名函数; 参数列表不需要小括号; 冒号是用来分割参数列表和表达式的; 不需要使用return，表达式的值，就是匿名函数返回值; lambda表达式(匿名函数)只能写在一行上，被称为单行函数 用途在高阶函数传参时，使用lambda表达式，往往能简化代码; 1234567891011121314151617181920212223242526print((lambda :0)())print((lambda x,y=3: x + y )(5))print((lambda x,y=3: x + y)(5,6))print((lambda x, *, y=30: x + y)(5))print((lambda x, *, y=30: x + y)(5, y=10))print((lambda *args: (x for x in args))(*range(5)))print((lambda *args:[x+1 for x in args])(*range(5)))print((lambda *args: [x + 2 for x in args])(*range(5)))print((lambda *args: &#123; x + 2 for x in args &#125;)(*range(5)))###高阶函数lst = [x for x in (lambda *args: map(lambda x: x+1,args))(*range(5))]print(lst)lst2 = [x for x in (lambda *args: map(lambda x:(x+1,args),args))(*range(5))]print(lst2)08113515&lt;generator object &lt;lambda&gt;.&lt;locals&gt;.&lt;genexpr&gt; at 0x10742dcf0&gt;[1, 2, 3, 4, 5][2, 3, 4, 5, 6]&#123;2, 3, 4, 5, 6&#125;[1, 2, 3, 4, 5][(1, (0, 1, 2, 3, 4)), (2, (0, 1, 2, 3, 4)), (3, (0, 1, 2, 3, 4)), (4, (0, 1, 2, 3, 4)), (5, (0, 1, 2, 3, 4))] 生成器 生成器generator生成器指的是生成器对象，可以由生成器表达式得到，也可以使用yeild关键字得到一个生成器函数，调用这个函数得到一个生成器对象 生成器函数函数体中包含yield语句的函数，返回生成器对象;生成器对象，是一个可迭代对象，是一个迭代对象;生成器对象，是延迟计算、惰性求值的。 123456789101112131415161718192021def inc(): for i in range(5): yield iprint(type(inc))print(type(inc()))x = inc()print(type(x))print(next(x))for m in x: print(m, '*')for m in x: print(m, '**')# 输出&lt;class 'function'&gt;&lt;class 'generator'&gt;&lt;class 'generator'&gt;01 *2 *3 *4 * 1234567In [1]: y = (i for i in range(5))In [2]: print(type(y))&lt;class 'generator'&gt;In [3]: print(next(y))0In [4]: print(next(y))1 普通的函数调用fn()， 函数会立即执行完毕，但是生成器函数可以使用next函数多次执行; 生成器函数等价于生成器表达式，只不过生成器函数可以更加的复杂; 123456789101112131415161718192021222324252627282930In [5]: def gen(): ...: print('line 1') ...: yield 1 ...: print('line 2') ...: yield 2 ...: print('line 3') ...: return 3In [6]: next(gen())line 1Out[6]: 1In [7]: next(gen())line 1Out[7]: 1In [8]: g = gen()In [9]: print(next(g))line 11In [10]: print(next(g))line 22In [11]: print(next(g))line 3---------------------------------------------------------------------------StopIteration Traceback (most recent call last)&lt;ipython-input-11-1dfb29d6357e&gt; in &lt;module&gt;()----&gt; 1 print(next(g))StopIteration: 3In [12]: print(next(g, 'End'))End 在生成器函数中，使用多个yield语句，执行一次后会暂停执行，把yeild表达式的值返回; 再次执行会执行到下一个yield语句; return语句依然可以终止函数运行,但是return语句的返回值不能被获取到; return会导致无法继续获取一下个值，抛出StopIteration异常; 如果函数没有显示的return语句，如果生成器函数执行到结尾，一样会抛出StopIteration异常; 生成器函数 包含yield语句的生成器函数生成生成器对象，生成器函数的函数体不会立即执行 next(generator)会从函数的当前位置向后执行到之后踫到的第一个yeild语句，会弹出值，并暂停函数执行; 再次调用next函数，和上一条一样的处理过程; 没有多余的yield语句的能被执行，继续调用next函数，会抛出StopIteration异常; 生成器应用12345678910111213141516In [13]: def counter(): ...: i = 0 ...: while True: ...: i +=1 ...: yield iIn [14]: def inc(c): ...: return next(c)In [15]: c = counter()In [16]: print(inc(c))1In [17]: print(inc(c))2In [18]: print(inc(c))3In [19]: print(inc(c))4 1234567891011121314151617In [21]: def counter(): ...: i = 0 ...: while True: ...: i += 1 ...: yield i ...:In [22]: def inc(): ...: c = counter() ...: return next(c)In [23]: print(inc())1In [24]: print(inc())1In [25]: print(inc())1 计数器 1234567891011121314151617def inc(): def counter(): i = 0 while True: i +=1 yield i c = counter() return lambda : next(c)foo = inc()print(foo())print(foo())print(foo())# 输出123 lambda 表达式是匿名函数return 返回的是一个匿名函数等价于下面的代码 123456789101112131415def inc(): def counter(): i = 0 while True: i +=1 yield i c = counter() def _inc(): return next(c) return _incfoo = inc()print(foo())print(foo())print(foo()) 处理递归问题 123456789101112def fib(): x = 0 y = 1 while True: yield y x,y = x, x+yfoo = fib()for _ in range(5): print(next(foo))for _ in range(100): next(foo)print(next(foo)) 等价于下面的代码 123456789pre = 0cur = 1print(pre, cur, end=' ')def fib1(n, pre=0, cur=1): pre, cur = cur, pre + cur print(cur, end=' ') if n ==2 : return fib1(n-1,pre,cur) 协程coroutine 生成器的高级用法 ; 比进程、线程轻量级; 是在用户空间调度函数的一种实现; Python3 asyncio就是协程实现，已经加入到标准库; Python3.5使用async、await关键字直接原生支持协程; 协程高度器实现思路; 有2个生成器A、B next(A)后，A执行到了yeild语句暂停，然后去执行next(B)，B执行到yield语句也暂停，然后再次调用next(A)，再调用next(B)在，周而复始，就实现了调度的效果; 可以引入调度的策略来实现切换的方式; 协程是一种非抢占调度 yield from 举例 12345678910111213In [26]: def inc(): ...: for x in range(1000): ...: yield x ...:In [27]: foo = inc()In [28]: print(next(foo))0In [29]: print(next(foo))1In [30]: print(next(foo))2 等价于下面的代码 123456789In [31]: def inc(): ...: yield from range(1000)In [32]: foo = inc()In [33]: print(next(foo))0In [34]: print(next(foo))1In [35]: print(next(foo))2 yield from 是Python 3.3 出现的新的语法 yield from iterable 是 for item in iterable: yield item 形式的语法粮 可迭代对象中一个个拿元素 123456789101112In [36]: def counter(n): ...: for x in range(n): ...: yield xIn [37]: def inc(n): ...: yield from counter(n)In [38]: foo = inc(10)In [39]: print(next(foo))0In [40]: print(next(foo))1In [41]: print(next(foo))2 格言知止而后有定，定而后能静，静而后能安，安而后能虑，虑而后能得 数语，尽矣;]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 函数(二)]]></title>
    <url>%2F2020%2F08%2F11%2Fpython%E5%87%BD%E6%95%B0%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[python 函数(二) nolocal 关键字 使用了nolocal关键字，将变量标记为在上级的局部作用域中的定义，但不能是全局作用域中定义 count 是外层函数的局部变量，被内部函数引用 内部函数使用nonlocal 关键字声明count 变量是在上一级作用域中 1234567891011121314In [2]: def counter(): ...: count =0 ...: def inc(): ...: nonlocal count ...: count +=1 ...: return count ...: return incIn [3]: foo = counter()In [4]: print(foo())1In [5]: print(foo())2In [6]: print(foo())3 默认值的作用域1234567891011In [7]: def foo(xyz=[]): ...: xyz.append('100') ...: print(xyz) ...:In [8]: foo()['100']In [9]: foo()['100', '100']In [10]: foo()['100', '100', '100'] 例子 123456789In [1]: def foo(xyz=[],u='abc',z=123): ...: xyz.append(1) ...: return xyzIn [2]: print(foo(),id(foo))[1] 4569788064In [3]: print(foo.__defaults__)([1], 'abc', 123)In [4]: print(foo(),id(foo))[1, 1] 4569788064 函数地址并没有变，就是说函数这个对象的没有变，调用它，它的属性defaults中使用元组保存所有默认值; xyz 默认值是引用类型，引用类型的元素变动，并不是元组的变动; 1234567891011In [8]: def foo(w,u='abc',z=123): ...: u = 'xyz' ...: z = 789 ...: print(w,u,z)In [9]: print(foo.__defaults__)('abc', 123)In [10]: foo('asjin')asjin xyz 789In [11]: print(foo.__defaults__)('abc', 123) 属性defaults 中使用元组保存所有默认值，它不会因为在函数体内使用了它而发生改变; 可变类型默认值，如果使用默认值，就可能修改这个默认值; 有时候这个特性是好的，有的时候这种我是不是好的，有副作用; 第一种方法 使用影子拷贝创建一个新的对象，永远不能改变传入的参数; 第二种方法 通过值的判断就可以灵活的选择创建或者修改传入对象; 这种方式灵活，应用广泛 ; 很多函数的定义，都可以看到使用None这个不可变的值作为默认参数，可以说是这一种惯用法。 函数的销毁* 全局函数销毁 重新定义同名函数 del 语句删除函数对象 程序结束时 12345678910111213141516171819202122 In [5]: def foo(xyz=[], u='abc', z=123): ...: xyz.append(1) ...: def inner(a=10): ...: pass ...: print(inner) ...: def inner(a=100): ...: print(xyz) ...: print(inner) ...: return innerIn [6]: bar =foo()&lt;function foo.&lt;locals&gt;.inner at 0x10529dbf8&gt;&lt;function foo.&lt;locals&gt;.inner at 0x1053c8f28&gt;In [7]: print(id(foo),id(bar), foo.__defaults__, bar.__defaults__)4382889232 4382822184 ([1], 'abc', 123) (100,)In [8]: del barIn [9]: print(id(foo),id(bar), foo.__defaults__, bar.__defaults__)---------------------------------------------------------------------------NameError Traceback (most recent call last)&lt;ipython-input-9-7b5c35b2c85a&gt; in &lt;module&gt;()----&gt; 1 print(id(foo),id(bar), foo.__defaults__, bar.__defaults__)NameError: name 'bar' is not defined 树 非线性结构，每个元素可以有多个前驱和后继 树是n(n&gt;=0)个元素的集合 n = 0 时， 称为空树; 树只有一个特殊的没有前驱的元素，称为树的根Root; 树中除了根结点外，其余元素只能有一个前驱，可以有零个或多个后继; 递归定义 树T是n(n&gt;=0)个元素的集合。n=0时，称为空树; 有且只有一个特殊元素根，剩余元素都可以被划分为m个互不相交的集合T1、T2、T3、… Tm，而每一个集合都有树，称为T的子树Subtree 子树也有自己的根 树的概念 结点: 树中的数据元素; 结点的度degree:结点拥有的子树的数目称为度，记作d(v); 叶子结点: 结点的度0， 称为叶子结点leaf、终端结点、末端结点; 分支结点: 结点的度不为0， 称为非终端结点或分结点; 分支: 结点之间的关系; 内部结点: 除根结点外的分支结点，当然也不包括叶子结点; 树的度是树内各结点的度的最大值。D结点度最大为3，树的度数就是3; 孩子(儿子Child)结点: 结点的子树的根结点成为该结点的孩子; 双亲(父Parent)结点: 一个结点是它各子树的根结点的双亲; 兄弟(Sibling)结点: 具有相同双亲结点的结点; 祖先结点: 从要结点到该结点所经分支上所有的结点。 A、B、D 都是G的祖先结点; 子孙结点: 结点的所有子树上的结点都称为该结点的子孙。B的子孙是D、G、H、I 结点的层次(Level): 根节点为第一层，根的孩子为第二层，以此类推，记作L(v) 树的深度(高度Depth); 树的层次的最大值。上图的树深度为4 堂兄弟:双亲在同一层结点。 有序树: 结点的子树是有顺序的(兄弟有大小，有先后次序)，不能交换。 无序树: 结点的子树是无序的，可以交换; 路径: 树中的k 个结点n1、n2、….、nk ，满足n1是n(i+1)的双亲，成为n1到nk的一条路径。就是一条线串下来的，前一个都是后一个父(前驱)结点。 路径长度=路径 上结点-1，也是分支数; 森林:m(m&gt;=0)棵不相交的树的集合;对于结点而言，其子树的集合就是森林。A结点的2棵子树的集合就是森林。 树 树的特点 唯一的根 子树不相交 除了根以外，每个元素只能有一个前驱，可以有零个或多个后继; 根结点没有双亲结点(前驱)，叶子结点没有孩子结点(后继) vi是 vj 的双亲，则L(vi) = L(vj)-1，也就是说双亲比孩子结点的层小1 二叉树 每个结点最多2棵了树 二叉树不存在度数大于2的结点 它是有序树，左子树、右子树是顺序的，不能交换次序; 即使某个结点只有一棵子树，也要确定它是左子树还是右子树; 二叉树的的五种基本形态 空二叉树 只有一个根结点 根结点只有左子树 根结点只有右子树 根结点有左子树和右子树 斜树 左斜树，所有结点都只有左子树; 右斜树，所有节点都只有右子树; 满二叉树 一棵二叉树的所有分支结点都存在左子树和右子树，并且所有叶子结点只存在在最下面一层; 同样深度二叉树中，满二叉树结点最多; k 为深度(1&lt;=k&lt;=n)，则结点总数为2^k-1; 完全二叉树Complete Binary Tree 若二叉树的深度为k, 二叉树的层数从1到k-1层的结点数都达到了最大个数,在第k层的所有结点都集中在最左边，这就是完全二叉树; 完全二叉树由满二叉树引出; 满二叉树一定是完全二叉树，但完全二叉树不是满二叉树; k为深度(1&lt;=k&lt;=n)，则结点总数最大值为2^k-1，当达到最大值的时候就是满二叉树； 二叉树性质 对任何一棵二叉树T，如果其终端节点数为n0，度数为2的结点为n2，则有n0=n2+1; 换句话说，就是叶子结点数-1就等于度数为2的结点数; 证明: 总结点数为n=n0+n1+n2，n1为度数为1的结点数; 一棵树的分支数为n-1，因为除了根结点外，其余结点都有一个分支，即n0+n1+n2-1; 分支数还等于n0*0+n1*1+n2*2，n2 是2分支结点所以乘以2，2*n2+n1。 可得2*n2+n1 = n0+n1+n2-1 =&gt; n2 =n0-1 其他性质 高度为k的二叉树，至少有k个结点; 含有n(n&gt;=1)的结点的二叉树高度至多为n，和上句一个意思; 含有n(n&gt;=1)的结点的二叉树高度至多为n，最小为meth.ceil(log2(n+1))，不小于对数值的最小整数，向上取整; 假设高度为h，2^h-1=n =&gt; h= log2(n+1)，层次数是取整。如果是8个节点，3.1699就要向上取整为4, 为4层。 具有n 个结点的完全二叉树的深度为int(log2n)+1 或者meth.ceil(log2(n+1)) 性质5 如果有一棵n个结点的完全二叉树，结点按照层序编号; 如果i=1, 则结点i是二叉树的根，无双亲;如果i&gt;1，则其双亲是int(i/2)，向下取整。就是子节点的编号整除2得到的就是父结点的编号。父结点如果是i，那么左孩子结点就是2i，右孩子结点就是2i+1; 如果2i&gt;n, 则结点i无左孩子，即结点i为叶子结点；否则其左孩子结点存在的编号为2i; 如果2i+1 &gt;n，则结点i无右孩子，注意这里并不能说明结点i 没有左孩子; 否则右孩子结点存在编号为2i+1。 格言有恒，乃为作圣之基凡人作一事，便须全副精神注在此一事，首尾不懈，不可见异思迁，做这样想那样，坐之山望那山。人而无恒，终身一无所成。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 函数(一)]]></title>
    <url>%2F2020%2F08%2F05%2Fpython%E5%87%BD%E6%95%B0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[python 函数(一) 函数数学定义: y=f(x)，y是x的函数，x是自变量 python 函数 由苦干语句组成的语句块、函数名称、参数列表构成，它是组织代码的最小单元格完成一定的功能 函数的作用 结构化编程对代码的最基本的封装，一般按照功能组织一段代码;封装的目的为了复用，减少冗余代码代码更加简洁美化、可读易懂 函数的分类 内建的函数，如max()、reversed()等库函数,如math.ceil()等 函数定义、调用 def语句定义函数def 函数名(参数列表):函数体(代码块)[return 返回值] 函数名就是标识符，命名要求一样： 语句块必须缩进，约定4个空格; Python 的函数没有return语句，隐式返回 一个None值 定义中的参数列表成为形式参数，只是一种符号表达，简称形参 调用函数定义，只是声明了一个函数，它不会被执行，需要调用;调用的方式，就是函数名加上小括号，括号内写上参数;调用时写的参数是实际参数，是实实在在传的值，简称实参 函数举例 123456789In [3]: def add(x,y): ...: result = x+y ...: return result ...: ...:In [4]: out = add(100,255)In [5]: outOut[5]: 355 上面只是一个函数的定义，有一个函数叫做add，接收2个参数计算的结果，通过返回值返回调用通过函数名add加2个参数，返回值可使用变量接收;定义需要在调用前，也就是说调用时，已经被定义过了，否则抛NameError异常函数是可调用的对象,callable() 函数参数 参数调用时传入的参数要和定义的个数相匹配(可变参数例外) 位置参数def f(x, y, z) 调用使用 f(1, 3, 5)按照参数定义顺序传入实参 关键字参数def f(x, y ,z) 调用使用f(x=1,y=3,z=5)使用形参的名字来出入实参的方式，如果使用了形象名字，那么传参顺序就可以定义顺序不同 传参 1234f(z=None, y=10, x=[1])f((1,), z=6, y=4.1)f(y=5,z=6.2)# 要求位置参数必须在关键字参数之前传入，位置参数是按位置对应的 函数参数默认值 定义时，在形参后跟上一个值 123456789101112In [6]: def add(x=1,y=5): ...: return x+yIn [7]: callable(add)Out[7]: TrueIn [8]: add()Out[8]: 6In [9]: add(6)Out[9]: 11In [10]: add(6,7)Out[10]: 13In [11]: add(y=8,x=1)Out[11]: 9 作用参数的默认值可以在未传入足够的实参的时候，对没有给定的参数赋值为默认值参数的非常多的时候，并不需要用户每次都输入所有的参数，简化函数调用 123456In [12]: def add(x,y=5): ...: return x+yIn [13]: add(3)Out[13]: 8In [14]: add(3,6)Out[14]: 9 举例定义一个函数login，参数名称为host、port、username、passwd 1234567def login(host='127.0.0.1',port='8080',username='rj',password='test'): print('&#123;&#125;:&#123;&#125;@&#123;&#125;/&#123;&#125;'.format(host,port,username,password))login()login('127.0.0.1',80,'tom','tom')login('127.0.0.1',username='root')login('localhost', port=80,password='com')login(port=80,password='test',host='web') 可变参数 问题有多个数，需要求累加求和 123456789In [15]: def add(nums): ...: sum = 0 ...: for x in nums: ...: sum += x ...: return sumIn [16]: add([1,2,5])Out[16]: 8In [17]: add((2,4,6))Out[17]: 12 可变参数 一个形参可以匹配任意个参数有多个数，需要累加求和 12345678910In [22]: def add(*nums): ...: sum = 0 ...: print(type(nums)) ...: for x in nums: ...: sum += x ...: print(sum) ...:In [23]: add(3,6,9)&lt;class 'tuple'&gt;18 在形参前使用*表示该形参是可变参数，可以接收多个实参;收集的实参名称和值组成一个tuple; 可变参数关键字参数的可变参数 配置信息打印 123456789101112In [9]: def showconfig(**kwargs): ...: for k,v in kwargs.items(): ...: print('&#123;&#125; = &#123;&#125;'.format(k,v)) ...:In [10]:In [10]: showconfig(host='127.0.0.1',port='8080',username='asjin',password='ssjinyao')host = 127.0.0.1port = 8080username = asjinpassword = ssjinyao 形参前使用**符号，表示可以接收多个关键字参数 收集的实参名称和值组成一个字典 混着写，关键的默认定义好，其它的用kwargs 123def showconfig(username, password, **kwargs)def showconfig(username, *args, **kwargs)def showconfig(username, password,**kwargs, *args) 总结 有位置可变参数和关键字可变参数; 位置可变参数在形参前使用一个星号*; 关键字可变参在形参前使用两个星号**; 位置可变参数和关键字可变参数都可以收集若干个实参，位置可变参数收集形成一个tuple，关键字可变参数收集形成一个dict; 混合使用参数的时候，可变参数要放到参数列表的最后，普通参数要放到参数列表前面，位置可变参数需要在关键字可变参数之前。 举例 123456789def fn(x, y, *args, **kwargs): print(x) print(y) print(args) print(kwargs)fn(3, 5, 7, 9, 10,a=1,b='python')fn(3, 5)fn(3, 5, 7)fn(3, 5, a=1,b='python') 举例 123456def fn(*args, x, y, **kwargs) print(x) print(y) print(args) print(kwargs)fn(7, 9, y=5, x=3, a=1, b='python' ) keyword-only 参数 keyword-only 参数(Python3 加入) 如果在一个星号参数后，或者一个位置可变参数后，出现的普通参数，实际上已经不是普通的参数了，而是keyword-only参数 1234def fn(*args, x): print(x) print(args)fn(3, 5, x=7) args 可以看做已经截获了所有的位置参数，x不使用关键字参数就可能拿到实参 keyword-only 参数另一种形式 1234def fn(*, x, y): print(x,y)fn(x=5, y=6) *号之后，普通形参都变成了必须给出的keyword-only参数 可变参数和参数默认值 举例 12345678def fn(*args, x=5): print(x) print(args)fn() # 等价于fn(x=5)fn(5)fn(x=6)fn(1 , 2, 3, x=10) x 是keyword-only 参数 举例 12345678def fn(x=5, **kwargs): print('x=&#123;&#125;'.format(x)) print(kwargs)fn()fn(5)fn(x=6)fn(y=3,x=10)fn(3,y=10) 函数参数 参数规则参数列表参数一般顺序是，普通参数、缺省参数、可变位置参数、keyword-only参数(可带缺省值)、可变关键字参数 1234def fn(x, y, z=3, *arg, m=4, n, **kwargs): print(x, y, z, m,n) print(args) print(kwargs) 1234567def connect(host='localhost',port='3306',user='admin',password='admin',**kwargs): print(host,port) print(user,passowrd) print(kwargs)connect(db='cmdb')connect(host='172.16.0.8',db='cmdb')connect(host='172.160.0.9',db='cmdb',password='mysql') 参数解构举例: 加法函数 12345678910111213def add(x, y): return x+yadd(4, 5)add((4, 5))t = (4, 5)add(t[0], t[1])# add(*t) 或 add(*(4, 5)) add(*[4,5]) add(*&#123;4,6&#125;)# add(*range(1,3))In [1]: def add(x, y): ...: return x+yIn [3]: add((1,2)[0],[3][0])Out[3]: 4 12345678In [8]: def add(x, y): ...: return x+yIn [9]: lst = [1,3]In [10]: add(*lst)Out[10]: 4# 当给定一个集合In [12]: add(*&#123;5,6&#125;)Out[12]: 11 例: 1234567In [28]: def add(*keys): ...: sumnum = 0 ...: for i in keys: ...: sumnum = sumnum + i ...: return sumnumIn [29]: add(*range(1,101))Out[29]: 5050 参数解构 给函数提供实参的时候，可以在集合类型前使用* 或者** , 把集合类型的结构解开，提取所有元素做为函数的实参非字典类型使用*解构成位置参数字典类型使用*解构成位置参数提取出来的元素数王要和参数的要求匹配，也要和参数的类型匹配 12345678def add(x, y): return x+yadd(*(4 ,5)) add(*[4,5])add(*&#123;4,6&#125;)d = &#123;'x': 5, 'y':6&#125;add(**d)add(**&#123;'a':5, 'b':6&#125;) 12345In [39]: def add(x, y): ...: return x+yIn [40]: dct = &#123;'x': 1, 'y':6&#125;In [41]: add(*dct.values())Out[41]: 7 练习编写一个函数，能够接受至少2个参数，返回最小值和最大值。 123456In [49]: def mums(x, y, *args): ...: print(min(x,y,*args)) ...: print(max(x,y,*args))In [50]: mums(*range(1,100001))1100000 方法二 12345678In [51]: import randomIn [52]: def double_values(*nums): ...: print(nums) ...: return max(nums), min(nums)In [53]: print(*double_values(*[random.randint(10,20) for _ in range(10)]))(14, 11, 19, 11, 17, 12, 13, 18, 12, 13)19 11 编写 一个函数，接受一个参数n， n为正整数, 左右两种打印方式, 要求数字必须对齐 12345678910111213141516171819202122232425262728In [59]: def trangle_print(n): ...: for i in range(1, n+1): ...: for j in range(n, 0, -1): ...: if i &lt; j: ...: print(' '*len(str(j)), end=' ') ...: else: ...: print(j, end=' ') ...: print() ...:In [60]: trangle_print(16) 1 2 1 3 2 1 4 3 2 1 5 4 3 2 1 6 5 4 3 2 1 7 6 5 4 3 2 1 8 7 6 5 4 3 2 1 9 8 7 6 5 4 3 2 1 10 9 8 7 6 5 4 3 2 1 11 10 9 8 7 6 5 4 3 2 1 12 11 10 9 8 7 6 5 4 3 2 1 13 12 11 10 9 8 7 6 5 4 3 2 1 14 13 12 11 10 9 8 7 6 5 4 3 2 1 15 14 13 12 11 10 9 8 7 6 5 4 3 2 116 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 方法二 1234567891011121314151617181920212223In [61]: def show(n): ...: tail = " ".join([str(i) for i in range(n,0,-1)]) ...: print(tail) ...: width = len(tail) ...: for i in range(1,n): ...: print("&#123;:&gt;&#123;&#125;&#125;".format(" ".join([str(j) for j in range(i,0,-1)]), width)) ...: print(tail) ...:In [62]: show(12)12 11 10 9 8 7 6 5 4 3 2 1 1 2 1 3 2 1 4 3 2 1 5 4 3 2 1 6 5 4 3 2 1 7 6 5 4 3 2 1 8 7 6 5 4 3 2 1 9 8 7 6 5 4 3 2 1 10 9 8 7 6 5 4 3 2 1 11 10 9 8 7 6 5 4 3 2 112 11 10 9 8 7 6 5 4 3 2 1 123456789101112131415161718192021In [63]: def showtail(n): ...: tail = " ".join([str(i) for i in range(n,0,-1)]) ...: print(tail) ...: for i in range(len(tail)): ...: if tail[i] == ' ': ...: print(' '*i, tail[i+1:]) ...:In [64]: showtail(12)12 11 10 9 8 7 6 5 4 3 2 1 11 10 9 8 7 6 5 4 3 2 1 10 9 8 7 6 5 4 3 2 1 9 8 7 6 5 4 3 2 1 8 7 6 5 4 3 2 1 7 6 5 4 3 2 1 6 5 4 3 2 1 5 4 3 2 1 4 3 2 1 3 2 1 2 1 1 直接插入排序在未排序序列中，构建一个子排序序列，直至全部数据排序完成;将待排序的数，插到已经排序的序列中合适的位置;增加一个哨兵，放入待比较值，让它和后面已经排好的序列比较，找到适合的插入点; 增加一个哨兵位，每轮比较将待比较数入; 哨兵依次和待比较数的前一个数据比较，大数靠右移动，找到哨兵中值的插入位置; 每一轮结束后，得到一个从开始到待比较数位置的一个有序序列 实例 12345678910111213141516171819m_list = [[1, 9, 8, 5, 6, 7, 4, 3, 2 ], [1, 2, 3, 4, 5, 6, 7, 8, 9], [9, 8, 7, 6, 5, 4, 3, 2, 1 ], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2]]nums = [0] + m_list[0]sentinel, *origin = nums #哨兵位，待比较数字count_swap = 0count_iter = 0length = len(nums)for i in range(2,length): #从2开始 nums[0] = nums[i] # 放置哨兵 j = i -1 count_iter +=1 if nums[j] &gt; nums[0]: # 大数右移，找到插入位置 while nums[j] &gt; nums[0]: nums[j+1] = nums[j] # 依次右移 j -= 1 count_swap +=1 nums[j+1] = nums[0] # 将哨兵插入，注意挺好入的右侧要+1print(nums, count_swap, count_iter) 作用域 一个标识符的可见范围，这就是标识符的作用域。一般常说的是变量的作用域 举例，对比左右2个函数 123456In [4]: x = 50In [5]: def show(): ...: print(x)In [7]: show()50 看似是可见的，但尝试以下语句 12345678910111213141516In [8]: x = 5In [9]: def foo(): ...: x += 1 ...: print(x)In [10]: foo()---------------------------------------------------------------------------UnboundLocalError Traceback (most recent call last)&lt;ipython-input-10-c19b6d9633cf&gt; in &lt;module&gt;()----&gt; 1 foo()&lt;ipython-input-9-69a7705e0064&gt; in foo() 1 def foo():----&gt; 2 x += 1 3 print(x) 4UnboundLocalError: local variable 'x' referenced before assignmentIn [11]: 全局作用域在整个程序运行环境中都可见 局部作用域在函数、类等内部可见局部变量使用范围不能超过期所有的局部作用域 12345def fn1(): x = 1 # 局部作用域，在fn1内def fn2(): print(x) print(x) 1234567891011In [16]: def outer(): ...: o = 65 ...: def inner(): ...: print("inner &#123;&#125;".format(o)) ...: print(chr(o)) ...: print("outer &#123;&#125;".format(o)) ...: inner()In [18]: outer()outer 65inner 65A 对比 12345678910111213In [19]: def outer2(): ...: o = 65 ...: def inner(): ...: o = 97 ...: print("inner &#123;&#125;".format(o)) ...: print(chr(o)) ...: print("outer &#123;&#125;".format(o)) ...: inner() ...:In [20]: outer2()outer 65inner 97a 全局变量global 1234x = 5def foo(): global x x += 1 使用global关键字的变量，将foo内的x声明为使用外部的全局作用域定义的x 全局作用域中必须有x的定义 1234567891011x = 100def foo(): global x x = 10 x += 1 print(x)foo()print(x)1111 但是, x=10 赋值即定义， x 在内部作用域为一个外部作用域的变量赋值, 所以x+=1会报错。 注意，这里的x的作用域还是全局的 global 总结 x+=1这种是特珠形式产生的错误的原因？ 先引用后赋值，而python动态语言是赋值才算定义，才能被引用。解决办法，在这条语句前加x=0之类的赋值语句，或者使用global告诉内部作用域，去全局作用域查变量定义 内部作用域作用x =5 之类的赋值语句会重新定义局部作用域使用的变量x，但是，一旦这个作用域中使用global声明x为全局的，那么x=5相当于在为全局作用域的变量x赋值 global的使用原则 外部作用域亦是会内部作用域可见，但也不要在这个内部的局部作用域中直接使用，因为函数的目的就是为了封装，尽量与外界隔离 如果函数需要使用外部全局变量，请使用函数的形参传参解决 闭包 自由变量: 未在本地作用域中定义的变量。例如定义在内存函数外的外层函数作用域中的变量 闭包: 就是一个概念，出现在嵌套函数中，指的内层函数引用到了外层函数的自由变量就形成了闭包。很多语言都有这个概念，最熟悉就是JavaScript 123456789101112131415In [8]: def counter(): ...: c = [0] ...: def inner(): ...: c[0] +=1 ...: return c[0] ...: return innerIn [9]: foo = counter()In [11]: print(type(foo))&lt;class 'function'&gt;In [12]: print(type(foo()))&lt;class 'int'&gt;In [13]: print(foo(),foo())2 3In [15]: print(foo())4]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 集合字典]]></title>
    <url>%2F2020%2F06%2F27%2Fpython_dict%2F</url>
    <content type="text"><![CDATA[python 集合、 字典 集合 基本概念全集：所有元素的集合。例如实数集，所有实数组成的集合就是全集;子集subset和超集superset: 一个集合A所有元素都在另一个集合B是A的真超集;并集: 多个集合合并的结果;交集: 多个集合的公共部分;差集: 集合中除去和其他集合公共部分。 并集将多个集合A和B的所有的元素合并到一起union(*others)返回和多个集合合并后的新的集合运算符重载，等同unionupdate(*others)和多个集合合并，就地修改|=等同update 12345In [8]: a = &#123;1,2,3&#125;In [9]: b = &#123;2,3,4&#125;In [10]: c = b.union(a)In [11]: cOut[11]: &#123;1, 2, 3, 4&#125; 12345In [29]: a = &#123;1,2,3,4&#125;In [30]: b = &#123;2,3,4,5&#125;In [31]: b.update(a)In [32]: bOut[32]: &#123;1, 2, 3, 4, 5&#125; 交集 集合A和B，由所有属于A且属于B的元素组成的集合intersection(*others) 返回和多个集合的交集&amp; 等同insersectionintersection_update(*others)获取和多个集合的交集，并就地修改&amp;=等同intersection_update 123456789In [1]: a=&#123;1,2,3&#125;In [2]: b=&#123;3,4,5&#125;In [3]: c = a &amp; bIn [4]: cOut[4]: &#123;3&#125;Out[7]: &#123;3&#125;In [8]: a.intersection_update(b)In [9]: aOut[9]: &#123;3&#125; 差集集合A和B，是所有属于A且不属于B的元素组成的集合difference(*others)返回和多个集合的差集- 等同differencedifference_update(*others)获取和多个集合的差集并就地修改-=等同difference_update123456789In [10]: a.update(&#123;1,2,3,4,5,6&#125;)In [11]: aOut[11]: &#123;1, 2, 3, 4, 5, 6&#125;In [12]: b.update(&#123;3,4,5&#125;)In [13]: a - bOut[13]: &#123;1, 2, 6&#125;In [15]: a -= bIn [16]: aOut[16]: &#123;1, 2, 6&#125; 对称差集集合A和B，由所有不属于A和B的交集元素组成的集合，记作(A-B)U(B-A)symmetric_differece(other)返回和另一个集合的差集^等同于symmetric_differecesymmetric_differece_update(other)获取和另一个集合的差集并就地修改^=等同于symmetric_differece_update1234567In [17]: a = &#123;1,2,3,4&#125;In [18]: b = &#123;2,3,4&#125;In [19]: a ^ bOut[19]: &#123;1&#125;In [20]: a ^= bIn [21]: aOut[21]: &#123;1&#125; 集合运算issubset(other)、&lt;=判断当前集合是否是另一个集合的子集set1 &lt; set2判断set1是否是set2的真子集issuperset(other)、&gt;=判断当前集合是否是other的超集set1 &gt; set2判断set1是否是set的真超集isdisjoint(other)当前集合和另一个集合没有交集没有交集，返回Ture 1234In [1]: a = &#123;1,2,3&#125;In [2]: b = &#123;1,2,3,4&#125;In [3]: b.issuperset(a)Out[3]: True set 和线性结构 线性结构的查询时间复杂度是O(n),即随着数据规模的增大而增加耗时 set、dict 等结构，内部使用hash值作为key，时间复杂度可以做O(1)，查询时间和数据规模无关 可hash 的数据类型数据型 int、float、complex布尔型 True、False字符串string、bytestupleNone 以上都是不可变类型，成为可哈希类型 ,hashble set 的元素必须是可hash的 简单选择排序 属于选择排序 两两比较在大小，找出极值(极大值或极小值)被放置在固定的位置，这个固定位置一般指的是某一端 结果分为升序和降序列 降序 n 个数从左至右，索引从0开始到n-1，两两依次比较，记录大值过引，此轮所有数比较完比，将大数和索引0数效换，如果大数就是索引1，不交换，第二轮，从1开始比较，找到最大值，将它和过引1位置交换，如果它就在过引1 位置则不交换。今次类推，每次左边都会固定下一个大数。 升序 和降序相反 简单选择排序代码实现(一)1234567891011121314151617181920212223242526272829#!/usr/bin/env python# -*- coding: utf-8 -*-m_list = [ [1,9,8,5,6,7,4,3,2], [1,2,3,4,5,6,7,8,9], [9,8,7,6,5,4,3,2,1]]nums = m_list[1]length = len(nums)print(nums)count_swap = 0count_iter = 0for i in range(length): maxindex = i for j in range(i+1,length): count_iter +=1 if nums[maxindex] &lt; nums[j]: maxindex = j if i != maxindex: tmp = nums[i] nums[i] = nums[maxindex] nums[maxindex] = tmp count_swap +=1print(nums,count_swap,count_iter)[1, 2, 3, 4, 5, 6, 7, 8, 9][9, 8, 7, 6, 5, 4, 3, 2, 1] 4 36 简单选择排序代码实现(二)，二元排序法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#!/usr/bin/env python# -*- coding: utf-8 -*-m_list = [ [1,9,8,5,6,7,4,3,2], [1,2,3,4,5,6,7,8,9], [9,8,7,6,5,4,3,2,1]]nums = m_list[1]length = len(nums)print(nums)count_swap = 0count_iter = 0for i in range(length // 2): maxindex = i minindex = -i -1 minorigin = minindex for j in range(i + 1, length -i): count_iter += 1 if nums[maxindex] &lt; nums[j]: maxindex = j if nums[minindex] &gt; nums[-j -1]: minindex = -j -1 print(maxindex,minindex) if i != maxindex: tmp = nums[i] nums[i] = nums[maxindex] nums[maxindex] = tmp count_swap += 1 if i == minindex or i == length + minindex: minindex = maxindex if minorigin != minindex: tmp = nums[minorigin] nums[minorigin] = nums[minindex] nums[minindex] = tmp count_swap +=1print(nums, count_swap,count_iter)[1, 2, 3, 4, 5, 6, 7, 8, 9]1 -22 -33 -44 -55 -66 -77 -88 -92 -33 -44 -55 -66 -77 -83 -44 -55 -66 -74 -55 -6[9, 8, 7, 6, 5, 4, 3, 2, 1] 8 20 简单选择排序总结 简单选择排序需要数据一轮轮比较，并在每一轮中发现极值 没有办法知道当前轮是否已经达到排序要求，但是可以知道极值是滞在目标索引位置上 遍历次数1,…,n-1之后n(n-1)/2 时间复杂度O(n2次方) 减少了交换次数，提高了效率，性能略好于冒泡法 字典dict可变的、无序的 、key 不重复 字典dict定义 初始化 d = dict() 或者 d={} dict(**kwargs)使用name=value 对初始化一个字典 dcit(iterable,**kwarg) 使用可迭代对象征和name=value对构造字典，不过可迭代对象的元素必须是一个二元结构 d = dict(((1,’a’),(2,’b’))) 或者 d = dict(([1,’a’],[2,’b’])) dict(mapping, ** kwarg)使用一个字典构建另一个字典d = {&#39;a&#39;:10,&#39;b&#39;:20,&#39;c&#39;:None,&#39;d&#39;:[1,2,3]} 例: 常用的变量赋值 123In [1]: d = dict(a=5,b=6,z=[123])In [2]: dOut[2]: &#123;'a': 5, 'b': 6, 'z': [123]&#125; 123In [43]: d = dict(((1,'a'),))In [44]: dOut[44]: &#123;1: 'a'&#125; 123In [45]: d = dict(([1,'a'],[2,'b']))In [46]: dOut[46]: &#123;1: 'a', 2: 'b'&#125; 类方法使用时需要注意 123456789101112131415161718192021222324252627In [47]: d1 = dict.fromkeys(range(1,11),[1,2])In [48]: d1Out[48]:&#123;1: [1, 2], 2: [1, 2], 3: [1, 2], 4: [1, 2], 5: [1, 2], 6: [1, 2], 7: [1, 2], 8: [1, 2], 9: [1, 2], 10: [1, 2]&#125;In [49]: d1[10].append(3)In [50]: d1Out[50]:&#123;1: [1, 2, 3], 2: [1, 2, 3], 3: [1, 2, 3], 4: [1, 2, 3], 5: [1, 2, 3], 6: [1, 2, 3], 7: [1, 2, 3], 8: [1, 2, 3], 9: [1, 2, 3], 10: [1, 2, 3]&#125; 字典元素的访问 d[key]返回key对应的值valuekey 不存在抛出KeyError异常 get(key[,default])返回key对应的值valuekey不存在返回缺省值，如果没有设置缺省值就返回None setdefault(key[,default])返回key对应的值valuekey不存在，添加kv对，value为default，并返回default,如果default没有设置，缺省为None 123456789101112131415161718192021In [51]: d2 = dict(([(1,3,4),&#123;1,2,3,4,5,6&#125;],))In [52]: d2Out[52]: &#123;(1, 3, 4): &#123;1, 2, 3, 4, 5, 6&#125;&#125;In [53]: d2[(1,3,4)]Out[53]: &#123;1, 2, 3, 4, 5, 6&#125;In [54]: f = d2.get((1,3,4))In [55]: fOut[55]: &#123;1, 2, 3, 4, 5, 6&#125;In [56]: type(f)Out[56]: set#如果不存在，则返回In [57]: d2.get(1,50)Out[57]: 50# 如果存在，则返回In [59]: d2.get((1,3,4),50)Out[59]: &#123;1, 2, 3, 4, 5, 6&#125;In [60]: f = d2.setdefault(4,400)In [61]: fOut[61]: 400In [62]: d2Out[62]: &#123;(1, 3, 4): &#123;1, 2, 3, 4, 5, 6&#125;, 4: 400&#125; 字典增加和修改 d[key] = value将key对应的值修改为valuekey 不存在添加新的kv对 update([other]) -&gt; None使用一个字典的kv对更新本字典key不存在，就添加key存在，覆盖已经存在的key对应的值就地修改 123d.upadte(red=1)d.update((('red',2),))d.update(&#123;'red':3&#125;) 123 In [63]: d2[100] = 100In [64]: d2Out[64]: &#123;(1, 3, 4): &#123;1, 2, 3, 4, 5, 6&#125;, 4: 400, 100: 100&#125; 12345678In [67]: d2Out[67]: &#123;(1, 3, 4): &#123;1, 2, 3, 4, 5, 6&#125;, 4: 300, 100: 100&#125;In [68]: d3 = &#123;100:1000, 5:'abc'&#125;In [69]: d3Out[69]: &#123;100: 1000, 5: 'abc'&#125;In [70]: d2.update(d3,red =1)In [71]: d2Out[71]: &#123;(1, 3, 4): &#123;1, 2, 3, 4, 5, 6&#125;, 4: 300, 100: 1000, 5: 'abc', 'red': 1&#125; 字典删除 pop(key[,default])key 存在，移除它，并返回它的valuekey 不存在，返回给定的defaultdefault未设置，key不存在则抛出KeyError异常 popitem()移除并返回一个任意的键值对字典为empty,抛出KeyError异常 clear()清空字典 字典删除del语句 1234567891011121314151617181920In [72]: a = TrueIn [73]: b = [6]In [76]: d = &#123;'a':1,'b':b,'c':[1,3,5]&#125;In [77]: del aIn [78]: a---------------------------------------------------------------------------NameError Traceback (most recent call last)&lt;ipython-input-78-3f786850e387&gt; in &lt;module&gt;()----&gt; 1 aNameError: name 'a' is not definedIn [79]: del d['c']In [80]: dOut[80]: &#123;'a': 1, 'b': [6]&#125;In [81]: del bIn [82]: dOut[82]: &#123;'a': 1, 'b': [6]&#125;In [84]: del d['b']In [85]: dOut[85]: &#123;'a': 1&#125;# del d['b'] 看着像删除了一个对象，本质上减少了一个对象引用，del实际上删除的是名称，而不是对象 字典遍历默认打印的是keys 12345678910In [86]: d2Out[86]: &#123;(1, 3, 4): &#123;1, 2, 3, 4, 5, 6&#125;, 4: 300, 100: 1000, 5: 'abc', 'red': 1&#125;In [87]: for item in d2: ...: print(item) ...:(1, 3, 4)41005red 打印value 和key 12345678910111213141516In [89]: for item in d2.values(): ...: print(item) ...:&#123;1, 2, 3, 4, 5, 6&#125;3001000abc1In [90]: for item in d2.keys(): ...: print(item) ...:(1, 3, 4)41005red 字典解构123456789101112131415161718In [92]: for k,b in d2.items(): ...: print(k,b) ...:(1, 3, 4) &#123;1, 2, 3, 4, 5, 6&#125;4 300100 10005 abcred 1#只取key的情况In [91]: for k,_ in d2.items(): ...: print(k) ...:(1, 3, 4)41005red 总结 Python3 中 ,keys、values、 items()方法返回一个类似一个生器的可迭代对象，不会把函数的反回结果复制到内存中 Python2 中，上面的方法会返回一个新的列表，占据新的内存空间，所以Python2 建议使用iterkeys、itervalues版本，返回一个迭代器，而不是一个copy 标准库datetime datetime模块对日期、时间 、时间戳的处理 datetime类类方法today() 返回本地时区当前时间的datetime对象now(tz=None)返回当前时间的datetime对象，时间到微秒，如果tz为None,返回和today()一样utcnow() 没有时区的当前时间fromtimestamp(timestamp,tz=None)从一个时间戳返回一个datetime对象 datetime对象timestamp()返回一个到微秒的时间戳时间戳:格林威治时间1970年1月1日0点到现在秒数 1234In [2]: datetime.datetime.now()Out[2]: datetime.datetime(2020, 7, 30, 21, 3, 4, 140745)In [3]: datetime.datetime.now().timestamp()Out[3]: 1596114189.706269 标准库datetime构造方法 datetime.datetime(2016,12,6,16,29,43,79043)year、 month、 day、hour、minute、 second、 microsecond，取datetime对象的年月日时分秒及微秒weekday() 返回星期的天，周一0，周日6isoweekday()返回星期的天,周一1，周日7date()返回日期date对象time()返回时间time对象repliace()修改并返回新的时间isocalendar()返回一个三元组(年，周数，周的天) 123456789In [2]: datetime.datetime.now()Out[2]: datetime.datetime(2020, 7, 30, 21, 3, 4, 140745)In [3]: datetime.datetime.now().timestamp()Out[3]: 1596114189.706269In [4]: a = datetime.datetime.now()In [5]: aOut[5]: datetime.datetime(2020, 7, 30, 21, 14, 47, 500215)In [6]: a.weekday()Out[6]: 3 标准库datetime 日期格式化类方法strptime(date_string,format),返回datetime对象对象方法strftime(format),返回字符串字符串format函数格式化 1234In [16]: dt = datetime.datetime.now()In [17]: dt = dt.strftime('%Y-%m-%d-%H-%M-%S')In [18]: dtOut[18]: '2020-07-30-21-21-39' 利用format 格式化 123In [26]: a = datetime.datetime.now()In [27]: '&#123;&#125;-&#123;&#125;-&#123;&#125;-&#123;&#125;-&#123;&#125;-&#123;&#125;'.format(a.year,a.month,a.day,a.hour,a.minute,a.second)Out[27]: '2020-7-30-21-27-33' 标准库datetime timedelta对象datetime2 = datetime1 + timedeltadatetime2 = datetime1 - timedeltatimedelta = datetime1 - datetime2 构造方法 1datetime.timedelta(days=0,seconds=0,microseconds=0,milliseconds=0,minutes=0,hours=0,weeks=0) year = datetime.timedelta(days=365)total_seconds()返回时间差的总秒数 1234567In [36]: hOut[36]: datetime.timedelta(days=1)In [37]: h = datetime.timedelta(hours=24)In [38]: hOut[38]: datetime.timedelta(days=1)In [39]: datetime.datetime.now() - hOut[39]: datetime.datetime(2020, 7, 29, 21, 37, 6, 827493) 标准库time将调用的线程挂起指定的秒数 ~12In [40]: import timeIn [41]: time.sleep(1) 列表解析List 语法[返回值for 元素 in 可迭代对象 if 条件]使用中括号[]，内部是for循环，if条件语句可选返回一个新的列表 列表解析式是一种语法糖编译器会优化，不会为简写而影响效率，反而因优化提交了效率;减少程序员工作量，减少出错;简化了代码，但可读性增强 123In [9]: newlist1 = [(i+1)**2 for i in range(10)]In [10]: newlist1Out[10]: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 举例1、获取10以内的偶数，比较执行效率 12345678910even = []In [11]: even = []In [12]: for x in range(10): ...: if x % 2 == 0: ...: even.append(x)In [13]: evenOut[13]: [0, 2, 4, 6, 8]In [15]: even = [ x for x in range(10) if x%2 ==0]In [16]: evenOut[16]: [0, 2, 4, 6, 8] 举例三种输出结果 123In [19]: list1 = [(i,j)for i in range(7) if i&gt;4 for j in range(20,25) if j&gt;23]In [20]: list1Out[20]: [(5, 24), (6, 24)] 123In [23]: list2 = [(i,j) for i in range(7) for j in range(20,25) if i&gt;4 if j&gt;23]In [24]: list2Out[24]: [(5, 24), (6, 24)] 1234In [28]: list3 = [(i,j) for i in range(7) for j in range(20,25) if i&gt;4 and j&gt;23] ...:In [29]: list3Out[29]: [(5, 24), (6, 24)] 练习，生成1-10 平方的列表 12print([i**2 for i in range(1,11)])[1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 练习，有一个列表lst = [1,4,9,16,2,5,10,15],生成一个新列表，要求新列表元素是lst想领2项的和 123In [34]: lst = [1,4,9,16,2,5,10,15]In [35]: [ lst[i] + lst[i+1] for i in range(len(lst)-1)]Out[35]: [5, 13, 25, 18, 7, 15, 25] 123456789101112In [44]: lst = [1,4,9,16,2,5,10,15]In [45]: for i in range(len(lst)-1): ...: newlist= lst[i] + lst[i+1] ...: print(newlist) ...:513251871525 用一行代码打印9 9乘法表 12345678910In [56]: print('\n'.join([''.join(['&#123;&#125;*&#123;&#125;=&#123;&#125;\t'.format(x,y,y*x) for x in range(1,y+1)]) for y in range(1,10)]))1*1=11*2=2 2*2=41*3=3 2*3=6 3*3=91*4=4 2*4=8 3*4=12 4*4=161*5=5 2*5=10 3*5=15 4*5=20 5*5=251*6=6 2*6=12 3*6=18 4*6=24 5*6=30 6*6=361*7=7 2*7=14 3*7=21 4*7=28 5*7=35 6*7=42 7*7=491*8=8 2*8=16 3*8=24 4*8=32 5*8=40 6*8=48 7*8=56 8*8=641*9=9 2*9=18 3*9=27 4*9=36 5*9=45 6*9=54 7*9=63 8*9=72 9*9=81 高效方法二 12345678910In [86]: print(''.join(['&#123;&#125;*&#123;&#125;=&#123;:&lt;3&#125;&#123;&#125;'.format(j,i,i*j,'\n' if i==j else'') for i in range(1,10) for j in range(1,i+1)]))1*1=11*2=2 2*2=41*3=3 2*3=6 3*3=91*4=4 2*4=8 3*4=12 4*4=161*5=5 2*5=10 3*5=15 4*5=20 5*5=251*6=6 2*6=12 3*6=18 4*6=24 5*6=30 6*6=361*7=7 2*7=14 3*7=21 4*7=28 5*7=35 6*7=42 7*7=491*8=8 2*8=16 3*8=24 4*8=32 5*8=40 6*8=48 7*8=56 8*8=641*9=9 2*9=18 3*9=27 4*9=36 5*9=45 6*9=54 7*9=63 8*9=72 9*9=81 练习 “0001.abadicddws” 是ID格式，要求ID格式是以点号分割， 左夯实是4位从1开始的整数，右边是10位随机小写英文字母。今次生成前100个列表 1234567In [100]: ['&#123;:04&#125;.&#123;&#125;'.format(n,''.join([random.choice(bytes(range(97,123)).decode()) for _ in range(10)])) for n in range(1,101)]Out[100]:['0001.yibbcfebfn', '0002.wvomuwuiaj', '0003.bplvnhkgfp', '0004.tnrjwiuipv',... 生成器表达式(Generator expression) 语法(返回值for 元素 in 可迭代对象if条件)列表解析式的中括号抱成小括号就行了返回一个生成器 和列表解析式的区别生成器表达式是按按需计算(或称惰性求值、延迟计算)，需要的时候才计算值列表解析式是立即返回值 生成器 可迭代对象 迭代器 生成器表达式 和列表解析式的对比计算方式生成器表达式延迟计算，列表解析式立即计算 内存占用单从返回值本身来说，生成器表达式省内存，列表解析式返回新的列表生成器没有数据，内存占用少，但是使用的时候，虽然一个个返回数据，但是合起来占用的内存也差不多列表解析式构造新的列表需要占用内存 计算速度单看计算时间看，生成器表达式耗时非常短，列表解析式耗时长但是生成器本身并没有返回任何值，只返回了一个生成器对象列表解析式构造并返回了一个新的列表 集合解析式 语法(返回值 for 元素 in 可迭代对象 if 条件)列表解析式的中括号换成大括号{}就行了立即返回一个集合 用法 12&#123;(x,x+1) for x in range(10)&#125;&#123;&#123;x&#125; for x in range(10)&#125; 字典解析式 语法(返回值 for 元素in可迭代对象if条件)列表解析式的中括号换成大括号{}就可行了使用key:value 形势立即返回一个字典 用法 123456&#123;x:(x,x+1) for x in range(10)&#125;&#123;x:[x,x+1] for x in range(10)&#125;&#123;(x,):[x,x+1] for x in range(10)&#125;&#123;[x]:[x,x+1] for x in range(10)&#125;&#123;chr(0x41+1):x**2 for x in range(10)&#125;&#123;str(x):y for x in range(3) for y in range(4)&#125; 12In [3]: &#123;chr(0x41+x):x**2 for x in range(5)&#125;Out[3]: &#123;'A': 0, 'B': 1, 'C': 4, 'D': 9, 'E': 16&#125; 12345678910In [4]: &#123;str(x):y for x in range(3) for y in range(4)&#125;Out[4]: &#123;'0': 3, '1': 3, '2': 3&#125;# 等价于In [13]: ret = &#123;&#125;In [14]: for x in range(3): ...: for y in range(4): ...: ret[str(x)] = y ...:In [15]: print(ret)&#123;'0': 3, '1': 3, '2': 3&#125; 总结 Python2 引入了列表解析式 Python2.4引入了生成器表达式 Python3 引入集合、字典解析式，并迁移到了2.7 一般来说，应该多应用解析式，简短、高效 如果一个解析式非常复杂，难以读懂，要考虑拆解成for循环 生成器和迭代器是不同的对象，但都是可迭代对象。 内建函数 标识 id返回对象的唯一标识，CPython 返回内存中 类型hash() 返回一个对象的哈希值 类型type() 返回对象的类型 类型转换 float() int() bin() hex() oct() bool() list() tuple() dict() set() complex() bytes() bytearray() 输入input([prompt]) 接收用户输入，返回一个字符串 打印 print(*objects, sep=’’,end=’\n’,file=sys.stdout, flush=False) 打印输出，默认使用空格分割、换行结尾，输出到控制台 对象长度len(s) 返回一个集合类型的元素个数 isinstance(obj,class_or_tuple) 判断对象obj是否属于某种类型或者元组中列出的某个类型isinstance(True,init) issubclass(cls,calss_or_tuple) 判断类型cls是否是某种类型的了类或元组中列出的某个类型的子类issubclass(bool,int) 绝对值abs(x) x 为数值 最大值max() 最小值min() 返回可迭代对象中最大或最小值 返回多个参数中最大或最小值 round(x) 四舍六入五取偶, round(-0.5) pow(x,y) 等价于x**y range(stop)从0开始到stop-1 的可迭代对象； range(start,stop,[,step]) 从start开始到stop-1 结束步长为step 的可迭代对象 divmod(x,y) 等价于tuple(x//y,x%y) sum(oterable[,start])对可迭代对象的所有数值元素求和sum(range(1,100,2)) 补充列表全部拷贝1234In [17]: lst = [1,2,3]In [18]: test = lst[:]In [19]: testOut[19]: [1, 2, 3] python 求一到100的和 12In [20]: sum(range(1,101))Out[20]: 5050 chr(i) 给一个一定范围的整数返回对应的字符chr(97) chr(20013) ord(c) 返回字符对应的整数 ord(‘a’) ord(‘中’) str() 、 repr()、 ascii() sorted(iterable) sorted(iterable[,key][,reverse])排序返回一个新的列表，默认升序reverse 是反转 123sorted([1,3,5])sorted([1,3,5], reverse=True)sorted(&#123;'c':1, 'b':2, 'a':1&#125;) 12345In [5]: lst = [1,4,3,5,8,7]In [6]: sorted(lst)Out[6]: [1, 3, 4, 5, 7, 8]In [7]: sorted(lst,reverse=True)Out[7]: [8, 7, 5, 4, 3, 1] 翻转 reversed(seq)返回一个翻转元素的迭代器 12list(reversed(*13579*))for x in reversed(["c","b","c"]: ) 1234In [13]: for k,v in enumerate(range(5)): ...: print(k,v,end='\t') ...:0 0 1 1 2 2 3 3 4 4 1234In [14]: for k,v in enumerate("mnopq",start=10): ...: print(k,v,end='\t') ...:10 m 11 n 12 o 13 p 14 q 迭代器和取元素iter(terable)、next(iterator)iter 将一个可迭代对象封装成一个迭代器next对一个迭代器取下一个元素。如果全部元素都取过了，再次next会抛StopIteration异常 1234it = iter(range(5))nex(it)it = reversed([1, 3, 5])next(it) 可迭代对象能够通过迭代一次次返回不同的元素的对象。所谓相同不是指值是否相同。而元素在容器中是否是同一个，例如列表中值可以重复。可以迭代，但是未必有序，未必可索引。可迭代对象有: list、tuple、string、bytes、bytearray、range、set、dict、生成器等；可以使用成员操作符in 、 not in，in本质上就是在遍历对象； 1233 in range(10)3 in (x for x in range(10))3 in &#123;x:y for x,y in zip(range(4),range(4,10))&#125; 迭代器特殊的对象，一定是可迭代对象，具备可迭代对象的特征;通过iter方法把一个可迭代对象封闭成迭代器;通过next 方法, 迭代 迭代器对象；生成器对象，就是迭代器对象 12345678910111213In [1]: for x in iter(range(10)): ...: print(x)In [3]: g = (x for x in range(10))In [4]: print(type(g))&lt;class 'generator'&gt;In [5]: print(next(g))0In [6]: print(next(g))1In [7]: print(next(g))2In [8]: print(next(g))3 拉链函数zip(*iterables) 像拉链一样，把多个可迭代对象合并在一起，返回一个迭代器将每次从不同对象中取到的元素合并成一个元组 1234list(zip(range(10),range(10)))list(zip(range(10),range(10),range(5),range(10)))dict(zip(range(10),range(10)))&#123;str(x):y for x,y in zip(range(10),range(10))&#125; 字典练习打印每一位数字及期重复的次数 12345678910while True: num = input('Please input a positice intteger &gt;&gt;').strip() if num.isdigit(): break else: print('Only digits are allowed! ')record = &#123;&#125;for i in num: record[i] = record.get(i,0) +1print(num,record,sep='\n') 方法二 123456789101112131415161718192021#!/usr/bin/env python# -*- coding: utf-8 -*-num = input('&gt;&gt; ')d = &#123;&#125;for c in num: if not d.get(c): d[c] = 1 continue d[c] +=1print(d)d = &#123;&#125;for c in num: if c not in d.keys(): d[c] =1 else: d[c] += 1print(d)&gt;&gt; 18933&#123;'1': 1, '8': 1, '9': 1, '3': 2&#125;&#123;'1': 1, '8': 1, '9': 1, '3': 2&#125; 字符串重复统计 字符表’abcdefghijklmnopqrstuvwxyz’随机挑选2个字母组成字符串，共挑选100个降序输出这100个字符串及重复的次数 123456789101112131415import randomimport stringstrs = 'abcdefghijklmnopqrstuvwxyz'dic = &#123;&#125;for _ in range(100): randstr = ''.join(random.sample(strs,2)) # randstr = ''.join(random.choice(strs) for _ in range(0,2)) # randstr = ''.join(random.sample(string.ascii_lowercase,2)) if randstr not in dic: dic.setdefault(randstr,1) else: dic[randstr] +=1sortstr = sorted(dic.keys())for i in sortstr: print('&#123;:&lt;4&#125; &#123;:&lt;4&#125;'.format(i,dic[i]))]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双网卡team 绑定实践记录]]></title>
    <url>%2F2020%2F06%2F17%2Fteam%20%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[双网卡team 绑定 很多时候，由于生产环境业务的特殊需求，我们需要对服务器的物理网卡实施特殊的配置，从而来满足不同业务场景下对服务器网络的特殊性要求。如高并发的网络IO型业务，需要高速的网络IO，即对网卡的收收发包处理能力及网卡最大带宽速度等性能指标提出了更高的要求；事务处理型的系统，如金融交易系统、电商平台等，对物理网络线路、网卡等物理设备的稳定可靠性提出了更高的要求。Linux系统中，可以通过多网卡绑定（bonding）和网络组（team）等技术，通过软件的方式来实现，来满足不同业务场景下的各种特殊需求。 用于kvm虚拟化环境的team绑定实例配置team112345678# vim /etc/sysconfig/network-scripts/ifcfg-team1DEVICE=team1BOOTPROTO=noneNAME=team1ONBOOT=yesDEVICETYPE=TeamBRIDGE="br-ext"TEAM_CONFIG='&#123;"runner": &#123;"name": "loadbalance"&#125;, "link_watch": &#123;"name": "ethtool"&#125;&#125;' bridge 配置注意生产的br-ext 的ip网段 和 测试的br-ext的ip网段 不是同一个网段 12345678910111213# vim /etc/sysconfig/network-scripts/ifcfg-br-extDEVICE="br-ext"ONBOOT="yes"TYPE="Bridge"BOOTPROTO="none"IPADDR="172.30.x.xx"NETMASK="255.255.192.0"#GATEWAY="172.30.x.x"IPV6INIT="yes"IPV6_AUTOCONF="yes"DHCPV6C="no"STP="on"DELAY="0" em2 配置1234567# vim /etc/sysconfig/network-scripts/ifcfg-em2TYPE=EthernetNAME=em2DEVICE=em2ONBOOT=yesTEAM_MASTER=team1DEVICETYPE=TeamPort em3 配置1234567# vim /etc/sysconfig/network-scripts/ifcfg-em3TYPE=EthernetNAME=em3DEVICE=em3ONBOOT=yesTEAM_MASTER=team1DEVICETYPE=TeamPort systctl 配置1234567# vim /etc/sysctl.confnet.ipv4.conf.em1.rp_filter = 0net.ipv4.conf.em2.rp_filter = 0net.ipv4.conf.em3.rp_filter = 0net.ipv4.conf.all.rp_filter = 0net.ipv4.conf.br-ext.rp_filter = 0net.ipv4.conf.team1.rp_filter = 0 rp_filter 简要说明 0:表示不开启源检测; 1:严格模式，根据数据包的源，通过查FIB表(Forward Information Table,可以理解为路由表)，检查数据包进入端口是同时也是出端口，以视为最佳路径，如果不符合最佳路径，则丢弃数据包; 2:松散模式,检查数据包的来源，查FIB表，如果通过任意端口都无法到达此源，则丢包。 启动并测试 123456# ifdown br-ext &amp;&amp; ifdown team1# ifup team1# ifup br-ext# ifdown em2 ; ifup em2# ifdown em3 ; ifup em3# sysctl -p]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 企业微信-微信信息发送]]></title>
    <url>%2F2020%2F05%2F13%2Fpython%20%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1-%E5%BE%AE%E4%BF%A1%E4%BF%A1%E6%81%AF%E5%8F%91%E9%80%81%2F</url>
    <content type="text"><![CDATA[python 企业微信-微信信息发送 主要用到的模块 urllib,json,simplejson,requests,bs4 urllib: urllib的request模块可以非常方便地抓取URL内容，也就是发送一个GET请求到指定的页面，然后返回HTTP的响应; json: JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式。易于人阅读和编写。同时也易于机器解析和生成; simplesjon: simplejson 是 json 标准模块的扩展（基础功能相同），是 pypi 提供的拓展模块，需要另行安装。不过可以使用 python 自带的 json 库，基本是相同的使用方法(提供的接口功能基本一致)。在 python 的 library 文档中将 JSON 归为网络数据控制类，很好的说明了他们的用途，主要用于网络数据控制，编解码等。但是也具有其他的用途，比如可以用来作为配置文件的读写模块，简单的文件操作等; requests: python HTTP库，一般用于爬虫; Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序; 创建企业微信用应用注: 这里我使用的是个人注册的企业微信，因为需要管理员的权限 用企业微信管理员登录后，我们可以新建一个应用程序用于送通知信息 我这里已经新建好了专用应用，点进去后添加可见应用的人。也就是所谓的应用授权。 在这里要记录下 Agentid 和 Secert 用于发送通时的认证口令 点击我的企业 –&gt;企业信息 ，在这里可以看到企业ID, 也用于代码中配置的通知id用 好了，这时候我们就可以开始写代码了，在此，我要发送的信息是天气信息，每日金句，和通知专项等信息 第三方网站、接口中国天气网 天气信息在这里我选择的是大同的天气页面 一言接口一言接口使用文档 接口信息如下 python 爬取天气–&gt;调用一言接口–&gt;专项通知代码实现登录个人服务器，source python3 环境 12~]# alias mp3='source ~/mypython/py3_env/bin/activate &amp;&amp; cd ~/mypython/python3'~]# mp3 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186#!/usr/bin/env python3# -*- coding: utf-8 -*-import urllibimport urllib.request as urllib2import jsonimport sysimport simplejsonimport requestsfrom bs4 import BeautifulSoup# reload(sys)# sys.setdefaultencoding('utf-8')def gettoken(corpid,corpsecret): gettoken_url = 'https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=' + corpid + '&amp;corpsecret=' + corpsecret print(gettoken_url) try: token_file = urllib2.urlopen(gettoken_url) except urllib2.HTTPError as e: print(e.code) print(e.read().decode("utf8")) sys.exit() token_data = token_file.read().decode('utf-8') token_json = json.loads(token_data) token_json.keys() token = token_json['access_token'] return tokendef senddata(access_token,user,subject,content): send_url = 'https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=' + access_token send_values = &#123; "touser": user, #企业号中的用户帐号，如果配置不正常，将按部门发送。 "toparty":"2", #企业号中的部门id。 "msgtype":"text", #消息类型。 "agentid":"100xxxxx", #企业号中的应用id。 "text":&#123; "content":subject + '\n' + content &#125;, "safe":"0" &#125;# send_data = json.dumps(send_values, ensure_ascii=False) send_data = simplejson.dumps(send_values, ensure_ascii=False).encode('utf-8') send_request = urllib2.Request(send_url, send_data) response = json.loads(urllib2.urlopen(send_request).read()) print(str(response)) def get_tianqi(url, data=None): # 用来获取天气网页信息 try: r = requests.get(url,timeout=30) r.raise_for_status() r.encoding = r.apparent_encoding return r.text except: return '产生异常'def get_qitian_data(html,city): # 处理网页信息提取近七天的情况 tianqi_list = [] soup = BeautifulSoup(html, 'html.parser') body = soup.body data = body.find('div',&#123;'id': '7d'&#125;) ul = data.find('ul') list1 = ul.find_all('li') for day in list1: temp_list = [city] date = day.find('h1').string temp_list.append(date) info = day.find_all('p') temp_list.append(info[0].string) if info[1].find('span') is None: temperature_highest = ' ' else: temperature_highest = info[1].find('span').string if info[1].find('i') is None: temperature_lowest = ' ' else: temperature_lowest = info[1].find('i').string temp_list.append(temperature_highest) temp_list.append(temperature_lowest) wind_scale = info[2].find('i').string temp_list.append(wind_scale) tianqi_list.append(temp_list) return tianqi_listdef save_tianqi_data(data,filename): # 将近七天的天气信息存放在文件中 f=open(filename,"wt") for line in data: f.write(str(line)+'\n') f.close()def get_hitokoto(get_url): f = requests.get(get_url) hitokoto_message = f.json() hitokoto_message_data = '嗨: ' + hitokoto_message['hitokoto'] hitokoto_message_data = hitokoto_message_data.replace("，","，\n").replace(",",",\n") hitokoto_message_from = '来自: ' + hitokoto_message['from'] return [hitokoto_message_data,hitokoto_message_from]def postrsg(filename,get_url,zhuanxiang_file): #取出信息并且用机器人发消息 hitokoto_memssage_print = get_hitokoto(get_url) with open(filename,'r') as f: lines = f.readlines() first = lines[0].rstrip("\n") first = first.replace("['",'').replace("']",'').replace("'","").replace("（今天）","") first1 = first.split(',',2)[0:2] str_first1 = "".join(first1).replace(" ","") first2 = first.split(',',2)[-1] str_first2 = "".join(first2).replace(" ","") sec = lines[1].rstrip("\n") sec = sec.replace("['",'').replace("']",'').replace("'","").replace("（明天）","") sec1 = sec.split(',',2)[0:2] str_sec1 = "".join(sec1).replace(" ","") sec2 = sec.split(',',2)[-1] str_sec2 = "".join(sec2).replace(" ","") with open(zhuanxiang_file,'r') as f: zhuanxiang_data = f.readlines() zhuanxiang_data = "".join(zhuanxiang_data) # tianqi_head = '天津天气信息' # formate_box = '☀️' * 12 + '\n' # formate_head = '&#123;:&lt;1&#125;&#123;:^36&#125;&#123;:&gt;1&#125;'.format('☀️' * 1, tianqi_head, '☀️' * 1) + '\n' # formate_first = '&#123;:&lt;1&#125;&#123;:^36&#125;&#123;:&gt;1&#125;'.format('' * 1, str_first1, '' * 1) + '\n' # formae_sec = '&#123;:&lt;2&#125;&#123;:^26&#125;&#123;:&gt;2&#125;'.format('*' * 2, str_first2, '*' * 2) + '\n' # formate_box_end = '*' * 30 if '晴' in str_first2: weather = '☀️' elif '雨' in str_first2: weather = '☂' elif '雪' in str_first2: weather = '❄️' elif '云' in str_first2: weather = '⛅️' elif '阴' in str_first2: weather = '🌑' else: weather = '*' if '晴' in str_sec2: weather_2 = '☀️' elif '雨' in str_sec2: weather_2 = '☂' elif '雪' in str_sec2: weather_2 = '❄️' elif '云' in str_first2: weather_2 = '⛅️' elif '阴' in str_first2: weather_2 = '🌑' else: weather_2 = '*' message_subject = '''&lt;-----------任锦专用----------&gt;''' message_content = '''&lt;-----------今日天气----------&gt; &#123;&#125; *&#123;&#125;&lt;-----------明日天气----------&gt; &#123;&#125; #&#123;&#125;&lt;-----------每日金句----------&gt; &#123;&#125; &#123;&#125;&lt;-----------提示专项----------&gt; &#123;&#125; '''.format(str_first1, str_first2, str_sec1, str_sec2, hitokoto_memssage_print[0], hitokoto_memssage_print[1], zhuanxiang_data).replace('*', weather).replace('#', weather_2) return [message_subject,message_content]if __name__ == '__main__': zhuanxiang_file = '/var/www/liuxxxx/liuxxxx_put.txt' tianqi_url = 'http://www.weather.com.cn/weather/101100201.shtml' html = get_tianqi(tianqi_url) result = get_qitian_data(html, '山西: 大同') filename = './liuxxxx.message' save_tianqi_data(result, filename) get_url = 'https://v1.hitokoto.cn/' postrsg_message = postrsg(filename,get_url,zhuanxiang_file) user = str('RenJin') subject = str(postrsg_message[0]) # 发送的标题信息 content = str(postrsg_message[1]) # 发送的主体信息 corpid = 'ww3xxxxxxxxxxxxxxxxx' #企业号的id corpsecret = 'OF-nuSt6xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' #管理组凭证密钥 accesstoken = gettoken(corpid,corpsecret) senddata(accesstoken,user,subject,content) 这个时候执行就可以在企业微信上收到信息了 企业微信能收到通知后，可以测试一下微信端的收信 在此补充一下，如果想在微信端收到通知信息，在收信息的人关注微信号就可以了 在企业微信页面点击我的企业 –&gt; 微信插件 –&gt; 邀请关注 关注后，再发送就会收到如下信息 专项通知实现进入nginx 站点根目录，这里需要有nginx环境 1~]# cd /var/www/liuxxxx/ html web输入框1234567891011121314151617&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;刘xxxx提示专项&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="./index.php" method="post"&gt; 提示内容1: &lt;input style="width:150px; height:50px;color:8B0000" type="text" name="ts1"&gt;&lt;br&gt; &lt;br&gt; 提示内容2: &lt;input style="width:150px; height:50px;color:8B000" type="text" name="ts2"&gt;&lt;br&gt; &lt;br&gt; 提示内容3: &lt;input style="width:150px; height:50px;color:1F099" type="text" name="ts3"&gt;&lt;br&gt; &lt;br&gt; &lt;input style="width:90px; height:50px;float:160px;color:8B0012" type="submit" value="本玲确认提交"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; php 提醒并写入文件1234567891011121314&lt;h1&gt; 写入新提示计划&lt;/h1&gt;提示通知1的内容是 &lt;?php echo $_POST["ts1"];?&gt;&lt;br&gt;提示通知2的内容是 &lt;?php echo $_POST["ts2"];?&gt;&lt;br&gt;提示通知3的内容是 &lt;?php echo $_POST["ts3"];?&gt;&lt;br&gt;&lt;h1&gt; 清空了旧提示计划&lt;/h1&gt;&lt;?php echo '清空id'; file_put_contents('liuxxxx_put.txt', ""); $file = fopen("liuxxxx_put.txt","w+"); echo fwrite($file,$_POST["ts1"]."\n"); echo fwrite($file," ".$_POST["ts2"]."\n"); echo fwrite($file," ".$_POST["ts3"]);fclose($file);?&gt; 编辑现有的nginx虚拟主机12345678910111213141516171819location /liuxxxx &#123; auth_basic "Auth Base For Liuxxxx"; # auth_basic_user_file /etc/nginx/conf.d/ssjinyao.db; # 这里用htpasswd 写了一个用户和密码保存在 ssjinyao.db 中 #error_page 405 =200 $uri; alias /var/www/liuxxxx; index index index.htm index.html php index.php; location ~ /liuxxxx/(.*)\.php(.*)$ &#123; #default_type text/html; #add_header Content-Type 'text/html; charset=utf-8'; #return 200 "$document_root , $fastcgi_script_name"; alias /var/www; fastcgi_split_path_info ^(.+\.php)(.*)$; #fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125;&#125; nginx 生效后，访问并页面写入专项通知 加入定时任务计划10 7,12 * * * source /root/mypython/py3_env/bin/activate &amp;&amp; cd /root/mypython/python3 &amp;&amp; python liuxxx.py 最后的效果 其它说明，这个python脚本可以把收信息的变量改为位置变量做zabbix prometehus 报警通知来用]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python表格操作]]></title>
    <url>%2F2020%2F04%2F22%2Fpython%20excel%E8%A1%A8%E6%A0%BC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[python 表格操作将awk生成的数据导入表格pandas ：pannel data analysis（面板数据分析）。pandas是基于numpy构建的，为时间序列分析提供了很好的支持。pandas中有两个主要的数据结构，一个是Series，另一个是DataFrame。 Series 类似于一维数组与字典(map)数据结构的结合。它由一组数据和一组与数据相对应的数据标签（索引index）组成。这组数据和索引标签的基础都是一个一维ndarray数组。可将index索引理解为行索引。 Series的表现形式为：索引在左，数据在右。 DataFrame是一个类似表格的数据结构，索引包括列索引和行索引，包含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。DataFrame的每一行和每一列都是一个Series，这个Series的name属性为当前的行索引名/列索引名。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161#!/usr/bin/env python# -*- coding: utf-8 -*-import openpyxl as xlimport pandas as pdimport numpy as npimport osimport datetimecycle=38time_year_month_day = str(datetime.date.today()-datetime.timedelta(days=cycle))def proj_xls_to_xlsx(file_path,sheet_name,save_name,tableTitle=None): with open(file_path) as f: data = f.readlines() if not os.path.exists(save_name): wb = xl.Workbook() wb.save(save_name) else: wb = xl.load_workbook(save_name) ws1 = wb.create_sheet(0) ws1.title = sheet_name if tableTitle != None: for n in range(len(tableTitle)): c = n + 1 ws1.cell(row=1, column=c).value = tableTitle[n] for d in data: value = d.split('\t') try: # print(value) value[5]=float(value[5]) except: pass ws1.append(value) wb.save(save_name)def crate_shuju_toushi(save_name,sheet_name,sheet_name2,index_name,values_name,department_name,new_department_name,personnel_name): f = pd.read_excel(io=save_name,sheet_name=sheet_name) res = pd.pivot_table(f,index=[index_name],values=[values_name],aggfunc=np.sum, margins=True) wb = xl.load_workbook(save_name) old_title = wb.worksheets[0] old_title.title = sheet_name2 all_xinxi_title=list(zip(list((res.index)),list(res[values_name]))) department_personnel = list(zip(f[department_name],f[index_name])) department_personnel_size_list = [] for user in all_xinxi_title: for department_personnel_list in department_personnel: if user[0] in department_personnel_list: if user[0] == '-': continue if user[0] == ' ': continue department_personnel_size_list.append((department_personnel_list[0],user[0],user[1])) end_department_personnel_size_list = sorted(list(set(department_personnel_size_list)), key=lambda x:x[2] ,reverse=True) all_xinxi_title_end = all_xinxi_title[-1] all_xinxi_title_end = list(all_xinxi_title_end) all_xinxi_title_end.insert(0,'') end_department_personnel_size_list.append(all_xinxi_title_end) end_department_personnel_size_list.insert(0,[new_department_name,personnel_name,values_name]) end_department_personnel_size_list.pop() user_volue = [] for user2 in end_department_personnel_size_list: user2 = list(user2) if user2[1] == user_volue: continue user_volue = user2[1] old_title.append(user2) wb.save(save_name)def create_space_toushi(save_name,sheet_name,sheet_name2,department_num,sum_name,data_total,index_name,values_name): f = pd.read_excel(io=save_name,sheet_name=sheet_name,dtype=&#123;'业务XX利润编号':str&#125;) res = pd.pivot_table(f,index=index_name,values=values_name,aggfunc=np.sum,margins=True) all_list = list(zip(list(res.index),list(res[values_name]))) wb = xl.load_workbook(save_name) sheet = wb.create_sheet(sheet_name2) space_list = [] for user in all_list: user2 = list(user)[1] user3 = list(list(user)[0]) if user3[0] == '-': space_list.append((user3[1],user2)) if user3[0] == ' ': space_list.append((user3[1],user2)) sum_list = [] for slist in space_list: sum_list.append(slist[1]) sum_list=sum(sum_list) sort_space_list = sorted(list(set(space_list)), key=lambda x:x[1] ,reverse=True) sort_space_list.append((sum_name, sum_list)) sort_space_list.insert(0,(department_num,data_total)) for all_space_list in sort_space_list: sheet.append(all_space_list) wb.save(save_name) if __name__=='__main__': sheet_name = 'XXX详情' save_name = 'TJ-XJ-DATASHOW-' + time_year_month_day + '.xlsx' save_name = 'TJ-XJ-DATASHOW-' + time_year_month_day + '.xlsx' file_path = './able.' + time_year_month_day +'.lib.xls' proj_xls_to_xlsx(file_path=file_path, sheet_name=sheet_name, save_name=save_name) sheet_name = 'XXX总体情况' save_name = 'TJ-XJ-DATASHOW-' + time_year_month_day + '.xlsx' file_path = './' + time_year_month_day + '.ProjInfo.XJpath.xls' table_title = ['业务XX名称','业务XX利润编号', '运营经理','信息分析','涉及项目数', '涉及数据量大小（G）','项目编号1', '项目名称1','数据量(G)1', '文库编号1','项目编号2', '项目名称2','数据量(G)2', '文库编号2','项目编号3', '项目名称3','数据量(G)3', '文库编号3','项目编号4', '项目名称4 数据量(G)4','文库编号4',] proj_xls_to_xlsx(file_path=file_path, sheet_name=sheet_name, tableTitle=table_title, save_name=save_name) save_name = 'TJ-XJ-DATASHOW-' + time_year_month_day + '.xlsx' sheet_name = 'XXX总体情况' sheet_name2 = 'XXX概况' index_name = '信息分析' values_name = '涉及数据量大小（G）' department_name = '业务XX名称' new_department_name = 'XX' personnel_name = '人员' crate_shuju_toushi(save_name=save_name, sheet_name=sheet_name, sheet_name2=sheet_name2, index_name=index_name, values_name=values_name, department_name=department_name, new_department_name=new_department_name, personnel_name=personnel_name) index_name = ['信息分析','业务XX利润编号'] save_name = 'TJ-XJ-DATASHOW-' + time_year_month_day + '.xlsx' sheet_name = 'XXX总体情况' department_num = 'XX编号' data_total = '数据量（G）' values_name = '涉及数据量大小（G）' sheet_name2 = '未匹配人员数据量' sum_name = 'ALL' create_space_toushi(index_name=index_name, save_name=save_name, sheet_name=sheet_name, department_num=department_num, data_total=data_total, values_name=values_name, sheet_name2=sheet_name2, sum_name=sum_name,) 完成数据透视,1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#!/usr/bin/env python# -*- coding: utf-8 -*-import pandas as pdimport openpyxl as xlimport datetimedifference_cycle=33time_year_month_day = str(datetime.date.today()-datetime.timedelta(days=difference_cycle))def add_last_excel(old_sheet,new_sheet,gaikuang): pd01 = pd.read_excel(old_sheet,sheet_name=gaikuang,encoding='utf-8') pd02 = pd.read_excel(new_sheet,sheet_name=gaikuang,encoding='utf-8') pd11 = pd.read_excel(old_sheet,sheet_name='未匹配人员数据量',encoding='utf-8') pd12 = pd.read_excel(new_sheet,sheet_name='未匹配人员数据量',encoding='utf-8') result = pd.merge(pd01,pd02[['人员','涉及数据量大小（G）']],on='人员') result_list = list(zip(list((result['XXX'])),list((result['人员'])),list((result['涉及数据量大小（G）_x'])),list((result['涉及数据量大小（G）_y'])))) not_match = pd.merge(pd11,pd12[['XXX编号','数据量（G）']],left_on='XXX编号',right_on='XXX编号') print(not_match) not_match_list = list(zip(list((not_match['XXX编号'])),list((not_match['数据量（G）_x'])),list((not_match['数据量（G）_y'])))) wb2 = xl.load_workbook(new_sheet) remove_sheet1 = wb2[gaikuang] remove_sheet2 = wb2['未匹配人员数据量'] wb2.remove(remove_sheet1) wb2.remove(remove_sheet2) wb2.save(new_sheet) wb2 = xl.load_workbook(new_sheet) sheet21 = wb2.create_sheet(gaikuang,0) sheet22 = wb2.create_sheet('未匹配人员数据量') result_head = ['XXX','人员','涉及数据量（G）','第二次涉及数据量（G）','任务额差'] result_list.insert(0,result_head) result_for_num = 1 for i in result_list: result_i = list(i) if result_for_num != 1: result_chae=i[2]-i[3]-i[2]*0.2 result_i.append(float('%.2f'% result_chae)) result_for_num = result_for_num + 1 sheet21.append(result_i) not_match_head = ['XXX编号','数据量（G）','第二次数据量（G）','任务额差'] not_match_list.insert(0,not_match_head) not_match_for_num = 1 for j in not_match_list: not_match_j = list(j) if not_match_for_num != 1: not_match_chae=j[1]-j[2]-j[1]*0.2 not_match_j.append(float('%.2f'% not_match_chae)) not_match_for_num = not_match_for_num + 1 sheet22.append(not_match_j) wb2.save(new_sheet)if __name__ == '__main__': old_sheet='TJ-XJ-DATASHOW-' + time_year_month_day + '-old.xlsx' new_sheet='TJ-XJ-DATASHOW-' + time_year_month_day + '.xlsx' gaikuang='XXX概况' add_last_excel(old_sheet=old_sheet,new_sheet=new_sheet,gaikuang=gaikuang)]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高可用gitlab服务器搭建]]></title>
    <url>%2F2020%2F03%2F26%2F%E9%AB%98%E5%8F%AF%E7%94%A8gitlab%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[高可用gitlab服务器搭建 环境准备,单节点部署 CentOS7.4 64C 192G CentOS7.4 64C 192G 服务器时间同步1~]# ntpdate ntp.aliyun.com 确保SELinux 是关闭的12~]# getenforce Disabled 配置postfix1234~]# yum -y install postfix~]# sed -i &apos;s/inet_interfaces = localhost/inet_interfaces = all/g&apos; /etc/postfix/main.cf~]# systemctl start postfix~]# systemctl restart postfix 配置gitlab-ce yum源并安装123456~]# vim /etc/yum.repos.d/gitlab-ce.repo[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1 123~]# yum clean all~]# yum makecache ~]# yum -y install gitlab-ce gitlab 配置12~]# cd /etc/gitlab/~]# cp gitlab.rb&#123;,.bak&#125; gitlab 配置文件12# 地址配置external_url 'https://gitdb.novogene.com' 1234567891011121314151617# ldap AD域配置gitlab_rails['ldap_enabled'] = truegitlab_rails['ldap_servers'] = YAML.load &lt;&lt;-'EOS' main: label: '诺禾AD' host: 'xx.xxx.xx.xxx' port: 3xx uid: 'sAMAccountName' method: 'plain' bind_dn: 'CN=xxx,OU=xxx,DC=xxx,DC=xxx' password: 'xxxxxxxx' active_directory: true allow_username_or_email_login: ture block_auto_created_users: false base: 'OU=xxx,DC=xxx,DC=xxx' user_filter: ''EOS 12345678910111213141516# gitlab 邮件配置gitlab_rails['smtp_enable'] = true;gitlab_rails['smtp_address'] = 'smtp.exmail.qq.com';gitlab_rails['smtp_port'] = 465;gitlab_rails['smtp_user_name'] = "xx@xxxxx.com"gitlab_rails['smtp_password'] = "xxxxxxx"gitlab_rails['smtp_domain'] = 'smtp.exmail.qq.com';gitlab_rails['smtp_authentication'] = "login"gitlab_rails['smtp_enable_starttls_auto'] = truegitlab_rails['smtp_tls'] = truegitlab_rails['gitlab_email_from'] = 'xxx@xxxxxx.com'nginx['redirect_http_to_https'] = truenginx['ssl_certificate'] = "/etc/gitlab/ssl/gitdb.pem"nginx['ssl_certificate_key'] = "/etc/gitlab/ssl/gitdb.key"nginx['redirect_http_to_https_port'] = 80nginx['listen_port'] = 443 gitlab服务启动1~]# gitlab-ctl start lsyncd 主从同步配置1234567~]# /etc/lsyncd.conf settings &#123; logfile ="/var/log/lsyncd/lsyncd.log", statusFile ="/var/log/lsyncd/lsyncd.status", inotifyMode = "Modify", maxProcesses = 20, &#125; 12345678910111213141516sync &#123; default.rsync, source = "/var/opt/gitlab", target = "root@172.30.1.17:/var/opt/gitlab/", exclude = &#123; "backups", "gitlab-ci", "sockets","gitlab.yml","redis","postmaster.pid "&#125;, maxDelays = 5, delay = 30, -- init = true, rsync = &#123; binary = "/usr/bin/rsync", archive = true, compress = true, bwlimit = 2000 -- rsh = "/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no" &#125; &#125; 123456789101112131415sync &#123; default.rsync, source = "/etc/gitlab/", target = "root@172.30.1.17:/etc/gitlab/", maxDelays = 5, delay = 30, -- init = true, rsync = &#123; binary = "/usr/bin/rsync", archive = true, compress = true, bwlimit = 2000 -- rsh = "/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no" &#125; &#125; 123456789101112131415! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 &#125;vrrp_script chk_gitlab &#123; script "/bin/bash /usr/local/keepalived/etc/keepalived/check_gitlab.sh" interval 5 weight -20&#125; 12345678910111213141516171819202122232425vrrp_instance VI_1 &#123; state BACKUP interface em1 virtual_router_id 55 priority 100 nopreempt advert_int 1 notify_master "/usr/local/keepalived/etc/keepalived/message.sh master" notify_backup "/usr/local/keepalived/etc/keepalived/message.sh backup" notify_fault "/usr/local/keepalived/etc/keepalived/message.sh fault" unicast_src_ip 172.30.1.16 unicast_peer &#123; 172.30.1.17 &#125; track_script &#123; chk_gitlab &#125; authentication &#123; auth_type PASS auth_pass xxxxxxxx &#125; virtual_ipaddress &#123; 172.30.1.20 &#125;&#125; keepalived 检测脚本123456789101112131415161718192021222324252627282930313233#!/bin/bashpackage() &#123; rpm -qf /usr/bin/curl &amp;&gt; /dev/null || yum -y install curl &amp;&gt; /dev/null&#125;packagegitlab_state () &#123; /usr/bin/curl -s https://gitdb.novogene.com/users/sign_in | grep "Username" &amp;&gt; /dev/null&#125;gitlab_state ; gitlab_state_num=$? ; echo $gitlab_state_numgitlab_state2 () &#123; /usr/bin/curl -s https://gitdb.novogene.com/users/sign_in | grep "Password" &amp;&gt; /dev/null&#125;kill_keepalived () &#123; kill -9 `cat /var/run/keepalived.pid`&#125;if [ $gitlab_state_num -ne 0 ] ; then echo "`date +"%Y-%m-%d-%H-%M-%S"` gitlab_status_one_check problem " &gt;&gt; /var/log/keepalived/check_gitlab.log gitlab_state2 ; gitlab_state2_num=$? ; echo $gitlab_state2_num if [ $gitlab_state2_num -ne 0 ] ; then echo "`date +"%Y-%m-%d-%H-%M-%S"` gitlab_status2_one_check problem" &gt;&gt; /var/log/keepalived/check_gitlab.log sleep 1 fifigitlab_state ; gitlab_state_num=$? ; echo $gitlab_state_numif [ $gitlab_state_num -ne 0 ] ; then echo "`date +"%Y-%m-%d-%H-%M-%S"` gitlab_status_two_check problem " &gt;&gt; /var/log/keepalived/check_gitlab.log gitlab_state2 ; gitlab_state2_num=$? ; echo $gitlab_state2_num if [ $gitlab_state2_num -ne 0 ] ; then echo "`date +"%Y-%m-%d-%H-%M-%S"` gitlab_status2_two_check problem " &gt;&gt; /var/log/keepalived/check_gitlab.log echo "gitdb jiqun change node1" | mutt -s "gitdb.novogene.com" renjin@novogene.com kill_keepalived fifi git 客户端常用命令12345678910111213141516# git config --global user.name &quot;name&quot; #设置全局用户名# git config --global user.email xxx@novogene.com # 设置全局邮箱# git config --global --list #列出用户全局设置# git add index.html / . #添加指定文件、目录或当前目录下所有数据到暂存区# git commit -m &quot;xx&quot; #提交文件到工作区# git status #查看工作区的状态# git push #提交代码到服务器# git pull # 获取代码到本地# git log # 查看操作日志# vim .gitignore # 定义忽略文件# git rest --hard HEAD^^ # git版本回滚，HEAD为当前版本，加一个^为上一个，^^为上上一个版本# git reflog # 获取每次提交的ID,可以使用--hard根据提交的ID进行版本回退# git reset --hard 5ae4b06 #回退到指定id的版本# git branch # 查看当前所处的分支# git checkout -b develop # 创建并切换到一个新分支# git checkout develop #切换分支 git缓存区与工作区等概念 工作区: clone 的代码或者开发自己编写的代码文件所在的目录，通常是代码所在的一个服务的目录名称; 暂存区: 用于存储在工作区中对代码进行修改后的文件所保存的地方，使用git add添加; 本地仓库: 用于提交存储在工作区和暂存区中改过的文件地方，使用git commit提交; 远程仓库: 多个开发共同协作提交代码的仓库，即gitlab或github服务器。 macos 安装 git未安装 Homebrew 的需要先安装Homebrew 12# /usr/bin/ruby -e \ "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 安装git 1# brew install git CentOS 安装 git1# yum -y install git Ubuntu 安装 git1# apt-get install git]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结glibc的升级操作]]></title>
    <url>%2F2020%2F03%2F11%2Fglibc%20%E5%8D%87%E7%BA%A7%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[总结glibc的升级操作 遇到的执行程序报错123fastp.sh 的时候报下面的错，其他节点都没问题fastp: /lib64/libc.so.6: version `GLIBC_2.14&apos; not found (required by fastp)fastp: /lib64/libc.so.6: version `GLIBC_2.14&apos; not found (required by /zlib/lib/libz.so.1) 在操作之前最好先备份 /lib64/libc.so.6 和它对应指向的链接文件 处理过程注: 操作服务器的时候，一定要把这个节点从集群中去除。确保不影响业务的使用12345678910111213141516171819# cat /etc/redhat-release CentOS release 6.5 (Final)# strings /lib64/libc.so.6 |grep GLIBC_ GLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_PRIVATE 由上面的信息可以看出系统是CentOS 6.5，最高支持glibc的版本为2.12，而研发程序要2.14版本，所以需要升级。 下载软件并升级12345678910# wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gz # wget http://ftp.gnu.org/gnu/glibc/glibc-ports-2.14.tar.gz # tar -xvf glibc-2.14.tar.gz # tar -xvf glibc-ports-2.14.tar.gz# mv glibc-ports-2.14 glibc-2.14/ports# mkdir glibc-2.14/build# cd glibc-2.14/build # ../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin# make# make install 遇到的问题这个时候可能遇到以下问题，千万不要断开ssh 执行以下命令进行补救 123# LD_PRELOAD=/lib64/libc-2.14.so # rm -f /lib64/libc.so.6# ln -s /lib64/libc-2.14.so /lib64/libc.so.6 这时候再看看系统命令还能否都正常使用 如果断开了ssh 的情况下如果断开了ssh 只能进系统救援模式进行补救了;重启，(single/1)单用户模式，/bin/bash，enforcing=0,selinux=0 都是无济于事的，因为它涉及的库是libc.so.6必需的，重启后会报内核恐慌Kernel panic – not syncing: Attempted to kill init;因此进入救援模式进行补救。 连接dell服务器远程控制台，映射本地镜像文件到dell服务器; 启动项默认调整为光盘镜像启动; 进入救援模式Rescue installed system; 选择语言和键盘用English、 us; 出现网络设置不需要配置; 挂载/mnt/sysimage 选用Continue; 发现磁盘，选择yes; 启用shell登录; cd /mnt/sysimage 目录; rm -f /lib64/libc.so.6 cd /lib64 &amp;&amp; ln -s libc-2.14.so libc.so.6; chroot /mnt/sysimage 切换根目录测试系统是否无误; 重新启动系统。]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络经济与企业管理(一)]]></title>
    <url>%2F2020%2F03%2F01%2Fzikao%2F%E7%BD%91%E7%BB%9C%E7%BB%8F%E6%B5%8E%E4%B8%8E%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[网络经济与企业管理(一) 企业及其形式 企业是以市场 为导向从事商品生产和流通的经济组织; 企业是以价值增值作为其经济活动的目的; 企业进行自主经营 自负盈亏和独立核算。独立核算 选择题 工厂制度的建立，标志着企业的真正形成。 多选，现代企业生产时期的特征 拥有现代技术 拥有现代化管理 所有者与经营者相分离 管理方面 拥有现代化管理 所有者与经营者相分离 生产技术 拥有现代技术 生产规模空前扩大，产生了垄断组织 劳动分工越来截止精细，协作关系复杂、严密 竞争 企业之间的竞争激烈 社会责任 企业的社会责任改变 企业类型根据企业所属的经济部(农业企业、工业企业、金融企业、商业企业)根据生产力要素比重(劳动密集型企业、技术密集型企业、知识密集型企业、资源密集型企业)根据企业经营规模(大型企业，中型企业，小型企业)根据企业财产构成和所负法律责任:1、个体企业又叫独资企业，是由业主个人出资兴办，由业主自己经营。在国外，许多零售商业、手工业、家庭工业、农业等多采用个体企业。2、 合伙企业由两个或两个以上的个人共同出资，通过签订协议联合经营。3、公司制企业(如有限责任公司和股份有限公司)由两个以上的出资者共同出资、依法组建，以盈利为目的的企业法人，是联合经营的企业组织形式。 公司制企业的特点公司制企业是法人。公司制企业实行有限责任制度。公司制企业的所有权和经营权相分离。 真题1、企业为了满足社会 管理1、管理是一个动态过程;2、管理的环抱是达到组织的预定目标;3、管理的载体是组织;4、管理的核心是对资源的合理配置和有效整合。 管理活动所具备的条件管理的主体(谁来管) 、 管理的客体(管理谁)、 管理的目的(为啥管) 五职能论法约尔认为，企业的管理活动就是由计划、组织、指挥、协调、控制 这五种职能级成的。 计划 是管理职能中的首要职能 –&gt; 管理 的计划职能计划、组织、领导、控制 是管理学派普通的公认的职能。 首要的职能计划职能 是对即定的目标进行具体安排，作为全体员工在一定时期的行动纲领，并规定实现目标的途径、方法的管理活活动。1 年以内是短期计划， 1-5 是中期计划 ，5年后是长期计划 组织工作的基本原则(简答)有效性原则: 能高效地完成工作；机构设置和人员配备到精简。精简人员实现任务和责任到人，有效地避免了推诿和扯皮现象。统一指挥原则: 在指挥和命令，严格执行”一元化”管理。责权利相一致则:为每一个层次和环节都规定责，同时赋予所必须的职权。集权和分权相结合原则: 对重大决策和全局性管理实行集权，对日常管理实行分权。弹性原则: 设计组织结构时要留有余地，制定一些带有伸缩性的组织规则。协调原则: 组织的优势之一是 “整体功能大于部分功能之和” 领导的活动内容1、权力的形成和运用2、指导3、激励4、沟通5、协调6、营造组织气氛，建设组织文化 控制的方式(选择)预先控制:是面向未来的控制，又称前馈控制。现场控制:指在实施计划过程中，充分体管理控制的那一部分工作，又称适时控制，是最基本的控制方式反馈控制: 也称过后行为控制或事后控制 企业是以价值增值作为其经济活动的目的企业管理的目标是实现企业价值的最大化 真题形成一项管理活动必须具备的条件，包括 有效管理的主体 ，有效管理的客体 ，有效管理的目的 管理的首要职能是计划 中期计划的时间一般是一到五年以内 运筹帷幄之中，决胜千里之外，这里运筹帷幄反应了管理的哪一个职能 计划职能 法约尔的企业管理活动“五职能论” 包括计划、组织、指挥及调协与控制 精简人员实现任务和责任到人，有效地避免了推诿和扯皮的现象，这体现了组织工作的哪项原则 有效性原则 按照控制方式的不同，一般把控制分为 预先控制，现场控制，反馈控制 现场控制，又称适时控制 对既定的目标进行具体安排，作为全体员工在一时时期内的行动纲领，并规定实现目标的途径，方法的管理的 计划职能 企业管理的目标利益相关着(资本所有者、债权人、客户、供应商、政府和社会) 企业管理理论与实践的产生与发展泰罗 《科学管理原理》 被称为科学管理之父法约尔《工业管理和一般管理》 管理过程理论之父韦伯《社会和经济理论》 被称为组织管理之父 行为科学理论，20世纪到30年代到60年代 姓名 理论 马斯洛 需求层次理论 赫茨伯格 双因素理论 麦克利兰 激励需求理论 麦格雷戈 X理论-Y理论 管理理论丛林 姓名 学派 巴纳德 社会系统学派 西蒙 决策学派 德鲁克 经验(案例) 学派 战略管理与实践的产生和发展20 世纪60年代中后期到80年代初，企业管理学界开始重点研究战略管理理论20 世纪六七十年代，日本引进美国质量管理专家戴明和朱兰的全面质量管理的思想企业文化成为80年企业管理研究的重点 时间 代表人物 理论 20世纪80年代后期 哈默&amp;钱皮 企业再造理论 20世纪90年代后期 彼德&amp;圣吉 第5项修炼-企业唯一持久的竞争优势源于比竞争对手学得更快、更好的能力 真题 简述古典管理理论三位主要代表代人物及其贡献a、泰罗的科学管理理论，重点研究了在工厂管理中如何提高效率，倡导要用科学思想，科学方法处理和解决企业管理问题。b、法约尔的管理过程理论，对组织管理进行了系统的、独创的研究，提出了管理具有计划、组织、指挥、协调和控制5大职能和14条管理原则。c、马克斯.韦伯的管理组织理论，提出了理想行政组织体系理论。 被称为”科学管理之父”的是泰罗 马斯洛的代表性理论成果是需求层次理论 经验(案例)学派的人物是巴纳德 20世纪60-70年代日本引入了美国质量管理专家戴明和朱兰的全面质量管理思想 法约尔认为，企业管理理活动的职能包括计划、组织和 指挥、协调和控制 被誉为”组织管理之父”的是 韦伯 被誉为”管理过程理论之父”是 法约尔 赫茨伯格提出了著名的双因素理论 9.麦格雷戈提出了著名的 X理论-Y理论 企业唯一持久的竞争优势源于比竞争对手学得更快、更好的能力，是哪位管理学者的观点 彼德.圣吉 网络时代的企业环境网络时代企业面对的机遇 企业可以更好地满足顾客的个性化需求； 企业可以降低交易成本; 企业可以减少库存; 企业可以使合作竞争战略更便利地实施; 提高获取知识、应用知识的能力。 网络时代企业面对的挑战 企业面临日益激烈的竞争； 顾客的权力大增加; 企业的整体盈利水平将会降低; 企业关键的成功因素将会改变; 企业资源配置的方式和界限将会发生重大变化。 网络时代企业管理的变革企业管理拓展的范围有哪些网络企业与实体企业相比有如下特点:a、网络企业所占的实现空间非常有限，不像生产企业和销售企业那样占有大面积的实现空间进行产品生产和产品存储;b、网络企业是计算机化和网络化的企业;c、网络企业是全天候运营的企业;d、网络企业是信息技术和信息产品应用型的企业;e、网络企业是高知识开型的松散企业。 企业管理拓展的范围有哪些a、网络企业管理;b、企业的网络化管理;c、更加重视以知识资本为核心的无形资本的管理；d、企业管理的范围拓展到整个供应链。 企业管理创新的内容有哪些 企业战略管理的创新; 企业组织管理的创新; 网络营销成为营销管理的重要内容; 敏捷制造成为企业生产运作管理最重要的方式; 企业管理将向战略型，集成化方向发展; 回归人本管理，重视人力资源管理; 知识管理成为企业管理的重要内容; 更加重视文化管理。 企业战略管理的变革开发和培育核心能力成为企业战略管理重点。 企业组织结构变革的方向四个现代化(扁平化–&gt; 虚拟化 –&gt; 柔性化 –&gt; 网络化) 企业管理方法和手段的创新 准时制 JIT Just In Time 在需要的时候，按需要的量，生产所需的产品: 零废品，零库存，零准备时间 制造资源计划 MRP Manufacturing Resources Planning 确保企业连续、均衡地生产，实现信息流、物流与资金流的有机集成，以计划的与控制为主线 企业资源计划 ERP Enterprise Resources Planning 以客户需求为导向，实行企业内外资源优化配置，消除生产经营过程中一切无效的劳动和资源 电子数据交换 EDI Electronic Data Interchange 并行工程 CE Concurrent Engineering 需要产品开发人员从设计开始设计就考虑产品整个生命周期的所有因素 计算机集成制造系统 CIMS Computer Intergrated Manufacturing System 分销资源计划 DRP Distribution Resource Planning 使企业具有对定单和供货具有快速反应和持续补充库存的能力 企业内部网和互联网 Intranet， Internet 真题 请阐述企业在网络时代会面对哪些机遇和挑战？ 网络时代企业面对的机遇 网络时代企业面对的挑战 企业可以更好地满足顾客的个性化需求 顾客的权力大大增加 企业可以降底交易成本 企业的整体盈力水平将会以降低 企业可以减少库存 企业资源的配置方式和界限将会发生重大变化 企业可以使竞争战略更利地实施 企业面临日益激烈的竞争 提高获取知识，应用知识的能力 企业关键的成功因素将会改变 企业战略管理的重点是开发和培育核心能力 作为应对网络经济的挑战，企业组织结构变革的方向有柔性化、虚拟化、网络化、扁平化 哪种管理方法的目标是通过管理，尽可能做到”零废品”、”零库存”和”零准备时间” JIT 体现了以客户需求为导向，消除生产经营过程中一切无效的劳动和资源的管理思想是ERP 企业资源计划简称ERP 企业制造资源计划是指 MRP 准时制简称 JIT 网络经济时代，企业经营战略将围绕下列哪一项来制订企业核心业务和核心竞争力]]></content>
      <tags>
        <tag>zikao</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 算法]]></title>
    <url>%2F2019%2F12%2F15%2Fpython%20%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[python 算法 命名元组namedtuple12345678910111213In [1]: from collections import namedtupleIn [2]: Point = namedtuple('P','x,y')In [3]: type(Point)Out[3]: typeIn [4]: p1 = Point(1,10)In [5]: p1Out[5]: P(x=1, y=10)In [6]: p1.xOut[6]: 1In [7]: p1.yOut[7]: 10In [8]: p1.x + p1.yOut[8]: 11 排序 12345678(py3_env) [root@ssjinyao:~/mypython/python3]# cat sort.py#!/usr/bin/env python3nums = []out = Nonefor i in range(3): nums.append(int(input('&#123;&#125;: '.format(i))))nums.sort()print(nums) 12345678910111213#!/usr/bin/env python3nums = []out = Nonefor i in range(3): nums.append(int(input('&#123;&#125;: '.format(i))))while True: cur = min(nums) print(cur) nums.remove(cur) if len(nums) == 1: print(nums[0]) break 12345678#!/usr/bin/env pythonnums = []out = Nonefor i in range(3): nums.append(int(input(&apos;&#123;&#125;:&apos;.format(i))))nums.sort()print(nums) 冒泡法代码实现(一)1234567891011121314151617181920#!/usr/bin/env python# -*- coding: utf-8 -*-num_list = [ [1,9,8,5,6,7,4,3,2], [1,2,3,4,5,6,7,8,9],]nums = num_list[0]print(nums)length = len(nums)count_swap = 0count = 0for i in range(length): for j in range(length-i-1): count += 1 if nums[j] &gt; nums [j+1]: tmp = nums[j] nums[j] = nums [j+1] nums[j+1] = tmp count_swap +=1print(nums, count_swap, count) 12[1, 9, 8, 5, 6, 7, 4, 3, 2][1, 2, 3, 4, 5, 6, 7, 8, 9] 25 36 冒泡法代码实现(二)12345678910111213141516171819202122232425262728293031323334#!/usr/bin/env python# -*- coding: utf-8 -*-num_list = [ [1,9,8,5,6,7,4,3,2], [1,2,3,4,5,5,7,8,9]]nums = num_list[0]print(nums)length = len(nums)flag = Falsecount_swap = 0count = 0for i in range(length): for j in range(length-i-1): count += 1 if nums[j] &gt; nums[j+1]: tmp = nums[j] nums[j] = nums[j+1] nums[j+1] = tmp flag = True count_swap += 1 if not flag: breakprint(nums,count_swap,count)``` ## 字符串修改```pythons = "I am very very very sorry "s.strip()Out[4]: 'I am very very very sorry' 字符串查找1find(sub,[,start[end]]) -&gt; int 123In [1]: s = "I am very very very sorry "In [2]: s.find("very")Out[2]: 5 1234567In [14]: s = 'I am very very very sorry'In [15]: i = 0In [16]: for x in s: ...: print(str(i)+x,end=" ") ...: i +=1 ...:0I 1 2a 3m 4 5v 6e 7r 8y 9 10v 11e 12r 13y 14 15v 16e 17r 18y 19 20s 21o 22r 23r 24y 字符串格式化123In [15]: t = ('asjin','.com')In [16]: "&#123;&#125;,&#123;&#125;".format(t[0],t[1])Out[16]: 'asjin,.com' 12345In [18]: &quot;&#123;0&#125;,&#123;0&#125;&quot;.format(t[0])Out[18]: &apos;asjin,asjin&apos;In [19]: &quot;&#123;&#125;&quot;.format([1,2])Out[19]: &apos;[1, 2]&apos; 对齐12In [28]: '&#123;0&#125;*&#123;1&#125;=&#123;2:&gt;02&#125;'.format(3,2,2*3)Out[28]: '3*2=06' 1234In [29]: '&#123;:^30&#125;'.format('asjin.com')Out[29]: ' asjin.com 'In [30]: '&#123;:#^30&#125;'.format('asjin.com')Out[30]: '##########asjin.com###########' 12In [12]: "&#123;&#125;:&#123;&#125;".format('192.168.1.100',8888)Out[12]: '192.168.1.100:8888' 123In [13]: t = ("asjin","com")In [14]: "&#123;&#125;.&#123;&#125;".format(t[0],t[1])Out[14]: 'asjin.com' 12In [15]: "&#123;0[0]&#125;.&#123;0[1]&#125;".format(("asjin","com"))Out[15]: 'asjin.com' 123456789In [16]: from collections import namedtupleIn [17]: Point = namedtuple('_Point','x,y')In [18]: p1 = Point(5,6)In [19]: p1.xOut[19]: 5In [20]: p1.yOut[20]: 6In [23]: "Point = (&#123;&#123;&#123;0.x&#125;,&#123;0.y&#125;&#125;&#125;)".format(p1)Out[23]: 'Point = (&#123;5,6&#125;)' 进制转换 12In [26]: "int: &#123;0:d&#125;; hex &#123;0:x&#125;; oct &#123;0:o&#125;; bin: &#123;0:b&#125;".format(1996)Out[26]: 'int: 1996; hex 7cc; oct 3714; bin: 11111001100' 12In [27]: "int: &#123;0:d&#125;; hex &#123;0:#x&#125;; oct &#123;0:#o&#125;; bin: &#123;0:#b&#125;".format(1996)Out[27]: 'int: 1996; hex 0x7cc; oct 0o3714; bin: 0b11111001100' ip 转换为十六进制 123In [30]: octets = [10,180,55,1]In [31]: "&#123;:02X&#125;&#123;:02X&#125;&#123;:02X&#125;&#123;:02X&#125;".format(*octets)Out[31]: '0AB43701' 练习让用户输入一个数，从后往前打印 12345678910#!/usr/bin/env python3# -*-coding: utf-8 -*-m = input("&gt;&gt;&gt;").strip().lstrip('0')print("这是&#123;&#125;位数".format(len(m)))for i in range(len(m)): print("&#123;&#125;'s count = &#123;&#125;".format(m[i],m.count(m[i])))for j in range(len(m)): n=m[-j-1] print(n)print(m) 123456789101112131415161718192021222324#!/usr/bin/env python# -*- coding: utf-8 -*-num = ""while True: num = input("Please input a interger: ").strip() num = int(num) num = str(num) if num.isdigit(): break else: print("Bad number")count = [0]*10 # 0~9for i in range(10): count[i] = num.count(str(i))for i in range(10): if count[i]: print(i,count[i])lst = list(num)lst.reverse()print(lst) 输入5个数字，打印每个数字的位数， 将这些数字排序打印，要求升序打印12345678#!/usr/bin/env python# -*- coding: utf-8 -*-lst = []for i in range(5): m = input("&gt;&gt;&gt; ").strip().lstrip("0") print("这是&#123;&#125;位数".format(len(m))) lst.append(int(m))print(sorted(lst)) 字符串格式化1234In [10]: "I am %-5d" % (20,)Out[10]: 'I am 20 'In [11]: "I am %-5d" % (20202,)Out[11]: 'I am 20202' 练习 判断是几位数 打印每位数字及其重复的次数 依次打印每一位数字，顺序个、十、百、千、万位 1234567891011In [32]: num = ''In [33]: while True: ...: num = input('Input a positive number &gt;&gt;&gt;').strip().lstrip('0') ...: if num.isdigit(): ...: break ...:Input a positive number &gt;&gt;&gt;111In [34]: print("The length of &#123;&#125; is &#123;&#125;.".format(num,len(num)))The length of 111 is 3. 倒序打印1 1234In [36]: for i in range(len(num),0,-1): ...: print(num[i-1],end=' ') ...: print()3 3 0 0 9 1 5 倒序打印2 1234In [37]: for i in reversed(num): ...: print(i,end=' ') ...: print()3 3 0 0 9 1 5 负索引方式打印 1234In [38]: for i in range(len(num)): ...: print(num[-i-1],end=' ') ...: print()3 3 0 0 9 1 5 判断0-9的数字在字符中出现的次数，每一次迭代都是用的count,都是0(n)问题 123456789101112In [57]: num = '1912334'In [58]: for i in range(10): ...: counter[i] = num.count(str(i)) ...: if counter[i]: ...: print("The count of &#123;&#125; is &#123;&#125;".format(i,counter[i])) ...:The count of 1 is 2The count of 2 is 1The count of 3 is 2The count of 4 is 1The count of 9 is 1 失代字符串本身的字符 1234567891011121314In [67]: num = '1912334'In [68]: counter = [0]*10In [69]: for x in num: ...: i = int(x) ...: if counter[i] == 0: ...: counter[i] = num.count(x) ...: print("The count of &#123;&#125; is &#123;&#125;".format(x,counter[i]))The count of 1 is 2The count of 9 is 1The count of 2 is 1The count of 3 is 2The count of 4 is 1 bytes 定义 1234In [2]: bytes("abc","utf-8")Out[2]: b'abc'In [3]: "abc".encode()Out[3]: b'abc' 线性结构线性结构 可抚迭代for … in len() 可以获取长度 通过下标可以访问 可以切片 如列表、元组、字符串、bytes、bytearry 切片1234567891011121314In [1]: 'www.asjin.com'[4:10]Out[1]: 'asjin.'In [2]: 'www.asjin.com'[4:9]Out[2]: 'asjin'In [3]: 'www.asjin.com'[:9]Out[3]: 'www.asjin'In [4]: 'www.asjin.com'[4:]Out[4]: 'asjin.com'In [5]: 'www.asjin.com'[:]Out[5]: 'www.asjin.com'In [6]: 'www.asjin.com'[:-1]Out[6]: 'www.asjin.co'In [7]: 'www.asjin.com'[4:-4]Out[7]: 'asjin' 补充for12345In [15]: for j, i in enumerate(['jen', 'bb','eee']): ...: print(j,i)0 jen1 bb2 eee 解构1234567In [4]: test,*te,test2 = "bbcccefsdde"In [5]: testOut[5]: 'b'In [6]: teOut[6]: ['b', 'c', 'c', 'c', 'e', 'f', 's', 'd', 'd']In [7]: test2Out[7]: 'e' 1234In [24]: lst = list(range(1,101,2))In [25]: head,*_,tail = lstIn [26]: head,tailOut[26]: (1, 99) _是合法的标识符，看到下划线就知道这个变量就是不想被使用 取其中的元素 1234In [4]: lst = [1,(2,3,4),5]In [5]: _,(*_,a),_ = lstIn [6]: aOut[6]: 4 取JAVA_HOME 和 PATH123456In [7]: s = 'JAVA_HOME=/usr/bin'In [8]: s.partition('=')Out[8]: ('JAVA_HOME', '=', '/usr/bin')In [9]: name,_,path=s.partition('=')In [10]: name,pathOut[10]: ('JAVA_HOME', '/usr/bin') 1234In [12]: s = 'JAVA_HOME=/usr/bin'In [13]: name,path = s.split('=')In [14]: print(name,path)JAVA_HOME /usr/bin 数字统计随机产生10个数字要求:每个数字取值范围[1,20]统计重复的数字有几个？分别是什么？统计不重复的数字有几个？ 分别是什么？ 123456789101112131415161718192021222324252627282930313233343536#!/usr/bin/env python# -*- coding: utf-8 -*-import randomnums = []for _ in range(10): nums.append(random.randrange(21))print("Origin numbers = &#123;&#125;".format(nums))print()length = len(nums)samenums = [] # 记录相同的数字diffnums = [] # 记录不同的数字states = [0] * length # 记录不同的索引异同状态for i in range(length): flag = False # 假设没有重复 if states[i] == 1: continue for j in range(i+1,length): if states[j] == 1: continue if nums[i] == nums[j]: flag = True states[j] = 1 if flag: # 有重复 samenums.append(nums[i]) states[i] = 1 else: diffnums.append(nums[i])print("Same numbers = &#123;1&#125;, counter = &#123;0&#125;".format(len(samenums), samenums))print("Different numbers = &#123;1&#125;, Counter = &#123;0&#125;".format(len(diffnums),diffnums))print(list(zip(states,nums))) 123Same numbers = [8, 20], counter = 2Different numbers = [19, 5, 10, 1, 9, 16], Counter = 6[(0, 19), (0, 5), (0, 10), (1, 8), (1, 20), (1, 20), (0, 1), (0, 9), (1, 8), (0, 16)] set 定义 初始化 约定 set 翻译为集合 collection 翻译为集合类型，是一个大概念set 可变的、 无序的 、 不重复的 元素集合 123456789101112In [4]: s2 = set(range(5))In [5]: s2Out[5]: &#123;0, 1, 2, 3, 4&#125;In [9]: s6=&#123;9,10,11&#125;In [10]: s6Out[10]: &#123;9, 10, 11&#125;In [14]: s7Out[14]: &#123;(1, 2), 3, 'a'&#125;In [15]: s2 = set(range(5))In [16]: s2.add(5)In [17]: s2Out[17]: &#123;0, 1, 2, 3, 4, 5&#125; 集合运算, 反单个集合合并到当前集合12345In [19]: s2Out[19]: &#123;0, 1, 2, 3, 4, 5, 6&#125;In [20]: s2.update(&#123;2,10,3&#125;)In [21]: s2Out[21]: &#123;0, 1, 2, 3, 4, 5, 6, 10&#125; 移除一个元素remove(elem) 从set 中移除一个元素 如果元素不存在，抛出KeyError异常12345In [21]: s2Out[21]: &#123;0, 1, 2, 3, 4, 5, 6, 10&#125;In [22]: s2.remove(2)In [23]: s2Out[23]: &#123;0, 1, 3, 4, 5, 6, 10&#125; discard(elem) 从set 中移除一个元素，和remove() 类似，只是不报错。 元素不存在，什么都不做pop()-&gt;item 移除并返回任意的元素 空集返回KeyError异常123456In [23]: s2Out[23]: &#123;0, 1, 3, 4, 5, 6, 10&#125;In [25]: s2.pop()Out[25]: 0In [26]: s2Out[26]: &#123;1, 3, 4, 5, 6, 10&#125; # 随机挑一个 clear() 移除所有元素 set 成员运算与效率 1234567# listIn [27]: %%timeit lst1 = list(range(100)) ...: a = -1 in lst11.53 µs ± 67 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)In [28]: %%timeit lst1 = list(range(100000)) ...: a = -1 in lst11.55 ms ± 98.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 12345678# set In [29]: %%timeit set1 = set(range(100)) ...: a = -1 in set138.3 ns ± 5.97 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)In [30]: %%timeit set1 = set(range(100000)) ...: a = -1 in set137 ns ± 7.05 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sge linux高性能集群的搭建与使用]]></title>
    <url>%2F2019%2F11%2F12%2Fsge%E9%9B%86%E7%BE%A4%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[sge高性能集群的搭建与使用 集群环境的准备 Node1(master) CentOS7.4 iptables/selinux(off) IP:10.180.66.11 hostname:node1 ali yum源 Node2(slave) CentOS7.4 iptables/selinux(off) IP:10.180.66.12 hostname:node2 ali yum源 Node3(slave) CentOS7.4 iptables/selinux(off) IP:10.180.66.13 hostname:node3 ali yum源 Node4(slave) CentOS7.4 iptables/selinux(off) IP:10.180.66.14 hostname:node4 ali yum源 Node5(slave) CentOS7.4 iptables/selinux(off) IP:10.180.66.15 hostname:node5 ali yum源 master 节点安装安装相关依赖包1# yum -y install jemalloc-devel openssl-devel ncurses-devel pam-devel libXmu-devel hwloc-devel hwloc hwloc-libs java-devel javacc ant-junit libdb-devel motif-devel csh ksh xterm db4-utils perl-XML-Simple perl-Env xorg-x11-fonts-ISO8859-1-100dpi xorg-x11-fonts-ISO8859-1-75dpi 新建sge管理员用户123# groupadd -g 490 sgeadmin# useradd -u 495 -g 490 -r -m -d /home/sgeadmin -s /bin/bash -c &quot;SGE Admin&quot; sgeadmin# sed -i &apos;/^%wheel/a\%sgeadmin ALL=(ALL) NOPASSWD: ALL&apos; /etc/sudoers 安装sgesge 链接 密码:c7hy 12345# cd /usr/local/src/# tar -xvf ge2011.11.tar.gz# mkdir -pv /data# cp -a ge2011.11 /data/sge# chown sgeadmin.sgeadmin /data/sge qmaster 安装自动回答脚本，依赖软件包expect, 所有节点都需要安装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160# cd /data/sge/# vim master.sh#!/bin/bashuser="sgeadmin"/usr/bin/expect &lt;&lt;-EOFspawn ./install_qmasterexpect "*&gt;&gt;"send ""expect "*&gt;&gt;"send "y"expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send "n"expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect eofEOF# sh master.sh 修改主节点环境变量 123456# export SGE_ROOT=/data/sge# echo 'export SGE_ROOT=/data/sge' &gt;&gt; ~/.bashrc# echo 'PATH=$PATH:/data/sge/bin/linux-x64/:/data/sge/bin/' &gt;&gt; ~/.bashrc# cp /data/sge/default/common/settings.sh /etc/profile.d/# sh /etc/profile.d/settings.sh# source /etc/profile 添加节点 12345# qconf -ah node1# qconf -ah node2# qconf -ah node3# qconf -ah node4# qconf -ah node5 master 服务器搭建 nfs 服务所有节点都需要安装1# yum -y install nfs-utils master节点操作 123# vim /etc/exports/data/sge 10.180.66.0/24(rw,sync)# systemctl restart nfs slave 节点挂载(node2,node3,node4,node5)执行 123# mkdir /data/sge -pv# mount -t nfs 10.180.66.11:/data/sge /data/sge/# chown sgeadmin.sgeadmin /data/ slave 服务器安装sgeexecd(node2,node3,node4,node5) 执行 123# yum -y install hwloc-devel# useradd -u 495 -g 490 -r -m -d /home/sgeadmin -s /bin/bash -c "SGE Admin" sgeadmin# sed -i '/^%wheel/a\%sgeadmin ALL=(ALL) NOPASSWD: ALL' /etc/sudoers 生效环境变量 123456# echo 'export SGE_ROOT=/data/sge' &gt;&gt; ~/.bashrc# echo 'PATH=$PATH:/data/sge/bin/linux-x64/:/data/sge/bin/' &gt;&gt; ~/.bashrc# echo 'export SGE_CELL=default' &gt;&gt; ~/.bashrc# cp /data/sge/default/common/settings.sh /etc/profile.d/ -a# source ~/.bashrc# source /etc/profile 进行安装，所有节点都执行此脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# vim slave.sh# cat slave.sh#!/bin/bashuser="sgeadmin"/usr/bin/expect &lt;&lt;-EOFspawn ./install_execdexpect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect "*&gt;&gt;"send ""expect eofEOF# sh slave.sh 完成集群搭建123456789# qhostHOSTNAME ARCH NCPU LOAD MEMTOT MEMUSE SWAPTO SWAPUS-------------------------------------------------------------------------------global - - - - - - -node1 linux-x64 1 0.01 968.3M 193.0M 2.0G 64.0Knode2 linux-x64 1 0.01 976.3M 151.0M 2.0G 0.0node3 linux-x64 1 0.02 978.3M 152.2M 2.0G 84.0Knode4 linux-x64 1 0.02 976.3M 155.4M 2.0G 0.0node5 linux-x64 1 0.01 978.3M 148.5M 2.0G 84.0K sge集群的使用]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kvm学习笔记]]></title>
    <url>%2F2019%2F08%2F28%2Fkvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[kvm 学习笔记 kvm相关知识梳理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051KVM: kernel-based Virtual Machine, Qumranet 公司，依赖于HVM: Intel VT-x, ADM ADM-V:KVM模块载入后的系统的运行模式: 内核模式: GuestOS执行I/O类操作，或其它的特殊指令的操作：称作“来宾-内核”模式; 用户模式: 代表GuestOS请求I/O类操作，宿主机用户模式; 来宾模式: GuestOS的非I/O类操作；事实上，它被称为“来宾-用户”模式。 kvm hypervisor:KVM的组件: /dev/kvm: 工作于hypervisor,在用户空间，可通过ioctl()系统调用来完成VM创建、启动管理功能；它是一个字符设备，功能: 创建VM、为VM分配内存、读写VCPU的寄存器、向VCPU注入中断、运行VCPU等等; qemu进程: 工作于用户空间，主要用于实现模拟PC机的IO设备;KVM特性: 内存管理: 将分配给VM的内存交换至SWAP; 支持使用Huge Page; 支持使用Intel EPT或AMD RVI技术完成内存地址映射; GVA--&gt; GPA --&gt;HPA 支持KSM(Kernel Same-page Merging)硬件支持: 取决于Linux内核存储: 本地存储: 网络附加存储: 存储区域名网络 分布式存储: 例如GlustFS实时迁移: 实时迁移: 支持的GuestOS: Linux, Windows, OpenBSD, FreeBSD, OpenSolaris; 设备驱动： IO设备的完全虚拟化: 模拟硬件 IO设备的半虚拟化: 在GuestOS中安装驱动: virtio virtio-blk, virtio-net, virtio-pci,virtio-console, virtio-ballonKVM局限性: 一般局限性: CPU overcommit 时间记录难以精确，依赖于时间同步机制 MAC地址: VM量特别大时，存在冲突的可能性; 实时迁移: 性能局限性:KVM的工具栈 qemu: qemu-kvm qemu-img libvirt GUI: virt-manager, virt-viewer CLI: virt-install, virsh QEMU主要用到以下几个部分: 处理器模拟器 仿真IO设备 关联模拟的设备至真实设备; 调试器 与模拟器交互的用户接口 安装1、确保CPU支持HVM # grep -E --color=auto &quot;(vmx|svm)&quot; /proc/cpuinfo2、装载模块 # modeprobe kvm # modeprobe kvm-intel3、验证 /dev/kvm 管理工具栈qemu-kvmlibvirt管理kvm虚拟的方案: qemu: /usr/libexec/ 安装工具: libvirt: virt-install virt-manager 管理工具: virsh virt-manager virt-viewer VM Platform1234567891011# yum install qemu-kvm# ln -sv /usr/libexec/qemu-kvm /usr/bin/命令选项 标准选项: 显示选项: 块设备选项: i386平台专用选项: 字符设备选项: 蓝牙设备选项: Linux 启动专用选项: 调试/专家模式选项: 补充资料: KVM内存管理KVM继承了Linux系统管理内存的诸多特性，比如，分配给虚拟使用的内存可以被交换至交换空间、能够使用大内存页以实现更的好的性能，以及对NUMA的支持能够让虚拟机高效访问更大的内存空间等。 KVM基于Intel的EPT(Extended Page Table) 或AMD的 RVI(Rapid Virtualization Indexing) 技术可以支持更新的内存虚拟功能，这可以降低CPU的占用率，并提供较好的吞吐量。 此外，KVM还借助于KSM(kernel Same-page Merging) 这个内核特性实现了内存页面共享，KSM通过扫描每个虚拟机的内存查找各虚拟机间相同的页面，并将这些内存页合并为一个被各相关虚拟机共享的单独页面。在某虚拟机试图修改此页面中的数据时，KSM会重新为其提供 一个新的页面副本。实践中，运行于同一个物理主机的具有相同GuestOS的虚拟机之间出现相同内存页面的概率是很高的，比如共享库，内核或其它内存对象等都有可能表现为机同的页面，因此，KSM技术可以降低内存占用进而提高整体性能。 补充资料: VMM: 对IO的驱动有三种模式: 自主VMM: VMM 自行提供驱动和控制台; 混合VMM: 借助于OS提供驱动; 依赖于外部OS实现特权域 自我提供特权域 寄宿式VMM: IO虚拟化模型: 模拟 半虚拟化 透传 KVM：hvm kvm, 12345 # modinfo kvm # lsmod | grep kvmkvm_intel 170086 0kvm 566340 1 kvm_intelirqbypass 13503 1 kvm 启动使用微缩版Linuxcirros project : 为cloud 环境测试vm提供的微缩版Linux:启动第一个虚拟机: cirros12# qemu-kvm -m 128 -smp 2 -name &quot;test&quot; -hda /images/kvm/cirros-0.3.4-x86_64-disk.imgVNC server running on `::1:5900&apos; 安装tigervnc 1# yum -y install tigervnc 用-drive指定磁盘映像文件 1# qemu-kvm -m 128 -name test -smp 2 -drive file=/images/kvm/cirros-0.3.4-x86_64-disk.img,if=virtio,media=disk,cache=writeback,fromat=qcow2 通过cdrom启动winxp的安装: 1# qemu-kvm -name winxp -smp 4, sockets=1,cores=2,threads=2 -m 512 -drive file=/images/kvm/winxp.img,if=ide,media=disk,cache=writeback,format=qcow2 -drive file=/root/winxp_ghost.iso,media=cdrom 指定使用格拉网络接口: 12# qemu-kvm -m 128 -name test -smp 2 -drive file= /images/kvm/cirros-0.3.4-x86_64-disk.img,if=virtio,media=disk,cache=writeback,format=qcow2 -net nic -net tap,script=/etc/if-up,downscript=no -nographic qemu-kvm管理KVM虚拟机Qemu是一个广泛使用的开源计算机仿真器和虚拟机。当作为仿真器时，可以在一种架构(如PC机)下运行另一个架构(如ARM)下的操作系统和程序，而通过动态转化，其可以获取很高的运行效率。当作为一个虚拟机时，qemu可以通过直接使用真机的系统资源，让虚拟系统能够获得接近于物理机的性能表现。qemu支持xen或者kvm模式下的虚拟化。当用kvm时，qemu可以虚拟x86、服务器和嵌入式powerpc，以及s390系统。 QEMU 当运行与主机架构相同的目标架构时可以使用KVM例如，当在一个x86兼容处理器上运行 qemu-system-x86时，可以利KVM加速一为宿主机和客户机提供更好的性能。 Qemu 有如下几个部组成: 处理器模拟器(x86、PowerPC和Sparc) 仿真设备(显卡、网卡、硬盘、鼠标等) 用于将仿真设备连接至主机设备(真实设备)的通用设备; 虚拟机的描述信息; 调试器； 与模拟器交互的用户接口。 使用qemu-kvm安装Guest基于libvirt 的工具如virt-manager和virt-install提供了非常便捷的虚拟机管理接口，但它们事实上已经第二次开发后又封装了qemu-kvm的工具。因此，直接使用qemu-vkm命令也能够完成此前的任务。 123# qemu-kvm -m 128 -cpu host -smp 2 -name &quot;test&quot; -drive file=/images/kvm/cirros-0.3.4-x86_64-disk.img,if=virtio,media=disk,format=qcow2,cache=writeback# qemu-img create -o size=20G,preallocation=metadata -f qcow2 /images/winxp.qcow2# qemu-kvm -m 512 -smp 2 -cpu host -drive file=/images/windows/winxp.qcow2,media=disk -drive file=/root/winxp_ghost.iso,media=cdrom --boot order=dc, once=d 指定vnc 桌面，如指定桌面号为1 则启用端口为5901, 若指定桌面号为0，则启用端口为5900 1# qemu-kvm -m 128 -cpu host -smp 2 -name &quot;test&quot; -drive file=/images/kvm/cirros-0.3.4-x86_64-disk.img,if=virtio,media=disk,format=qcow2,cache=writeback -vnc 0.0.0.0:1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081qemu-kvm命令在RHEL6上，qemu-kvm位于/usr/libexec目录中。由于此目录不属于PATH环境变量，故无法直接使用，这样也阻止了可以直接使用qemu作为创建并管理虚拟机。如若想使用qemu虚拟机，可以通过将/usr/libexec/qemu-kvm链接为/usr/bin/qemu实现。# ln -sv /usr/lib/exec/qemu-kvm /usr/bin/qemu-kvmqemu-kvm命令使用格式为“qemu-kvm [options] [disk_image]”，其选项非常多，不过，大致可分为如下几类。👉🏾 标准选项；👉🏾 USB选项；👉🏾 显示选项；👉🏾 i386平台专用选项；👉🏾 网络选项；👉🏾 字符设备选项；👉🏾 蓝牙相关选项；👉🏾 Linux系统引导专用选项；👉🏾 调试/专家模式选项；👉🏾 PowerPC专用选项；👉🏾 Sparc32专用选项；考虑到篇幅及使用需要，这里介绍的选项主要涉及到标准选项、显示选项、i386平台专用选项及Linux系统引导专用选项等相关的选项。qemu-kvm的标准选项qemu-kvm的标准选项主要涉及指定主机类型、CPU模式、NUMA、软驱设备、光驱设备及硬件设备等。👉🏾 -name name：设定虚拟机名称；👉🏾 -M machine：指定要模拟的主机类型，如Standard PC、ISA-only PC或Intel-Mac等，可以使用“qemu-kvm -M ?”获取所支持的所有类型；👉🏾 -m megs：设定虚拟机的RAM大小；👉🏾 -cpu model：设定CPU模型，如coreduo、qemu64等，可以使用“qemu-kvm -cpu ?”获取所支持的所有模型；👉🏾 -smp n[,cores=cores][,threads=threads][,sockets=sockets][,maxcpus=maxcpus]：设定模拟的SMP架构中CPU的个数等、每个CPU的核心数及CPU的socket数目等；PC机上最多可以模拟255颗CPU；maxcpus用于指定热插入的CPU个数上限；👉🏾 -numa opts：指定模拟多节点的numa设备；👉🏾 -fda file👉🏾 -fdb file：使用指定文件(file)作为软盘镜像，file为/dev/fd0表示使用物理软驱；👉🏾 -hda file👉🏾 -hdb file👉🏾 -hdc file👉🏾 -hdd file：使用指定file作为硬盘镜像；👉🏾 -cdrom file：使用指定file作为CD-ROM镜像，需要注意的是-cdrom和-hdc不能同时使用；将file指定为/dev/cdrom可以直接使用物理光驱；👉🏾 -drive option[,option[,option[,...]]]：定义一个硬盘设备；可用子选项有很多。👉🏾 file=/path/to/somefile：硬件映像文件路径；👉🏾 if=interface：指定硬盘设备所连接的接口类型，即控制器类型，如ide、scsi、sd、mtd、floppy、pflash及virtio等；👉🏾 index=index：设定同一种控制器类型中不同设备的索引号，即标识号；👉🏾 media=media：定义介质类型为硬盘(disk)还是光盘(cdrom)；👉🏾 snapshot=snapshot：指定当前硬盘设备是否支持快照功能：on或off；👉🏾 cache=cache：定义如何使用物理机缓存来访问块数据，其可用值有none、writeback、unsafe和writethrough四个；👉🏾 format=format：指定映像文件的格式，具体格式可参见qemu-img命令；👉🏾 -boot [order=drives][,once=drives][,menu=on|off]：定义启动设备的引导次序，每种设备使用一个字符表示；不同的架构所支持的设备及其表示字符不尽相同，在x86 PC架构上，a、b表示软驱、c表示第一块硬盘，d表示第一个光驱设备，n-p表示网络适配器；默认为硬盘设备； -boot order=dc,once=dqemu-kvm的显示选项显示选项用于定义虚拟机启动后的显示接口相关类型及属性等。👉🏾 -nographic：默认情况下，qemu使用SDL来显示VGA输出；而此选项用于禁止图形接口，此时,qemu类似一个简单的命令行程序，其仿真串口设备将被重定向到控制台；👉🏾 -curses：禁止图形接口，并使用curses/ncurses作为交互接口；👉🏾 -alt-grab：使用Ctrl+Alt+Shift组合键释放鼠标；👉🏾 -ctrl-grab：使用右Ctrl键释放鼠标；👉🏾 -sdl：启用SDL；👉🏾 -spice option[,option[,...]]：启用spice远程桌面协议；其有许多子选项，具体请参照qemu-kvm的手册；👉🏾 -vga type：指定要仿真的VGA接口类型，常见类型有：👉🏾 cirrus：Cirrus Logic GD5446显示卡；👉🏾 std：带有Bochs VBI扩展的标准VGA显示卡；👉🏾 vmware：VMWare SVGA-II兼容的显示适配器；👉🏾 qxl：QXL半虚拟化显示卡；与VGA兼容；在Guest中安装qxl驱动后能以很好的方式工作，在使用spice协议时推荐使用此类型；👉🏾 none：禁用VGA卡；👉🏾 -vnc display[,option[,option[,...]]]：默认情况下，qemu使用SDL显示VGA输出；使用-vnc选项，可以让qemu监听在VNC上，并将VGA输出重定向至VNC会话；使用此选项时，必须使用-k选项指定键盘布局类型；其有许多子选项，具体请参照qemu-kvm的手册； display: （1）host:N 172.16.100.7:1, 监听于172.16.100.7主的5900+N的端口上 (2) unix:/path/to/socket_file (3) none options: password: 连接时需要验正密码；设定密码通过monitor接口使用change reverse: “反向”连接至某处于监听状态的vncview上； -monitor stdio：表示在标准输入输出上显示monitor界面 -nographic Ctrl-a, c: 在console和monitor之间切换 Ctrl-a, h: 显示帮助信息SDL: Simple Directmedia LayerVNC: Virtual Network Computing，基于RFB # rpm -ql bridge-utils 12345678# brctl addbr br0# brctl stp br0 off# brctl delbr br0# brctl show# ip link set dev br0 down# ip link set dev br0 up# ip link show# 临时生效 12# nmtui# nmcli 12# qemu-kvm -net nic,model=?qemu: Supported NIC models: ne2k_pci,i82551,i82557b,i82559er,rtl8139,e1000,pcnet,virtio 123456789101112131415161718192021网络属性相关选项网络属性相关选项用于定义网络设备接口类型及其相关的各属性等信息。这里只介绍nic、tap和user三种类型网络接口的属性，其它类型请参照qemu-kvm手册。👉🏾 -net nic[,vlan=n][,macaddr=mac][,model=type][,name=name][,addr=addr][,vectors=v]：创建一个新的网卡设备并连接至vlan n中；PC架构上默认的NIC为e1000，macaddr用于为其指定MAC地址，name用于指定一个在监控时显示的网上设备名称；emu可以模拟多个类型的网卡设备，如virtio、i82551、i82557b、i82559er、ne2k_isa、pcnet、rtl8139、e1000、smc91c111、lance及mcf_fec等；不过，不同平台架构上，其支持的类型可能只包含前述列表的一部分，可以使用“qemu-kvm -net nic,model=?”来获取当前平台支持的类型；👉🏾 -net tap[,vlan=n][,name=name][,fd=h][,ifname=name][,script=file][,downscript=dfile]：通过物理机的TAP网络接口连接至vlan n中，使用script=file指定的脚本(默认为/etc/qemu-ifup)来配置当前网络接口，并使用downscript=file指定的脚本(默认为/etc/qemu-ifdown)来撤消接口配置；使用script=no和downscript=no可分别用来禁止执行脚本；注意: 默认mac 地址均为: 52:54:00:12:34:56，使用中需要手动指定。👉🏾 -net user[,option][,option][,...]：在用户模式配置网络栈，其不依赖于管理权限；有效选项有：👉🏾 vlan=n：连接至vlan n，默认n=0；👉🏾 name=name：指定接口的显示名称，常用于监控模式中；👉🏾 net=addr[/mask]：设定GuestOS可见的IP网络，掩码可选，默认为10.0.2.0/8；👉🏾 host=addr：指定GuestOS中看到的物理机的IP地址，默认为指定网络中的第二个，即x.x.x.2；👉🏾 dhcpstart=addr：指定DHCP服务地址池中16个地址的起始IP，默认为第16个至第31个，即x.x.x.16-x.x.x.31；👉🏾 dns=addr：指定GuestOS可见的dns服务器地址；默认为GuestOS网络中的第三个地址，即x.x.x.3；👉🏾 tftp=dir：激活内置的tftp服务器，并使用指定的dir作为tftp服务器的默认根目录；👉🏾 bootfile=file：BOOTP文件名称，用于实现网络引导GuestOS；如：qemu -hda linux.img -boot n -net user,tftp=/tftpserver/pub,bootfile=/pxelinux.0brctl addbr br0brctl addif br0 eth0brctl addbr br1 kvm的网络模型: 1、隔离模型: 在host 创建一个vswitch (bridge device): 每个虚拟机的tap设备直接添加至vswitch上;2、路由模型:激活tap,并将其加入到指定的bridge,给虚拟的brige添加地址，打开核心转发;3、NAT模型:激活tap,并将其加入到指定的bridge; 额外: 打开核心转发，并添加到nat规则;4、桥接模型:激活tap,并将其加入到指定的bridge; 安装示例 123456# qemu-kvm -name &quot;rhel5.8&quot; -m 512 \-smp 2 -boot d \-drive file=/VM/images/rhel5.8/hda,if=virtio,index=0,media=disk,format=qcow2 \-drive file=/isos/rhel-5.8.iso,index=1,media=cdrom \-net nic,model=virtio,macaddr=52:54:00:A5:41:1E \-vga cirrus -balloon virtio 12# qemu-img create /images/centos/centos6.img -o size=120G, preallocation=metadata -f qcow2# qemu-kvm -m 512 -smp 2 -name centos -drive file=/images/centos/centos6.img,media=disk,if=virtio -net nic,model=virtio,macaddr=52:54:00:55:31:18 -net tap,ifname=centos6.0,script=/etc/qemu-ifup -boot order=nc, once=n libvirt 工具栈支持的虚拟化技术: KVM, XEN, VMAWARE, Qemu, LXC, OpenVZ; 安装:CentOS6yum install libvirt libvirt-client python-virtinst virt-managerCentOS7yum install libvirt libvirt-client virt-install virt-manager 12libvirt: 工具实现虚拟机管理： 装系统：virt-manager, virt-install, virsh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162使用virt-install创建虚拟机并安装GuestOSvirt-install是一个命令行工具，它能够为KVM、Xen或其它支持libvrit API的hypervisor创建虚拟机并完成GuestOS安装；此外，它能够基于串行控制台、VNC或SDL支持文本或图形安装界面。安装过程可以使用本地的安装介质如CDROM，也可以通过网络方式如NFS、HTTP或FTP服务实现。对于通过网络安装的方式，virt-install可以自动加载必要的文件以启动安装过程而无须额外提供引导工具。当然，virt-install也支持PXE方式的安装过程，也能够直接使用现有的磁盘映像直接启动安装过程。virt-install命令有许多选项，这些选项大体可分为下面几大类，同时对每类中的常用选项也做出简单说明。👉🏾 一般选项：指定虚拟机的名称、内存大小、VCPU个数及特性等；👉🏾 -n NAME, --name=NAME：虚拟机名称，需全局惟一；👉🏾 -r MEMORY, --ram=MEMORY：虚拟机内在大小，单位为MB；👉🏾 --vcpus=VCPUS[,maxvcpus=MAX][,sockets=#][,cores=#][,threads=#]：VCPU个数及相关配置；👉🏾 --cpu=CPU：CPU模式及特性，如coreduo等；可以使用qemu-kvm -cpu ?来获取支持的CPU模式；👉🏾安装方法：指定安装方法、GuestOS类型等；👉🏾 -c CDROM, --cdrom=CDROM：光盘安装介质；👉🏾 -l LOCATION, --location=LOCATION：安装源URL，支持FTP、HTTP及NFS等，如ftp://172.16.0.1/pub；👉🏾 --pxe：基于PXE完成安装；👉🏾 --livecd: 把光盘当作LiveCD；👉🏾 --os-type=DISTRO_TYPE：操作系统类型，如linux、unix或windows等；👉🏾 --os-variant=DISTRO_VARIANT：某类型操作系统的变体，如rhel5、fedora8等；👉🏾 -x EXTRA, --extra-args=EXTRA：根据--location指定的方式安装GuestOS时，用于传递给内核的额外选项，例如指定kickstart文件的位置，--extra-args &quot;ks=http://172.16.0.1/class.cfg&quot;👉🏾 --boot=BOOTOPTS：指定安装过程完成后的配置选项，如指定引导设备次序、使用指定的而非安装的kernel/initrd来引导系统启动等 ；例如：👉🏾 --boot cdrom,hd,network：指定引导次序；👉🏾 --boot kernel=KERNEL,initrd=INITRD,kernel_args=”console=/dev/ttyS0”：指定启动系统的内核及initrd文件；👉🏾 存储配置：指定存储类型、位置及属性等；👉🏾 --disk=DISKOPTS：指定存储设备及其属性；格式为--disk /some/storage/path,opt1=val1，opt2=val2等；常用的选项有：👉🏾 device：设备类型，如cdrom、disk或floppy等，默认为disk；👉🏾 bus：磁盘总结类型，其值可以为ide、scsi、usb、virtio或xen；👉🏾 perms：访问权限，如rw、ro或sh（共享的可读写），默认为rw；👉🏾 size：新建磁盘映像的大小，单位为GB；👉🏾 cache：缓存模型，其值有none、writethrouth（缓存读）及writeback（缓存读写）；👉🏾 format：磁盘映像格式，如raw、qcow2、vmdk等；👉🏾 sparse：磁盘映像使用稀疏格式，即不立即分配指定大小的空间；👉🏾 --nodisks：不使用本地磁盘，在LiveCD模式中常用；👉🏾网络配置：指定网络接口的网络类型及接口属性如MAC地址、驱动模式等；👉🏾 -w NETWORK, --network=NETWORK,opt1=val1,opt2=val2：将虚拟机连入宿主机的网络中，其中NETWORK可以为：👉🏾 bridge=BRIDGE：连接至名为“BRIDEG”的桥设备；👉🏾 network=NAME：连接至名为“NAME”的网络；其它常用的选项还有：👉🏾 model：GuestOS中看到的网络设备型号，如e1000、rtl8139或virtio等；👉🏾 mac：固定的MAC地址；省略此选项时将使用随机地址，但无论何种方式，对于KVM来说，其前三段必须为52:54:00；👉🏾 --nonetworks：虚拟机不使用网络功能；👉🏾 图形配置：定义虚拟机显示功能相关的配置，如VNC相关配置；👉🏾 --graphics TYPE,opt1=val1,opt2=val2：指定图形显示相关的配置，此选项不会配置任何显示硬件（如显卡），而是仅指定虚拟机启动后对其进行访问的接口；👉🏾 TYPE：指定显示类型，可以为vnc、sdl、spice或none等，默认为vnc；👉🏾 port：TYPE为vnc或spice时其监听的端口；👉🏾 listen：TYPE为vnc或spice时所监听的IP地址，默认为127.0.0.1，可以通过修改/etc/libvirt/qemu.conf定义新的默认值；👉🏾 password：TYPE为vnc或spice时，为远程访问监听的服务进指定认证密码；👉🏾 --noautoconsole：禁止自动连接至虚拟机的控制台；👉🏾 设备选项：指定文本控制台、声音设备、串行接口、并行接口、显示接口等；👉🏾 --serial=CHAROPTS：附加一个串行设备至当前虚拟机，根据设备类型的不同，可以使用不同的选项，格式为“--serial type,opt1=val1,opt2=val2,...”，例如：👉🏾 --serial pty：创建伪终端；👉🏾 --serial dev,path=HOSTPATH：附加主机设备至此虚拟机；👉🏾 --video=VIDEO：指定显卡设备模型，可用取值为cirrus、vga、qxl或vmvga；👉🏾 虚拟化平台：虚拟化模型（hvm或paravirt）、模拟的CPU平台类型、模拟的主机类型、hypervisor类型（如kvm、xen或qemu等）以及当前虚拟机的UUID等；👉🏾 -v, --hvm：当物理机同时支持完全虚拟化和半虚拟化时，指定使用完全虚拟化；👉🏾 -p, --paravirt：指定使用半虚拟化；👉🏾 --virt-type：使用的hypervisor，如kvm、qemu、xen等；所有可用值可以使用’virsh capabilities’命令获取；👉🏾 其它：👉🏾 --autostart：指定虚拟机是否在物理启动后自动启动；👉🏾 --print-xml：如果虚拟机不需要安装过程(--import、--boot)，则显示生成的XML而不是创建此虚拟机；默认情况下，此选项仍会创建磁盘映像；👉🏾 --force：禁止命令进入交互式模式，如果有需要回答yes或no选项，则自动回答为yes；👉🏾 --dry-run：执行创建虚拟机的整个过程，但不真正创建虚拟机、改变主机上的设备配置信息及将其创建的需求通知给libvirt；👉🏾 -d, --debug：显示debug信息；尽管virt-install命令有着类似上述的众多选项，但实际使用中，其必须提供的选项仅包括--name、--ram、--disk（也可是--nodisks）及安装过程相关的选项。此外，有时还需要使用括--connect=CONNCT选项来指定连接至一个非默认的hypervisor。 1# virt-install -n centos6.7 -r 512 -vcpus=2, maxvcpus=4 --pxe --disk /images/centos/centos6.7.qcow2,size=120,format=qcow2,bus=virtio,spare=yes --network bridge=br0,model-virtio --force 生产示例 1virt-install --name testwinserver --memory 6144 --vcpus 2 --disk device=cdrom,path=/kvmiso/cn_windows_server_2016_x64_dvd_9718765.iso --disk device=cdrom,path=/usr/share/virtio-win/virtio-win.iso --disk path=/kvmdata/testwinserver.img,size=300,bus=virtio --network bridge=br-ext,model=virtio --noautoconsole --accelerate --hvm --graphics vnc,listen=0.0.0.0 --video vga --input tablet,bus=usb --os-type=windows --check path_in_use=off]]></content>
      <tags>
        <tag>linux</tag>
        <tag>cloud</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes操作记录(七)]]></title>
    <url>%2F2019%2F06%2F15%2Fkubernetes%E6%93%8D%E4%BD%9C%E8%AE%B0%E5%BD%957%2F</url>
    <content type="text"><![CDATA[kubernetes 操作记录七 资源指标API及自定义指标API资源指标: metrics-server自定义指标: prometheus, k8s-prometheus-adapter 新一代架构: 核心指标流水线：由kubelet、metrics-server 以及由API server 提供的api组成;CPU、内存实时使用率、Pod的资源占用率及窗口的磁盘占用率; 监控流水线: 用于从系统收集各种指标数据并提供终端用户、存储系统以及HPA。它们包含核心指标及许多非核心指标。非核心指标本身不能被k8s所解析; metrics-server: API server 部署 metrics-server1234# mkdir metrics-server# wget https://github.com/kubernetes-incubator/metrics-server/archive/v0.3.1.zip # cd metrics-server/metrics-server-0.3.1/deploy/1.8+/# mv * ../../../ 问题修正 问题1：metrics-server默认使用节点hostname通过kubelet 10250端口获取数据，但是coredns里面没有该数据无法解析(10.96.0.10:53)，可以在metrics server启动命令添加参数 –kubelet-preferred-address-types=InternalIP 直接使用节点IP地址获取数据 问题2：kubelet 的10250端口使用的是https协议，连接需要验证tls证书。可以在metrics server启动命令添加参数–kubelet-insecure-tls不验证客户端证书 问题3：yaml文件中的image地址k8s.gcr.io/metrics-server-amd64:v0.3.0 需要梯子，需要改成中国可以访问的image地址，可以使用aliyun的 registry.cn-hangzhou.aliyuncs.com/google_containers/ 修改以下内容 12345678910111213containers: - name: metrics-server #image: k8s.gcr.io/metrics-server-amd64:v0.3.0 image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server-amd64:v0.3.0 imagePullPolicy: IfNotPresent command: - /metrics-server - --metric-resolution=30s - --kubelet-insecure-tls - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP volumeMounts: - name: tmp-dir mountPath: /tmp 12# kubectl api-versions | grep metricsmetrics.k8s.io/v1beta1 12345678910111213141516171819202122232425262728# curl http://localhost:8080/apis/metrics.k8s.io/v1beta1&#123; "kind": "APIResourceList", "apiVersion": "v1", "groupVersion": "metrics.k8s.io/v1beta1", "resources": [ &#123; "name": "nodes", "singularName": "", "namespaced": false, "kind": "NodeMetrics", "verbs": [ "get", "list" ] &#125;, &#123; "name": "pods", "singularName": "", "namespaced": true, "kind": "PodMetrics", "verbs": [ "get", "list" ] &#125; ]&#125; 错误日志排查 1# kubectl logs -f metrics-server-68cdb458db-rgjtr -c metrics-server -n kube-system 主要提供node 和Pod的监控数据; 123456kubectl top nodesNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%node01 94m 4% 1574Mi 42%node02 92m 4% 1901Mi 51%node03 108m 5% 1803Mi 48%master 238m 11% 1879Mi 50% prometheus 部署12345678910111213# git clone https://github.com/iKubernetes/k8s-prom.git# cd k8s-prom# kubectl apply -f namespace.yaml# cd node_exporter/# kubectl apply -f ./# kubectl get pods -n promNAME READY STATUS RESTARTS AGEprometheus-node-exporter-2xrqp 1/1 Running 0 47sprometheus-node-exporter-cgkp7 1/1 Running 0 47sprometheus-node-exporter-t7vh7 1/1 Running 0 47sprometheus-node-exporter-vrw89 1/1 Running 0 46s# cd ../prometheus/# kubectl apply -f ./ 注: 在生产环境中，至少要用pv存储，不然当Pod删除时，数据也会被删除; 安装 kube-state-metrics12345# cd ../kube-state-metrics/# vim kube-state-metrics-deploy.yaml # 修改image镜像源image: quay.io/coreos/kube-state-metrics:v1.3.1# kubectl apply -f ./# kubectl get all -n prom 安装 k8s-prometheus-adapter12345678# /etc/kubernetes/pki/# (umask 077; openssl genrsa -out serving.key 2048)# openssl req -new -key serving.key -out serving.csr -subj &quot;/CN=serving&quot;# openssl x509 -req -in serving.csr -CA ./ca.crt -CAkey ./ca.key -CAcreateserial -out serving.crt -days 36500# kubectl create generic cm-adapter-serving-certs --from-file=serving.crt --from-file=serving.key# kubectl create secret generic cm-adapter-serving-certs --from-file=serving.crt --from-file=serving.key -n prom# cd manifests/metrics/k8s-prom/k8s-prometheus-adapter# kubectl apply -f ./ 发现k8s-prometheus-adapter中的custom-metrics-apiserver-deployment.yaml 配置变了，这里可以根据原有内容 image: directxman12/k8s-prometheus-adapter-amd64 google搜索directxman12更新 12345# mv custom-metrics-apiserver-deployment.yaml&#123;,.bak&#125;# wget https://raw.githubusercontent.com/DirectXMan12/k8s-prometheus-adapter/master/deploy/manifests/custom-metrics-apiserver-deployment.yaml# vim custom-metrics-apiserver-deployment.yaml # 改namespace: prom # wget https://raw.githubusercontent.com/DirectXMan12/k8s-prometheus-adapter/master/deploy/manifests/custom-metrics-config-map.yaml# vim custom-metrics-config-map.yaml # 改namespace: prom 123456789# kubectl get all -n promNAME READY STATUS RESTARTS AGEpod/custom-metrics-apiserver-667fd4fffd-qs2zk 1/1 Running 0 3m18spod/kube-state-metrics-6697d66bbb-w7k4d 1/1 Running 0 20mpod/prometheus-node-exporter-2xrqp 1/1 Running 0 71mpod/prometheus-node-exporter-cgkp7 1/1 Running 0 71mpod/prometheus-node-exporter-t7vh7 1/1 Running 0 71mpod/prometheus-node-exporter-vrw89 1/1 Running 0 71mpod/prometheus-server-75cf46bdbc-kpgzs 1/1 Running 0 69m 补充kubelet 启动失败 swapoff -a新入新节点时卡住 kubeadm token create kubeadm token list 1# curl http://localhost:8080/apis/custom.metrics.k8s.io/v1beta1 安装 grafana改原grafana 配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980apiVersion: apps/v1kind: Deploymentmetadata: name: monitoring-grafana namespace: promspec: replicas: 1 selector: matchLabels: task: monitoring k8s-app: grafana template: metadata: labels: task: monitoring k8s-app: grafana spec: containers: - name: grafana image: registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-grafana-amd64:v5.0.4 ports: - containerPort: 3000 protocol: TCP volumeMounts: - mountPath: /etc/ssl/certs name: ca-certificates readOnly: true - mountPath: /var name: grafana-storage env: #- name: INFLUXDB_HOST # value: monitoring-influxdb - name: GF_SERVER_HTTP_PORT value: "3000" # The following env variables are required to make Grafana accessible via # the kubernetes api-server proxy. On production clusters, we recommend # removing these env variables, setup auth for grafana, and expose the grafana # service using a LoadBalancer or a public IP. - name: GF_AUTH_BASIC_ENABLED value: "false" - name: GF_AUTH_ANONYMOUS_ENABLED value: "true" - name: GF_AUTH_ANONYMOUS_ORG_ROLE value: Admin - name: GF_SERVER_ROOT_URL # If you're only using the API Server proxy, set this value instead: # value: /api/v1/namespaces/kube-system/services/monitoring-grafana/proxy value: / volumes: - name: ca-certificates hostPath: path: /etc/ssl/certs - name: grafana-storage emptyDir: &#123;&#125;---apiVersion: v1kind: Servicemetadata: labels: # For use as a Cluster add-on (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons) # If you are NOT using this as an addon, you should comment out this line. kubernetes.io/cluster-service: 'true' kubernetes.io/name: monitoring-grafana name: monitoring-grafana namespace: promspec: # In a production setup, we recommend accessing Grafana through an external Loadbalancer # or through a public IP. # type: LoadBalancer # You could also use NodePort to expose the service at a randomly-generated port # type: NodePort type: NodePort ports: - port: 80 targetPort: 3000 nodePort: 30098 protocol: TCP selector: k8s-app: grafana# kubectl apply -f grafana.yaml 下载并导入模版 资源限制与伸缩12345678# kubectl run myapp --image=ikubernetes/myapp:v1 --replicas=0 --requests='cpu=50m,memory=256Mi' --limits='cpu=50m,memory=256Mi' --labels='app=myapp' --expose --port=80# kubectl autoscale deployment myapp --min=1 --max=8 --cpu-percent=60horizontalpodautoscaler.autoscaling/myapp autoscaled# kubectl get hpaNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEmyapp Deployment/myapp 0%/60% 1 8 1 22s# kubectl patch svc myapp -p '&#123;"spec":&#123;"type": "NodePort"&#125;&#125;'service/myapp patched 1#ssjinyao ➤ ab -c 100 -n 50000 http://xx.x.xx.xx:31257/index.html 当压测，CPU 内存资源超出时，会扩展Pod数目 1234567891011121314151617181920apiVersion: autoscaling/v2beta1kind: HorizontalPodAutoscalermetadata: name: myapp-hpa-v2spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: myapp minReplicas: 1 maxReplicas: 10 metrics: - type: Resource resource: name: cpu targetAverageUtilization: 55 - type: Resource resource: name: memory targetAverageValue: 50Mi 根据请求数升Pod数 12345678910111213141516apiVersion: autoscaling/v2beta1kind: HorizontalPodAutoscalermetadata: name: myapp-hpa-v2spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: myapp minReplicas: 1 maxReplicas: 10 metrics: - type: Pods pods: metricName: http_requests targetAverageValue: 800m helm 入门核心术语: Chart: 一个helm程序包; Repository: Charts仓库,https/http服务器; Release:特定的Chart部署于目标集群上的一个实例; Chart -&gt; Config -&gt; Release程序架构: helm：客户端，管理本地的Chart仓库，管理Chart，与Tiller服务器交互，发送Chart,实例安装、查询、卸载等操作 Tiller: 服务端 ，接收helm发来的Chart与Config,合并生成release; helm github官网 安装helm123# wget https://get.helm.sh/helm-v2.9.1-linux-amd64.tar.gz# mv linux-amd64/helm /usr/sbin/# helm 要使用helm 还需要安装 Tillerhelm 会识别 .kube/config 扮演成kubectl 客户端去连接至kubernetes集群 安装 TillerClusterRoleBinding RBAC配置文件 12345678910111213141516171819202122# mkdir helm# cd helm/# vim tiller-rbac.yamlapiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system# kubectl apply -f tiller-rbac.yaml 1# helm init --service-account tiller 报错与处理 1234567891011# helm init --service-account tillerCreating /root/.helmCreating /root/.helm/repositoryCreating /root/.helm/repository/cacheCreating /root/.helm/repository/localCreating /root/.helm/pluginsCreating /root/.helm/startersCreating /root/.helm/cache/archiveCreating /root/.helm/repository/repositories.yamlAdding stable repo with URL: https://kubernetes-charts.storage.googleapis.comError: Looks like "https://kubernetes-charts.storage.googleapis.com" is not a valid chart repository or cannot be reached: Get https://kubernetes-charts.storage.googleapis.com/index.yaml: read tcp 10.1.87.80:41084-&gt;172.217.163.240:443: read: connection reset by peer 添加国内源 1# helm init --client-only --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts 如果报如下错误，请按照下面解决 12Error: Couldn't load repositories file (/home/docker/.helm/repository/repositories.yaml).You might need to run `helm init` (or `helm init --client-only` if tiller is already installed) 解决办法 1helm init --client-only --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts –stable-repo-url 指定下载软件从那个源下载，默认的是从google下载，国内下载不下来，所以我们指定源为阿里云的源。 下载完之后我们还把源更换回来，要不然后面会报错 1# helm repo add rancher-stable https://releases.rancher.com/server-charts/stable 123# helm init --service-account tiller --tiller-image \registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.12.3 \--stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts 更新 helm 源 123456# helm repo updateHang tight while we grab the latest from your chart repositories......Skip local chart repository...Successfully got an update from the "stable" chart repository...Successfully got an update from the "rancher-stable" chart repositoryUpdate Complete. ⎈ Happy Helming!⎈ helm 官方可用的Chart列表 1234# helm search jenkins # 搜索应用# helm inspect stable/jenkins # 查看使用配置信息# helm install --name mem1 stable/memcached # 安装Memcached# kubectl get pods --namespace default -l "app=mem1-memcached" -o jsonpath="&#123;.items[0].metadata.name&#125;" mem1-memcached-0 #验证 helm 常用命令release 管理 123456insstalldeleteupgrade/rollbacklisthistorystatus 获取release 状态信息 chart 管理 123456cratefetch get inspectpackageverify chart get 到本地路径 /root/.helm/cache/archive 根据自定义变量创建 12# helm install --name redis1 -f values.yaml stable/redis# helm status redis1 # 再次显示NOTES 部署EFK 日志系统部署elasticsearchEFK: Fluentd 在容器集群岩调，再接入Pod查询日志是不可能的，所以必要的有一个统一的日志收集系统;一个完整的kubernetes系统应该有:kubedns or coredns ,ingress-contraler,heapster or metracs server prometheus , dashboard 。而EFK是一个kubernetes基本上需要提供的完整组件; 添加helm源 123# helm repo add extra https://burdenbear.github.io/kube-charts-mirror/# helm repo add stable http://mirror.azure.cn/kubernetes/charts/ # helm repo add incubator http://mirror.azure.cn/kubernetes/charts-incubator/ 12345678910111213141516171819# helm fetch stable/elasticsearch# helm fetch stable/fluentd-elasticsearch# helm fetch stable/kibana# tar -xvf elasticsearch-1.28.5.tgz# tar -xvf fluentd-elasticsearch-2.0.7.tgz# tar -xvf kibana-3.1.0.tgz# cd elasticsearch# vim values.yaml # 修改以下内容 pullPolicy: "IfNotPresent" persistence: enabled: false# kubectl create namespace efk# helm package elasticsearch/# 新开启一个终端# helm serveRegenerating index. This may take a moment.Now serving you on 127.0.0.1:8879# helm install --name els1 --namespace=efk local/elasticsearch 测试 12345678910111213141516171819202122232425262728293031# kubectl run cirror-$RANDOM --rm -it --image=cirros -- /bin/sh/ # nslookup els1-elasticsearch-client.efk.svcServer: 10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localName: els1-elasticsearch-client.efk.svcAddress 1: 10.111.159.57 els1-elasticsearch-client.efk.svc.cluster.localcurl els1-elasticsearch-client.efk.svc.cluster.local:9200&#123; "name" : "els1-elasticsearch-client-787568fb55-9zd9k", "cluster_name" : "elasticsearch", "cluster_uuid" : "_na_", "version" : &#123; "number" : "6.4.3", "build_flavor" : "default", "build_type" : "tar", "build_hash" : "fe40335", "build_date" : "2018-10-30T23:17:19.084789Z", "build_snapshot" : false, "lucene_version" : "7.4.0", "minimum_wire_compatibility_version" : "5.6.0", "minimum_index_compatibility_version" : "5.0.0" &#125;, "tagline" : "You Know, for Search"&#125;/ # curl els1-elasticsearch-client.efk.svc.cluster.local:9200/_cat/nodes10.244.1.215 15 90 7 0.12 0.36 0.35 di - els1-elasticsearch-data-110.244.2.132 19 60 2 0.09 0.23 0.19 di - els1-elasticsearch-data-010.244.1.213 22 90 7 0.12 0.36 0.35 i - els1-elasticsearch-client-787568fb55-9zd9k10.244.2.131 26 60 2 0.09 0.23 0.19 i - els1-elasticsearch-client-787568fb55-sxhhp10.244.1.214 44 90 7 0.12 0.36 0.35 mi * els1-elasticsearch-master-0 部署 fluentd12345678910111213141516171819202122232425# cd fluentd-elasticsearch/ # vim values.yamlimage: repository: registry.cn-hangzhou.aliyuncs.com/google_containers/fluentd-elasticsearchelasticsearch: host: 'els1-elasticsearch-client.efk.svc.cluster.local' port: 9200 scheme: 'http' ssl_version: TLSv1_2 buffer_chunk_limit: 2M buffer_queue_limit: 8 logstash_prefix: 'logstash'tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedulepodAnnotations: prometheus.io/scrape: "true" prometheus.io/port: "24231"service: type: ClusterIP ports: - name: "monitor-agent" port: 24231 12# helm package ../fluentd-elasticsearch/# helm install --name flu1 --namespace=efk local/fluentd-elasticsearch 安装 kibana1234567891011121314151617181920212223242526# cd kibana# vim values.yaml # 修改以下内容 elasticsearch.hosts: http://els1-elasticsearch-client.efk.svc.cluster.local:9200 service: type: NodePort# helm package ../kibana/# helm install --name kibana1 --namespace=efk local/kibana# kubectl get pods -n efkNAME READY STATUS RESTARTS AGEels1-elasticsearch-client-6b4b8c7485-7grbt 1/1 Running 0 96mels1-elasticsearch-client-6b4b8c7485-sqgtl 1/1 Running 0 96mels1-elasticsearch-data-0 1/1 Running 0 96mels1-elasticsearch-data-1 1/1 Running 0 78mels1-elasticsearch-master-0 1/1 Running 0 96mels1-elasticsearch-master-1 1/1 Running 0 93mels1-elasticsearch-master-2 1/1 Running 0 78mflu1-fluentd-elasticsearch-95b95 1/1 Running 0 26mflu1-fluentd-elasticsearch-vpcsg 1/1 Running 0 26mflu1-fluentd-elasticsearch-w5wjj 1/1 Running 0 26mflu1-fluentd-elasticsearch-xkpv2 1/1 Running 0 26mkibana1-5dcf5f5d47-rsmqb 1/1 Running 0 21m# kubectl get svc -n efkNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEels1-elasticsearch-client ClusterIP 10.98.8.75 &lt;none&gt; 9200/TCP 97mels1-elasticsearch-discovery ClusterIP None &lt;none&gt; 9300/TCP 97mkibana1 NodePort 10.96.230.3 &lt;none&gt; 443:31746/TCP 21m docker pull 报错信息总结error pulling image configuration 1234# echo &quot;DOCKER_OPTS=\&quot;\$DOCKER_OPTS --registry-mirror=http://f2d6cb40.m.daocloud.io\&quot;&quot; | tee -a /etc/default/docker# 或者 vim /etc/default/docker 更改以下信息DOCKER_OPTS=&quot;$&#123;DOCKER_OPTS&#125; --registry-mirror=https://mirror.gcr.io&quot;# systemctl restart docker 配置并访问kibana]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes操作记录(六)]]></title>
    <url>%2F2019%2F05%2F30%2Fkubernetes%E6%93%8D%E4%BD%9C%E8%AE%B0%E5%BD%956%2F</url>
    <content type="text"><![CDATA[kubernetes 操作记录六 调度器、预选策略及优选函数整个调度大致可以分为三个过程: Predicate(预先) –&gt; Priority(优选) –&gt; Select(选定) 调度器: 预选策略: CheckNodeCondition: 检查节点本身是否正常; GeneralPredicates: HostName: 检查Pod对象是否定义了 pod.spec.hostname, PodFitsHostPorts:pods.spec.containers.ports.hostPort MatchNodeSelector: pods.sepc.nodeSelector PodFitsResources: 检查Pod的资源需求是否能被节点的需求所满足 NoDiskConflicts:检查Pod依赖的存储卷是否能满足需求; PodToleratesNodeTaints: 检查Pod上的spec.tolerations可容忍的污点是否完全包含节点上的污点; PodToleratesNodeNoExecuteTaints: 不能执行的污点,这个预选策略默认是不检查的; CheckNodeLabelPresence: 检查节点指定标签的存在性; CheckServiceAffinity: 把这个Pod调度到它所属的Service,已经调度完成其它Pod所在的节点上去; MaxEBSVolumeCount: MaxGCEPDVolumeCount: MaxAzureDiskVolumeCount: CheckVolumeBinding: NoVolumeZoneConflict: CheckNodeMemoryPressure:检查节点内存资源是否处于压力过大的状态; CheckNodePidPressure:检查PId状态是否紧缺; CheckNodeDiskPressure: MatchInterPodAffity: 优选函数 LeastRequested: (cpu(capacity-sum(requested))*10/capacity)+memory((capacity-sum(requested))*10/capacity))/2 BalancedResourceAllocation: CPU和内存资源被占用率相近的胜出; NodePreferAvoidPods: 节点注解信息”scheduler .alpha.kubernetes.io/preferAvoidPods” TaintToleration: 将Pod对象的spec.tolerations列表项与节点的taints列表项进行匹配度检查，匹配条目越多，得分越低; SelectorSpreading: 标签选择器的分散度，与当前Pod对象同属的标签选择器，选择适配的其它Pod的对象所在的节点，越多的，得分越底，否则得分越高; InterPodAffinity: 遍历Pod的亲和性条目，并将那些能够匹配到给定节点的条目相加，结果值越大，得分越低; NodeAffinity: 根据NodeSelecter进行匹配度检查，能成功匹配的越多，得分就越高; MostRequested: 空闲量越小的，得分越大。他会尽量把一个节点的资源先用完; NodeLabel: 标签越多，得分越高; ImageLocality: 此节点是否有此Pod 所需要的镜像，拥有镜像越多的，得分越高，而它是根据镜像体积大小之和来计算的; kubernetes 高级调度方式节点选择器: nodeSelector, nodeName节点亲和性调度: nodeAffinity 注: 当调度选择器选择了不存的标签时，Pod 会成为Pending状态 nodeSelector: disktype: harddisk 节点亲和性调度; 硬亲和 12345678910111213141516171819202122# vim pod-nodeaffinity-demo.yamlapiVersion: v1kind: Podmetadata: name: pod-node-affinity-demo labels: app: myapp tier: frontendspec: containers: - name: myapp image: ikubernetes/myapp:v1 affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: zone operator: In values: - foo - bar 软亲和 1234567891011121314151617181920212223# vIm pod-nodeaffinity-demo-2.yamlapiVersion: v1kind: Podmetadata: name: pod-node-affinity-demo-2 labels: app: myapp tier: frontendspec: containers: - name: myapp image: ikubernetes/myapp:v1 affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - preference: matchExpressions: - key: zone operator: In values: - foo - bar weight: 60 123456789101112131415161718192021222324252627282930313233# vim pod-required-affinity-demo.yamlapiVersion: v1kind: Podmetadata: name: pod-first labels: app: myapp tier: frontendspec: containers: - name: myapp image: ikubernetes/myapp:v1---apiVersion: v1kind: Podmetadata: name: pod-second labels: app: backend tier: dbspec: containers: - name: busybox image: busybox:latest imagePullPolicy: IfNotPresent command: ["sh","-c","sleep 3600"] affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - &#123;key: app, operator: In, values: ["myapp"]&#125; topologyKey: kubernetes.io/hostname 注: podAntiAffinity 一定不会调度到同一节点上 taint 的effect定义对Pod排斥效果: NoSchedule: 仅影响调度过程，对现存的Pod对象不产生影响; NoExecute: 既影响调度过程，也影响现存的Pod对象; 不容忍的Pod对象将被驱逐; PreferNoSchedule: 12# kubectl taint node node01 node-type=production:NoSchedule# kubectl taint node node02 node-type=dev:NoExecute 12345678910111213141516171819202122232425262728apiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deploy namespace: defaultspec: replicas: 5 selector: matchLabels: app: myapp release: canary template: metadata: labels: app: myapp release: canary spec: containers: - name: myapp image: ikubernetes/myapp:v2 ports: - name: http containerPort: 80 tolerations: - key: "node-type" operator: "Equal" value: "production" effect: "NoSchedule" 123456tolerations:- key: "node-type" operator: "Equal" value: "production" effect: "NoExecute" tolerationSeconds: 3600 12345tolerations:- key: "node-type" operator: "Exists" value: "" effect: "NoExecute" 容器资源需求、限制、及HeapSterrequests: 需求，最低保障;limits: 限制，硬限制;limits 一般大于等于 requests CPU: 1颗逻辑CPU 1逻辑核心=1000,millicores 500m = 0.5CPU内存: E、P、T、G、M、K Ei、Pi 取消节点污点 1# kubectl taint node node01 node-type- 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: pod-demo namespace: renjin labels: app: myapp tier: frontendspec: containers: - name: myapp image: ikubernetes/stress-ng command: ["/usr/bin/stress-ng", "-c 1", "--metrics-brief"] resources: requests: cpu: "500m" memory: "128Mi" limits: cpu: "500m" memory: "512Mi" QoS: Guranteed: 每个容器同时设置CPU和内在的requests和limits, cpu.limits=cpu.requests memory.limits=memory.request Burstable:至少有一个容器设置CPU或内存资源的requests BestEffort: 没有任何一个容器设置了requests或limits属性;最低优先级别; 是自动配置的; 配置influxdb12345678910111213141516 # wget https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/influxdb.yaml # 更改以下内容 apiVersion: apps/v1 spec: replicas: 1 selector: matchLabels: task: monitoring k8s-app: influxdb spec: containers: - name: influxdb image: registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-influxdb-amd64:v1.5.2# kubectl apply -f influxdb.yaml 配置heapster-rbac12# wget https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml# kubectl apply -f heapster-rbac.yaml 配置heapster12345678910111213141516# wget https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/heapster.yaml# 修改以下内容apiVersion: apps/v1spec: replicas: 1 selector: matchLabels: task: monitoring k8s-app: heapsterimage: registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-amd64:v1.5.4spec: ports: - port: 80 targetPort: 8082 type: NodePort# kubectl apply -f heapster.yaml 123456# kubectl get svc -n kube-systemNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEheapster NodePort 10.101.89.141 &lt;none&gt; 80:31261/TCP 63skube-dns ClusterIP 10.96.0.10 &lt;none&gt; 53/UDP,53/TCP,9153/TCP 48dkubernetes-dashboard NodePort 10.103.25.80 &lt;none&gt; 443:30660/TCP 21dmonitoring-influxdb ClusterIP 10.103.131.36 &lt;none&gt; 8086/TCP 153m 看下图说明，heapster此时可以调通 grafana配置123456789101112131415# wget https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/grafana.yaml# vim grafana.yaml # 修改以下内容apiVersion: apps/v1spec: replicas: 1 selector: matchLabels: task: monitoring k8s-app: grafana image: registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-grafana-amd64:v5.0.4 ports: - port: 80 targetPort: 3000 type: NodePort# kubectl apply -f grafana.yaml]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes操作记录(五)]]></title>
    <url>%2F2019%2F05%2F24%2Fkubernetes%E6%93%8D%E4%BD%9C%E8%AE%B0%E5%BD%955%2F</url>
    <content type="text"><![CDATA[kubernetes 操作记录五 配置网络插件flannel在Kubernetes集群中要解决四种通信的问题;Kubernetes网络通信: (1) 容器间通信: 同一个Pod内的多个容器间的通信，lo (2) Pod通信: Pod IP &lt;–&gt; Pod IP (3) Pod与 Service通信: PodIP &lt;–&gt; ClusterIP,不在同一网段，通过iptables规则实现通信 (4) Service 与集群外部客户端的通信;CNI: (Container Network Interface) flannel,calico,canel,kube-router … 12# kubectl get configmap kube-proxy -n kube-system -o yamlmode: "" # 改为ipvs 就可以了 解决方案: 虚拟网桥: 纯软件的方式，实现一个虚拟网卡接到网桥上去; 多路复用: MacVlAN 配置多个Mac物理地址，使得一个物理网卡，可以承载多个容器去使用; 硬件交换: SR-IOV 单根IO虚拟化; kubelet, /etc/cin/net.d/ 12345678910111213141516171819# cat /etc/cni/net.d/10-flannel.conflist&#123; &quot;name&quot;: &quot;cbr0&quot;, &quot;plugins&quot;: [ &#123; &quot;type&quot;: &quot;flannel&quot;, &quot;delegate&quot;: &#123; &quot;hairpinMode&quot;: true, &quot;isDefaultGateway&quot;: true &#125; &#125;, &#123; &quot;type&quot;: &quot;portmap&quot;, &quot;capabilities&quot;: &#123; &quot;portMappings&quot;: true &#125; &#125; ]&#125; flannel: 支持多种后端 VxLAN host-gw: Host Gateway 123456789# kubectl get daemonset -n kube-systemNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEkube-flannel-ds 3 3 3 3 3 beta.kubernetes.io/arch=amd64 31dkube-flannel-ds-amd64 4 4 4 4 4 beta.kubernetes.io/arch=amd64 31dkube-flannel-ds-arm 0 0 0 0 0 beta.kubernetes.io/arch=arm 31dkube-flannel-ds-arm64 0 0 0 0 0 beta.kubernetes.io/arch=arm64 31dkube-flannel-ds-ppc64le 0 0 0 0 0 beta.kubernetes.io/arch=ppc64le 31dkube-flannel-ds-s390x 0 0 0 0 0 beta.kubernetes.io/arch=s390x 31dkube-proxy 4 4 4 4 4 &lt;none&gt; 31d 12345678# kubectl get pods -n kube-system -o wide | grep "flannel"kube-flannel-ds-amd64-45rhc 1/1 Running 2 31d 10.1.87.80 bj-zb-vm-ops-test5 &lt;none&gt; &lt;none&gt;kube-flannel-ds-amd64-4cs6r 1/1 Running 0 31d 10.1.87.83 node03 &lt;none&gt; &lt;none&gt;kube-flannel-ds-amd64-bst7g 1/1 Running 0 31d 10.1.87.81 node01 &lt;none&gt; &lt;none&gt;kube-flannel-ds-amd64-gqvz2 1/1 Running 0 31d 10.1.87.82 node02 &lt;none&gt; &lt;none&gt;kube-flannel-ds-brzp7 2/2 Running 0 31d 10.1.87.83 node03 &lt;none&gt; &lt;none&gt;kube-flannel-ds-khpr5 2/2 Running 2 31d 10.1.87.82 node02 &lt;none&gt; &lt;none&gt;kube-flannel-ds-q6z65 2/2 Running 0 31d 10.1.87.81 node01 kube-flannel-cfg 用来配置以上flannel Pod是如何运行的; flannel的配置参数: Network: flannel使用的CIDR格式的网络地址，用于为Pod的配置网络功能; 10.244.0.0/16 -&gt; master: 10.244.0.0/24 node01:10.244.1.0/24 … node255: 10.244.255.0./24 SubnetLen: 把Network切分子网供各节点使用时，使用多长的掩码进行切分，默认为24位; SubnetMin: 10.244.10.0/24 指定子网使用起始，从哪里开始; SubnetMax: 10.244.10.0/24 指定子网使用最大限制; Backend: 各Pod通信时使用什么方式进行通信: vxlan, host-gw , udp 测试 12345# kubectl get pods -o wide# kubectl get pods -o wide | grep &quot;myapp-deploy&quot;myapp-deploy-675558bfc5-947g6 1/1 Running 0 4d1h 10.244.1.173 node01 &lt;none&gt; &lt;none&gt;myapp-deploy-675558bfc5-9xfdm 1/1 Running 0 4d6h 10.244.3.176 node03 &lt;none&gt; &lt;none&gt;myapp-deploy-675558bfc5-qhl4w 1/1 Running 0 5h41m 10.244.2.195 node02 &lt;none&gt; &lt;none&gt; 接入一个容器ping另一容器的ip 1234567# kubectl exec -it myapp-deploy-675558bfc5-947g6 -- /bin/sh/ # ping 10.244.2.195PING 10.244.2.195 (10.244.2.195): 56 data bytes64 bytes from 10.244.2.195: seq=0 ttl=62 time=0.871 ms64 bytes from 10.244.2.195: seq=1 ttl=62 time=0.925 ms64 bytes from 10.244.2.195: seq=2 ttl=62 time=0.886 ms64 bytes from 10.244.2.195: seq=3 ttl=62 time=1.171 ms 在容器所在的物理服务器上抓包, 12345678910# tcpdump -i cni0 -nn icmptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on cni0, link-type EN10MB (Ethernet), capture size 262144 bytes16:52:45.457148 IP 10.244.1.173 &gt; 10.244.2.195: ICMP echo request, id 3328, seq 0, length 6416:52:45.457743 IP 10.244.2.195 &gt; 10.244.1.173: ICMP echo reply, id 3328, seq 0, length 6416:52:46.457445 IP 10.244.1.173 &gt; 10.244.2.195: ICMP echo request, id 3328, seq 1, length 6416:52:46.457948 IP 10.244.2.195 &gt; 10.244.1.173: ICMP echo reply, id 3328, seq 1, length 6416:52:47.457722 IP 10.244.1.173 &gt; 10.244.2.195: ICMP echo request, id 3328, seq 2, length 6416:52:47.458313 IP 10.244.2.195 &gt; 10.244.1.173: ICMP echo reply, id 3328, seq 2, length 6416:52:48.458036 IP 10.244.1.173 &gt; 10.244.2.195: ICMP echo request, id 3328, seq 3, length 64 12345678910# tcpdump -i flannel.1 -nntcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes17:01:13.757750 IP 10.244.1.0 &gt; 10.244.2.195: ICMP echo request, id 2, seq 37, length 6417:01:13.758396 IP 10.244.2.195 &gt; 10.244.1.0: ICMP echo reply, id 2, seq 37, length 6417:01:14.758058 IP 10.244.1.0 &gt; 10.244.2.195: ICMP echo request, id 2, seq 38, length 6417:01:14.758791 IP 10.244.2.195 &gt; 10.244.1.0: ICMP echo reply, id 2, seq 38, length 6417:01:15.758376 IP 10.244.1.0 &gt; 10.244.2.195: ICMP echo request, id 2, seq 39, length 6417:01:15.759072 IP 10.244.2.195 &gt; 10.244.1.0: ICMP echo reply, id 2, seq 39, length 6417:01:16.758661 IP 10.244.1.0 &gt; 10.244.2.195: ICMP echo request, id 2, seq 40, length 64 12345678910# tcpdump -i eth0 -nn host 10.1.87.82tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes17:03:44.145010 IP 10.1.87.81.44247 &gt; 10.1.87.82.8472: OTV, flags [I] (0x08), overlay 0, instance 1IP 10.244.1.0 &gt; 10.244.2.195: ICMP echo request, id 3, seq 0, length 6417:03:44.145551 IP 10.1.87.82.8942 &gt; 10.1.87.81.8472: OTV, flags [I] (0x08), overlay 0, instance 1IP 10.244.2.195 &gt; 10.244.1.0: ICMP echo reply, id 3, seq 0, length 6417:03:45.145300 IP 10.1.87.81.44247 &gt; 10.1.87.82.8472: OTV, flags [I] (0x08), overlay 0, instance 1IP 10.244.1.0 &gt; 10.244.2.195: ICMP echo request, id 3, seq 1, length 6417:03:45.145854 IP 10.1.87.82.8942 &gt; 10.1.87.81.8472: OTV, flags [I] (0x08), overlay 0, instance 1 Flannel VxLAN的Direct routing模式配置12345678910111213141516171819# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml# vim kube-flannel.yml net-conf.json: | &#123; "Network": "10.244.0.0/16", "Backend": &#123; "Type": "vxlan", "Directrouting": true # 添加字段 &#125; &#125;# kubectl delete -f kube-flannel.yml# kubectl apply -f kube-flannel.yml# ip route showdefault via 10.1.87.1 dev eth010.1.87.0/24 dev eth0 proto kernel scope link src 10.1.87.8010.244.0.0/24 dev cni0 proto kernel scope link src 10.244.0.110.244.1.0/24 via 10.1.87.81 dev eth010.244.2.0/24 via 10.1.87.82 dev eth010.244.3.0/24 via 10.1.87.83 dev eth0 注: 在生产环境中不可以这么做，会影响到Pod的网络环境。生产环境一般在使用前会考虑并初始化好网络环境，也就是说先修改 flannel 才开始使用创建Pod; calico 安装使用Canal/flannel Hosted Install 官方文档 12# kubectl apply -f https://docs.projectcalico.org/v3.0/getting-started/kubernetes/installation/hosted/canal/rbac.yaml# kubectl apply -f https://docs.projectcalico.org/v3.0/getting-started/kubernetes/installation/hosted/canal/canal.yaml 创建名称空间podSelector: {} 为空时，代表所有Pod1234567891011121314151617# kubectl create namespace devnamespace/dev created# kubectl create namespace prodnamespace/prod created# vim ingress-def.yamlapiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: deny-all-ingressspec: podSelector: &#123;&#125; policyTypes: - Ingress# kubectl apply -f ingress-def.yaml -n dev# kubectl get netpol -n devNAME POD-SELECTOR AGEdeny-all-ingress &lt;none&gt; 93s 12345678910111213# vim pod-a.yamlapiVersion: v1kind: Podmetadata: name: pod1spec: containers: - name: myapp image: ikubernetes/myapp:v1# kubectl apply -f pod-a.yaml -n dev# kubectl get pods -n dev -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod1 1/1 Running 0 54s 10.244.3.2 node03 &lt;none&gt; &lt;none&gt; 这是请求10.244.3.2 发现是请求不通的 12# curl 10.244.3.2curl: (7) Failed connect to 10.244.3.2:80; Connection timed out 而把 pod-a.yaml 创建在prod 名称空间，此时prod名称空间是没有定义的 12345# kubectl apply -f pod-a.yaml -n prodpod/pod1 created# kubectl get pods -n prod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod1 1/1 Running 0 17s 10.244.3.3 node03 &lt;none&gt; &lt;none&gt;node 请求10.244.3.3名称空间的可以请求通 12# curl 10.244.3.3Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt; 当允许dev名称空间的Pod 都可以访问时，只需加 ingress: - {} 就可以了 12345678910111213apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: deny-all-ingressspec: podSelector: &#123;&#125; ingress: - &#123;&#125; policyTypes: - Ingress# kubectl apply -f ingress-def.yaml -n dev# curl 10.244.3.2Hello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt; 定义允许访问一组Pod,使用标签来实现 12# kubectl label pods pod1 app=myapp -n devpod/pod1 labeled 还原ingress-def 为默认，拒绝所有dev 名称空间所有Pod的访问 123456789101112# vim ingress-def.yamlapiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: deny-all-ingressspec: podSelector: &#123;&#125; policyTypes: - Ingress# kubectl apply -f ingress-def.yaml -n dev# curl 10.244.3.2curl: (7) Failed connect to 10.244.3.2:80; Connection timed out 配置测略，允许某网段允许访问指定策略 123456789101112131415161718192021222324252627# vim allow-netpol-demo.yamlapiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-myapp-ingressspec: podSelector: matchLabels: app: myapp ingress: - from: - ipBlock: cidr: 10.244.0.0/16 except: - 10.244.1.2/32 ports: - protocol: TCP port: 80 - protocol: TCP port: 443# kubectl apply -f allow-netpol-demo.yaml -n dev# kubectl get netpol -n devNAME POD-SELECTOR AGEallow-myapp-ingress app=myapp 2mdeny-all-ingress &lt;none&gt; 34m# curl 10.244.3.2:80Hello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt; 管控出站流量的方式 1234567891011121314151617181920212223# vim egress-def.yamlapiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: deny-all-egressspec: podSelector: &#123;&#125; policyTypes: - Egress# kubectl apply -f egress-def.yaml -n prodnetworkpolicy.networking.k8s.io/deny-all-egress created# kubectl apply -f pod-a.yaml -n prod # 将之前的pod-a.yaml 创建到prod名称空间pod/pod1 unchanged# kubectl get pods -n prod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod1 1/1 Running 0 34m 10.244.3.3 node03 &lt;none&gt; &lt;none&gt;node# kubectl exec pod1 -it -n prod -- /bin/sh/ # ping 10.1.87.81PING 10.1.87.81 (10.1.87.81): 56 data bytes^C--- 10.1.87.81 ping statistics ---4 packets transmitted, 0 packets received, 100% packet loss/ # 123456789101112131415161718192021# vim egress-def.yamlapiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: deny-all-egressspec: podSelector: &#123;&#125; egress: - &#123;&#125; policyTypes: - Egress# kubectl apply -f egress-def.yaml -n prod# kubectl exec pod1 -it -n prod -- /bin/sh/ # ping 10.1.87.81PING 10.1.87.81 (10.1.87.81): 56 data bytes64 bytes from 10.1.87.81: seq=0 ttl=63 time=0.660 ms64 bytes from 10.1.87.81: seq=1 ttl=63 time=0.564 ms^C--- 10.1.87.81 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.564/0.612/0.660 ms 可以看到放行所有Pod出站规则,网络是通的; 网络策略: 名称空间: 拒绝所有出站，入站; 放行所有出站目标本名称空间内的所有Pod;]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes操作记录(四)]]></title>
    <url>%2F2019%2F05%2F22%2Fkubernetes%E5%AE%9E%E6%93%8D%E8%AE%B0%E5%BD%954%2F</url>
    <content type="text"><![CDATA[kubernetes 操作记录四 kubernetes认证及Service Account在master服务器上启动 proxy 并监听至8080 12# kubectl proxy --port=8080 &amp;# curl http://localhost:8080/api/v1/namespaces 仅有权限获取当前Pod自身的相关信息 1234# kubectl get secret -n ingress-nginxNAME TYPE DATA AGEdefault-token-t54dl kubernetes.io/service-account-token 3 5d23hnginx-ingress-serviceaccount-token-5dwv4 kubernetes.io/service-account-token 3 5d23h 生成yaml框架，快速编写清单 1234567# kubectl create serviceaccount mysa -o yaml --dry-runapiVersion: v1kind: ServiceAccountmetadata: creationTimestamp: null name: mysa# kubectl get pods myapp-deploy-675558bfc5-2rfrs -o yaml --export 1234567891011121314151617# kubectl create serviceaccount admin# kubectl describe sa adminName: adminNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Image pull secrets: &lt;none&gt;Mountable secrets: admin-token-hxqqfTokens: admin-token-hxqqfEvents: &lt;none&gt;# kubectl get secretNAME TYPE DATA AGEadmin-token-hxqqf kubernetes.io/service-account-token 3 66sdefault-token-2sgn5 kubernetes.io/service-account-token 3 26dmysql-root-password Opaque 1 45htomcat-ingress-secret kubernetes.io/tls 2 5d22h 12345678910111213141516171819202122# vim pod-sa-demo.yamlapiVersion: v1kind: Podmetadata: name: pod-sa-demo namespace: default labels: app: myapp tier: frontend annotations: ssjinyao.com/create-by: "cluster admin"spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 serviceAccountName: admin# kubectl apply -f pod-sa-demo.yaml# kubectl describe pods pod-sa-demo | grep 'SecretName' SecretName: admin-token-hxqqf kubernetes 集群有两类认证时的用户账号useraccount,我们称之为用户账号，通常定义的是人使用的账号servicecacount, 服务账号，指pod中应用的应用程序运行在kubernetes ，想访问apiserver时用的认证信息，包括用户名密码等等; 1234567891011121314151617181920# kubectl config viewapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: https://10.1.87.80:6443 name: kubernetescontexts:- context: cluster: kubernetes user: kubernetes-admin name: kubernetes-admin@kubernetescurrent-context: kubernetes-admin@kuberneteskind: Configpreferences: &#123;&#125;users:- name: kubernetes-admin user: client-certificate-data: REDACTED client-key-data: REDACTED 12345678910111213141516171819202122/etc/kubernetes/pki# (umask 077; openssl genrsa -out ssjinyao.key 2048)# openssl req -new -key ssjinyao.key -out ssjinyao.csr -subj "/CN=ssjinyao"# openssl x509 -req -in ssjinyao.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out ssjinyao.crt -days 36500Signature oksubject=/CN=ssjinyaoGetting CA Private Key# openssl x509 -in ssjinyao.crt -text -nooutCertificate: Data: Version: 1 (0x0) Serial Number: f3:fe:ff:e5:0e:0b:37:e2 Signature Algorithm: sha256WithRSAEncryption Issuer: CN=kubernetes Validity Not Before: May 22 07:57:01 2019 GMT Not After : Apr 28 07:57:01 2119 GMT Subject: CN=ssjinyao Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) 接下来把用户账号信息添加到连接kubernetes 的配置信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# kubectl config set-credentials ssjinyao --client-certificate=./ssjinyao.crt --client-key=./ssjinyao.key --embed-certs=trueUser "ssjinyao" set.# kubectl config viewapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: https://10.1.87.80:6443 name: kubernetescontexts:- context: cluster: kubernetes user: kubernetes-admin name: kubernetes-admin@kubernetescurrent-context: kubernetes-admin@kuberneteskind: Configpreferences: &#123;&#125;users:- name: kubernetes-admin user: client-certificate-data: REDACTED client-key-data: REDACTED- name: ssjinyao user: client-certificate: /etc/kubernetes/pki/ssjinyao.crt client-key: /etc/kubernetes/pki/ssjinyao.key# kubectl config set-context ssjinyao@kubernetes --cluster=kueberntes --user=ssjinyaoContext "ssjinyao@kubernetes" created.# kubectl config viewapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: https://10.1.87.80:6443 name: kubernetescontexts:- context: cluster: kubernetes user: kubernetes-admin name: kubernetes-admin@kubernetes- context: cluster: kueberntes user: ssjinyao name: ssjinyao@kubernetescurrent-context: kubernetes-admin@kuberneteskind: Configpreferences: &#123;&#125;users:- name: kubernetes-admin user: client-certificate-data: REDACTED client-key-data: REDACTED- name: ssjinyao user: client-certificate: /etc/kubernetes/pki/ssjinyao.crt client-key: /etc/kubernetes/pki/ssjinyao.key 这时候多了一个context, 可切换用户 12# kubectl config use-context ssjinyao@kubernetesSwitched to context &quot;ssjinyao@kubernetes&quot;. 1234567891011121314# kubectl config set-cluster mycluster --kubeconfig=/tmp/test.conf --server=&quot;https://10.1.87.80:6443&quot; --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=trueCluster &quot;mycluster&quot; set.# kubectl config view --kubeconfig=/tmp/test.confapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: https://10.1.87.80:6443 name: myclustercontexts: []current-context: &quot;&quot;kind: Configpreferences: &#123;&#125;users: [] RBAC授权插件: Node, ABAC,RBAC,Webhook(基于http的回调来实现)RBAC: Role-based AC 角色 (role)许可 (permission) role: operations,objectsrolebinding: user account OR service account , roleclusterrole: clusterrolebinding 操作: GET HEAD PUT PUST PATCH DELETE role binding定义 123456789101112131415161718192021222324252627282930313233343536373839404142# kubectl create role pods-reader --verb=get,list,watch --resource=pods --dry-run -o yaml &gt; role-demo.yaml# vim role-demo.yamlapiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: creationTimestamp: null name: pods-reader namespace: defaultrules:- apiGroups: - "" resources: - pods verbs: - get - list - watch# kubectl apply -f role-demo.yaml# kubectl describe role pods-readerName: pods-readerLabels: &lt;none&gt;Annotations: kubectl.kubernetes.io/last-applied-configuration: &#123;"apiVersion":"rbac.authorization.k8s.io/v1","kind":"Role","metadata":&#123;"annotations":&#123;&#125;,"creationTimestamp":null,"name":"pods-reader","nam...PolicyRule: Resources Non-Resource URLs Resource Names Verbs --------- ----------------- -------------- ----- pods [] [] [get list watch]# kubectl create rolebinding ssjinyao-read-pods --role=pods-reader --user=ssjinyao --dry-run -o yaml &gt; rolebinding-demo.yaml# vim rolebinding-demo.yamlapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: creationTimestamp: null name: ssjinyao-read-podsroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: pods-readersubjects:- apiGroup: rbac.authorization.k8s.io kind: User name: ssjinyao clusterrole binding 定义 1234# useradd ik8s# cp -a .kube/ /home/ik8s/# chown -R ik8s.ik8s /home/ik8s/# 123456789101112131415161718# kubectl config use-context kubernetes-admin@kubernetes# kubectl create clusterrole cluster-reader --verb=get,list,watch --resource=pods -o yaml --dry-run &gt; clusterrole-demo.yaml# vim clusterrole-demo.yaml kind: ClusterRolemetadata: name: cluster-readerrules:- apiGroups: - "" resources: - pods verbs: - get - list - watch# kubectl apply -f clusterrole-demo.yamlclusterrole.rbac.authorization.k8s.io/cluster-reader created# kubectl create clusterrolebinding ssjinyao-read-all-pods --clusterrole=cluster-reader --user=ssjinyao --dry-run -o yaml &gt; clusterrolebind-demo.yaml cluster-role 被 rolebinding 会使的cluster 被降级 1# kubectl create rolebinding ssjinyao-read-pods --clusterrole=cluster-reader --user=ssjinayo --dry-run -o yaml &gt; rolebinding-clusterrole-demo.yaml 查看系统默认的授权引用授权 123# kubectl get clusterrole admin -o yaml# kubectl create rolebinding default-ns-admin --clusterrole=admin --user=ssjinyaorolebinding.rbac.authorization.k8s.io/default-ns-admin created dashboard 及认证分级授权部署 dashboard 1# kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml 部署时下载镜像出错 12345678910# kubectl describe pods -n kube-system kubernetes-dashboard-5f7b999d65-jpmhsEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 113s default-scheduler Successfully assigned kube-system/kubernetes-dashboard-5f7b999d65-jpmhs to node01 Warning Failed 53s (x3 over 105s) kubelet, node01 Failed to pull image "k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1": rpc error: code = Unknown desc = Error response from daemon: Get https://k8s.gcr.io/v2/: dial tcp 74.125.203.82:443: connect: connection timed out Warning Failed 53s (x3 over 105s) kubelet, node01 Error: ErrImagePull Normal BackOff 15s (x5 over 105s) kubelet, node01 Back-off pulling image "k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1" Warning Failed 15s (x5 over 105s) kubelet, node01 Error: ImagePullBackOff Normal Pulling 2s (x4 over 112s) kubelet, 01 Pulling image "k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1" 用手动下载的方法进行解决 123456# vim docker_install_dashboard.sh#!/bin/shdocker pull mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.10.1docker tag mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.10.1 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1docker rmi mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.10.1# sh docker_install_dashboard.sh 然后再执行以下部署清单 123 kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml # kubectl get pods -n kube-system | grep dashkubernetes-dashboard-5f7b999d65-fcb28 1/1 Running 0 71s 可以看到kubernetes-dashbroad 已经运行 默认服务暴露为ClusterIP类型的，我们需要将其改为NodePort 类型12345# kubectl patch svc kubernetes-dashboard -p '&#123;"spec":&#123;"type":"NodePort"&#125;&#125;' -n kube-system# kubectl get svc -n kube-system\NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkube-dns ClusterIP 10.96.0.10 &lt;none&gt; 53/UDP,53/TCP,9153/TCP 27dkubernetes-dashboard NodePort 10.109.190.204 &lt;none&gt; 443:31984/TCP 3m41s 这个时候可以看到登录界面 使用用token实现认证登录这里登录需要的是serviceaccount用户， 所以这里创建 serviceaccount 1234# kubectl create serviceaccount dashboard-admin -n kube-systemserviceaccount/dashboard-admin created # kubectl get sa -n kube-system | grep dashdashboard-admin 1 6m33s serviceaccount 创建好后， 需要将serviceaccount绑定cluster这个角色上 1234# kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-adminclusterrolebinding.rbac.authorization.k8s.io/dashboard-cluster-admin created# kubectl get secret -n kube-system | grep dashdashboard-admin-token-grj84 kubernetes.io/service-account-token 3 5m46s 绑定好 cluster 后， 查看token信息，并拿token进行登录 1# kubectl describe secret -n kube-system dashboard-admin-token-grj84 登录后，可以看到整个kubernetes集群的概况 建立专用dashborad用户 123456789# cd /etc/kubernetes/pki/# (umask 077; openssl genrsa -out dashboard.key 2048)# openssl req -new -key dashboard.key -out dashboard.csr -subj "/O=ssjinyao/CN=dashboard"# openssl x509 -req -in dashboard.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out dashboard.crt -days 3650Signature oksubject=/O=ssjinyao/CN=dashboardGetting CA Private Key# kubectl create secret generic dashboard-cert -n kube-system --from-file=dashboard.crt=./dashboard.crt --from-file=dashboard.key=./dashboard.keysecret/dashboard-cert created 12# kubectl create serviceaccount def-ns-admin -n defaultserviceaccount/def-ns-admin created role binding 到 default 名称空间，只允许访问default 名称空间 123# kubectl create rolebinding def-ns-admin --clusterrole=admin --serviceaccount=default:def-ns-adminrolebinding.rbac.authorization.k8s.io/def-ns-admin created# kubectl describe secret admin-token-hxqqf # 查看 token信息登录 接下来配置kube config 文件认证 1234567891011121314# kubectl config set-cluster kubernetes --certificate-authority=./ca.crt --server="https://10.1.87.80:6443" --embed-certs=true --kubeconfig=/root/def-ns-admin.confCluster "kubernetes" set.# kubectl config view --kubeconfig=/root/def-ns-admin.confapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: https://10.1.87.80:6443 name: kubernetescontexts: []current-context: ""kind: Configpreferences: &#123;&#125;users: [] 12345# CLUSTER_ADMIN_TOKEN=$(kubectl get secret -n kube-system dashboard-admin-token-grj84 -o jsonpath=&#123;.data.token&#125; | base64 -d )# kubectl config set-credentials dashboard-cluster-admin --token=$CLUSTER_ADMIN_TOKEN --kubeconfig=/root/def-ns-admin.confUser "dashboard-cluster-admin" set.# kubectl config set-context dashboard-cluster-admin@kubernetes --cluster=kubernetes --user=dashboard-cluster-admin --kubeconfig=/root/def-ns-admin.conf# kubectl config use-context dashboard-cluster-admin@kubernetes --kubeconfig=/root/def-ns-admin.conf 将生成的conf文件远程复制到桌面上 1ssjinyao ➤ scp root@10.1.87.80:/root/def-ns-admin.conf ~/Desktop 此时使用可以用 kubeconfig 来登录dashboard 了]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes操作记录(三)]]></title>
    <url>%2F2019%2F05%2F17%2Fkubernets%E5%AE%9E%E6%93%8D%E8%AE%B0%E5%BD%953%2F</url>
    <content type="text"><![CDATA[kubernetes 操作记录三 存储卷emptyDir1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# vim pod-vol-demo.yaml apiVersion: v1kind: Podmetadata: name: pod-demo namespace: default labels: app: myapp tier: frontend annotations: ssjinyao.com/create-by: "cluster admin"spec: containers: - name: myapp image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 volumeMounts: - name: html mountPath: /data/www/html command: ["/bin/sh"] args: ["-c" , "httpd -h /data/www/html &amp;&amp; sleep 300000"] - name: busybox image: busybox:latest imagePullPolicy: IfNotPresent volumeMounts: - name: html mountPath: /data/ command: ["/bin/sh"] args: [ "-c", "while sleep 2 ; do echo $(date) &gt;&gt; /data/index.html; done"] volumes: - name: html emptyDir: &#123;&#125;# kubectl exec -it pod-demo -c busybox -- /bin/sh/ # echo $(date) &gt;&gt; /data/index.html/ # cat /data/index.htmlFri May 17 06:59:59 UTC 2019# kubectl exec -it pod-demo -c myapp -- /bin/sh/ # ls /data/web/html/index.html/data/web/html/index.html/ # cat /data/web/html/index.htmlFri May 17 06:59:59 UTC 2019# curl 10.244.2.183Fri May 17 07:33:24 UTC 2019Fri May 17 07:33:26 UTC 2019Fri May 17 07:33:28 UTC 2019Fri May 17 07:33:30 UTC 2019Fri May 17 07:33:32 UTC 2019Fri May 17 07:33:34 UTC 2019Fri May 17 07:33:36 UTC 2019Fri May 17 07:33:38 UTC 2019Fri May 17 07:33:40 UTC 2019Fri May 17 07:33:42 UTC 2019Fri May 17 07:33:44 UTC 2019 hostPath挂载使用12345678910111213141516171819# vim pod-hostpath-vol.yamlapiVersion: v1kind: Podmetadata: name: pod-vol-hostpath namespace: defaultspec: containers: - name: myapp image: ikubernets/myapp:v1 volumeMounts: - name: html mountPath: /usr/share/nginx/html/ volumes: - name: html hostPath: path: /data/pod/volume1 type: DirectoryOrCreate# kubectl apply -f pod-hostpath-vol.yaml node1,node2,node3 分别创建以下目录 123456# mkdir -p /data/pod/volume1/ #注三个节点都要执行# echo "node1.ssjinyao.com" &gt;&gt; /data/pod/volume1/index.html# echo "node2.ssjinyao.com" &gt;&gt; /data/pod/volume1/index.html# echo "node3.ssjinyao.com" &gt;&gt; /data/pod/volume1/index.html# curl 10.244.1.155node1.ssjinyao.com 可以看出当前运行在node1节点上 nfs 卷挂载使用选择一台服务器，安装并开启nfs 服务 12345# mkdir -pv /data/volumes# yum -y install nfs nfs-utils # vim /etc/exports/data/volumes 10.1.87.83/24(rw,no_root_squash)# systemctl start nfs 注: 其它节点也需要安装 nfs-utils 不然pod驱动不了 在node02上手动测试挂载 1# mount -t nfs node03:/data/volumes/ /mnt 在kubernetes 集群中使用nfs volumes 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: pod-vol-nfs namespace: defaultspec: containers: - name: myapp image: ikubernetes/myapp:v1 volumeMounts: - name: html mountPath: /usr/share/nginx/html/ volumes: - name: html nfs: path: /data/volumes server: node03# kubectl apply -f pod-vol-nfs.yaml 在nfs服务器上写入数据 1# echo "&lt;h1&gt;nfs.ssjinyao.com&lt;/h1&gt;" &gt;&gt; /data/volumes/index.html 尝试访问 12# curl 10.244.2.185&lt;h1&gt;nfs.ssjinyao.com&lt;/h1&gt; pv, pvc 的使用nfs 服务器上创建多个目录 1234567891011121314# mkdir /data/volumes/v&#123;1,2,3,4,5&#125;# vim /etc/exports/data/volumes/v1 10.1.87.83/24(rw,no_root_squash)/data/volumes/v2 10.1.87.83/24(rw,no_root_squash)/data/volumes/v3 10.1.87.83/24(rw,no_root_squash)/data/volumes/v4 10.1.87.83/24(rw,no_root_squash)/data/volumes/v5 10.1.87.83/24(rw,no_root_squash)# exportfs -arvexporting 10.1.87.83/24:/data/volumes/v5exporting 10.1.87.83/24:/data/volumes/v4exporting 10.1.87.83/24:/data/volumes/v3exporting 10.1.87.83/24:/data/volumes/v2exporting 10.1.87.83/24:/data/volumes/v1# systemctl restart nfs 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# vim pv-demo.yamlapiVersion: v1kind: PersistentVolumemetadata: name: pv01 labels: name: pv001spec: nfs: path: /data/volumes/v1 server: node03 accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 5Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv02 labels: name: pv002spec: nfs: path: /data/volumes/v2 server: node03 accessModes: ["ReadWriteOnce"] capacity: storage: 10Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv03 labels: name: pv003spec: nfs: path: /data/volumes/v3 server: node03 accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 20Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv04 labels: name: pv004spec: nfs: path: /data/volumes/v4 server: node03 accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 10Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv05 labels: name: pv005spec: nfs: path: /data/volumes/v5 server: node03 accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 10Gi---# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpv01 5Gi RWO,RWX Retain Available 74spv02 10Gi RWO Retain Available 74spv03 20Gi RWO,RWX Retain Available 74spv04 10Gi RWO,RWX Retain Available 74spv05 10Gi RWO,RWX Retain Available 74s pvc 绑定 pv 123456789101112131415161718192021222324252627282930313233343536373839# cat pod-vol-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: mypvc namespace: defaultspec: accessModes: ["ReadWriteMany"] resources: requests: storage: 11Gi---apiVersion: v1kind: Podmetadata: name: pod-vol-pvc namespace: defaultspec: containers: - name: myapp image: ikubernetes/myapp:v1 volumeMounts: - name: html mountPath: /usr/share/nginx/html/ volumes: - name: html persistentVolumeClaim: claimName: mypvc# kubectl apply -f pod-vol-pvc.yaml# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpv01 5Gi RWO,RWX Retain Available 40mpv02 10Gi RWO Retain Available 40mpv03 20Gi RWO,RWX Retain Bound default/mypvc 40mpv04 10Gi RWO,RWX Retain Available 40mpv05 10Gi RWO,RWX Retain Available 40m# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEmypvc Bound pv03 20Gi RWO,RWX 8s configmap 的使用1234567891011121314151617181920# kubectl create configmap nginx-config --from-literal=nginx_port=80 --from-literal=server_name=myapp.ssjinyao.comconfigmap/nginx-config created# kubectl get cmNAME DATA AGEnginx-config 2 25s# kubectl describe cm nginx-configName: nginx-configNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Data====nginx_port:----80server_name:----myapp.ssjinyao.comEvents: &lt;none&gt; 123456789101112131415161718192021222324252627# mkdir configmap# cd configmap/# vim www.confserver &#123; server_name myapp.ssjinyao.com; listen 80; root /data/web/html/;&#125;# kubectl create configmap nginx-www --from-file=./www.conf# kubectl get cmNAME DATA AGEnginx-config 2 4m4snginx-www 1 3s# kubectl get cm nginx-www -o yamlapiVersion: v1data: www.conf: "server &#123;\n\tserver_name myapp.ssjinyao.com;\n listen 80;\n root /data/web/html/;\n\n&#125;\n"kind: ConfigMapmetadata: creationTimestamp: "2019-05-20T08:17:37Z" name: nginx-www namespace: default resourceVersion: "3462936" selfLink: /api/v1/namespaces/default/configmaps/nginx-www uid: ba1625a7-7ad7-11e9-8902-525400c45563 Pod 引用 configmap ，环境变量方式 1234567891011121314151617181920212223242526272829303132333435# vim pod-configmap.yamlapiVersion: v1kind: Podmetadata: name: pod-cm-1 namespace: default labels: app: myapp tier: frontend annotations: ssjinyao.com/create-by: "cluster admin"spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 env: - name: NGINX_SERVER_PORT valueFrom: configMapKeyRef: name: nginx-config key: nginx_port - name: NGINX_SERVER_NAME valueFrom: configMapKeyRef: name: nginx-config key: server_name# kubectl apply -f pod-configmap.yamlpod/pod-cm-1 created# kubectl exec pod-cm-1 -it -- /bin/sh/ # printenv | grep NGINX_SERVERNGINX_SERVER_PORT=80NGINX_SERVER_NAME=myapp.ssjinyao.com 当环境变量获取时，容器的变量不是实时更新的 123456789101112131415161718192021222324# kubectl edit cm nginx-configconfigmap/nginx-config edited# 将nginx_port: "80" 改变 nginx_port: "8080"# 可以看到configmap 是实时生效的# kubectl describe cm nginx-configName: nginx-configNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Data====nginx_port:----8080server_name:----myapp.ssjinyao.comEvents: &lt;none&gt;# 而容器中则不会时实更新变量# kubectl exec pod-cm-1 -it -- /bin/sh/ # printenv | grep NGINX_SERVERNGINX_SERVER_PORT=80NGINX_SERVER_NAME=myapp.ssjinyao.com 存储卷挂载方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# vim pod-configmap2.yamlapiVersion: v1kind: Podmetadata: name: pod-cm-2 namespace: default labels: app: myapp tier: frontend annotations: ssjinyao.com/create-by: "cluster admin"spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 volumeMounts: - name: nginxconf mountPath: /etc/nginx/config.d/ readOnly: true volumes: - name: nginxconf configMap: name: nginx-config# kubectl apply -f pod-configmap2.yamlpod/pod-cm-2 created# kubectl exec pod-cm-2 -it -- /bin/sh/ # cd /etc/nginx/confconf.d/ config.d// # cd /etc/nginx/config.d//etc/nginx/config.d # lsnginx_port server_name/etc/nginx/config.d # cat nginx_port8080/etc/nginx/config.d #/etc/nginx/config.d # cat server_namemyapp.ssjinyao.com/etc/nginx/config.d ## kubectl edit cm nginx-configconfigmap/nginx-config edited# 将nginx_port: "8080" 改为 nginx_port: "8088" # 稍等片刻后，接入容器发现nginx_port值实时更新# kubectl edit cm nginx-configEdit cancelled, no changes made.[root@bj-zb-vm-ops-test5 configmap]# kubectl exec pod-cm-2 -it -- /bin/sh/ # cd /etc/nginx/config.d//etc/nginx/config.d # cat nginx_port8088/etc/nginx/config.d # 案例,配置文件焙进镜像 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# vim pod-configmap3.yaml# kubectl apply -f pod-configmap3.yamlapiVersion: v1kind: Podmetadata: name: pod-cm-3 namespace: default labels: app: myapp tier: frontend annotations: ssjinyao.com/create-by: "cluster admin"spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 volumeMounts: - name: nginxconf mountPath: /etc/nginx/conf.d/ readOnly: true volumes: - name: nginxconf configMap: name: nginx-www# kubectl exec pod-cm-3 -it -- /bin/sh/ # cd /etc/nginx/conf.d//etc/nginx/conf.d # cat www.confserver &#123; server_name myapp.ssjinyao.com; listen 80; root /data/web/html/;&#125;# kubectl edit cm nginx-wwwconfigmap/nginx-www edited# 将 listen 80 改为 listen 8080，稍等片刻后接入容器查看配置# kubectl exec pod-cm-3 -it -- /bin/sh/ # cd /etc/nginx/conf.d//etc/nginx/conf.d # cat www.confserver &#123; server_name myapp.ssjinyao.com; listen 8080; root /data/web/html/;&#125;# echo "&lt;h1&gt; Nginx Server Configured by CM &lt;/h1&gt;" &gt; /data/web/html/index.html# 说明配置文件焙进镜像的方式是可以实时更新的;当然配置文件生效，需要nginx -s reload# vim /etc/hosts 加入本地解析至Pod ip10.244.1.158 myapp.ssjinyao.com# curl http://myapp.ssjinyao.com:8080&lt;h1&gt; Nginx Server Configured by CM &lt;/h1&gt; secret 的使用configmap 都是明文存数据的，私钥和证书要放在secret中，密码要写成dns secret 而非configamp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# kubectl create secret generic mysql-root-password --from-literal=passwod=H@ndih3secret/mysql-root-password created# kubectl get secretNAME TYPE DATA AGEdefault-token-2sgn5 kubernetes.io/service-account-token 3 24dmysql-root-password Opaque 1 45stomcat-ingress-secret kubernetes.io/tls 2 4d# kubectl describe secret mysql-root-passwordName: mysql-root-passwordNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Type: OpaqueData====passwod: 7 bytes# 对比configmap 的Data数据，secret 值是不显示的# kubectl describe configmap nginx-wwwName: nginx-wwwNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Data====www.conf:----server &#123; server_name myapp.ssjinyao.com; listen 8080; root /data/web/html/;&#125;Events: &lt;none&gt;# 而 configmap Data的值是显示的# 我们也可以这样看# kubectl get secret mysql-root-password -o yamlapiVersion: v1data: passwod: SEBuZGloMw==kind: Secretmetadata: creationTimestamp: "2019-05-20T09:20:53Z" name: mysql-root-password namespace: default resourceVersion: "3469600" selfLink: /api/v1/namespaces/default/secrets/mysql-root-password uid: 90cd9aaa-7ae0-11e9-8902-525400c45563type: Opaque」 可以看出数据还是有的，因此安全没有那好，也没有加密码的意义可以直接用 base64 -d 进行解密 12# echo SEBuZGloMw== | base64 -dH@ndih3 123456789101112131415161718192021222324# vim pod-secret-1.yamlapiVersion: v1kind: Podmetadata: name: pod-secret-1 namespace: default labels: app: myapp tier: frontend annotations: ssjinyao.com/create-by: "cluster admin"spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 env: - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mysql-root-password key: passwod 12# kubectl exec pod-secret-1 -- printenv | grep MYSQLMYSQL_ROOT_PASSWORD=H@ndih3 statefulset 的使用nfs服务器还是在node3 上，配置信息如下 123456# cat /etc/exports/data/volumes/v1 10.1.87.83/24(rw,no_root_squash)/data/volumes/v2 10.1.87.83/24(rw,no_root_squash)/data/volumes/v3 10.1.87.83/24(rw,no_root_squash)/data/volumes/v4 10.1.87.83/24(rw,no_root_squash)/data/volumes/v5 10.1.87.83/24(rw,no_root_squash) 注：确保三台node服务器都安装了 nfs-utils pv改动及创建 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# cat volumes/pv-demo.yamlapiVersion: v1kind: PersistentVolumemetadata: name: pv01 labels: name: pv001spec: nfs: path: /data/volumes/v1 server: node03 accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 5Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv02 labels: name: pv002spec: nfs: path: /data/volumes/v2 server: node03 accessModes: ["ReadWriteOnce"] capacity: storage: 5Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv03 labels: name: pv003spec: nfs: path: /data/volumes/v3 server: node03 accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 5Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv04 labels: name: pv004spec: nfs: path: /data/volumes/v4 server: node03 accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 10Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv05 labels: name: pv005spec: nfs: path: /data/volumes/v5 server: node03 accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 10Gi---# kubectl apply -f volumes/pv-demo.yaml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# vim stateful-demo.yamlapiVersion: v1kind: Servicemetadata: name: myapp labels: app: myappspec: ports: - port: 80 name: web clusterIP: None selector: app: myapp-pod---apiVersion: apps/v1kind: StatefulSetmetadata: name: myappspec: serviceName: myapp replicas: 3 selector: matchLabels: app: myapp-pod template: metadata: labels: app: myapp-pod spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - containerPort: 80 name: web volumeMounts: - name: myappdata mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: myappdata spec: accessModes: ["ReadWriteOnce"] resources: requests: storage: 5Gi# kubectl get podsNAME READY STATUS RESTARTS AGEclient 1/1 Running 0 23dmyapp-0 1/1 Running 0 7m10smyapp-1 1/1 Running 0 7m5smyapp-2 1/1 Running 0 7m1s# kubectl get stsNAME READY AGEmyapp 3/3 7m32s# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpv01 5Gi RWO,RWX Retain Bound default/myappdata-myapp-1 8m12spv02 5Gi RWO Retain Bound default/myappdata-myapp-0 8m12spv03 5Gi RWO,RWX Retain Bound default/myappdata-myapp-2 8m12spv04 10Gi RWO,RWX Retain Available 8m12spv05 10Gi RWO,RWX Retain Available 8m12s# kubectl exec -it myapp-0 -- /bin/sh/ # nslookup myapp-0.myapp.default.svc.cluster.localnslookup: can't resolve '(null)': Name does not resolveName: myapp-0.myapp.default.svc.cluster.localAddress 1: 10.244.1.162 myapp-0.myapp.default.svc.cluster.local/ # nslookup myapp-1.myapp.default.svc.cluster.localnslookup: can't resolve '(null)': Name does not resolveName: myapp-1.myapp.default.svc.cluster.localAddress 1: 10.244.2.192 myapp-1.myapp.default.svc.cluster.local/ # nslookup myapp-2.myapp.default.svc.cluster.localnslookup: can't resolve '(null)': Name does not resolveName: myapp-2.myapp.default.svc.cluster.localAddress 1: 10.244.3.172 myapp-2.myapp.default.svc.cluster.local pod 数量扩展 1234567891011# kubectl scale sts myapp --replicas=5statefulset.apps/myapp scaled# kubectl patch sts myapp -p '&#123;"spec":&#123;"replicas":2&#125;&#125;'statefulset.apps/myapp patched# kubectl patch sts myapp -p '&#123;"spec":&#123;"updateStrategy":&#123;"rollingUpdate":&#123;"partition":4&#125;&#125;&#125;&#125;'statefulset.apps/myapp patched# kubectl set image sts/myapp myapp=ikubernetes/myapp:v2statefulset.apps/myapp image updated# kubectl get sts -o wideNAME READY AGE CONTAINERS IMAGESmyapp 2/2 53m myapp ikubernetes/myapp:v2]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes操作记录(二)]]></title>
    <url>%2F2019%2F05%2F10%2Fkubernetes%E5%AE%9E%E6%93%8D%E8%AE%B0%E5%BD%952%2F</url>
    <content type="text"><![CDATA[kubernetes 操作记录二 Kubernetes Pod 控制器Replica Set(RS) kubernetes 新一代的Pod controller1234567891011121314151617181920212223242526272829303132333435363738394041424344# vim rs-demo.yamlapiVersion: apps/v1kind: ReplicaSetmetadata: name: myapp namespace: defaultspec: replicas: 2 selector: matchLabels: app: myapp release: canary template: metadata: name: myapp-pod labels: app: myapp release: canary environment: qa spec: containers: - name: myapp-container image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80# kubectl get rsNAME DESIRED CURRENT READY AGEmyapp 2 2 2 6m51s# kubectl get podsNAME READY STATUS RESTARTS AGEmyapp-5xbwq 1/1 Running 0 7m17smyapp-jdzph 1/1 Running 0 7m17s# curl 10.244.3.157Hello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;# kubectl delete pods myapp-5xbwq # kubectl get podsNAME READY STATUS RESTARTS AGEmyapp-jdzph 1/1 Running 0 10mmyapp-xg9mm 1/1 Running 0 16s# kubectl label pods pod-demo release=canary# kubectl get pods --show-labelsNAME READY STATUS RESTARTS AGE LABELSmyapp-jdzph 1/1 Running 0 31m app=myapp,environment=qa,release=canary 精确满足用户期望 apply -f 声明式更新，即可以创建，也可以更新12345678910111213141516171819202122232425262728293031323334353637383940# vim deploy-demo.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deploy namespace: defaultspec: replicas: 2 selector: matchLabels: app: myapp release: canary template: metadata: labels: app: myapp release: canary spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80# kubectl apply -f deploy-demo.yaml# kubectl get deployNAME READY UP-TO-DATE AVAILABLE AGEmyapp-deploy 2/2 2 2 115s# kubectl get podsNAME READY STATUS RESTARTS AGEmyapp-deploy-67b6dfcd8-6q725 1/1 Running 0 4m39smyapp-deploy-67b6dfcd8-mshw8 1/1 Running 0 4m39s# vim deploy-demo.yaml将 replicas: 2 改为 replicas: 3# kubectl apply -f deploy-demo.yaml# kubectl get podsNAME READY STATUS RESTARTS AGEmyapp-deploy-67b6dfcd8-6q725 1/1 Running 0 6m34smyapp-deploy-67b6dfcd8-gltjz 1/1 Running 0 58smyapp-deploy-67b6dfcd8-mshw8 1/1 Running 0 6m34s 实现流动更新1234567891011121314151617181920212223242526272829303132# vim deploy-demo.yamlimage: ikubernetes/myapp:v1 改为 image: ikubernetes/myapp:v2# kubcetl apply -f deploy-demo.yaml# kubectl get pods -l app=myapp -wNAME READY STATUS RESTARTS AGEmyapp-deploy-67b6dfcd8-6q725 1/1 Running 0 3h23mmyapp-deploy-67b6dfcd8-gltjz 1/1 Running 0 3h18mmyapp-deploy-67b6dfcd8-mshw8 1/1 Running 0 3h23mmyapp-deploy-675558bfc5-89nc7 0/1 Pending 0 0smyapp-deploy-675558bfc5-89nc7 0/1 Pending 0 0smyapp-deploy-675558bfc5-89nc7 0/1 ContainerCreating 0 0smyapp-deploy-675558bfc5-89nc7 1/1 Running 0 2smyapp-deploy-67b6dfcd8-gltjz 1/1 Terminating 0 3h18mmyapp-deploy-675558bfc5-7zht2 0/1 Pending 0 0smyapp-deploy-675558bfc5-7zht2 0/1 Pending 0 0smyapp-deploy-675558bfc5-7zht2 0/1 ContainerCreating 0 0smyapp-deploy-67b6dfcd8-gltjz 0/1 Terminating 0 3h18mmyapp-deploy-675558bfc5-7zht2 1/1 Running 0 3smyapp-deploy-67b6dfcd8-6q725 1/1 Terminating 0 3h24mmyapp-deploy-675558bfc5-xjq9z 0/1 Pending 0 0smyapp-deploy-675558bfc5-xjq9z 0/1 Pending 0 0smyapp-deploy-675558bfc5-xjq9z 0/1 ContainerCreating 0 0smyapp-deploy-67b6dfcd8-gltjz 0/1 Terminating 0 3h18mmyapp-deploy-67b6dfcd8-gltjz 0/1 Terminating 0 3h18mmyapp-deploy-67b6dfcd8-6q725 0/1 Terminating 0 3h24mmyapp-deploy-675558bfc5-xjq9z 1/1 Running 0 2smyapp-deploy-67b6dfcd8-mshw8 1/1 Terminating 0 3h24mmyapp-deploy-67b6dfcd8-6q725 0/1 Terminating 0 3h24mmyapp-deploy-67b6dfcd8-6q725 0/1 Terminating 0 3h24mmyapp-deploy-67b6dfcd8-mshw8 0/1 Terminating 0 3h24mmyapp-deploy-67b6dfcd8-mshw8 0/1 Terminating 0 3h24mmyapp-deploy-67b6dfcd8-mshw8 0/1 Terminating 0 3h24m 查看目前所有的replica set1234# kubectl get rs -o wideNAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTORmyapp-deploy-675558bfc5 3 3 3 3m19s myapp ikubernetes/myapp:v2 app=myapp,pod-template-hash=675558bfc5,release=canarymyapp-deploy-67b6dfcd8 0 0 0 3h27m myapp ikubernetes/myapp:v1 app=myapp,pod-template-hash=67b6dfcd8,release=canary 查看历史滚动信息12345# kubectl rollout history deployment myapp-deploydeployment.extensions/myapp-deployREVISION CHANGE-CAUSE1 &lt;none&gt;2 &lt;none&gt; 定义一个补丁12345678# kubectl patch deployment myapp-deploy -p '&#123;"spec":&#123;"replicas":5&#125;&#125;'# kubectl get podsNAME READY STATUS RESTARTS AGEmyapp-deploy-675558bfc5-7zht2 1/1 Running 0 11mmyapp-deploy-675558bfc5-89nc7 1/1 Running 0 11mmyapp-deploy-675558bfc5-9nkk4 1/1 Running 0 33smyapp-deploy-675558bfc5-rbs4d 1/1 Running 0 33smyapp-deploy-675558bfc5-xjq9z 1/1 Running 0 11m 1234# kubectl patch deployment myapp-deploy -p '&#123;"spec":&#123;"strategy":&#123;"rollingUpdate":&#123;"maxSurge":1,"maxUnavailable":0&#125;&#125;&#125;&#125;'deployment.extensions/myapp-deploy patched# kubectl describe deployment myapp-deployRollingUpdateStrategy: 0 max unavailable, 1 max surge 金丝雀更新发布1234567891011121314# kubectl set image deployment myapp-deploy myapp=ikubernetes/myapp:v3 &amp;&amp; kubectl rollout pause deployment myapp-deploy # 更新并且暂停更新deployment.extensions/myapp-deploy image updateddeployment.extensions/myapp-deploy paused# kubectl get pods -l app=myapp -wNAME READY STATUS RESTARTS AGEmyapp-deploy-675558bfc5-7zht2 1/1 Running 0 27mmyapp-deploy-675558bfc5-89nc7 1/1 Running 0 27mmyapp-deploy-675558bfc5-9nkk4 1/1 Running 0 17mmyapp-deploy-675558bfc5-rbs4d 1/1 Running 0 17mmyapp-deploy-675558bfc5-xjq9z 1/1 Running 0 27mmyapp-deploy-7f577979c8-92tj8 0/1 Pending 0 0smyapp-deploy-7f577979c8-92tj8 0/1 Pending 0 0smyapp-deploy-7f577979c8-92tj8 0/1 ContainerCreating 0 0smyapp-deploy-7f577979c8-92tj8 1/1 Running 0 14s 使用以下命令进行监控更新12# kubectl rollout status deployment myapp-deployWaiting for deployment "myapp-deploy" rollout to finish: 1 out of 5 new replicas have been updated... 若发现没有问题后继续更新 1234567891011121314151617181920# kubectl rollout resume deployment myapp-deploydeployment.extensions/myapp-deploy resumed# kubectl rollout status deployment myapp-deployWaiting for deployment "myapp-deploy" rollout to finish: 1 out of 5 new replicas have been updated...Waiting for deployment spec update to be observed...Waiting for deployment spec update to be observed...Waiting for deployment "myapp-deploy" rollout to finish: 1 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 1 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 2 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 2 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 2 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 3 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 3 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 3 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 4 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 4 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 4 out of 5 new replicas have been updated...Waiting for deployment "myapp-deploy" rollout to finish: 1 old replicas are pending termination...Waiting for deployment "myapp-deploy" rollout to finish: 1 old replicas are pending termination...deployment "myapp-deploy" successfully rolled out 若更新时发现问题，我们可以执行回滚查看可以回滚的版本 123456# kubectl rollout history deployment myapp-deploydeployment.extensions/myapp-deployREVISION CHANGE-CAUSE1 &lt;none&gt;2 &lt;none&gt;3 &lt;none&gt; 12345678# kubectl rollout undo deployment myapp-deploy --to-revision=1deployment.extensions/myapp-deploy rolled back# kubectl rollout history deployment myapp-deploydeployment.extensions/myapp-deployREVISION CHANGE-CAUSE2 &lt;none&gt;3 &lt;none&gt;4 &lt;none&gt; 这时第一版已经回滚成第一版了 1234# kubectl get rs -o wideNAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTORmyapp-deploy-675558bfc5 0 0 0 42m myapp ikubernetes/myapp:v2 app=myapp,pod-template-hash=675558bfc5,release=canarymyapp-deploy-67b6dfcd8 5 5 5 4h6m myapp ikubernetes/myapp:v1 app=myapp,pod-template-hash=67b6dfcd8,release=canary DaemonSetDaemonSet 在整个集群的每个节点上只运行指定Pod的一个副本，用于系统级的管理功能比如filebeat，收集日志的服务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# vim ds-demo.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: redis namespace: defaultspec: replicas: 1 selector: matchLabels: app: redis role: logstor template: metadata: labels: app: redis role: logstor spec: containers: - name: redis image: redis:4.0-alpine ports: - name: redis containerPort: 6379---apiVersion: apps/v1kind: DaemonSetmetadata: name: filebeat-ds namespace: defaultspec: selector: matchLabels: app: filebeat release: stable template: metadata: labels: app: filebeat release: stable spec: containers: - name: filebeat image: ikubernetes/filebeat:5.6.5-alpine env: - name: REDIS_HOST value: redis.default.svc.cluster.local - name: REDIS_LOG_LEVEL value: info# kubectl apply -f ds-demo.yaml# kubectl expose deployment redis --port=6379service/redis exposed# kubectl set image daemonsets filebeat-ds filebeat=ikubernetes/filebeat:5.6.6-alpinedaemonset.extensions/filebeat-ds image updated Kubernetes ServiceExternalName, ClusterIP, NodePort, and LoadBalancer 123456789101112131415# vim redis-svc.yamlapiVersion: v1kind: Servicemetadata: name: redis namespace: defaultspec: selector: app: redis role: logstor clusterIP: 10.96.88.88 type: ClusterIP ports: - port: 6339 targetPort: 6379 资源记录SVC_NAME.NS_NAME.DOMAIN.LTD.svc.cluster.localredis.default.svc.cluster.local 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# vim myapp-svc.yamlapiVersion: v1kind: Servicemetadata: name: myapp namespace: defaultspec: selector: app: myapp release: canary clusterIP: 10.99.99.99 type: NodePort ports: - port: 80 targetPort: 80 nodePort: 30080# kubectl get svc myappNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmyapp NodePort 10.99.99.99 &lt;none&gt; 80:30080/TCP 4m50sssjinyao ➤ while true; do curl 10.1.87.82:30080/hostname.html ; sleep 1 ; donemyapp-deploy-675558bfc5-5c8hnmyapp-deploy-675558bfc5-qtlqfmyapp-deploy-675558bfc5-qtlqfmyapp-deploy-675558bfc5-5c8hnmyapp-deploy-675558bfc5-qgps7myapp-deploy-675558bfc5-5c8hnmyapp-deploy-675558bfc5-qgps7myapp-deploy-675558bfc5-qgps7myapp-deploy-675558bfc5-qtlqf# 来自同上客户端的请求发往同一Pod# kubectl patch svc myapp -p '&#123;"spec":&#123;"sessionAffinity":"ClientIP"&#125;&#125;'service/myapp patched# kubectl describe svc myappName: myappNamespace: defaultLabels: &lt;none&gt;Annotations: kubectl.kubernetes.io/last-applied-configuration: &#123;"apiVersion":"v1","kind":"Service","metadata":&#123;"annotations":&#123;&#125;,"name":"myapp","namespace":"default"&#125;,"spec":&#123;"clusterIP":"10.99.99.99","...Selector: app=myapp,release=canaryType: NodePortIP: 10.99.99.99Port: &lt;unset&gt; 80/TCPTargetPort: 80/TCPNodePort: &lt;unset&gt; 30080/TCPEndpoints: 10.244.1.150:80,10.244.2.166:80,10.244.3.167:80Session Affinity: ClientIPExternal Traffic Policy: ClusterEvents: &lt;none&gt;ssjinyao ➤ while true; do curl 10.1.87.82:30080/hostname.html ; sleep 1 ; donemyapp-deploy-675558bfc5-qgps7myapp-deploy-675558bfc5-qgps7myapp-deploy-675558bfc5-qgps7myapp-deploy-675558bfc5-qgps7 无头服务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# vim myapp-svc-headless.yamlapiVersion: v1kind: Servicemetadata: name: myapp-svc namespace: defaultspec: selector: app: myapp release: canary clusterIP: None ports: - port: 80 targetPort: 80# kubectl apply -f myapp-svc-headless.yamlservice/myapp-svc created# dig -t A myapp-svc.default.svc.cluster.local. @10.96.0.10; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-73.el7_6 &lt;&lt;&gt;&gt; -t A myapp-svc.default.svc.cluster.local. @10.96.0.10;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 38590;; flags: qr aa rd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; WARNING: recursion requested but not available;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;myapp-svc.default.svc.cluster.local. IN A;; ANSWER SECTION:myapp-svc.default.svc.cluster.local. 5 IN A 10.244.3.167myapp-svc.default.svc.cluster.local. 5 IN A 10.244.1.150myapp-svc.default.svc.cluster.local. 5 IN A 10.244.2.166;; Query time: 0 msec;; SERVER: 10.96.0.10#53(10.96.0.10);; WHEN: Thu May 16 10:59:03 CST 2019;; MSG SIZE rcvd: 217# kubectl get svc -n kube-systemNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkube-dns ClusterIP 10.96.0.10 &lt;none&gt; 53/UDP,53/TCP,9153/TCP 20d# kubectl get pods -o wide -l app=myappNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyapp-deploy-675558bfc5-5c8hn 1/1 Running 0 42h 10.244.1.150 bj-gzf-vm-ops-test01 &lt;none&gt; &lt;none&gt;myapp-deploy-675558bfc5-qgps7 1/1 Running 0 42h 10.244.2.166 bj-gzf-vm-ops-test02 &lt;none&gt; &lt;none&gt;myapp-deploy-675558bfc5-qtlqf 1/1 Running 0 42h 10.244.3.167 bj-gzf-vm-ops-test03 &lt;none&gt; &lt;none&gt; ingress 及 ingress controller123# mkdir ingress-nginxfor file in configmap.yaml mandatory.yaml namespace.yaml rbac.yaml with-rbac.yaml ; do wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/$file ; done# kubectl apply -f ./ 123456789101112131415161718192021222324252627282930313233343536373839# cat deploy-demo.yamlapiVersion: v1kind: Servicemetadata: name: myapp namespace: defaultspec: selector: app: myapp release: canary ports: - name: httpd targetPort: 80 port: 80---apiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deploy namespace: defaultspec: replicas: 3 selector: matchLabels: app: myapp release: canary template: metadata: labels: app: myapp release: canary spec: containers: - name: myapp image: ikubernetes/myapp:v2 ports: - name: http containerPort: 80 12345# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/baremetal/service-nodeport.yaml# pwd/root/ingress-nginx# lsconfigmap.yaml mandatory.yaml namespace.yaml rbac.yaml service-nodeport.yaml with-rbac.yaml 12345678910111213141516171819202122232425262728293031# vim service-nodeport.yamlapiVersion: v1kind: Servicemetadata: name: ingress-nginx namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: type: NodePort ports: - name: http port: 80 targetPort: 80 protocol: TCP nodePort: 30080 - name: https port: 443 targetPort: 443 protocol: TCP nodePort: 30443 selector: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx---# kubectl apply -f ./# kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.96.59.169 &lt;none&gt; 80:30080/TCP,443:30443/TCP 2m35s 现在可以尝试访问 查看访问apiVersion 1234# kubectl explain ingressKIND: IngressVERSION: extensions/v1beta1# kubectl explain ingress.spec.rules.http.paths 1234567891011121314151617# vim ingress-myapp.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-myapp namespace: default annotations: kubernetes.io/ingress.class: "nginx"spec: rules: - host: myapp.ssjinyao.com http: paths: - path: backend: serviceName: myapp servicePort: 80 12345678910111213141516171819# kubectl describe ingress ingress-myappName: ingress-myappNamespace: defaultAddress:Default backend: default-http-backend:80 (&lt;none&gt;)Rules: Host Path Backends ---- ---- -------- myapp.ssjinyao.com myapp:80 (10.244.1.150:80,10.244.2.166:80,10.244.3.167:80)Annotations: kubectl.kubernetes.io/last-applied-configuration: &#123;"apiVersion":"extensions/v1beta1","kind":"Ingress","metadata":&#123;"annotations":&#123;"kubernetes.io/ingress.class":"nginx"&#125;,"name":"ingress-myapp","namespace":"default"&#125;,"spec":&#123;"rules":[&#123;"host":"myapp.ssjinyao.com","http":&#123;"paths":[&#123;"backend":&#123;"serviceName":"myapp","servicePort":80&#125;,"path":null&#125;]&#125;&#125;]&#125;&#125; kubernetes.io/ingress.class: nginxEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal CREATE 18s nginx-ingress-controller Ingress default/ingress-myapp# kubectl exec -n ingress-nginx nginx-ingress-controller-5694ccb578-xkgkx -it -- /bin/sh 这时再访问 tomcat 七层负载创建 1234567891011121314151617181920212223242526272829303132333435363738394041424344# vim tomcat-deploy.yamlapiVersion: v1kind: Servicemetadata: name: tomcat namespace: defaultspec: selector: app: tomcat release: canary ports: - name: httpd targetPort: 8080 port: 8080 - name: ajp targetPort: 8009 port: 8009---apiVersion: apps/v1kind: Deploymentmetadata: name: tomcat-deploy namespace: defaultspec: replicas: 3 selector: matchLabels: app: tomcat release: canary template: metadata: labels: app: tomcat release: canary spec: containers: - name: tomcat image: tomcat:8.5.32-jre8-alpine ports: - name: http containerPort: 8080 - name: ajp containerPort: 8009# kubectl apply -f tomcat-deploy.yaml 123456789101112131415161718# vim ingress-tomcat.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-tomcat namespace: default annotations: kubernetes.io/ingress.class: "nginx"spec: rules: - host: tomcat.ssjinyao.com http: paths: - path: backend: serviceName: tomcat servicePort: 8080# kubectl apply -f ingress-tomcat.yaml secret 创建与使用 1234567891011121314# kubectl create secret tls tomcat-ingress-secret --cert=2214184_tomcat.ssjinyao.com.pem --key=2214184_tomcat.ssjinyao.com.keysecret/tomcat-ingress-secret created# kubectl describe secret tomcat-ingress-secretName: tomcat-ingress-secretNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Type: kubernetes.io/tlsData====tls.crt: 3659 bytestls.key: 1675 bytes 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# vim ingress-tomcat-tls.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-tomcat-tls namespace: default annotations: kubernetes.io/ingress.class: "nginx"spec: tls: - hosts: - tomcat.ssjinyao.com secretName: tomcat-ingress-secret rules: - host: tomcat.ssjinyao.com http: paths: - path: backend: serviceName: tomcat servicePort: 8080# kubectl apply -f ingress-tomcat-tls.yaml# kubectl get ingressNAME HOSTS ADDRESS PORTS AGEingress-tomcat tomcat.ssjinyao.com 80 39mingress-tomcat-tls tomcat.ssjinyao.com 80, 443 93s# kubectl describe ingress ingress-tomcat-tlsName: ingress-tomcat-tlsNamespace: defaultAddress:Default backend: default-http-backend:80 (&lt;none&gt;)TLS: tomcat-ingress-secret terminates tomcat.ssjinyao.comRules: Host Path Backends ---- ---- -------- tomcat.ssjinyao.com tomcat:8080 (10.244.1.153:8080,10.244.2.171:8080,10.244.3.170:8080)Annotations: kubectl.kubernetes.io/last-applied-configuration: &#123;"apiVersion":"extensions/v1beta1","kind":"Ingress","metadata":&#123;"annotations":&#123;"kubernetes.io/ingress.class":"nginx"&#125;,"name":"ingress-tomcat-tls","namespace":"default"&#125;,"spec":&#123;"rules":[&#123;"host":"tomcat.ssjinyao.com","http":&#123;"paths":[&#123;"backend":&#123;"serviceName":"tomcat","servicePort":8080&#125;,"path":null&#125;]&#125;&#125;],"tls":[&#123;"hosts":["tomcat.ssjinyao.com"],"secretName":"tomcat-ingress-secret"&#125;]&#125;&#125; kubernetes.io/ingress.class: nginxEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal CREATE 2m29s nginx-ingress-controller Ingress default/ingress-tomcat-tls]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes操作记录(一)]]></title>
    <url>%2F2019%2F04%2F25%2Fkubernetes%E5%AE%9E%E6%93%8D%E8%AE%B0%E5%BD%951%2F</url>
    <content type="text"><![CDATA[kubernetes 操作记录(一)kubernetes 有两种部署方式，其中一种方式是将kubernetes 每个组件都以系统进程的方式运行成系统层面的服务;这样的部署繁琐而复杂，当然也可用别人写的ansible自动化工具推送一次;另外一部署部署方式是就是用 kubeadm 将 Kuberntes 每个组件都Pod形势进行部署; 使用 kubeadm 集群部署 kubernetes 节点网络 10.1.87.0/24 Pod网络 10.244.0.0/16 Service网络 10.96.0.0/12 部署准备kubeadm 需要每个节点都安装 kubelte,docker 而把其中一个节点初始化为master;其kuberntes 自己的各个组件都运行为Pod，其中的这些Pod都是静态Pod; kubeadm1、 master,nodes: 安装kubelet,kubeadm,docker2、 master: kubeadm init3、 nodes: kubeadm join https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md 节点服务器共四台，/etc/hosts配置信息如下 123410.1.87.80 master10.1.87.81 node0110.1.87.82 node0210.1.87.83 node03 注: 四台节点服务器时间需要同步 配置 kubernetes 及 docker 的Yum源123456789101112Master:配置# vim /etc/yum.repos.d/kubernetes.repo[kubernetes]name=kebernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpggpgcheck=1enabled=1# cd /etc/yum.repos.d/ &amp;&amp; wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# yum clean all &amp;&amp; yum makecache同步Yum配置到其它节点 # for i in &#123;1..3&#125; ;do scp docker-ce.repo kubernetes.repo node0$i:/etc/yum.repos.d/ ; done 四台服务器安装以下软件包 1234# yum -y install docker-ce kubelet kubeadm kubectl出现gpgkey问题，通过以下方式解决# wget https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg # rpm --import rpm-package-key.gpg 12345678master# vim /usr/lib/systemd/system/docker.service在[service]下添加以下内容Environment="HTTPS_PROXY=http://www.ik8s.io:10080"Environment="NO_PROXY=127.0.0.0/8, 10.1.87.0/24"# systemctl daemon-reload# systemctl restart docker# docker info 确保以下两个内核参数都是开启状态 1234# cat /proc/sys/net/bridge/bridge-nf-call-ip6tables1# cat /proc/sys/net/bridge/bridge-nf-call-iptables1 查看kubelet 所生成的文件 1234567# rpm -ql kubelet/etc/kubernetes/manifests/etc/sysconfig/kubelet/usr/bin/kubelet/usr/lib/systemd/system/kubelet.service# systemctl enable kubelet# systemctl enable docker 或者用脚本下载，并修改标签 12345678910111213141516# vim docker_install_kubelet_image.sh#!/bin/bashdocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.14.0docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.14.0docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.14.0docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.14.0docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.14.0 k8s.gcr.io/kube-apiserver:v1.14.0docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.14.0 k8s.gcr.io/kube-controller-manager:v1.14.0docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.14.0 k8s.gcr.io/kube-scheduler:v1.14.0docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.14.0 k8s.gcr.io/kube-proxy:v1.14.0docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10 k8s.gcr.io/etcd:3.3.10docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1 查看 kubeadm init 初始化集群的帮助信息 1# kubeadm init --help kubernetes 初始化123# vim /etc/sysconfig/kubeletKUBELET_EXTRA_ARGS="--fail-swap-on=false"# kubeadm init --kubernetes-version=v1.14.0 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=swap 12345# mkdir -p $HOME/.kube# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config# sudo chown $(id -u):$(id -g) $HOME/.kube/configkubeadm join 10.1.87.80:6443 --token 7pr4nt.q2vfoir7qia0vrcd \ --discovery-token-ca-cert-hash sha256:7e38f83642e4633a48efa1bd2bdc3cd2523e83736091b38ead58c88530758bdc 12345# kubectl get cs (componentstatus)NAME STATUS MESSAGE ERRORscheduler Healthy okcontroller-manager Healthy oketcd-0 Healthy &#123;"health":"true"&#125; 123# kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster NotReady master 23m v1.14.1 部署flannel 1# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 这时再看kubernetes集群已经运行起来了 123# kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready master 27m v1.14.1 查看Kubernetes的名称空间 123456# kubectl get nsNAME STATUS AGEdefault Active 28mkube-node-lease Active 28mkube-public Active 28mkube-system Active 28m 其它node{1..3}节点加入kubernetes 集群在node{1..3} 分别执行以下命令 12# systemctl start docker &amp;&amp; systemctl enable docker &amp;&amp; systemctl enable kubelet# kubeadm join 10.1.87.80:6443 --token 7pr4nt.q2vfoir7qia0vrcd --discovery-token-ca-cert-hash sha256:7e38f83642e4633a48efa1bd2bdc3cd2523e83736091b38ead58c88530758bdc --ignore-preflight-errors=swap 注: 这里需要手动去下载指定的镜像 123456# vim docker_install_join_kublet_image.sh#!/bin/bashdocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.14.0docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.14.0 k8s.gcr.io/kube-proxy:v1.14.0 将这个脚本同步到其它所有从服务器并执行 1234# scp docker_install_join_kublet_image.sh node02:/root/# scp docker_install_join_kublet_image.sh node03:/root/# 其余节点执行# sh docker_install_join_kublet_image.sh 123456# kubectl get nodesNAME STATUS ROLES AGE VERSIONnode01 Ready &lt;none&gt; 74m v1.14.1node02 Ready &lt;none&gt; 74m v1.14.1node03 Ready &lt;none&gt; 71m v1.14.1master Ready master 16h v1.14. 至此kubernetes 集群已经初始化完成 kubernetes 应用快速入门描述一个节点 1# kubectl describe node node01 查看kubernetes 集群信息 12# kubectl version# kubectl cluster-info 创建一个nginx Pod 1# kubectl run nginx-deploy --image=nginx:1.14-alpine --port=80 --replicas=1 1234567891011121314151617181920212223242526# curl 10.244.3.2&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 当把pod 手动删除时，会重新创建，因为首次创建pod 时指定了 replicas=1 1# kubectl delete pod nginx-deploy-55d8d67cf-qwlc2 123# kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-deploy-55d8d67cf-qj9z8 1/1 Running 0 5m44s 10.244.1.2 node01 &lt;none&gt; &lt;none&gt; 暴露服务端口 123456# kubectl expose deployment nginx-deploy --name=nginx --port=80 --target-port=80 --protocol=TCPservice/nginx exposed# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 2d16hnginx ClusterIP 10.96.181.70 &lt;none&gt; 80/TCP 52s 在集群内部访问 10.96.181.70 123456789101112131415161718192021222324252627# curl 10.96.181.70&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;You have new mail in /var/spool/mail/root 查看 kube-system (kube-dns) 的CLUSTER-IP 123# kubectl get svc -n kube-systemNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkube-dns ClusterIP 10.96.0.10 &lt;none&gt; 53/UDP,53/TCP,9153/TCP 2d16h 创建客户端 Pod 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# kubectl run client --image=busybox --replicas=1 -it --restart=Never/ # cat /etc/resolv.confnameserver 10.96.0.10search default.svc.cluster.local svc.cluster.local cluster.local localdomainoptions ndots:5# dig -t A nginx.default.svc.cluster.local @10.96.0.10; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-73.el7_6 &lt;&lt;&gt;&gt; -t A nginx.default.svc.cluster.local @10.96.0.10;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 19937;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; WARNING: recursion requested but not available;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;nginx.default.svc.cluster.local. IN A;; ANSWER SECTION:nginx.default.svc.cluster.local. 5 IN A 10.96.181.70;; Query time: 1 msec;; SERVER: 10.96.0.10#53(10.96.0.10);; WHEN: Sun Apr 28 10:41:56 CST 2019;; MSG SIZE rcvd: 107/ # wget -O - -q nginx&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 1# kubectl run myapp --image=ikubernetes/myapp:v1 --replicas=2 1234# kubectl get deployment -wNAME READY UP-TO-DATE AVAILABLE AGEmyapp 1/2 2 1 70snginx-deploy 1/1 1 1 60m 1# kubectl expose deployment myapp --name=myapp --port=80 两个pod 之间随机调度 123456789101112131415161718/ # wget -O - -q myappHello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;/ # wget -O - -q myapp/hostname.htmlmyapp-5bc569c47d-fhf7w/ # wget -O - -q myapp/hostname.htmlmyapp-5bc569c47d-fhf7w/ # wget -O - -q myapp/hostname.htmlmyapp-5bc569c47d-fhf7w/ # wget -O - -q myapp/hostname.htmlmyapp-5bc569c47d-fhf7w/ # wget -O - -q myapp/hostname.htmlmyapp-5bc569c47d-fhf7w/ # wget -O - -q myapp/hostname.htmlmyapp-5bc569c47d-xnslk/ # wget -O - -q myapp/hostname.htmlmyapp-5bc569c47d-xnslk/ # wget -O - -q myapp/hostname.htmlmyapp-5bc569c47d-fhf7w 修改pod数量 1# kubectl scale --replicas=5 deployment myapp 123456789# kubectl get podsNAME READY STATUS RESTARTS AGEclient 1/1 Running 0 35mmyapp-5bc569c47d-fhf7w 1/1 Running 0 22mmyapp-5bc569c47d-mqzdc 1/1 Running 0 112smyapp-5bc569c47d-w55fb 1/1 Running 0 13mmyapp-5bc569c47d-xkk2x 1/1 Running 0 112smyapp-5bc569c47d-xnslk 1/1 Running 0 22mnginx-deploy-55d8d67cf-v85hb 1/1 Running 0 32m 123456789101112# while sleep 1 ; do wget -O - -q myapp/hostname.html ;donemyapp-5bc569c47d-mqzdcmyapp-5bc569c47d-mqzdcmyapp-5bc569c47d-xkk2xmyapp-5bc569c47d-xnslkmyapp-5bc569c47d-w55fbmyapp-5bc569c47d-mqzdcmyapp-5bc569c47d-w55fbmyapp-5bc569c47d-fhf7wmyapp-5bc569c47d-xnslkmyapp-5bc569c47d-xkk2xmyapp-5bc569c47d-xnslk 滚动更新 12# kubectl set image deployment myapp myapp=ikubernetes/myapp:v2deployment.extensions/myapp image updated 实时监控滚动更新 1# kubectl rollout status deployment myapp 1234567# while sleep 1 ; do wget -O - -q myapp ;doneHello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;Hello MyApp | Version: v2 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;Hello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;Hello MyApp | Version: v2 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;Hello MyApp | Version: v2 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;Hello MyApp | Version: v2 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt; 回滚操作 12# kubectl rollout undo deployment myappdeployment.extensions/myapp rolled back 12345/ # while sleep 1 ; do wget -O - -q myapp ;doneHello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;Hello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;Hello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt;Hello MyApp | Version: v1 | &lt;a href="hostname.html"&gt;Pod Name&lt;/a&gt; 以myapp 为例，在集群外部进行访问 123# kubectl edit svc myapptype: ClusterIp 改为以下type: NodePort 12345# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 2d17hmyapp NodePort 10.100.210.54 &lt;none&gt; 80:32672/TCP 46mnginx ClusterIP 10.96.181.70 &lt;none&gt; 80/TCP 77m 客户端外部访问 1234567~ ➤ while sleep 1 ; do curl http://10.1.87.80:32672/hostname.html ; donemyapp-86984b4c7c-2vpjqmyapp-86984b4c7c-2vpjqmyapp-86984b4c7c-vw5mdmyapp-86984b4c7c-vj7qmmyapp-86984b4c7c-vj7qmmyapp-86984b4c7c-2vpjq 此时便可以使用keepalived + nginx(或haproxy)等实现负载均衡 资源定义清单入门定义一个简单的资源清单 12345678910111213141516171819# vim pod-demo.yamlapiVersion: v1kind: Podmetadata: name: pod-demo namespace: default labels: app: myapp tier: frontendspec: containers: - name: myapp image: ikubernetes/myapp:v1 - name: busybox image: busybox:latest command: - "/bin/sh" - "-c" - "sleep 5000" 1234# kubectl create -f pod-demo.yaml# kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEpod-demo 1/2 Running 5 4m19s 10.244.3.124 node03 &lt;none&gt; &lt;none&gt; 查看相关Pod相关信息 1# kubectl describe pod-demo Pod控制器应用进阶-L 选项 用于指定显示指定资源对象类别所有资源对应标签的值 1234567# kubectl get pods -L appNAME READY STATUS RESTARTS AGE APPclient 1/1 Running 0 8dmyapp-86984b4c7c-rf4lz 1/1 Running 0 27hmyapp-86984b4c7c-wss2h 1/1 Running 0 28hnginx-deploy-55d8d67cf-v85hb 1/1 Running 0 8dpod-demo 2/2 Running 121 7d2h myapp -l 获取标签，做标签过滤 123# kubectl get pods -l app --show-labelsNAME READY STATUS RESTARTS AGE LABELSpod-demo 2/2 Running 121 7d2h app=myapp,tier=frontend 显示多个标签的标签值 1234567# kubectl get pods -L app,runNAME READY STATUS RESTARTS AGE APP RUNclient 1/1 Running 0 8d clientmyapp-86984b4c7c-rf4lz 1/1 Running 0 27h myappmyapp-86984b4c7c-wss2h 1/1 Running 0 28h myappnginx-deploy-55d8d67cf-v85hb 1/1 Running 0 8d nginx-deploypod-demo 2/2 Running 121 7d2h myapp pod-demo 再次打标签 12345# kubectl label pods pod-demo release=canarypod/pod-demo labeled# kubectl get pods -l app --show-labels;NAME READY STATUS RESTARTS AGE LABELSpod-demo 2/2 Running 121 7d2h app=myapp,release=canary,tier=frontend 如果已有标签强行打标的话会报错 12# kubectl label pods pod-demo release=stableerror: 'release' already has a value (canary), and --overwrite is false 这个时候需要加上 –overwrite 12# kubectl label pods pod-demo release=stable --overwritepod/pod-demo labeled 查看既有release标签的又有app标签的Pod 123# kubectl get pods -l release,appNAME READY STATUS RESTARTS AGEpod-demo 2/2 Running 121 7d2h 给nginx-deploy Pod打标签 release=canary 12# kubectl label pods nginx-deploy-55d8d67cf-v85hb release=canarypod/nginx-deploy-55d8d67cf-v85hb labeled 查看 标签release=canary的Pod 123456# kubectl get pods -l releaseNAME READY STATUS RESTARTS AGEnginx-deploy-55d8d67cf-v85hb 1/1 Running 0 8dpod-demo 2/2 Running 121 7d3h# kubectl get pods -l release=canaryNAME READY STATUS RESTARTS AGE 标签选择器多条件选择 123# kubectl get pods -l release=stable,app=myappNAME READY STATUS RESTARTS AGEpod-demo 2/2 Running 121 7d3h 123456# kubectl get pods -l release!=stableNAME READY STATUS RESTARTS AGEclient 1/1 Running 0 8dmyapp-86984b4c7c-rf4lz 1/1 Running 0 27hmyapp-86984b4c7c-wss2h 1/1 Running 0 28hnginx-deploy-55d8d67cf-v85hb 1/1 Running 0 8d 123456789# kubectl get pods -l "release in (canary,beta,alpha)"NAME READY STATUS RESTARTS AGEnginx-deploy-55d8d67cf-v85hb 1/1 Running 0 8d# kubectl get pods -l "release notin (canary,beta,alpha)"NAME READY STATUS RESTARTS AGEclient 1/1 Running 0 8dmyapp-86984b4c7c-rf4lz 1/1 Running 0 27hmyapp-86984b4c7c-wss2h 1/1 Running 0 28hpod-demo 2/2 Running 121 7d3h 123456# kubectl get nodes --show-labelsNAME STATUS ROLES AGE VERSION LABELSnode01 Ready &lt;none&gt; 10d v1.14.1 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node01,kubernetes.io/os=linuxnode02 Ready &lt;none&gt; 10d v1.14.1 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node02,kubernetes.io/os=linuxnode03 Ready &lt;none&gt; 10d v1.14.1 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node03,kubernetes.io/os=linuxmaster Ready master 10d v1.14.1 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master,kubernetes.io/os=linux,node-role.kubernetes.io/master= 给node01 打额外标签，磁盘类型有固态硬盘 1234# kubectl label nodes node01 disktype=ssd# kubectl get nodes node01 --show-labelsNAME STATUS ROLES AGE VERSION LABELSnode01 Ready &lt;none&gt; 10d v1.14.1 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,disktype=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=node01,kubernetes.io/os=linux 这样做的好处: 当节点有标签后，随后添加资源时就可以对节点有倾向性 如下，创建Pod时指定nodeSelector 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: pod-demo namespace: default labels: app: myapp tier: frontendspec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 - name: https containerPort: 443 - name: busybox image: busybox:latest imagePullPolicy: IfNotPresent command: - "/bin/sh" - "-c" - "sleep 5000" nodeSelector: disktype: ssd nodeSelector disktype: ssdnodeName 指定直接运行在哪个节点上 12345# kubectl describe pods pod-demo可以查看以下信息，确定pod-demo 运行在node01上面 Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 2m46s default-scheduler Successfully assigned default/pod-demo to node01 annotations 添加注解 12345678910111213141516171819202122232425262728apiVersion: v1kind: Podmetadata: name: pod-demo namespace: default labels: app: myapp tier: frontend annotations: ssjinyao.com/create-by: "cluster admin"spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 - name: https containerPort: 443 - name: busybox image: busybox:latest imagePullPolicy: IfNotPresent command: - "/bin/sh" - "-c" - "sleep 5000" nodeSelector: disktype: ssd 123# kubectl create -f pod-demo.yaml# kubectl describe pods pod-demoAnnotations: ssjinyao.com/create-by: cluster admin ExecAction 用自定义的命令存活性探测 1234567891011121314151617181920212223242526272829# vim liveness-exec.yamlapiVersion: v1kind: Podmetadata: name: liveness-exec-pod namespace: defaultspec: containers: - name: liveness-exec-container image: busybox:latest imagePullPolicy: IfNotPresent command: ["/bin/sh" , "-c", "touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 3600"] livenessProbe: exec: command: ["test","-e","/tmp/healthy"] initialDelaySeconds: 1 periodSeconds: 3# kubectl create -f liveness-exec.yaml# kubectl get pods -wNAME READY STATUS RESTARTS AGEclient 1/1 Running 0 10dliveness-exec-pod 1/1 Running 0 47smyapp-86984b4c7c-rf4lz 1/1 Running 0 3d4hmyapp-86984b4c7c-wss2h 1/1 Running 0 3d5hnginx-deploy-55d8d67cf-v85hb 1/1 Running 0 10dpod-demo 2/2 Running 34 2dliveness-exec-pod 1/1 Running 1 69sliveness-exec-pod 1/1 Running 2 2m19sliveness-exec-pod 1/1 Running 3 3m28s 这个时候liveness-exec-pod 会不断因存活性探测而重启 基于HTTPGetAction探测 12345678910111213141516171819202122232425262728# vim liveness-httpget.yaml# cat liveness-httpget.yamlapiVersion: v1kind: Podmetadata: name: liveness-httpget-pod namespace: defaultspec: containers: - name: liveness-httpget-container image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 livenessProbe: httpGet: port: http path: /index.html initialDelaySeconds: 1 periodSeconds: 3# kubectl create -f liveness-httpget.yaml# kubectl exec liveness-httpget-pod -it -- /bin/sh# rm -f /usr/share/nginx/html/index.html# kubectl get podsNAME READY STATUS RESTARTS AGEclient 1/1 Running 0 10dliveness-httpget-pod 1/1 Running 2 6m31s 就续状态检查，如果pod不就续则不向外提供服务 12345678910111213141516171819202122232425# vim readiness-httpget.yamlapiVersion: v1kind: Podmetadata: name: readiness-httpget-pod namespace: defaultspec: containers: - name: readiness-httpget-container image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 readinessProbe: httpGet: port: http path: /index.html initialDelaySeconds: 1 periodSeconds: 3# kubectl exec readiness-httpget-pod -it -- /bin/sh/ # rm -f /usr/share/nginx/html/index.html# kubectl get podsNAME READY STATUS RESTARTS AGEreadiness-httpget-pod 0/1 Running 0 2m52s 可以看到readinss-httpget-pod 是不就续的 12345# kubectl exec readiness-httpget-pod -it -- /bin/sh/ # echo "test html" &gt; /usr/share/nginx/html/index.html# kubectl get podsNAME READY STATUS RESTARTS AGEreadiness-httpget-pod 1/1 Running 0 4m30s 当创建就绪探测HTTPGet页面文件时， pod 就绪状态立马恢复; Pod生命周期行为，启动前钩子，终止前钩子 lifecycle postStart postStop; 注: 启动容器时先执行command 再执行postStart因此 command命令不能强依赖于postStart执行结果; 12345678910111213141516171819# vim poststart-pod.yamlapiVersion: v1kind: Podmetadata: name: poststart-pod namespace: defaultspec: containers: - name: busybox-httpd image: busybox:latest ports: - containerPort: 80 imagePullPolicy: IfNotPresent lifecycle: postStart: exec: command: ["/bin/sh","-c","echo 'welcome www.ssjinyao.com' &gt; /tmp/index.html"] command: ["/bin/sh"] args: ["-c","httpd -h /tmp &amp;&amp; sleep 300000" ]]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fabric自动化之kvm私有云服务器快速开通与交付]]></title>
    <url>%2F2019%2F03%2F20%2Ffabric%E8%87%AA%E5%8A%A8%E5%8C%96%E4%B9%8Bkvm%E7%A7%81%E6%9C%89%E4%BA%91%E5%BF%AB%E9%80%9F%E5%BC%80%E9%80%9A%2F</url>
    <content type="text"><![CDATA[一、先来看看需求及对应的设计图 什么是FabricFabric是一个Python的库，提供了丰富的同SSH交互的接口，可以用来在本地或远程机器上自动化、流水化地执行Shell命令。非常适合用来做应用的远程部署及系统维护。简单易用，只需懂得基本的Shell命令。 版本区分Fabric：官方Fabric，兼容 Python 2 &amp; Python 3，但不兼容Fabric 1.x的fabfile；fabric2： 与Fabric相同，仅作为平滑迁移（使用Fabric包安装1.x 版本，使用Fabric2包安装2.x版本，来实现1.x和2.x的共存）；Fabric3：是一个基于Fabric 1.x 的fork，兼容Python2 &amp; Python3，兼容 Fabric1.x 的 fabfile； 二、项目结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107kvm_create/├── application│ ├── appcreate.py│ ├── __init__.py│ ├── kvmcreate.py├── config│ ├── hosts.py│ ├── __init__.py│ ├── messages.py│ └── test│ ├── __init__.py│ ├── kvm_config.py├── files│ ├── adminset_agent.tar.gz│ ├── mysqlxxxx│ │ ├── backup.sh│ │ ├── init_backup.sh│ │ ├── lepus_slowquery.sh│ │ ├── mysql-x.x.xx-linux-glibcx.xx-x86_64.tar.gz│ │ └── percona-toolkit_x.x.xx-x.tar.gz│ ├── mysqlxxxx│ │ ├── backup.sh│ │ ├── init_backup.sh│ │ ├── lepus_slowquery.sh│ │ ├── mysql-x.xx.xx-linux-glibcx.xx-86_64.tar.gz│ │ └── percona-toolkit_x.x.xx-x.tar.gz│ ├── nginx│ │ ├── nginx-1.xx.x.tar.gz│ │ └── nginx-1.xx.x.tar.gz│ ├── node_exporter│ │ ├── LICENSE│ │ ├── node_exporter│ │ └── NOTICE│ ├── php│ │ ├── php-x.x.xx.tar.gz│ │ ├── php-x.x.xx.tar.gz│ │ ├── php-x.x.xx.tar.gz│ │ ├── php-x.x.xx.tar.gz│ │ ├── php-x.x.xx.tar.gz│ │ └── php.ini│ ├── redis│ │ └── redis-x.x.x.tar.gz│ └── zabbix│ └── zabbix-x.x.x.tar.gz├── kernel│ ├── clone.py│ ├── __init__.py│ ├── last.py│ ├── mysqlxxxx.py│ ├── mysqlxx.py│ ├── nginx.py│ ├── php.py│ ├── redis.py│ ├── standard.py│ ├── start.py│ ├── yum.py│ ├── zabbix_agent.py├── kvm.py├── local│ ├── __init__.py│ ├── localall.py│ ├── mysqlxxxxreplace.py│ ├── mysqlxxreplace.py│ ├── nginxreplace.py│ ├── phpreplace.py│ ├── redisreplace.py│ ├── replacetemp.py│ ├── zabbixreplace.py├── templates│ ├── hosts│ ├── ifcfg-eth0│ ├── mysqlxx│ │ ├── my.cnf│ │ ├── mysql_install.sh│ │ └── mysql.service│ ├── mysqlxxxx│ │ ├── my.cnf│ │ ├── mysql_install.sh│ │ └── mysql.service│ ├── nginx│ │ ├── nginx.conf│ │ ├── nginx_install.sh│ │ ├── nginx.service│ │ └── vhost.conf│ ├── php│ │ ├── php-fpm.conf│ │ ├── php-fpm.service│ │ ├── php_install.sh│ │ └── www.conf│ ├── redis│ │ ├── redis.conf│ │ ├── redis_install.sh│ │ └── redis.service│ └── zabbix│ ├── zabbix_agentd│ ├── zabbix_agentd.conf│ └── zabbixagent_install.sh├── tmp_cache└── vars ├── __init__.py ├── kvmvar.py ├── mysqlxxxx.py ├── mysqlxxxx.py ├── nginxvar.py ├── phpvar.py ├── redisvar.py └── zabbix_agentvar.py 三、kernel 目录下的功能模块kvm服务器镜像clone 同步、kvm xml 配置模板的生成同步，网卡配置文件整合kvm新服务器;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/usr/bin/env python2# -*- coding: utf-8 -*-from fabric.contrib.files import *from config import *from vars.kvmvar import *from local.replacetemp import *class generate_kvmimg(object): def __init__(self): pass def clone_cevsxx(self): run(' [ -d' + ' ' + kvmtmpdir + ' ' +']' + ' ' + '||' + ' ' + 'mkdir -pv' + ' ' + kvmtmpdir) run('virt-clone -o ' + kvmce7name + ' ' + '-n' + ' ' + KVM_IP_HOSTNAME + ' ' + '-f' + ' ' + kvmtmpdir + KVM_IP_HOSTNAME + '.img') # run('mv' + ' ' + kvmdata + KVM_IP_HOSTNAME + '.img' + ' ' + kvmtmpdir) run('sed -i' + ' ' + '"s' + '#' + kvmtmpdir + '#' + kvmdata + '#g"' + ' ' + kvmqemu + KVM_IP_HOSTNAME + '.xml' ) run('cp' + ' ' + kvmqemu + KVM_IP_HOSTNAME + '.xml' + ' ' + kvmtmpdir) run('virsh undefine' + ' ' + KVM_IP_HOSTNAME) def site_imgip(self): rekvmeth = replace_tmp_file() rekvmeth.kvm_eth0() put(local_write_eth0 , kvmtmpdir) rekvmeth.kvm_eth0_local_remove() with cd(kvmtmpdir): run('virt-copy-in' + ' ' + 'ifcfg-eth0' + ' ' + '-a' + ' ' + KVM_IP_HOSTNAME + '.img' + ' ' + kvm_eth0_dir + '/') run('rm -f' + ' ' + kvmtmpdir + 'ifcfg-eth0') def site_imgxml_cpu(self): with cd(kvmtmpdir): run('sed -i \"s\\current=\'2\'\\current=\'' + KVM_CPU +'\'\\g\"' + ' ' + KVM_IP_HOSTNAME + '.xml') def site_imgxml_mem(self): with cd(kvmtmpdir): run('sed -i \"s\\4194304\\' + KVM_MEM + '\\g\"' + ' ' + KVM_IP_HOSTNAME + '.xml') def scp_cloned_img(self): run('scp' + ' ' + kvmtmpdir + KVM_IP_HOSTNAME + '.img' + ' ' + 'root@' + TARGETS_HOST + ':' + kvmdata) #run('scp' + ' ' + '-l 25000' + ' ' + kvmtmpdir + KVM_IP_HOSTNAME + '.img' + ' ' + 'root@' + TARGETS_HOST + ':' + kvmdata) run('rm -f' + ' ' + kvmtmpdir + KVM_IP_HOSTNAME + '.img') def scp_cloned_xml(self): run('scp' + ' ' + kvmtmpdir + KVM_IP_HOSTNAME + '.xml' + ' ' + 'root@' + TARGETS_HOST + ':' + kvmqemu) run('rm -f' + ' ' + kvmtmpdir + KVM_IP_HOSTNAME + '.xml') 突破 virt-copy-in 命令可以将已生成的网卡配置文件焙进镜像，依赖工具包libguestfs-tools-c 这样虚拟服务器开机后就可以直接分配指定的ip 操作目标服务器，将已经同步xml配置定义为虚拟机，扩展相应磁盘、并开启虚拟服务器;123456789101112131415161718192021222324#!/usr/bin/env python2# -*- coding: utf-8 -*-from fabric.contrib.files import *from config import *from vars.kvmvar import *class start_kvm(object): def __init__(self): pass def define_kvm(self): run('virsh define' + ' ' + kvmqemu + KVM_IP_HOSTNAME + '.xml') run(' [ -d' + ' ' + kvmtmpdir + ' ' + ']' + ' ' + '||' + ' ' + 'mkdir -pv' + ' ' + kvmtmpdir) def start_kvm(self): run('virsh start' + ' ' + KVM_IP_HOSTNAME) def extend_disk(self): run('qemu-img create -f qcow2' + ' ' + kvmdata + KVM_IP_HOSTNAME + '-data1.img' + ' ' + KVM_DISK) run('virsh attach-disk' + ' ' + KVM_IP_HOSTNAME + ' ' + kvmdata + KVM_IP_HOSTNAME + '-data1.img' + ' ' + 'vdc --subdriver=qcow2') run('virsh dumpxml' + ' ' + KVM_IP_HOSTNAME + ' ' + '&gt;' + ' ' + kvmqemu + KVM_IP_HOSTNAME + '.xml') run('virsh destroy' + ' ' + KVM_IP_HOSTNAME ) run('virsh define' + ' ' + kvmqemu + KVM_IP_HOSTNAME + '.xml') run('virsh start' + ' ' + KVM_IP_HOSTNAME) 虚拟服务器开机后完成相应的补充操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/env python2# -*- coding: utf-8 -*-from fabric.contrib.files import *from vars.kvmvar import localsrc,kvmsrc,kvm_install_localfrom config import LOGING_USERfrom local.replacetemp import *from local.localall import *class standard_kvm(object): def __init__(self): pass def site_kvm_hosts(self): kvm_host_init = replace_tmp_file() kvm_host_init.kvm_hosts() put(local_write_hosts,'/etc') local('rm -f' + ' ' + local_write_hosts) run('hostnamectl set-hostname' + ' ' + KVM_IP_HOSTNAME) run('mkfs.xfs /dev/vdb') run('ls -l /data &amp;&gt;/dev/null || mkdir /data') fstab_shell_list = ''' cat /etc/fstab | grep data &gt; /dev/null || \\ for i in `ls -l /dev/disk/by-uuid/ | grep vdb | awk '&#123;print $9&#125;'` ; \\ do echo "UUID=$i /data xfs defaults 0 0" &gt;&gt; /etc/fstab; \\ done ''' run(fstab_shell_list) run('mount -a') def install_kvm_adminsetd(self): put(localsrc + '/' + 'adminset_agent.tar.gz',kvmsrc) run('yum clean all') yum_clean_wait = command(25) yum_clean_wait.wait_sleep() with cd(kvmsrc): run('tar -xvf' + ' ' + 'adminset_agent.tar.gz') with cd(kvmsrc +'/' + 'adminset_agent'): run('sh install.sh') def install_node_exporter(self): put(localsrc + '/' + 'node_exporter', kvm_install_local) run('chmod +x /usr/local/node_exporter/node_exporter') run('echo \" nohup /usr/local/node_exporter/node_exporter &amp;&gt; /dev/null &amp; \" &gt;&gt; /etc/rc.local') run('nohup /usr/local/node_exporter/node_exporter &amp;&gt; /dev/null &amp;') run('hwclock --systohc') def set_kvm_passwd(self): run('echo' + ' ' + '\"' + new_pass + '\"' + ' ' + '| passwd --stdin' + ' ' + LOGING_USER) mysqlxx 补充模块, 实现功能与ansible-playbook roles 类似，现整合在kvm自动化中123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#!/usr/bin/env python2# -*- coding: utf-8 -*-from vars.mysqlxx import *from local.mysqlxxreplace import replace_mysqlxx_tmpfrom fabric.contrib.files import *from vars.kvmvar import tmp_cache, systemdreplace_mysqlxx = replace_mysqlxx_tmp()class mysqlxx_kvm(object): def __init__(self): pass def delete_old_conf(self): run('rm -f /etc/my.cnf') def delete_old_conf_dir(self): run('rm -rf /etc/my.cnf') def cp_source(self): put(mysqlfile + 'mysql-' + mysqlversion + '.tar.gz', datasrc) with cd(datasrc): run('tar -xvf' + ' ' 'mysql-' + mysqlversion + '.tar.gz' + ' ' + '-C /usr/local') def cp_mysql_conf(self): put(mysqltemp + 'my.cnf', '/etc/') def copy_mysql_install_sh(self): replace_mysqlxx.mysql_install_sh() put(tmp_cache + 'mysql_install.sh', datasrc) def add_mysql_user_and_group(self): run('id -g' + ' ' + mysqlgroup + ' ' + '||' + ' ' + 'groupadd' + ' ' + mysqlgroup) run('id -u' + ' ' + mysqluser + ' ' + '||' + ' ' + 'useradd -r' + ' ' + mysqluser + ' ' + '-g' + ' ' + mysqluser + ' ' + '-s' + ' ' + '/sbin/nologin') def create_related_directories(self): run('mkdir -pv' + ' ' + mysqldatapath ) run('mkdir -pv' + ' ' + mysqlbinlogpath) run('mkdir -pv' + ' ' + mysqlslowlogpath) run('mkdir -pv' + ' ' + mysqltmppath) run('mkdir -pv' + ' ' + mysqlerrlogpath) run('chmod 755' + ' ' + mysqldatapath) run('chmod 755' + ' ' + mysqlbinlogpath) run('chmod 755' + ' ' + mysqlslowlogpath) run('chmod 755' + ' ' + mysqltmppath) run('chmod 755' + ' ' + mysqlerrlogpath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqldatapath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqlbinlogpath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqlslowlogpath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqltmppath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqlerrlogpath) def create_slowlog_file(self): run('touch' + ' ' + mysqlslowlogpath + 'slowquery.log') run('chmod 644' + ' ' + mysqlslowlogpath + 'slowquery.log') run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqlslowlogpath + 'slowquery.log') def install_mysql(self): with cd(datasrc): run('/bin/bash' + ' ' + 'mysql_install.sh' + ' ' + '&amp;&amp; touch /tmp/mysql_installed') def add_mysql_to_PATH(self): run('echo \'export PATH=$PATH:' + mysqlinstallpath + 'bin\' &gt;&gt; /etc/profile &amp;&amp; touch /tmp/mysql_addtopath') def copy_mysql_service_file(self): replace_mysqlxx.mysql_service() put(tmp_cache + 'mysql.service', systemd) def clean_local_tmp_cache_file(self): replace_mysqlxx.clean_mysqlxx_tmp_cache() def start_mysql_and_enable_it_onboot(self): run('systemctl daemon-reload') run('systemctl start mysql') run('systemctl enable mysql') run('pip install MySQL-python') run('ln -s /data/mysqltmp/mysql.sock /tmp/mysql.sock') run('ln -s /usr/local/mysql-x.x.xx-linux-glibcx.xx-x86_64/lib/libmysqlclient.so.20 /usr/lib64/libmysqlclient.so.20') run('ln -s /usr/local/mysql-x.x.xx-linux-glibcx.xx-x86_64/ /usr/local/mysql') run('[ -d /data/scripts/ ] || mkdir /data/scripts/') put(mysqlfile + 'backup.sh', '/data/scripts') put(mysqlfile + 'lepus_slowquery.sh', '/data/scripts') put(mysqlfile + 'percona-toolkit_x.x.xx-x.tar.gz', '/data/scripts') put(mysqlfile + 'init_backup.sh', '/data/scripts') mysqlxxxx 同上，实现多版本并存123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#!/usr/bin/env python2# -*- coding: utf-8 -*-from vars.mysqlxxxx import *from local.mysqlxxxxreplace import replace_mysqlxx13_tmpfrom fabric.contrib.files import *from vars.kvmvar import tmp_cache, systemdreplace_mysqlxxxx = replace_mysqlxxxx_tmp()class mysqlxxxx_kvm(object): def __init__(self): pass def delete_old_conf(self): run('rm -f /etc/my.cnf') def delete_old_conf_dir(self): run('rm -rf /etc/my.cnf') def cp_source(self): put(mysqlfile + 'mysql-' + mysqlversion + '.tar.gz', datasrc) with cd(datasrc): run('tar -xvf' + ' ' 'mysql-' + mysqlversion + '.tar.gz' + ' ' + '-C /usr/local') def cp_mysql_conf(self): put(mysqltemp + 'my.cnf', '/etc/') def copy_mysql_install_sh(self): replace_mysqlxxxx.mysql_install_sh() put(tmp_cache + 'mysql_install.sh', datasrc) def add_mysql_user_and_group(self): run('id -g' + ' ' + mysqlgroup + ' ' + '||' + ' ' + 'groupadd' + ' ' + mysqlgroup) run('id -u' + ' ' + mysqluser + ' ' + '||' + ' ' + 'useradd -r' + ' ' + mysqluser + ' ' + '-g' + ' ' + mysqluser + ' ' + '-s' + ' ' + '/sbin/nologin') def create_related_directories(self): run('mkdir -pv' + ' ' + mysqldatapath ) run('mkdir -pv' + ' ' + mysqlbinlogpath) run('mkdir -pv' + ' ' + mysqlslowlogpath) run('mkdir -pv' + ' ' + mysqltmppath) run('mkdir -pv' + ' ' + mysqlerrlogpath) run('chmod 755' + ' ' + mysqldatapath) run('chmod 755' + ' ' + mysqlbinlogpath) run('chmod 755' + ' ' + mysqlslowlogpath) run('chmod 755' + ' ' + mysqltmppath) run('chmod 755' + ' ' + mysqlerrlogpath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqldatapath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqlbinlogpath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqlslowlogpath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqltmppath) run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqlerrlogpath) def create_slowlog_file(self): run('touch' + ' ' + mysqlslowlogpath + 'slowquery.log') run('chmod 644' + ' ' + mysqlslowlogpath + 'slowquery.log') run('chown' + ' ' + mysqluser + ':' + mysqlgroup + ' ' + mysqlslowlogpath + 'slowquery.log') def install_mysql(self): with cd(datasrc): run('/bin/bash' + ' ' + 'mysql_install.sh' + ' ' + '&amp;&amp; touch /tmp/mysql_installed') def add_mysql_to_PATH(self): run('echo \'export PATH=$PATH:' + mysqlinstallpath + 'bin\' &gt;&gt; /etc/profile &amp;&amp; touch /tmp/mysql_addtopath') def copy_mysql_service_file(self): replace_mysqlxxxx.mysql_service() put(tmp_cache + 'mysql.service', systemd) def clean_local_tmp_cache_file(self): replace_mysqlxxxx.clean_mysqlxxxx_tmp_cache() def start_mysql_and_enable_it_onboot(self): run('systemctl daemon-reload') run('systemctl start mysql') run('systemctl enable mysql') run('pip install MySQL-python') run('ln -s /data/mysqltmp/mysql.sock /tmp/mysql.sock') run('ln -s /usr/local/mysql-x.x.xx-linux-glibc2.5-x86_64/lib/libmysqlclient.so.20 /usr/lib64/libmysqlclient.so.20') run('ln -s /usr/local/mysql-x.x.xx-linux-glibc2.5-x86_64/ /usr/local/mysql') run('[ -d /data/scripts/ ] || mkdir /data/scripts/') put(mysqlfile + 'backup.sh', '/data/scripts') put(mysqlfile + 'lepus_slowquery.sh', '/data/scripts') put(mysqlfile + 'percona-toolkit_x.x.xx-1.tar.gz', '/data/scripts') put(mysqlfile + 'init_backup.sh', '/data/scripts') kvm 整合 redis安装自动化1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/usr/bin/env python2# -*- coding: utf-8 -*-from local.redisreplace import replace_redis_tmpfrom vars.redisvar import *from fabric.contrib.files import *from vars.kvmvar import tmp_cache, systemdreplace_redis = replace_redis_tmp()class redis_kvm(object): def __init__(self): pass def cp_source(self): put(redisfile + 'redis-' + redisversion + '.tar.gz', datasrc) with cd(datasrc): run('tar -xvf' + ' ' + 'redis-' + redisversion + '.tar.gz') def cp_redis_install_shell(self): replace_redis.redis_install_sh() put(tmp_cache + 'redis_install.sh', datasrc) def create_redis_group_and_user(self): run('id -g' + ' ' + redisgroup + ' ' + '||' + ' ' + 'groupadd' + ' ' + redisgroup) run('id -u' + ' ' + redisgroup + ' ' + '||' + ' ' + 'useradd -r' + ' ' + redisuser + ' ' + '-g' + ' ' + redisgroup + ' ' + '-s' + ' ' + '/sbin/nologin') def install_redis(self): run('/bin/bash' + ' ' + datasrc + 'redis_install.sh' + ' ' + '&amp;&amp; touch /tmp/redis_installed') def create_redis_log_file(self): run('touch' + ' ' + redislogpath) run('chmod 644' + ' ' + redislogpath) run('chown' + ' ' + redisuser + ':' + redisgroup + ' ' + redislogpath) def crate_redis_data_dir(self): run('mkdir -pv' + ' ' + redisdatapath) run('chmod 755' + ' ' + redisdatapath) run('chown' + ' ' + redisuser + ':' + redisgroup + ' ' + redisdatapath) def copy_redis_config(self): replace_redis.redis_conf() put(tmp_cache + 'redis.conf', redisdatapath + 'redis' + redisport + '.conf') run('chmod 644' + ' ' + redisdatapath + 'redis' + redisport + '.conf') run('chown' + ' ' + redisuser + ':' + redisgroup + ' ' + redisdatapath + 'redis' + redisport + '.conf') def copy_redis_service_config(self): replace_redis.redis_service() put(tmp_cache + 'redis.service', systemd + 'redis' + redisport + '.service') run('systemctl daemon-reload') run('systemctl start' + ' ' + 'redis' + redisport) def clean_local_tmp_cache_file(self): replace_redis.clean_redis_tmp_cache() run('echo \'export PATH=$PATH:/usr/local/src/redis-' + redisversion + '/src/' + '\' &gt;&gt; /etc/profile') kvm整合nginx 安装自动化1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/usr/bin/env python2# -*- coding: utf-8 -*-from local.nginxreplace import replace_nginx_tmpfrom fabric.contrib.files import *from vars.nginxvar import *from vars.kvmvar import kvmsrc,tmp_cache,systemdreplace_nginx = replace_nginx_tmp()class nginx_kvm(object): def __init__(self): pass def copy_source(self): put(nginxfile + 'nginx-' + nginxversion + '.tar.gz' , kvmsrc) with cd(kvmsrc): run('tar -xvf' + ' ' + 'nginx-' + nginxversion + '.tar.gz') def copy_nginx_install_shell(self): replace_nginx.nginx_install_sh() put(tmp_cache + 'nginx_install.sh', kvmsrc) def create_nginx_log_dir(self): run('mkdir -pv' + ' ' + nginxlogpath) run('chmod 755' + ' ' + nginxlogpath) def create_nginx_group_and_user(self): run('id -g' + ' ' + nginxgroup + ' ' + '||' + ' ' + 'groupadd' + ' ' + nginxgroup) run('id -u' + ' ' + nginxuser + ' ' + '||' + ' ' + 'useradd -r' + ' ' + nginxuser + ' ' + '-g' + ' ' + nginxgroup + ' ' + '-s' + ' ' + '/sbin/nologin') def install_nginx(self): with cd(kvmsrc): run('/bin/bash' + ' ' + 'nginx_install.sh') def create_nginx_vhosts_dir(self): run('mkdir -pv' + ' ' + nginxinstallpath + 'conf/vhost') run('chmod 755' + ' ' + nginxinstallpath + 'conf/vhost') def copy_main_template_config_file(self): replace_nginx.nginx_conf() # run('mv' + ' ' + nginxinstallpath + 'conf/nginx.conf&#123;,.bak&#125;') put(tmp_cache + 'nginx.conf', nginxinstallpath + 'conf/nginx.conf') def copy_vhost_template_config_file(self): replace_nginx.nginx_vhost() put(tmp_cache + 'vhost.conf', nginxinstallpath + 'conf/vhost') def clean_local_tmp_cache_file(self): replace_nginx.clean_nginx_tmp_cache() def copy_service_config_file(self): replace_nginx.nginx_service() put(tmp_cache + 'nginx.service',systemd) def start_nginx(self): run('systemctl daemon-reload') run('systemctl start nginx') kvm 整合php 自动化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647!/usr/bin/env python2# -*- coding: utf-8 -*-from local.phpreplace import replace_php_tmpfrom vars.phpvar import *from fabric.contrib.files import *from vars.kvmvar import kvmsrc, tmp_cache, systemdreplace_php = replace_php_tmp()class php_kvm(object): def __init__(self): pass def cp_source(self): put(phpfile + 'php-' + phpversion + '.tar.gz', kvmsrc) with cd(kvmsrc): run('tar -xvf' + 'php-' + phpversion + '.tar.gz') def cp_php_install_shell(self): replace_php.php_install_sh() put(tmp_cache + 'php_install.sh', kvmsrc) def create_php_group_and_user(self): run('id -g' + ' ' + phpgroup + ' ' + '||' + ' ' + 'groupadd' + ' ' + phpgroup) run('id -u' + ' ' + phpuser + ' ' + '||' + ' ' + 'useradd -r' + ' ' + phpuser + ' ' + '-g' + ' ' + phpgroup + ' ' + '-s' + ' ' + '/sbin/nologin') def create_php_log_dir(self): run('mkdir -pv' + ' ' + phplogpath) run('chmod 755' + ' ' + phplogpath) run('chown' + ' ' + phpuser + ':' + phpgroup + ' ' + phplogpath) def create_php_error_log_file(self): run('touch' + ' ' + phplogpath + 'php_errors.log') run('chmod 644' + ' ' + phplogpath + 'php_errors.log') run('chown' + ' ' + phpuser + ':' + phpgroup + ' ' + phplogpath + 'php_errors.log') def install_php(self): with cd(kvmsrc): run('/bin/bash' + ' ' + 'php_install.sh') def cp_main_phpini_config(self): put(phpfile + 'php.ini', phpinstallpath + 'etc/') def cp_php_www_conf_config(self): replace_php.php_www() put(tmp_cache + 'www.conf', phpinstallpath + 'etc/php-fpm.d/') def cp_php_php_fpm_config(self): replace_php.php_conf() put(tmp_cache + 'php-fpm.conf', phpinstallpath + 'etc/') def cp_php_php_fpm_service(self): replace_php.php_service() put(tmp_cache + 'php-fpm.service', systemd) def start_php(self): run('systemctl daemon-reload') run('systemctl start php-fpm || ss -tnl | grep 9000') def clean_local_tmp_cache_files(self): replace_php.clean_php_tmp_cache() kvm 整合zabbix_agent自动化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/usr/bin/env python2# -*- coding: utf-8 -*-from vars.zabbix_agentvar import *from local.zabbixreplace import replace_zabbix_tmpfrom fabric.contrib.files import *from vars.kvmvar import kvmsrc, tmp_cache, systemdreplace_zabbix_agent = replace_zabbix_tmp()class zabbix_agent_kvm(object): def __init__(self): pass def cp_source(self): put(zabbixfile + 'zabbix-' + zabbixagentversion + '.tar.gz' , datasrc) with cd(datasrc): run('tar -xvf' + ' ' + 'zabbix-' + zabbixagentversion + '.tar.gz') def cp_zabbix_agent_install_shell(self): replace_zabbix_agent.zabbix_agent_install_sh() put(tmp_cache + 'zabbixagent_install.sh', datasrc) def create_zabbix_group_and_user(self): run('id -g' + ' ' + zabbixagentgroup + ' ' + '||' + ' ' + 'groupadd' + ' ' + zabbixagentgroup) run('id -u' + ' ' + zabbixagentuser + ' ' + '||' + ' ' + 'useradd -r' + ' ' + zabbixagentuser + ' ' + '-g' + ' ' + zabbixagentgroup + ' ' + '-s' + ' ' + '/sbin/nologin') def create_zabbix_agent_log_dir(self): run('mkdir -pv' + ' ' + zabbixagentlogpath) run('chmod 755' + ' ' + zabbixagentlogpath) run('chown' + ' ' + zabbixagentuser + ':' + zabbixagentgroup + ' ' + zabbixagentlogpath) def install_zabbix_agent(self): with cd(datasrc): run('/bin/bash' + ' ' + 'zabbixagent_install.sh' + ' ' + 'touch /tmp/zabbixagent_installed') def copy_zabbix_agent_config_file(self): replace_zabbix_agent.zabbix_agent_conf() put(tmp_cache + 'zabbix_agentd.conf', zabbixagentinstallpath + '/etc/') def copy_zabbix_agent_init_file(self): replace_zabbix_agent.zabbix_agent_service() put(tmp_cache + 'zabbix_agentd', '/etc/init.d/') run('chmod 755' + ' ' + '/etc/init.d/zabbix_agentd') def clean_local_tmp_cache_file(self): replace_zabbix_agent.clean_zabbix_tmp_cache() def add_zabbix_agent_init(self): run('chkconfig --add zabbix_agentd') run('chkconfig zabbix_agentd on') def start_zabbix_agentd(self): run('service zabbix_agentd start') yum 安装相关依赖包123456789#!/usr/bin/env python2# -*- coding: utf-8 -*-from fabric.contrib.files import *from vars.kvmvar import yum_install_require_packages,yum_install_jdk_packagesdef yum_install_packages(): run('yum -y install' + '\\' + yum_install_require_packages)def yum_install_jdk(): run('yum -y install' + '\\' + yum_install_jdk_packages) 输入输出信息打印123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env python2# -*- coding: utf-8 -*-from fabric.colors import redfrom config import TARGETS_HOST, KVM_IP_HOSTNAME, KVM_IP_HOST, KVM_IP_GATEWAY, KVM_IP_NETMASK, ENV, APP, KVM_CPU, KVM_MEM ,KVM_DISK,KVM_IP_PASSWDfrom config.messages import MESSAGE_INFOfrom local.localall import new_pass, common_firstclass last(object): def __init__(self): pass def print_start_kvm_message(self): app_list = str(APP) app_list = app_list.replace("'","") app_list = app_list.replace("[","") app_list = app_list.replace("]","") app_list = app_list.replace(",","") first_print = common_first(MESSAGE_INFO['env'] + ENV, MESSAGE_INFO['name'] + KVM_IP_HOSTNAME, MESSAGE_INFO['ip'] + KVM_IP_HOST, MESSAGE_INFO['target'] +TARGETS_HOST, MESSAGE_INFO['gateway'] + KVM_IP_GATEWAY, MESSAGE_INFO['netmask'] + KVM_IP_NETMASK, MESSAGE_INFO['app'] + app_list, MESSAGE_INFO['cpu'] + KVM_CPU, MESSAGE_INFO['memory'] + KVM_MEM, MESSAGE_INFO['disk'] + KVM_DISK, MESSAGE_INFO['passwd'] + KVM_IP_PASSWD) first_print.message_all() user_choice = raw_input(red('If the information is incorrect, please input no: ')) if user_choice == "N" or user_choice == "n" or user_choice == "no" or user_choice == "No" or user_choice == "NO": print print(red('User check configuration is incorrect. Please rewrite configuration!')) print exit(1000) def print_kvm_message(self): app_list = str(APP) app_list = app_list.replace("'","") app_list = app_list.replace("[","") app_list = app_list.replace("]","") app_list = app_list.replace(",","") last_print = common_first(MESSAGE_INFO['env'] + ENV, MESSAGE_INFO['name'] + KVM_IP_HOSTNAME, MESSAGE_INFO['ip'] + KVM_IP_HOST, MESSAGE_INFO['target'] + TARGETS_HOST, MESSAGE_INFO['gateway'] + KVM_IP_GATEWAY, MESSAGE_INFO['netmask'] + KVM_IP_NETMASK, MESSAGE_INFO['app'] + app_list, MESSAGE_INFO['cpu'] + KVM_CPU, MESSAGE_INFO['memory'] + KVM_MEM, MESSAGE_INFO['disk'] + KVM_DISK, MESSAGE_INFO['passwd'] + new_pass) last_print.last_message_all() local 实现配置文件修改与替换例ifcfg-eth0 123456789101112131415161718192021222324252627282930313233343536373839#!/usr/bin/env python2# -*- coding: utf-8 -*-from fabric.api import *from vars.kvmvar import local_read_eth0,local_write_eth0,local_read_hosts,local_write_hosts,tmp_cachefrom config import KVM_IP_HOST,KVM_IP_NETMASK,KVM_IP_GATEWAY,KVM_IP_STATUE,KVM_IP_HOSTNAMEimport reclass replace_tmp_file(): def __init__(self): pass def kvm_eth0(self): network_file_read = open(local_read_eth0,"r") network_file_write = open(local_write_eth0,"w") with network_file_read as f: data = f.read() data = data.replace('$NETWORK_STATUS$',KVM_IP_STATUE) data = data.replace('$NETWORK_IPADDR$',KVM_IP_HOST) data = data.replace('$NETWORK_NETMASK$',KVM_IP_NETMASK) data = data.replace('$NETWORK_GATEWAY$',KVM_IP_GATEWAY) with network_file_write as f: f.write(data) def kvm_eth0_local_remove(self): local('rm -f' + ' ' + local_write_eth0) def kvm_hosts(self): hosts_file_read = open(local_read_hosts,"r") hosts_file_write = open(local_write_hosts,"w") with hosts_file_read as f: hosts = f.read() hosts = hosts.replace('$HOSTSIP$', KVM_IP_HOST) hosts = hosts.replace('$HOSTNAME$', KVM_IP_HOSTNAME) with hosts_file_write as f: f.write(hosts) def kvm_hosts_remove(self): local('rm -f' + ' ' + local_write_eth0) 其它功相关调用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#!/usr/bin/env python2# -*- coding: utf-8 -*-import randomimport stringfrom fabric.colors import *from time import sleepclass command(object): def __init__(self,info): self.info = info def wait_sleep(self): sleep(self.info) def create_pass(self,chars=string.ascii_uppercase+string.ascii_lowercase+string.digits):#string.punctuation return ''.join([random.choice(chars) for i in range(self.info)])from fabric.colors import *class common(object): def __init__(self,info): self.info = info def wait(self): for waits in range(1,2): sleep(waits) def message_green(self): print green('**' * 50) print green('&#123;:&lt;10&#125;&#123;:^80&#125;&#123;:&gt;10&#125;'.format('*' * 10, self.info , '*' * 10)) print green('**' * 50) print def message_blue(self): print blue('**' * 50) print blue('&#123;:&lt;10&#125;&#123;:^80&#125;&#123;:&gt;10&#125;'.format('*' * 10, self.info , '*' * 10)) print blue('**' * 50) print def message_orange(self): print yellow('**' * 50) print yellow('&#123;:&lt;10&#125;&#123;:^80&#125;&#123;:&gt;10&#125;'.format('*' * 10, self.info , '*' * 10)) print yellow('**' * 50) printclass common_first(object): def __init__(self, env, name, ip, target, gateway, netmask, app, cpu, memory, disk ,passwd): self.env = env self.name = name self.ip = ip self.target = target self.gateway = gateway self.netmask = netmask self.app = app self.cpu = cpu self.memory = memory self.disk = disk self.passwd = passwd def message_all(self): print magenta('**' * 50) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.env, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.name, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.ip, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.target, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.gateway, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.netmask, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.app, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.cpu, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.memory, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.disk, '*' * 10)) print magenta('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.passwd, '*' * 10)) print magenta('**' * 50) print def last_message_all(self): print cyan('**' * 50) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.env, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.name, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.ip, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.target, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.gateway, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.netmask, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.app, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.cpu, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.memory, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.disk, '*' * 10)) print cyan('&#123;:&lt;10&#125;&#123;:&lt;80&#125;&#123;:&gt;10&#125;'.format('*' * 10, ' ' + self.passwd, '*' * 10)) print cyan('**' * 50) printnewpasswd = command(12)new_pass = newpasswd.create_pass() config 目录存放配置相关的信息message.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#!/usr/bin/env python2# -*- coding: utf-8 -*-from config import ENVMESSAGE_INFO = &#123; &apos;start_kvm_site&apos;: &apos;Now Start KVM Create&apos;, &apos;app_clone&apos;: &apos;App Clone Genreate CentOS74&apos;, &apos;site_image_ip&apos;: &apos;Source Hosts Site Image IP&apos;, &apos;site_imgxml_cpu&apos;: &apos;Sources Hosts Site Image XML CPU&apos;, &apos;site_imgxml_mem&apos;: &apos;Sources Hosts Site Image XML Memory&apos;, &apos;scp_cloned_img&apos;: &apos;Sources Hosts Scp Cloned Image To Targets hosts&apos;, &apos;scp_cloned_xml&apos;: &apos;Sources Hosts Scp Cloned XML To Targets hosts&apos;, &apos;define_kvm&apos;: &apos;Targets Hosts Define Kvm Hosts&apos;, &apos;start_kvm&apos;: &apos;Targets Hosts Start Kvm Hosts&apos;, &apos;extend_disk&apos;: &apos;Targets Hosts Extend Kvm Disk&apos;, &apos;wait_sleep&apos;: &apos;Sleep 60s For Wait Start Kvm Hosts&apos;, &apos;site_kvm_hosts&apos;: &apos;KVM Site KVM Hosts&apos;, &apos;install_kvm_adminsetd&apos;: &apos;KVM Install Adminsetd And Node_exporter&apos;, &apos;start_yum_tools_install&apos;: &apos;Now Start Yum Tools Install&apos;, &apos;start_nginx_install&apos;: &apos;Now Start Nginx Install&apos;, &apos;nginx_copy&apos;: &apos;Nginx Copy Source File&apos;, &apos;copy_nginx_install_shell&apos;: &apos;Nginx Copy Install Shell&apos;, &apos;create_nginx_log_dir&apos;: &apos;Nginx Create Log Dir&apos;, &apos;create_nginx_group_and_user&apos;: &apos;Nginx Create Group And User&apos;, &apos;install_nginx&apos;: &apos;Nginx Install&apos;, &apos;create_nginx_vhosts_dir&apos;: &apos;Nginx Create Vhosts Dir&apos;, &apos;copy_main_template_config_file&apos;: &apos;Nginx Main Template Config File&apos;, &apos;copy_vhost_template_config_file&apos;: &apos;Nginx Copy Vhost Template Config File&apos;, &apos;copy_service_config_file&apos;: &apos;Nginx Copy Service Config File&apos;, &apos;start_nginx&apos;: &apos;Nginx Start&apos;, &apos;nginx_clean_local_tmp_cache_file&apos;: &apos;Nginx Clean local Tmp Cache File&apos;, &apos;start_php_install&apos;: &apos;Now Start PHP Install&apos;, &apos;php_copy&apos;: &apos;PHP Copy Source File&apos;, &apos;cp_php_install_shell&apos;: &apos;PHP Copy Install Shell&apos;, &apos;create_php_group_and_user&apos;: &apos;PHP Create Group And User&apos;, &apos;create_php_log_dir&apos;: &apos;PHP Create Log Dir&apos;, &apos;create_php_error_log_file&apos;: &apos;PHP Create Error Log File&apos;, &apos;install_php&apos;: &apos;PHP Install&apos;, &apos;cp_main_phpini_config&apos;: &apos;PHP Copy Phpini Config&apos;, &apos;cp_php_www_conf_config&apos;: &apos;PHP Copy PHP WWW Config&apos;, &apos;cp_php_php_fpm_config&apos;: &apos;PHP Copy php-fpm Config&apos;, &apos;cp_php_php_fpm_service&apos;: &apos;PHP Copy php-fpm Service&apos;, &apos;start_php&apos;: &apos;PHP Start&apos;, &apos;php_clean_local_tmp_cache_files&apos;: &apos;PHP Clean local Tmp Cache File&apos;, &apos;start_redis_install&apos;: &apos;Now Start Reids Install&apos;, &apos;redis_copy&apos;: &apos;Redis Copy Source File&apos;, &apos;cp_redis_install_shell&apos;: &apos;Redis Copy Install Shell&apos;, &apos;create_redis_group_and_user&apos;: &apos;Redis Create Grup And User&apos;, &apos;install_redis&apos;: &apos;Redis Install&apos;, &apos;create_redis_log_file&apos;: &apos;Redis Create Redis Log File&apos;, &apos;crate_redis_data_dir&apos;: &apos;Redis Create Data Dir&apos;, &apos;copy_redis_config&apos;: &apos;Redis Copy Config&apos;, &apos;copy_redis_service_config&apos;: &apos;Redis Copy Service Config&apos;, &apos;redis_clean_local_tmp_cache_file&apos;: &apos;Redis Clean Local Tmp Cache File&apos;, &apos;start_jdk_install&apos;: &apos;Now Start Install JDK&apos;, &apos;yum_install_jdk&apos;: &apos;JDK Yum Install&apos;, &apos;start_zabbix_agentd_install&apos;: &apos;Now Start Zabbix Agent Install&apos;, &apos;zabbix_copy&apos;: &apos;Zabbix Copy Source File&apos;, &apos;cp_zabbix_agent_install_shell&apos;: &apos;Zabbix Copy Agent Install Shell&apos;, &apos;create_zabbix_group_and_user&apos;: &apos;Zabbix Create Zabbix Group And User&apos;, &apos;create_zabbix_agent_log_dir&apos;: &apos;Zabbix Create Agent Log Dir&apos;, &apos;install_zabbix_agent&apos;: &apos;Zabbix Install Agent&apos;, &apos;copy_zabbix_agent_config_file&apos;: &apos;Zabbix Copy Zabbix Agent Config&apos;, &apos;copy_zabbix_agent_init_file&apos;: &apos;Zabbix Copy Zabbix Agent init&apos;, &apos;add_zabbix_agent_init&apos;: &apos;Zabbix Agent init&apos;, &apos;start_zabbix_agentd&apos;: &apos;Zabbix Agent start&apos;, &apos;zabbix_clean_local_tmp_cache_file&apos;: &apos;Zabbix Clean Local Tmp Cache File&apos;, &apos;start_mysqlxx_install&apos;: &apos;Now Start Mysqlxx Install&apos;, &apos;deletexx_old_conf&apos;: &apos;MySQLxx Delete Old Conf&apos;, &apos;deletexx_old_conf_dir&apos;: &apos;MySQLxx Delete Old Conf Dir&apos;, &apos;mysqlxx_source&apos;: &apos;MySQLxx Copy Source File&apos;, &apos;cp_mysqlxx_conf&apos;: &apos;MySQLxx Copy Conf&apos;, &apos;copy_mysqlxx_install_sh&apos;: &apos;MySQLxx Copy Install Shell&apos;, &apos;add_mysqlxx_user_and_group&apos;: &apos;MySQLxx Add User And Group&apos;, &apos;createxx_related_directories&apos;: &apos;MySQlxx Create Related Directories&apos;, &apos;createxx_slowlog_file&apos;: &apos;MySQLxx Create Slowlog File&apos;, &apos;install_mysqlxx&apos;: &apos;MySQLxx Install&apos;, &apos;add_mysqlxx_to_PATH&apos;: &apos;MySQLxx Add To PATH&apos;, &apos;cleanxx_local_tmp_cache_file&apos;: &quot;MySQLxx Clean Local Tmp Cache File&quot;, &apos;copy_mysqlxx_service_file&apos;: &quot;MySQLxx Copy Service File&quot;, &apos;start_mysqlxx_and_enable_it_onboot&apos;: &apos;MySQLxx start And Enable Onboot&apos;, &apos;start_mysqlxx13_install&apos;: &apos;Now Start Mysqlxx13 Install&apos;, &apos;deletexx13_old_conf&apos;: &apos;MySQLxx13 Delete Old Conf&apos;, &apos;deletexx13_old_conf_dir&apos;: &apos;MySQLxx13 Delete Old Conf Dir&apos;, &apos;mysqlxx13_source&apos;: &apos;MySQLxx13 Copy Source File&apos;, &apos;cp_mysqlxx13_conf&apos;: &apos;MySQLxx13 Copy Conf&apos;, &apos;copy_mysqlxx13_install_sh&apos;: &apos;MySQLxx13 Copy Install Shell&apos;, &apos;add_mysqlxx13_user_and_group&apos;: &apos;MySQLxx13 Add User And Group&apos;, &apos;createxx13_related_directories&apos;: &apos;MySQlxx13 Create Related Directories&apos;, &apos;createxx13_slowlog_file&apos;: &apos;MySQLxx13 Create Slowlog File&apos;, &apos;install_mysqlxx13&apos;: &apos;MySQLxx13 Install&apos;, &apos;add_mysqlxx13_to_PATH&apos;: &apos;MySQLxx13 Add To PATH&apos;, &apos;cleanxx13_local_tmp_cache_file&apos;: &quot;MySQLxx13 Clean Local Tmp Cache File&quot;, &apos;copy_mysqlxx13_service_file&apos;: &quot;MySQLxx13 Copy Service File&quot;, &apos;start_mysqlxx13_and_enable_it_onboot&apos;: &apos;MySQLxx13 Start And Enable Onboot&apos;, &apos;set_kvm_passwd&apos;: &apos;KVM Set root passwd&apos;, &apos;env&apos;: &apos;KVM ENV Is: &apos;, &apos;name&apos;: &apos;KVM Host Name Is: &apos;, &apos;ip&apos;: &apos;KVM IP Is: &apos;, &apos;target&apos;: &apos;TARGET IP Is: &apos;, &apos;gateway&apos;: &apos;KVM Gateway Is: &apos;, &apos;netmask&apos;: &apos;KVM Netmask Is: &apos;, &apos;app&apos;: &apos;KVM APP Is: &apos;, &apos;cpu&apos;: &apos;KVM CPU Is: &apos;, &apos;memory&apos;: &apos;KVM Memory Is: &apos;, &apos;disk&apos;: &apos;KVM Disk Is: &apos;, &apos;passwd&apos;: &apos;KVM Passwd IS: &apos;&#125; host.py 开通服务器所要操控的三台服务器 1234567891011121314#!/usr/bin/env python2# -*- coding: utf-8 -*-from config import *SOURCES_HOSTS = [ LOGING_USER + '@' + SOURCES_HOST]TARGETS_HOSTS = [ LOGING_USER + '@' + TARGETS_HOST]KVM_HOSTS = [ LOGING_USER + '@' + KVM_IP_HOST] init.py 生产与生产环境配置的开关 1234#!/usr/bin/env python2# -*- coding: utf-8 -*-#from config.prod.kvm_config import *from config.test.kvm_config import * kvm_create.py 每次开通服务器所需要的配置信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/usr/bin/env python2# -*- coding: utf-8 -*-from fabric.api import envfrom local.localall import newpasswd########################################### 以下为通常不变的信息 ########################################## 登录用户信息，默认为rootENV = 'prod'LOGING_USER = 'root'## 生产环境网关信息,生产网关默认不变KVM_IP_GATEWAY = 'xxx.xx.xx.xx'## kvm服务器密码信息kvm服务器中的模板，一般不变KVM_IP_PASSWD = 'xxxxxxxxXXXX'## 源服务器信息，一般从物理服务器(xxx.xx.xx.xx)进行克隆SOURCES_HOST = 'xxx.xx.xx.xx'SOURCES_PASS = 'xxxxxxxxxxxxxxxxxxxxxxx'## kvm虚拟机启动后网卡的开启状态，一般不变KVM_IP_STATUE = 'yes'########################################## 以下为通常改变的信息 ############################################# 目标服务器信息(切记改变配置信息)#TARGETS_HOST = 'xxx.xx.xxx.xx'#TARGETS_PASS = 'xxxxxxxxxxxxxxxxxxxxxxxx'### kvm服务器信息(切记改变配置信息)#KVM_IP_HOSTNAME = 'xx-xxxx-xx-xxx-xxxx-xxxx'#KVM_IP_HOST = '172.30.70.'#KVM_IP_NETMASK = '255.255.192.0'#KVM_CPU = '2'#KVM_DISK = '100G'##KVM_MEM = '10xx144'##KVM_MEM = '2114288'##KVM_MEM = '2097152'##KVM_MEM = '4194304'##KVM_MEM = '6291456'#KVM_MEM = '8388608'##KVM_MEM = '1048xx60'##KVM_MEM = '12582912'##KVM_MEM = '14680064'##KVM_MEM = '16777216'##KVM_MEM = '20971520'##KVM_MEM = '25165824'#APP = ['zabbix_agent', 'jdk']##APP = ['zabbix_agent', 'nginx', 'php', 'redis', 'jdk', 'mysql_xx', 'mysql_xx13']############################################# 以下为代替的执行登录信息 ####################################env.passwords[LOGING_USER + '@' + SOURCES_HOST + ':22'] = SOURCES_PASSenv.passwords[LOGING_USER + '@' + TARGETS_HOST + ':22'] = TARGETS_PASSenv.passwords[LOGING_USER + '@' + KVM_IP_HOST + ':22'] = KVM_IP_PASSWD application 定义自动化执行流程 kvmcreate.py 定义kvm 自动部署流程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#!/usr/bin/env python2# -*- coding: utf-8 -*-from config import KVM_CPU,KVM_MEM,KVM_DISKfrom config.messages import MESSAGE_INFOfrom kernel.clone import *from kernel.start import *from kernel.standard import *from kernel.last import *from local.localall import commonapp_clone_generate = generate_kvmimg()app_targets_hosts_start = start_kvm()app_kvm_hosts_start_site = standard_kvm()app_kvm_hosts_start_print = last()def kvm_create(): print_first_message = last() print_first_message.print_start_kvm_message() print_kvm_message = common(MESSAGE_INFO['start_kvm_site']) print_kvm_message.message_blue() print_kvm_message = common(MESSAGE_INFO['app_clone']) print_kvm_message.message_green() app_clone_generate.clone_cevs74() print_kvm_message = common(MESSAGE_INFO['site_image_ip']) print_kvm_message.message_green() app_clone_generate.site_imgip() if KVM_CPU != '2' and KVM_MEM != '4194304': print_kvm_message = common(MESSAGE_INFO['site_imgxml_cpu']) print_kvm_message.message_green() app_clone_generate.site_imgxml_cpu() print_kvm_message = common(MESSAGE_INFO['site_imgxml_mem']) print_kvm_message.message_green() app_clone_generate.site_imgxml_mem() if KVM_CPU != '2' and KVM_MEM == '4194304': print_kvm_message = common(MESSAGE_INFO['site_imgxml_cpu']) print_kvm_message.message_green() app_clone_generate.site_imgxml_cpu() if KVM_MEM != '4194304' and KVM_CPU == '2': print_kvm_message = common(MESSAGE_INFO['site_imgxml_mem']) print_kvm_message.message_green() app_clone_generate.site_imgxml_mem() print_kvm_message = common(MESSAGE_INFO['scp_cloned_img']) print_kvm_message.message_green() app_clone_generate.scp_cloned_img() print_kvm_message = common(MESSAGE_INFO['scp_cloned_xml']) print_kvm_message.message_green() app_clone_generate.scp_cloned_xml()def targets_hosts_start_kvm(): print_kvm_message = common(MESSAGE_INFO['define_kvm']) print_kvm_message.message_green() app_targets_hosts_start.define_kvm() print_kvm_message = common(MESSAGE_INFO['start_kvm']) print_kvm_message.message_green() app_targets_hosts_start.start_kvm() if KVM_DISK is not '': print_kvm_message = common(MESSAGE_INFO['extend_disk']) print_kvm_message.message_green() app_targets_hosts_start.extend_disk() print_kvm_message = common(MESSAGE_INFO['wait_sleep']) print_kvm_message.message_green() time_sleep_wait_start = command(60) time_sleep_wait_start.wait_sleep()def kvm_virture_hosts_site(): print_kvm_message = common(MESSAGE_INFO['site_kvm_hosts']) print_kvm_message.message_green() app_kvm_hosts_start_site.site_kvm_hosts() print_kvm_message = common(MESSAGE_INFO['install_kvm_adminsetd']) print_kvm_message.message_green() app_kvm_hosts_start_site.install_kvm_adminsetd() app_kvm_hosts_start_site.install_node_exporter()def kvm_tirture_hosts_site_passwd(): print_kvm_message = common(MESSAGE_INFO['set_kvm_passwd']) print_kvm_message.message_green() app_kvm_hosts_start_site.set_kvm_passwd()def kvm_virture_hosts_print(): app_kvm_hosts_start_print.print_kvm_message() appcreate.py 用于定义应用程序的部署流程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348#!/usr/bin/env python2# -*- coding: utf-8 -*-from config.messages import MESSAGE_INFOfrom local.localall import commonfrom kernel.yum import yum_install_packages, yum_install_jdkfrom kernel.nginx import nginx_kvmfrom kernel.php import php_kvmfrom kernel.redis import redis_kvmfrom kernel.zabbix_agent import zabbix_agent_kvmfrom kernel.mysqlxx import mysqlxx_kvmfrom kernel.mysqlxxxx import mysqlxxxx_kvmfrom config import APPnginx_install = nginx_kvm()php_install = php_kvm()redis_install = redis_kvm()zabbix_agent_install = zabbix_agent_kvm()mysqlxx_install = mysqlxx_kvm()mysqlxxxx_install = mysqlxxxx_kvm()def run_yum_install(): yum_install_packages()def run_install_nginx(): print_application_message = common(MESSAGE_INFO['nginx_copy']) print_application_message.message_green() nginx_install.copy_source() print_application_message = common(MESSAGE_INFO['copy_nginx_install_shell']) print_application_message.message_green() nginx_install.copy_nginx_install_shell() print_application_message = common(MESSAGE_INFO['create_nginx_log_dir']) print_application_message.message_green() nginx_install.create_nginx_log_dir() print_application_message = common(MESSAGE_INFO['create_nginx_group_and_user']) print_application_message.message_green() nginx_install.create_nginx_group_and_user() print_application_message = common(MESSAGE_INFO['install_nginx']) print_application_message.message_green() nginx_install.install_nginx() print_application_message = common(MESSAGE_INFO['create_nginx_vhosts_dir']) print_application_message.message_green() nginx_install.create_nginx_vhosts_dir() print_application_message = common(MESSAGE_INFO['copy_main_template_config_file']) print_application_message.message_green() nginx_install.copy_main_template_config_file() print_application_message = common(MESSAGE_INFO['copy_vhost_template_config_file']) print_application_message.message_green() nginx_install.copy_vhost_template_config_file() print_application_message = common(MESSAGE_INFO['copy_service_config_file']) print_application_message.message_green() nginx_install.copy_service_config_file() print_application_message = common(MESSAGE_INFO['start_nginx']) print_application_message.message_green() nginx_install.start_nginx() print_application_message = common(MESSAGE_INFO['nginx_clean_local_tmp_cache_file']) print_application_message.message_green() nginx_install.clean_local_tmp_cache_file()def run_install_php(): print_application_message = common(MESSAGE_INFO['php_copy']) print_application_message.message_green() php_install.cp_source() print_application_message = common(MESSAGE_INFO['cp_php_install_shell']) print_application_message.message_green() php_install.cp_php_install_shell() print_application_message = common(MESSAGE_INFO['create_php_group_and_user']) print_application_message.message_green() php_install.create_php_group_and_user() print_application_message = common(MESSAGE_INFO['create_php_log_dir']) print_application_message.message_green() php_install.create_php_log_dir() print_application_message = common(MESSAGE_INFO['create_php_error_log_file']) print_application_message.message_green() php_install.create_php_error_log_file() print_application_message = common(MESSAGE_INFO['install_php']) print_application_message.message_green() php_install.install_php() print_application_message = common(MESSAGE_INFO['cp_main_phpini_config']) print_application_message.message_green() php_install.cp_main_phpini_config() print_application_message = common(MESSAGE_INFO['cp_php_www_conf_config']) print_application_message.message_green() php_install.cp_php_www_conf_config() print_application_message = common(MESSAGE_INFO['cp_php_php_fpm_config']) print_application_message.message_green() php_install.cp_php_php_fpm_config() print_application_message = common(MESSAGE_INFO['cp_php_php_fpm_service']) print_application_message.message_green() php_install.cp_php_php_fpm_service() print_application_message = common(MESSAGE_INFO['start_php']) print_application_message.message_green() php_install.start_php() print_application_message = common(MESSAGE_INFO['php_clean_local_tmp_cache_files']) print_application_message.message_green() php_install.clean_local_tmp_cache_files()def run_install_redis(): print_application_message = common(MESSAGE_INFO['redis_copy']) print_application_message.message_green() redis_install.cp_source() print_application_message = common(MESSAGE_INFO['cp_redis_install_shell']) print_application_message.message_green() redis_install.cp_redis_install_shell() print_application_message = common(MESSAGE_INFO['create_redis_group_and_user']) print_application_message.message_green() redis_install.create_redis_group_and_user() print_application_message = common(MESSAGE_INFO['install_redis']) print_application_message.message_green() redis_install.install_redis() print_application_message = common(MESSAGE_INFO['create_redis_log_file']) print_application_message.message_green() redis_install.create_redis_log_file() print_application_message = common(MESSAGE_INFO['crate_redis_data_dir']) print_application_message.message_green() redis_install.crate_redis_data_dir() print_application_message = common(MESSAGE_INFO['copy_redis_config']) print_application_message.message_green() redis_install.copy_redis_config() print_application_message = common(MESSAGE_INFO['copy_redis_service_config']) print_application_message.message_green() redis_install.copy_redis_service_config() print_application_message = common(MESSAGE_INFO['redis_clean_local_tmp_cache_file']) print_application_message.message_green() redis_install.clean_local_tmp_cache_file()def run_install_jdk(): print_application_message = common(MESSAGE_INFO['yum_install_jdk']) print_application_message.message_green() yum_install_jdk()def run_install_zabbix_agent(): print_application_message = common(MESSAGE_INFO['zabbix_copy']) print_application_message.message_green() zabbix_agent_install.cp_source() print_application_message = common(MESSAGE_INFO['cp_zabbix_agent_install_shell']) print_application_message.message_green() zabbix_agent_install.cp_zabbix_agent_install_shell() print_application_message = common(MESSAGE_INFO['create_zabbix_group_and_user']) print_application_message.message_green() zabbix_agent_install.create_zabbix_group_and_user() print_application_message = common(MESSAGE_INFO['create_zabbix_agent_log_dir']) print_application_message.message_green() zabbix_agent_install.create_zabbix_agent_log_dir() print_application_message = common(MESSAGE_INFO['install_zabbix_agent']) print_application_message.message_green() zabbix_agent_install.install_zabbix_agent() print_application_message = common(MESSAGE_INFO['copy_zabbix_agent_config_file']) print_application_message.message_green() zabbix_agent_install.copy_zabbix_agent_config_file() print_application_message = common(MESSAGE_INFO['copy_zabbix_agent_init_file']) print_application_message.message_green() zabbix_agent_install.copy_zabbix_agent_init_file() print_application_message = common(MESSAGE_INFO['zabbix_clean_local_tmp_cache_file']) print_application_message.message_green() zabbix_agent_install.clean_local_tmp_cache_file() print_application_message = common(MESSAGE_INFO['add_zabbix_agent_init']) print_application_message.message_green() zabbix_agent_install.add_zabbix_agent_init() print_application_message = common(MESSAGE_INFO['start_zabbix_agentd']) print_application_message.message_green() zabbix_agent_install.start_zabbix_agentd()def run_install_mysqlxx(): print_application_message = common(MESSAGE_INFO['deletexx_old_conf']) print_application_message.message_green() mysqlxx_install.delete_old_conf() print_application_message = common(MESSAGE_INFO['deletexx_old_conf_dir']) print_application_message.message_green() mysqlxx_install.delete_old_conf_dir() print_application_message = common(MESSAGE_INFO['mysqlxx_source']) print_application_message.message_green() mysqlxx_install.cp_source() print_application_message = common(MESSAGE_INFO['cp_mysqlxx_conf']) print_application_message.message_green() mysqlxx_install.cp_mysql_conf() print_application_message = common(MESSAGE_INFO['copy_mysqlxx_install_sh']) print_application_message.message_green() mysqlxx_install.copy_mysql_install_sh() print_application_message = common(MESSAGE_INFO['add_mysqlxx_user_and_group']) print_application_message.message_green() mysqlxx_install.add_mysql_user_and_group() print_application_message = common(MESSAGE_INFO['createxx_related_directories']) print_application_message.message_green() mysqlxx_install.create_related_directories() print_application_message = common(MESSAGE_INFO['createxx_slowlog_file']) print_application_message.message_green() mysqlxx_install.create_slowlog_file() print_application_message = common(MESSAGE_INFO['install_mysqlxx']) print_application_message.message_green() mysqlxx_install.install_mysql() print_application_message = common(MESSAGE_INFO['add_mysqlxx_to_PATH']) print_application_message.message_green() mysqlxx_install.add_mysql_to_PATH() print_application_message = common(MESSAGE_INFO['copy_mysqlxx_service_file']) print_application_message.message_green() mysqlxx_install.copy_mysql_service_file() print_application_message = common(MESSAGE_INFO['cleanxx_local_tmp_cache_file']) print_application_message.message_green() mysqlxx_install.clean_local_tmp_cache_file() print_application_message = common(MESSAGE_INFO['start_mysqlxx_and_enable_it_onboot']) print_application_message.message_green() mysqlxx_install.start_mysql_and_enable_it_onboot()def run_install_mysqlxx13(): print_application_message = common(MESSAGE_INFO['deletexx13_old_conf']) print_application_message.message_green() mysqlxx13_install.delete_old_conf() print_application_message = common(MESSAGE_INFO['deletexx13_old_conf_dir']) print_application_message.message_green() mysqlxx13_install.delete_old_conf_dir() print_application_message = common(MESSAGE_INFO['mysqlxx13_source']) print_application_message.message_green() mysqlxx13_install.cp_source() print_application_message = common(MESSAGE_INFO['cp_mysqlxx13_conf']) print_application_message.message_green() mysqlxx13_install.cp_mysql_conf() print_application_message = common(MESSAGE_INFO['copy_mysqlxx13_install_sh']) print_application_message.message_green() mysqlxx13_install.copy_mysql_install_sh() print_application_message = common(MESSAGE_INFO['add_mysqlxx13_user_and_group']) print_application_message.message_green() mysqlxx13_install.add_mysql_user_and_group() print_application_message = common(MESSAGE_INFO['createxx13_related_directories']) print_application_message.message_green() mysqlxx13_install.create_related_directories() print_application_message = common(MESSAGE_INFO['createxx13_slowlog_file']) print_application_message.message_green() mysqlxx13_install.create_slowlog_file() print_application_message = common(MESSAGE_INFO['install_mysqlxx13']) print_application_message.message_green() mysqlxx13_install.install_mysql() print_application_message = common(MESSAGE_INFO['add_mysqlxx13_to_PATH']) print_application_message.message_green() mysqlxx13_install.add_mysql_to_PATH() print_application_message = common(MESSAGE_INFO['copy_mysqlxx13_service_file']) print_application_message.message_green() mysqlxx13_install.copy_mysql_service_file() print_application_message = common(MESSAGE_INFO['cleanxx13_local_tmp_cache_file']) print_application_message.message_green() mysqlxx13_install.clean_local_tmp_cache_file() print_application_message = common(MESSAGE_INFO['start_mysqlxx13_and_enable_it_onboot']) print_application_message.message_green() mysqlxx13_install.start_mysql_and_enable_it_onboot()def run_install_all_application_package(): if len(APP) != (0): print_application_message = common(MESSAGE_INFO['start_yum_tools_install']) print_application_message.message_blue() run_yum_install() if 'nginx' in APP: print_application_message = common(MESSAGE_INFO['start_nginx_install']) print_application_message.message_blue() run_install_nginx() if 'php' in APP: print_application_message = common(MESSAGE_INFO['start_php_install']) print_application_message.message_blue() run_install_php() if 'redis' in APP: print_application_message = common(MESSAGE_INFO['start_redis_install']) print_application_message.message_blue() run_install_redis() if 'jdk' in APP: print_application_message = common(MESSAGE_INFO['start_jdk_install']) print_application_message.message_blue() run_install_jdk() if 'zabbix_agent' in APP: print_application_message = common(MESSAGE_INFO['start_zabbix_agentd_install']) print_application_message.message_blue() run_install_zabbix_agent() if 'mysql_xx' in APP: print_application_message = common(MESSAGE_INFO['start_mysqlxx_install']) print_application_message.message_blue() run_install_mysqlxx() if 'mysql_xx13' in APP: print_application_message = common(MESSAGE_INFO['start_mysqlxx13_install']) print_application_message.message_blue() run_install_mysqlxx13() 定义入口文件kvm.py 是所有程序执行的入口文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#!/usr/bin/env python2# -*- coding: utf-8 -*-from prettytable import PrettyTablefrom config.hosts import SOURCES_HOSTS,TARGETS_HOSTS,KVM_HOSTSfrom fabric.contrib.files import *from application.kvmcreate import *from application.appcreate import *@hosts(SOURCES_HOSTS)def kvm_sources_clone_scp(): kvm_create()@hosts(TARGETS_HOSTS)def kvm_targets_site(): targets_hosts_start_kvm()@hosts(KVM_HOSTS)def kvm_virture_host_start_site(): kvm_virture_hosts_site() run_install_all_application_package() kvm_tirture_hosts_site_passwd() kvm_virture_hosts_print()@task(name='install')def run_all(): execute(kvm_sources_clone_scp) execute(kvm_targets_site) execute(kvm_virture_host_start_site)@task(name='help')def deploy_help(): print green("KVM产品及CentOS7应用部署") print yellow(" 1.配置文件") helper = PrettyTable() helper.field_names = ["配置","说明"] helper.align = "l" helper.add_row(["config/__init__.py", "配置文件开关"]) helper.add_row(["config/test/kvm_config.py", "测试环境部署配置"]) helper.add_row(["config/prod/kvm_config.py", "生产环境部署配置"]) print helper print red(" 2.指令说明") helper = PrettyTable() helper.field_names = ["指令","说明"] helper.align = "l" helper.add_row(["fab -f kvm.py -l", "列出部署产品"]) helper.add_row(["fab -f kvm.py install", "安装kvm,并整合配置的应用至kvm新虚拟服务器"]) print helper print blue(" 3.作者信息") helper = PrettyTable() helper.field_names = ["作者","信息"] helper.add_row(["姓名", "任锦"]) helper.add_row(["手机号", "13161389224"]) helper.add_row(["博客地址", "www.ssjinyao.com"]) print helper 服务器部署完此代码后，定义别名调用kvm.py实现快速开通1234567# alias kc1='source /root/renjin/kvm_pyenv/bin/activate &amp;&amp; vim /root/renjin/kvm_create/config/__init__.py'# alias kc2p='vim +33 /root/renjin/kvm_create/config/prod/kvm_config.py'# alias kc2t='vim +33 /root/renjin/kvm_create/config/test/kvm_config.py'# alias kc3='cd /root/renjin/kvm_create/ &amp;&amp; fab -f kvm.py install'# alias kcok1='vim /root/renjin/kvm_create/config/__init__.py'# alias kcok2p='vim +33 /root/renjin/kvm_create/config/prod/kvm_config.py'# alias kcok2t='vim +33 /root/renjin/kvm_create/config/test/kvm_config.py' 自动化快速开启开通kvm虚拟化服务器123456789101112131415************************************************************************************************************** KVM ENV Is: test ******************** KVM Host Name Is: xx-xxxx-xx-xxx-xxxx-xxxx ******************** KVM IP Is: xxx.xx.xx.xx ******************** TARGET IP Is: xxx.xx.xxx.xx ******************** KVM Gateway Is: xxx.xx.x.x ******************** KVM Netmask Is: xxx.xxx.xxx.x ******************** KVM APP Is: zabbix_agent nginx mysql_xx ******************** KVM CPU Is: 2 ******************** KVM Memory Is: 4194304 ******************** KVM Disk Is: 100G ******************** KVM Passwd IS: xxxxxxxXXXX **************************************************************************************************************If the information is incorrect, please input no: 开通kvm虚似服务器已经完成，信息如下12345678910111213141516171819************************************************************************************************************** KVM ENV Is: test ******************** KVM Host Name Is: bj-xxxx-xx-xxx-xxxx-xxxxx ******************** KVM IP Is: xxx.xx.xx.xx ******************** TARGET IP Is: xxx.xx.xxx.xx ******************** KVM Gateway Is: xxx.xx.xx.x ******************** KVM Netmask Is: xxx.xxx.xxx.0 ******************** KVM APP Is: zabbix_agent nginx mysql_xx ******************** KVM CPU Is: 2 ******************** KVM Memory Is: 4194304 ******************** KVM Disk Is: 100G ******************** KVM Passwd IS: XXXXXXXX **************************************************************************************************************Done.Disconnecting from xxx.xx.xx.xx... done.Disconnecting from xxx.xx.xx.xx... done.Disconnecting from xxx.xx.xx.xx... done.]]></content>
      <tags>
        <tag>linux</tag>
        <tag>cloud</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于某系统阵发性网络问题的处理。]]></title>
    <url>%2F2019%2F03%2F16%2F%E5%85%B3%E4%BA%8E%E6%9F%90%E7%B3%BB%E7%BB%9F%E9%98%B5%E5%8F%91%E6%80%A7%E7%BD%91%E7%BB%9C%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[关于某系统阵发性网络问题的处理。 一、问题描述 1、xxx 、移动 xx 等系统阵发性网络连接失败; 2、keepalived 虚拟ip未发生切换，nginx 访问日志记录正常，未收到错误日志，网络及链路测试正常; 3、keepalvied+ nginx 反代的其余系统未发现阵发性网络问题; 4、修改本地解析到keepalived虚拟ip，XXX相关系统访问正常。 二、应急切换与故障重现 1、周二频繁出现阵发性网络连接失败，应急将XXX虚ip切换回原私有云服务器，系统恢复; 2、后考虑移动xx系统出现的网络问题频率较高，因此考虑在个人客户端重现故障; 3、在个人macos中搭建dns服务器，配置xx域名解析到非XXX 系统keepavlied虚ip所映射的公网ip; 4、在手机上刷新app，多次刷新，锁屏再打开后故障重现。 三、问题定位 1、故障重现后，在XXX系统 keepailved 所在的服务器上进行 tcpdump 抓包分析; 2、因目前只有一个客户端访问非XXX nginx，因此可以看到nginx日志是一个公网ip访问过来的; 3、开启两个终端，一个实时监控日志，另一个用于tcpdump抓包保存 12# tail -f /var/log/nginx/oa.huatu.com.log # tcpdump -i team1 -s 0 -n &apos;host xxx.xxx.xxx.xxx&apos; -w /tmp/xx_packet.pcap 4、当app端问题复现后，发现nginx 未记录日志, 将 xx_packet.pcap 导出，用wireshark 导出分析 5、发现有三次tcp请求是正常进入网卡的，但是服务器没有回应，问题定位在服务器网络层面; 6、google搜索 linux tcp 没有回包 ，发现原理是由以下两个参数导致的 7、net.ipv4.tcp_timestamps net.ipv4.tcp_tw_recycle; 8、发现服务器上的net.ipv4.tcp_timestamps，net.ipv4.tcp_tw_recycle 都为1; 四、故障处理修改两台服务器的 /etc/sysctl.conf 以下两条内核参数，并生效; 12345# vim /etc/sysctl.confnet.ipv4.tcp_tw_recycle = 0net.ipv4.tcp_timestamps = 0 # sysctl -p 生效 将keepalived 虚拟ip再切换回物理服务器，故障处理; 五、内核参数说明; 1、net.ipv4.tcp_timestamps 是给所有进入服务器网卡的流量打时间标签，就像生产的面包打印生产日期; 2、net.ipv4.tcp_tw_recycle 是对连接时间超过60s的tcp资源进行回收并reject，同一时间内同一ip访问过多的tcp连接，它只会认为最近的一次SYN有效，其余的SYN拒绝; 这两条参数配合起来，当都开启时用于防范tcp攻击; 3、这两个参数结合起来是为了防止同一ip的tcp攻击，因同一局域网内是同一个公网ip，故造成同一局域网内多人访问时，SYN被拒绝，报网络错误，这也解释了为何非XXX业务访问未出现这样的问题、通过修改本地host解析直接访问私网ip未出现这样的问题。]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx+lua+redis 实现短链接转发长链接]]></title>
    <url>%2F2019%2F03%2F11%2Fnginx-lua-redis%E5%AE%9E%E7%9F%AD%E9%93%BE%E6%8E%A5%E8%BD%AC%E5%8F%91%E9%95%BF%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[nginx + lua + redis 实现短链接转发长链接 重新编译安装 nginx 及相关依赖安装相关依赖包 1# yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel lua-devel luajit-devel pcre pcre-devel libxml2 libxml2-dev libxslt-devel gd-devel perl-devel perl-ExtUtils-Embed GeoIP GeoIP-devel GeoIP-data gperftools 下载nginx_devel_kit lua-nginx-module 1234# wget https://github.com/simplresty/ngx_devel_kit/archive/master.zip# wget https://github.com/openresty/lua-nginx-module/archive/v0.10.13.tar.gz# unzip master.zip &amp;&amp; mv ngx_devel_kit-master/ /usr/local/# tar -xvf v0.10.13.tar.gz -C /usr/local/ 重新安装 nginx 123# cd /usr/local/src/nginx-1.12.2# ./configure --prefix=/usr/share/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --http-client-body-temp-path=/var/lib/nginx/tmp/client_body --http-proxy-temp-path=/var/lib/nginx/tmp/proxy --http-fastcgi-temp-path=/var/lib/nginx/tmp/fastcgi --http-uwsgi-temp-path=/var/lib/nginx/tmp/uwsgi --http-scgi-temp-path=/var/lib/nginx/tmp/scgi --pid-path=/run/nginx.pid --lock-path=/run/lock/subsys/nginx --user=nginx --group=nginx --with-file-aio --with-ipv6 --with-http_auth_request_module --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_addition_module --with-http_xslt_module=dynamic --with-http_image_filter_module=dynamic --with-http_geoip_module=dynamic --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_degradation_module --with-http_slice_module --with-http_stub_status_module --with-http_perl_module=dynamic --with-mail=dynamic --with-mail_ssl_module --with-pcre --with-pcre-jit --with-stream=dynamic --with-stream_ssl_module --with-google_perftools_module --with-debug --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic' --with-ld-opt='-Wl,-z,relro -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -Wl,-E' --add-module=/usr/local/lua-nginx-module-0.10.13 --add-module=/usr/local/ngx_devel_kit-master# make &amp;&amp; make install 安装lua-resty-redis 12345678# cd /usr/local/src# wget https://github.com/openresty/lua-resty-redis/archive/master.zip# unzip master.zip# cd lua-resty-redis-master/# make &amp;&amp; make installmake: Nothing to be done for `all'.install -d /usr/local/lib/lua//restyinstall lib/resty/*.lua /usr/local/lib/lua//resty 修改nginx http 段内配置文件http内添加 lua_package_path &quot;/usr/local/lib/lua/?.lua;;&quot;;;; 代表的是LuaJIT安装时的原始搜索路径 1# nginx -t &amp;&amp; nginx -s reload 修改nginx server或location 字段1234location /lua &#123; default_type text/plain; content_by_lua_file /usr/local/lua/request.lua; &#125; request.lua12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# vim /usr/local/lua/request.lualocal redis = require "resty.redis"local cache = redis:new()-- redis连接local ok,err = cache.connect(cache, '127.0.0.1', '25612')if not ok then ngx.say("failed to connect redis cache:", err); returnend-- redis认证local countcount, err = cache:get_reused_times()if 0 == count then ok,err = cache:auth("xxxxx") if not ok then ngx.say("failed to auth redis: " , err) return endelseif err then ngx.say("failed to get reused times: ", err) returnend-- 选择使用的redis数据库cache:select(7)-- 当前访问地址local url = ngx.var.uri-- 主机名local host = ngx.var.host-- 链接参数local args = ngx.var.args-- 获取方法local sch =ngx.var.scheme-- 获取端口--local pot =ngx.var.server_port-- 定义通用完整 url 路径local url_full_path = sch .. "://" .. host .. url-- 获取redis 中的值local res, err = cache:get(url_full_path)-- ngx.req.set_uri(url)if res then --ngx.say(sch .. "://" .. host .. url .. " " .. res) ngx.redirect(res,302)end# nginx -s reload 在redis 写入key 并测试1234567# redis-cli -h 127.0.0.1 -p 25612127.0.0.1:25612&gt; AUTH xxxxxxxxxxOK127.0.0.1:25612&gt; SELECT 7OK127.0.0.1:25612[7]&gt; set https://www.ssjinyao.com/lua/test https://www.ssjinyao.com/2019/03/16/%E5%85%B3%E4%BA%8E%E6%9F%90%E7%B3%BB%E7%BB%9F%E9%98%B5%E5%8F%91%E6%80%7%E7%BD%91%E7%BB%9C%E5%A4%84%E7%90%86/OK 可以看到访问时的中转 补充nginx rewrite转发正则匹配1rewrite ^/([0-9][0-9][0-9][0-9])/([0-1][0-9][0-9][0-9])/([0-9]+\.html) http://test.ssjinyao.com/$1/$2/$3 permanent;]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器常用配置参数明细]]></title>
    <url>%2F2018%2F10%2F29%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E6%98%8E%E7%BB%86%2F</url>
    <content type="text"><![CDATA[线上服务配置参数明细 问答nginx 反向代理的作用1、使用反向代理可以理解为7层应用层的负载均衡，使用负载均衡之后可以非常便捷的横向扩展服务器集群，实现集群整体并发能力、抗压能力的提高。2、通常反向代理服务器会带有本地 Cache 功能，通过静态资源的 Cache，有效的减少后端服务器所承载的压力，从而提高性能。 磨刀意识 1、关于任何操作配置，最好先搞明白操作或配置的原理，然后再去操作。应一句话叫做“磨刀不误砍柴功”，而且对于类似的操作可以举一反三。 nginx服务配置项1、 nginx 全局配置明细 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 默认 /etc/nginx/nginx.conf 全局配置文件 #指定nginx worker进程运行用户以及用户组，也可以是 user www-data www-data;user www-data; # 指明nginx要开启的进程数为4，一般为CPU核心数的1到2倍;worker_processes 4;# nginx pid文件存放位置 pid /run/nginx.pid;# events &#123;这里都是nginx的事件模块&#125;events &#123;# worker_connetctions 是指nginx最大的并发连接数; worker_connections 768;&#125;# http &#123;设定http服务&#125;http &#123;# 设置nginx上传文件最大限制 client_max_body_size 50m; # 配置可以提高 Nginx 静态资源托管效率。sendfile 是一个系统调用，直接在内核空间完成文件发送，不需要先 read 再 write，没有上下文切换开销; sendfile on; # Nginx 里统一用 tcp_nopush 来控制它,只有在启用了 sendfile 之后才生效，启用它之后，数据包会累计到一定大小之后才会发送，减小了额外开销，提高网络效率; tcp_nopush on; # 启用后会禁用 Nagle 算法，尽快发送数据，Nginx 只会针对处于 keep-alive 状态的 TCP 连接才会启用; tcp_nodelay on; # 长连接超时时间，单位是秒,长连接请求大量小文件的时候，可以减少重建连接的开销，但假如有大文件上传 # 65s内没上传完成会导致失败。如果设置时间过长，用户又多，长时间保持连接会占用大量资源。 keepalive_timeout 65; # types_hash_max_size 影响散列表的冲突率。types_hash_max_size越大，就会消耗更多的内存# 但散列key的冲突率会降低，检索速度就更快# types_hash_max_size越小，消耗的内存就越小，但散列key的冲突率可能上升 types_hash_max_size 2048; # 定义 mime 配置文件的文位 include /etc/nginx/mime.types; # 当用户请求的文件类型 不在服务器定义的mime类型映射时，使用DefaultType default_type application/octet-stream; # 定义nginx正常访问日志位置 access_log /var/log/nginx/access.log; # 定义nginx错误访问日志位置 error_log /var/log/nginx/error.log; # 开启nginx压缩功能，压缩的过程是个消耗CPU的过程，而压缩过后传输过程可以节省带宽; gzip on; # 对于microsoft explorer 6 不启用gzip压缩功能; gzip_disable &quot;msie6&quot;;# nginx 虚拟服务器配置文件所在目录; include /etc/nginx/conf.d/*.conf; # nginx 虚拟服务器配置文件所在目录; include /etc/nginx/sites-enabled/*.conf;&#125; 2、 nginx 默认80重定向443配置 12345678910111213141516# 每个server代表一台虚拟主机;server &#123; # listen 80 监听80端口; listen 80; # server_name _; 定义任意域名; server_name _；# 将返回301的重写到https://源服务器源uri; return 301 https://$HOST$request_uri;# 将server_name 永久的将任意字符开头结尾的 重写至https://源主机源uri位置;# server_name test.com; # rewrite ^(.*)$ https://$host$1 permanent; &#125; 3、 nginx 线上虚拟主机配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 每个server代表到哪虚拟主机;server &#123;# 监听https传输协议的443端口，ssl为采用加密传输，并且身份证明; listen 443 ssl;# ssl安全传输开启; ssl on;# 注在apache中证书与加密传输还有pem是三个文件# ssl授权证书文件，也可以理解为身份的证明文件; ssl_certificate /home/admin/api_ssl/server.crt;# ssl加密文件,数据传输过程中，通过此密钥文件将传送的数据加密码; ssl_certificate_key /home/admin/api_ssl/server.key;# 设置客户端能够重复使用存储在缓存中的会话参数时间为5分钟; ssl_session_timeout 5m;# 指定使用的SSL协议 ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2;# 指定许可密码的描述。密码以openssl支持的格式指定； ssl_ciphers &quot;HIGH:!aNULL:!MD5 or HIGH:!aNULL:!MD5:!3DES&quot;;# 对SSLv3和TLSv1协议的服务器端密码需求优先级高于客户端密码; ssl_prefer_server_ciphers on;# 指定虚拟主机的主机名; server_name api.ssjinyao.com.com; # location 指定匹配规则, / 这里指默认匹配项; location / &#123; # 将匹配到的location反代到至http://127.0.0.1:17777; proxy_pass http://127.0.0.1:17777; # 这里是指向 gunicorn host 的服务地址# 设置反向代理的请求头部host为源http的请求host; proxy_set_header Host $host;# 设置反向代理的请求头部转发的内容为请求url的源地址; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;# 设置将用户的IP赋值给X-Real-IP以供各应用调用; proxy_set_header X-Real-Ip $Remote_addr;# 设置代理缓冲大小为128k proxy_buffer_size 128k;# 设置代理缓冲区间4至 256k proxy_buffers 4 256k; # 设置代理最大缓冲区间为256k; proxy_busy_buffers_size 256k; &#125;&#125; 4、需求-负载均衡配置项: 12345678910111213# 在http段中加入以下配置# 指定upstream负载均衡模块,指定将要在server中调用的调度服务名称; upstream tewww &#123;# 指定web服务的第一个节点; 注:之后配置使用IP来配置，而不使用域名 server wwwnode1.ssjinyao.com.com:443; # 若有性能较高的服务器，可以采用加权轮询，那么这台服务器的权重是3/5; server wwwnode2.ssjinyao.com.com:443 weight=3;# 指定web服务的第三个节点; server wwwnode3.ssjinyao.com.com:443; &#125; 12345678910111213141516171819202122# 在定义一台虚拟主机；server &#123; listen 443; server_name www.ssjinyao.com.com; ssl on; ssl_certificate /etc/nginx/te_ssl/ssjinyao.com.crt; ssl_certificate_key /etc/nginx/te_ssl/ssjinyao.com.key; ssl_session_timeout 5m; ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers &quot;HIGH:!aNULL:!MD5 or HIGH:!aNULL:!MD5:!3DES&quot;; ssl_prefer_server_ciphers on; location / &#123;# 指定反代的服务器，为tewww负载均衡集群; proxy_pass http://tewww; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; 5、nginx操作注意项 12345678a、不影响其它服务的情况下重读配置文件, 一定要先对nginx的配置语法进行测试; # sudo nginx -t b、在没有nginx监听端口变更的情况下，则不要重启服务; # sudo nginx -s reload c、如上，反之，则必需重启服务器 # sudo nginx -s restart # sudo /etc/init.d/nginx restart 6、nginx监控 1服务端的监控，监控nginx 443端口，80端口, 最近最后一次值不为1时报警; 7、手头存一份标准的配置文件 8、一次比较复杂的虚拟主机配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758server &#123; listen 80; server_name jr.local.ssjinyao.com; charset gb2312; access_log /Users/zlz/wwwroot/logs/jr.access.log; location / &#123; root /Users/zlz/wwwroot/dedecms/a/bank; index index.html index.htm index.php; location ~ \.php$ &#123; # default_type text/html; # add_header Content-Type &apos;text/html; charset=utf-8&apos;; # return 200 &quot;$document_root , $fastcgi_script_name&quot;; fastcgi_split_path_info ^(.+\.php)(.*)$; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; &#125; location /zt &#123; alias /Users/zlz/wwwroot/dedecms/zt; #default_type text/html; #add_header Content-Type &apos;text/html; charset=utf-8&apos;; #return 200 &quot;&lt;h1&gt;十月十七&lt;/h1&gt;&quot;; location ~ /zt/(.*)\.php(.*)$ &#123; #default_type text/html; #add_header Content-Type &apos;text/html; charset=utf-8&apos;; #return 200 &quot;$document_root , $fastcgi_script_name&quot;; alias /Users/zlz/wwwroot/dedecms; fastcgi_split_path_info ^(.+\.php)(.*)$; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; location ~ /\.ht &#123; deny all; &#125;&#125;# proxy_pass http://127.0.0.1:8080/;#/Users/zlz/wwwroot/dedecms/zt;#proxy_pass http://127.0.0.1:8089/; 补充一伪静态的重写，即 ww.ssjinyao.com/xxxx/xxxxx 重写至 www.ssjinyao.com/xxxx/xxxx/ 1rewrite /(.*) https://www.ssjinyao.com/$1/ permanent; rewrite 直接重写目录 rewrite 301 12rewrite ^/zhaokao/ /list/zhaokao/ permanent;rewrite ^/szrd/ /list/szrd/ permanent; rewrite 302 12rewrite ^/zhaokao/ /list/zhaokao/ redirect;rewrite ^/szrd/ /list/szrd/ redirect; nginx php-fpm 安全项配置 12345678910111213# php-fpm.confsecurity.limit_extensions = .php .php2 .php4 .php5 .php7 .html .htm# nginx vhostslocation ~* ^/jt/.*.(php|php3|php4|php5)$ &#123;deny all;&#125;# 测试访问调度 location ~ \.php|\.php7|\.html|.htm$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; fastcgi_read_timeout 600; &#125;&#125; redis服务配置项1、redis持久化配置 注: 若不需要则关闭以下配置； 1234567891011121314151617# 持久化数据保存规则# 自己支实现一下# 900 秒内如果至少有 1 个 key 的值变化，则保存# 300 秒内如果至少有 10 个 key 的值变化，则保存# 60 秒内如果至少有 10000 个 key 的值变化，则保存save 900 1save 300 10save 60 10000# redis持久化保存数据配置stop-writes-on-bgsave-error yes# 数据保存的位置dir /usr/local/redis/db/# 数据库的文件名称,另外要确定数据保存的位置redis有owner权限dbfilename dump.rdb 2、redis是否需要外网连接; 12345678# 绑定的ip # bind 127.0.0.1# port 6379 或者port 25133# 若需要外网连接，则# bind 0.0.0.0# port 6379 或者port 25133 注: 另外还需要在阿里云上添加对应的需要访问的地址白名单与端口白名单; 3、目前三条业务线上的redis数据重要性 12345678910111213# 配置未开持久化，保存的数据皆为临时数据，可以清空;# 配置已经开启持久化，保存的数据为数据索引;数据不可以清空;# 配置已经开启持久化，保存的数据为用户数据;数据不可以清空;注: 不论数据是否为临时数据，每次对服务器的操作都要先对数据临时保存，确保操作后不会造成数据丢失;# 操作过程如下# redis-cli 127.0.0.1:6379&gt; AUTH Amdce0De1fxxxxxOK127.0.0.1:6379&gt; CONFIG SET dir &quot;/usr/local/redis/db&quot;OK127.0.0.1:6379&gt; SAVEOK127.0.0.1:6379&gt; 4、掌握redis重启命令 12345# /etc/init.d/redis-server stop# /etc/init.d/redis-server start# /etc/init.d/redis-server restart# redis-cli -h 127.0.0.1 -p 6379 shutdown # kill -9 REDISPID 5、redis监控 1a、监控服务redis端口 25133 或者 6379 6、记得在/etc/redis/redis.conf中要配置密码 1# requirepass Amdce0De1fxxxxx 7、注意白名单配置，让线上的服务器可以访问; mongo服务配置项1、保证有需要开机自启mongo的服务器,开机启动mongo 123# 在mongo的/etc/rc.local中加入以下内容 # mongod --auth --fork -f /etc/mongod.conf # 并保证 /etc/rc.local有执行权限 2、保证线上使用的mongo服务器都是3.4的 123456789# sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv # 0C49F3730359A14518585931BC711F9BA15703C6 # echo &quot;deb [ arch=amd64 ] http://repo.mongodb.org/apt/ubuntu &quot;$(lsb_release -sc)&quot;/mongodb-org/3.4 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-3.4.list&apos; # sudo apt-get update # sudo apt-get install mongodb-org # sudo killall mongod# sudo echo &apos;never&apos; &gt; /sys/kernel/mm/transparent_hugepage/enabled# sudo echo &apos;never&apos; &gt; /sys/kernel/mm/transparent_hugepage/defrag# sudo service mongod restart # sudo chkconfig mongod on 3、会对用户的操作(增/删/改/查) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106# 添加admin用户use admindb.auth(&quot;admin&quot;,&quot;passwdxxxxxxxxxxx&quot;)use bc_cccdb.createUser( &#123; user:&quot;ht_eedu&quot;, pwd:&apos;ht_eedom99xxx&apos;, roles:[ &#123;role:&quot;dbOwner&quot;,db:&apos;ht_eedu&apos;&#125; ] &#125; ) db.createUser( &#123; user:&quot;admin&quot;, pwd:&apos;passwdxxxxxxxxxxx&apos;, roles:[ &#123;role:&quot;dbOwner&quot;,db:&apos;test&apos;&#125; ] &#125; ) db.createUser( &#123; user:&quot;admin&quot;, pwd:&apos;passwdxxxxxxxxxxx&apos;, roles:[ &#123;role:&quot;userAdminAnyDatabase&quot;,db:&apos;admin&apos;&#125; ] &#125; ) # 添加对应数据库的用户 use te_data;db.createUser( &#123; user:&quot;admin&quot;, pwd:&apos;passwdxxxxxxxxxxxx&apos;, roles:[ &#123;role:&quot;dbOwner&quot;,db:&apos;test_data&apos;&#125; ] &#125; )# 删除用户db.dropUser(&quot;test_data&quot;) db.createUser( &#123; user:&quot;test_data_read&quot;, pwd:&apos;passwdxxxxxxxxxxx&apos;, roles:[ &#123;role:&quot;read&quot;,db:&apos;test_data&apos;&#125; ] &#125; ) db.createUser( &#123; user:&quot;test_read&quot;, pwd:&apos;passwdxxxxxxxxxxx&apos;, roles:[ &#123;role:&quot;read&quot;,db:&apos;test&apos;&#125; ] &#125; ) # 修改用户密码db.changeUserPassword(&apos;admin&apos;,&apos;passwdxxxxxxxxxxxx&apos;);# 查看目前存在的用户&gt; show dbsadmin 0.000GBbac_data 0.000GBkk 0.000GBlocal 0.000GBmigrate_data 0.000GBte_data 0.031GB&gt; show users&#123; &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &#123; &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; &#125; ]&#125;&gt; use trisk_tmp&gt; show users;&gt; db.dropAllUsers()# 在库中增新建表use bm_kycdb.createCollection(&quot;ep_search&quot;)db.createCollection(&quot;screening_sections&quot;)# 删除字段db.screening_sections.remove(&#123;&apos;no&apos;:&apos;5a279xxxxxxxxx&apos;&#125;) 4、数据的备份(导入/导出) 1234567mkdir /tmp/bak/mongomongodump --db test_kyc --out /tmp/bak/mongo/`date +&quot;%m-%d-%y&quot;`cd /tmp/bak/mongo &amp;&amp; tar -cvf xxxx-xx-xx.tar.gz xxxx-xx-xxscp /tmp/bak/mongo/xxxx-xx-xx.tar.gz root@xx.xxx.xx.xxx:/tmp/crontab -e3 1 * * * find /tmp/bak/mongo -mtime +7 -exec rm -rf &#123;&#125; \;mongorestore -u admin -p xxxx --db newdb --drop /tmp/bak/mongo 注: --drop 要小心使用 5、php模块编译安装3.4的支持 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758a、mac 安装php mongo模块的支持# brew install mongo# brew install mongodb# cd /Library/WebServer/Documents# brew install php56-mongo# 以下为测试连接文件 ➜ cat index.php &lt;?php $m = new MongoClient(&apos;mongodb://admin:passwdxxxxxxxxxxx@47.92.xxx.xxxx:20911/bc_ccc&apos;); echo &quot;Connection to database successfully&quot;; // 选择一个数据库 $db = $m-&gt;bm_kyc; echo &quot;Database mydb selected&quot;; ?&gt;➜ cat test2.php &lt;?php phpinfo();?&gt;# sudo vim /etc/php.ini extension=/usr/local/opt/php56-mongodb/mongodb.so extension=/usr/local/opt/php56-mongo/mongo.so b、ubuntu 安装 php mongo模块的支持# cd root &amp;&amp; wget https://github.com/mongodb/mongo-php-driver-legacy/archive/master.zip# cd root &amp;&amp; unzip master.zip # cd /root/mongo-php-driver-legacy-master/# phpize# ./configure # make# make install# ls /usr/lib/php5/20121212/mongo.so # vim /etc/php5/apache2/php.iniextension = /usr/lib/php5/20121212/mongo.so# apachectl restart测试➜ cat index.php &lt;?php $m = new MongoClient(&apos;mongodb://admin:passwdxxxxxxxxxxx@47.92.162.27:20911/bc_ccc&apos;); echo &quot;Connection to database successfully&quot;; // 选择一个数据库 $db = $m-&gt;bc_ccc; echo &quot;Database mydb selected&quot;; ?&gt; ➜ cat test2.php &lt;?php phpinfo();?&gt;# 访问test2.php可以过滤到以下内容MONGODB-CR enabledSCRAM-SHA-1 enabledMONGODB-X509 enabledGSSAPI (Kerberos) disabledPLAIN disabled 6、注意白名单配置，让线上的服务器可以访问; 123net: port =20133 # 配置mongo监听地址 bind_ip =0.0.0.0 # 配置绑定的IP 7、 注意配置文件中开启auth认证 1auth =true 8、代码中不支持带有@的密码 mysql服务配置项123# 注意清空连接mysql的使用记录# 注意数据库的备份文件所在的服务器只能以密钥登录# 注意RDS的使用率 apache服务配置项1、apache全局配置项 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556Mutex file:$&#123;APACHE_LOCK_DIR&#125; defaultPidFile $&#123;APACHE_PID_FILE&#125;Timeout 300KeepAlive OnMaxKeepAliveRequests 100KeepAliveTimeout 5User $&#123;APACHE_RUN_USER&#125;Group $&#123;APACHE_RUN_GROUP&#125;# 使得主机名能被记入日志HostnameLookups OffErrorLog $&#123;APACHE_LOG_DIR&#125;/error.log# 定义apache记录日志的级别为warnLogLevel warn#加载模块配置文件，虚拟主机配置文件，与端配置文件IncludeOptional mods-enabled/*.loadIncludeOptional mods-enabled/*.confInclude ports.conf# 定义不允许访问站点根目录索引&lt;Directory /&gt; Options FollowSymLinks AllowOverride None Require all denied&lt;/Directory&gt;&lt;Directory /usr/share&gt; AllowOverride None Require all granted&lt;/Directory&gt;# 允许在/var/www/中建立url&lt;Directory /var/www/&gt; AllowOverride All Require all granted&lt;/Directory&gt;# 定义允许访问的用户， .htaccess定义了用户名AccessFileName .htaccess# 拒绝所以 任意以.ht后缀结尾的文件 &lt;FilesMatch &quot;^\.ht&quot;&gt; Require all denied&lt;/FilesMatch&gt;# 定义 vhost_combined combined comman referer的四种日志格式,供虚拟主机调用LogFormat &quot;%v:%p %h %l %u %t \&quot;%r\&quot; %&gt;s %O \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; vhost_combinedLogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %O \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combinedLogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %O&quot; commonLogFormat &quot;%&#123;Referer&#125;i -&gt; %U&quot; refererLogFormat &quot;%&#123;User-agent&#125;i&quot; agentIncludeOptional conf-enabled/*.confIncludeOptional sites-enabled/*.conf 2、apache虚拟主机配置项 12345678910111213141516# 指定 VirtualHost 以端口进行定义&lt;VirtualHost *:8001&gt;# 指定VirtualHost域名 ServerAdmin www.ssjinyao.com.com# 指定虚拟主机url根路径 DocumentRoot /var/www/html/tweb# 指定访问错误日志保路径 ErrorLog $&#123;APACHE_LOG_DIR&#125;/error.log# 指定访问日志保存路径 CustomLog $&#123;APACHE_LOG_DIR&#125;/access.log combined&lt;/VirtualHost&gt; 3、同nginx一样，做完变更之后需要先测试语法再重读，或重起 4、端口配置文件 1234567# 将虚拟主机中所用到的对应端口启动; # Listen 80Listen 8001Listen 8002Listen 8003Listen 8004Listen 8101 supvisord 服务配置项1、更换服务器之后，需要修改服务器的监听地址； 123# 部署监听端口的问题[inet_http_server] ; inet (TCP) server disabled by defaultport=172.17.xxx.xxx:7558 ; (ip_address:port specifier, *:port for all iface) 2、部署python系统时报依赖问题 1234cd /home/admin/xbasement/source ./ENV/bin/activatepip install -r requirements.txt 如果安装软件包存在问题，把对应的软件包给删除; 3、查看对应服务器启动时的报错 1234567891011admin@iZ2zegjb9m90kxovynpkbzZ:~$ tail -f ~/xbasement/log/xbasement-server-stdout.log File &quot;server.py&quot;, line 3, in &lt;module&gt; from tornado.wsgi import WSGIContainerImportError: No module named tornado.wsgiTraceback (most recent call last): File &quot;server.py&quot;, line 3, in &lt;module&gt; from tornado.wsgi import WSGIContainerImportError: No module named tornado.wsgiTraceback (most recent call last): File &quot;server.py&quot;, line 3, in &lt;module&gt; from tornado.wsgi import WSGIContainerImportError: No module named tornado.wsgi 4、python部署时缺少模块的问题 123456789101112131415161718192021222324252627282930# 问题如下supervisor&gt; statuscustomer:customer-0 RUNNING pid 7981, uptime 0:00:19customer:job-recieve-0 RUNNING pid 7980, uptime 0:00:19order:api-0 FATAL Exited too quickly (process log may have details)order:forward-job-0 FATAL Exited too quickly (process log may have details)order:order-job-payment-0 FATAL Exited too quickly (process log may have details)order:order-risk-job-0 FATAL Exited too quickly (process log may have details)supervisor&gt; staus*** Unknown syntax: staussupervisor&gt; admin@ssjinyao.com-007:~/torder/venv/lib/python2.7/site-packages$ !tailtail -f torder/log/order-api-out.log from api import appImportError: No module named apiTraceback (most recent call last): File &quot;api/server.py&quot;, line 10, in &lt;module&gt; from api import appImportError: No module named apiTraceback (most recent call last): File &quot;api/server.py&quot;, line 10, in &lt;module&gt; from api import appImportError: No module named api# 解决方式 admin@ssjinyao.com-007:~/torder/venv/lib/python2.7/site-packages$ cat v.pth /home/admin/torderadmin@ssjinyao.com-007:~/torder/venv/lib/python2.7/site-packages$ pwd/home/admin/torder/venv/lib/python2.7/site-packagesadmin@ssjinyao.com-007:~/torder/venv/lib/python2.7/site-packages$ history | grep ln ln -s /home/admin/torder/ . 5、加入新工程时，要复制编辑~/opt/supervisord.conf 12[include]files = /home/admin/xbasement/config/supervisor/xbasement.server.ini /home/admin/topen/config/supervisor/*.ini /home/admin/cashier/config/supervisor/*.ini 6、部署open 工程时，要把ssl也复制上7、应用变动时，要注意mongo,redis白名单 zabbix 配置1、zabbix_agent 配置 123456789101112131415161718192021222324# 进程的pid保存的配置PidFile=/tmp/zabbix_agentd.pid# zabbix_agent 端日志保存位置 LogFile=/var/log/zabbix-agent/zabbix_agentd.log# 日志文件存储大小 LogFileSize=33# 日志级别DebugLevel=4# 注:这个是重点，需要指定zabbix_server端的ip zabbix_server端才能实别Server=121.xxx.xx.xxx# 监听的端口ListenPort=10050# zabbix_agent 端进程监听的地址 ListenIP=0.0.0.0# zabbix_agent 主动请求服务端时的地址 与 Server配合使用ServerActive=121.xxx.xx.xxxHostname=te_server 2、 zabbix_server 端配置 1234567891011121314151617181920212223242526272829303132333435363738# 指定zabbix_server 端监听的地址ListenPort=10051# 指定zabbix_server 产生的日志所保存的文件位置 LogFile=/var/log/zabbixsrv/zabbix_server.log# 指定日志的大小LogFileSize=0# 指定zabbix_server PidFile所保存的位置PidFile=/var/run/zabbixsrv/zabbix_server.pid# 指定zabbix 调用的数据库库名DBName=zabbix# 指定zabbix 调用的数据库的用户名 DBUser=zabbix# 指定zabbix 使用的数据库密码DBPassword=centos.xxxxxxxx# 指定mysql的sock文件DBSocket=/var/lib/mysql/mysql.sock# 指定mysql所监听的端口，注，zabbix_server所占用的数据库不大，且只需要监听本地DBPort=3306# 指定zabbix_server 所监听的地址ListenIP=0.0.0.0# 指定供zabbix调用的脚本程序(bash || python || perl),目前使用的是bashAlertScriptsPath=/var/lib/zabbixsrv/alertscripts# 自定义监控项时的保存位置 ExternalScripts=/var/lib/zabbixsrv/externalscripts# 指定临时的脚本程序 TmpDir=/var/lib/zabbixsrv/tmp 123456789101112131415# 调用接口程序#!/bin/bash#export PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binecho &quot;$2$3&quot; | /usr/bin/mutt -s &quot;ZABBIX 报警&quot; $1zabbix.sh #!/bin/bash#Can send weixin mail export path=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin#/bin/weixin --corpid=ww3bba6a2898b91e69 --corpsecret=3GqhGNZeEYuVvr9SRSyBWCOsbGvNcc6LXAn0uCO24XM --msg=&quot;$2 $3&quot; --user=&quot;$1&quot; --agentid=1000002/bin/weixin --corpid=wwfc47b4739f369c7c --corpsecret=hD0ITPFehD8WJm-3ydJVxWamXQYs2l64xPCx9K76doM --msg=&quot;$2$3&quot; --user=$1 --agentid=1000003 12345678910111213141516171819202122# 安装发送邮件报警程序的依赖# yum -y install msmtp mutt# 邮件发是由系统用户zabbixsrv调用，所以配置文件要在公共配置目录/etc/中配置# 不可以在 admin/root 或者其它用户下配置# muttrc 配置项/etc/muttrc set sendmail=&quot;/usr/bin/msmtp&quot;set use_from=yesset realname=&quot;15822097176@139.com&quot;set editor=&quot;vim&quot;# msmtprc 配置项/etc/msmtprc account defaulthost smtp.ssjinyao.comport 25from dev@ssjinyao.comauth logintls offuser dev@ssjinyao.compassword xxxxxxxxxx 12需求, 代码要一条条的写 设计, 先实现再设计优化 线上ssh服务配置项1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# 指定ssh默认监听的地址Port 22# 指定ssh使用的协议Protocol 2# 指定当前服务器使用的私钥HostKey /etc/ssh/ssh_host_rsa_keyHostKey /etc/ssh/ssh_host_dsa_keyHostKey /etc/ssh/ssh_host_ecdsa_keyHostKey /etc/ssh/ssh_host_ed25519_key# 是否让sshd通过创建非特权子进程处理接入请求的方法来进行权限分离。默认值是&quot;yes&quot;。认证成功后，将以该认证用户的身份创建另一个子进程。这样做的目的是为了防止通过有缺陷的子进程提升权限，从而使系统更加安全UsePrivilegeSeparation yes# 设置在多少秒之后自动重新生成服务器的密匙（如果使用密匙）。重新生成密匙是为了防止用盗用的密匙解密被截获的信息。KeyRegenerationInterval 3600# Server Key 的加密码强度，强度越大越安全，传输速率也越慢ServerKeyBits 1024# sshd 记录日志的级别 LogLevel INFO# 用户登录时可视界面及时间LoginGraceTime 120# 当使用者的 host key 改变之后，Server 就不接受联机，StrictModes yes# 使用纯rsa认证方式RSAAuthentication yes# 是否允许pubkey认证PubkeyAuthentication yes# 是否取消使用 ~/.ssh/.hosts 来做为认证IgnoreRhosts yes# 这个选项是专门给 version 1 用的RhostsRSAAuthentication no# 这个项目与上面的项目类似，不过是给 version 2 使用的HostbasedAuthentication no#这个项目在是否允许以空的密码登入！# 此项要注意PermitEmptyPasswords no# 挑战任何的密码认证, 任何 login.conf都能使用 ChallengeResponseAuthentication no# x11转发功能开启，可以使用基于ssh的加密码图形工具X11Forwarding yes# 自适大小X11DisplayOffset 10# 打印Motd信息PrintMotd no# 登录前后输出日志PrintLastLog yes# 开启tcp长连接TCPKeepAlive yes# 设置x11的转输语言及编码AcceptEnv LANG LC_*# 基于ssh 的vftp服务Subsystem sftp /usr/lib/openssh/sftp-server#利用 PAM 管理使用者认证UsePAM yes#使用dns解析 UseDNS no#AddressFamily inet# 允许root用户直接登录 PermitRootLogin yes# 记录系统日志SyslogFacility AUTHPRIV# 开启用户认证登录PasswordAuthentication yes]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes笔记]]></title>
    <url>%2F2018%2F10%2F04%2Fkubernetes%20%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[kubernetes 笔记CI: 持续集成CD: 持续交付，DeliveryCD: 持续部署，Deployment kubernetes的releases版本 kubernetes 自动装箱、自我修复、自动实现水平扩展自动实现服务发现和负载均衡，自动发布和回滚密钥和配置集中化管理、存储编排(动态供给)任务批处理 123456789101112131415161718master/node master: API Sserver,Scheduler, Controller-Manager node: kubelet, docker(容器引擎), kube-proxyPod， Label, Label Selector Label: key=value Label: Selector:Pod: 自主式Pod 控制器管理的Pod ReplicationController ReplicaSet Deployment StateFulSet(有状态副本集) DaemonSet Job,Ctonjob AddOns: 附加组件HPA HorizontalPodAutoscaler Master 节点: 整个k8s集群的司令部核心组件: api_server 负责接收并处理请求 schechuler 调度容器的创建请求 控制器管理器: 确保控制器是健康状态的k8s 并不直接调度容器，而调度的是pod。pod对容器做为封装; 服务的自动发现功能，就是把自己信息注册上去;NMT: 一般开放给外部访问的只有N，而N 在集群内其实是也是客户端;在一个大的集群中，只把有特殊需求的，开放给客户端;LBaaS: 负载均衡及服务; 多种通信同一个Pod内的多个容器间通信:lo各Pod之间的通信 Overlay Network,叠加网络通信(二层叠加，三层叠加)Pod与Service之间的通信 1234CNI插件体系:容器网络接口 flannel: 网络配置 calico: 网络配置，网络策略 canel: 网络配置，网络策略 客户端–&gt; API server user: username, uid group: extra: 环境: 1234master: etcd: 10.180.66.11node1: 10.180.66.12node2: 10.180.66.13注意这三台服务器需要时间同步 前提: 123451、基于主机名通信: /etc/hosts;2、时间同步;3、关闭firewalld和iptables.service;OS: CentOS 7.3.1611， Extras仓库中; 安装配置步骤: 12345678910111、etcd cluster，仅Master节点;2、flannel,集群的所有节点;3、配置k8s的master:仅master节点; kubernetes-master 启动的服务: kube-apiserver,kub-scheduler,kube-controller-manager4、配置k8s的各Node节点; kubernetes-node 先设定启动docker服务; 启动的k8s的服务: kube-proxy,kubelet kubeadm 123451、master, nodes:安装kubelet,kubeadm,docker2、master: kubeadm init3、nodes: kubeadm join https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md无论server 还是node 一般服务 1234567891011master:# cd /etc/yum.repos.d/# wget https://mirrors.aliyun.com/docker-ce/linux/centos-ce.repo# vim kubernetes.repo [kubernetes]name=Kubernetes Repo baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kuberentes-el7-x86_64/gpgcheck=1pgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpgenabled=1# yum -y install docker-ce kubelet kubeadm kubectl 补充:清华大学mirrors地址阿里云k8s地址 提供网络功能RESTful GET, PUT, DELETE, POST, … kubectl run, get, edit, …资源:对象 工作负载性资源对象 workload: Pod,ReplicaSet, Deployment, StatefulSet, DaemonSet, Job, Cronjob, … 服务发现及服务均衡: Service, Ingerss, … 配置与存储: Volume,CSI ConfigMap,Secret, DownwardAPI, 集群级资源: Namespace,Node,Role,ClusterRole,RoleBinding, ClusterRoleBinding 无数据型资源: HPA,PodTemplate,LimitRange创建资源的方法: apiserver仅接收JSON格式的资源定义; yaml格式提供配置清单，apiserver可自动将其转为json格式，而后再提交; 大部分资源的配置清单: apiversion:group/version; $ kubectl api-versions kind:资源类别 metadata:元数据 name必需是唯一的 namespace labels annotations 每个资源的引用PATH /api/GROUP/VERSION/namspace/NAMESAPCE/TYPE/NAME spec:期望的状态，disired state status: 当前状态，current state,本字段由kubernetes集群维护;资源配置清单: 自主式Pod资源 资源的清单格式: 一级字段: apiVersion(group/version),kind,metadata(name,namespace,lables,annotations,…)spec,status(只读) Pod资源: spec.container&lt;[]object&gt; - name &lt;string&gt; - image &lt;string&gt; imagePullPloicy &lt;string&gt; Always(下载), Never(不下载), IfNotPresent(本地不存在镜像则下载) 修改镜像中的默认应用: command,args https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/ liveness probe:存活状态检测 Image Entrypoint Image Cmd Container command Container args Command run [/ep-1] [foo bar] \ \ [ep-1 foo bar] [/ep-1] [foo bar] [/ep-2] \ [ep-2] [/ep-1] [foo bar] \ [zoo boo] [ep-1 zoo boo] [/ep-1] [foo bar] [/ep-2] [zoo boo] [ep-2 zoo boo] 标签: key=value key: 字母、数字、_、-、. value: 可以为空,只能字母或数字开头及结尾，中间可使用标签选择器: 等值关系:=，==，!= 集合关系: KEY in (VALUE1,VALUE2,…) KEY notin (VALUE1,VALUE2,…) KEY 存在这个键就可以 !KEY 不存在这个键的资源1# kubectl get pods -l &quot;release notin (canary,beta,alpha)&quot; 许多资源支持内嵌字段定义其使用的标签选择器:matchLables: 直接给定键值matchLables: 基于给定的表达式来定义使用的标签选择器,{key:”KEY”,operator:”OPERATOR”, value:[VAL1,VAL2,…]} 操作符: IN, NotIN:vlaues字段的值必须为空列表; Exists, NotExists:values字段的值必须为空列表; nodeSelector 节点标签选择器,nodeName annotations: 与label不同的地方在于， 它不能用于挑选资源对象，仅用于为对象提供”元数据”。Pod的生命周期 状态:Pending(挂起)，已经创建，但未找到运行它的节点; Running; Failed; Succeede; Unknown Pod生命周期中的重要行为： 实始化容器 容器探测： liveness readliness restartPolicy: Always, OnFailure, Never. Default to Always. 探针类型有三种: ExecAction、 TCPSocketAction、 HTTPGetAction Pod控制器: ReplicationController: ReplicaSet: 代用户创建指定数量的Pod副本，多退少补，滚动更新;新一代的ReplicationController Deployment: 建构在ReplicaSet之上的，流动更新，回滚，声明式配置; DemonSet: Job: CronJob: StatefulSet TRR: Third Party Resources, 1.2+, 1.7 CDR: Custom Defined Resources, 1.8+ Operator:一个坏的脚本在k8s集群中，很有可能导致整个k8s集群岩掉; 1234567891011121314151617181920212223242526apiVersion: apps/v1kind: ReplicaSetmetadata: name: myapp namespace: default spec: replicas: 2 relector: matchLabels: app: myapp replease: canary template: metadata: name: myapp-pod labels: app: myapp replease: canary environment:qa spec: contrainers: - name: myapp-container image: ikuberentes/myapp:v1 ports: - name: http containerPort: 80# kubectl create -f rs-demo.yaml Helm: 外壳 类似于redhat系统上的yum管理器一样 Service 工作模式:userspace, iptables, ipvs userspace: 1.1- iptables: 1.10- ipvs: 1.11+ 类型: ExternalName, CluseterIP, NodePort, and LoadBalancer 资源记录: SVC_NAME.NS_NAME.DOMAIN.LTD. svc.cluster.local. redis.default.svc.custer.local. NodePort:client –&gt; NodeIP:NodePort –&gt;ClusterIP:ServciePort –&gt; PodIP:containerPortLoadBalancerExternelName FQDN CNAME –&gt; FQDNNo ClusterIP: Headless Service ServiceName –&gt; PodIP 解决方案多组nginx server 对应多个pod;多个url 映射多个pod; 配置容器化应用的方式: 1、 自定义命令行参数; args: [] 2、 把配置文件直接焙进镜像; 3、 环境变量 (1) Cloud Native的应用程序一般可以直接 通过环境变量加载配置; (2) 通过entrypoint脚本来预处理变量为配置文件中的配置信息; 4、 存储卷 CoreOS: operatorStatefulSet: 1、稳定且惟一的网络标识符;2、稳定且持久的存储;3、有序、平滑地部署和扩展;4、有序、平滑地删除和终止;5、有序的滚动更新; 三个组件: headless service、 StatefulSet 、 volumeClaimTemplatepod_name.service_name.ns_name.svc.cluster.local myapp-0.myapp.default.svc.cluster.local APIRequest path http://172.20.0.70:6443/apls/apps/v1/namespaces/default/deployment/myapp-deploy/ HTTP request verb: get, post, pub, deleteAPI request verb: get, list, create, update, patch, watch, redirect, delete, deletecollection Resource:Subresource:NamespaceAPI group Object URL: /apis///namespaces// role: operation objectsrolebinding: user account OR service account role clusterrole, clusterrolebinding role 授权: get * ; get pod ; get deployment; 授权插件: Node, ABAC, RBAC, Webhook(基于httpd的回调机制) RBAC: Role-based AC ‘ 角色(role) 许可(permission) 当用户权限 rolebinding 绑定到 clusterrolebinding 时，clusterrolebinding 会被降权为rolebinding; spec.serviceAccountName rolebinding serviceaccount role Kubernetes:认证、授权 API server: subject –&gt; action –&gt; object 认证: token,tls,user/password 账号:UserAccount, ServiceAccount 授权:RBAC role,rolebinding clusterrole,clusterrolebinding subject: user group serviceaccount object: resource group resource non-resource url action:get,list,watch,patch,delete,deletecollection… Dashboard1、部署 1kubectl apply -f https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml 2、将Service 改为NodePort 1kubectl patch svc kubernetes-dashboard -p &apos;&#123;&quot;spec&quot;:&#123;&quot;type&quot;:&quot;NodePort&quot;&#125;&#125;&apos; -n kube-system 3、 认证: 认证时的账号必须为ServiceAccount: 被dashboard pod拿来由kubernetes进行认证的; token: (1) 创建ServiceAccount，根据其管理目标，使用rolebinding或clusterrolebinding 绑定至合理role或clusterrole; (2) 获取到此ServiceAccount的secret，查看secret的详细信息，其中就有token; kubeconfig:把ServiceAccount的token封装为kubeconfig文件 (1) 创建ServiceAccount，根据其管理目标，使用rolebinding或clusterrolebinding 绑定至合理role或clusterrole; (2) 12kubectl get secret | awk &apos;/^ServiceAccount/&#123;print $1&#125;&apos;DEF_NS_ADMIN_TOKEN=$(kubectl get secret SERVCIEACCOUNT_SERRET_NAME -o jsonpath=&#123;.data.token&#125; | base64 -d ) (3)生成kubeconfig 文件 1234kubectl config set-cluster --kuberconfig=/PATH/TO/SOMEFILEkubectl config set-credentials NAME --token=$KUBE_TOKEN --kubeconfig=/PATH/TO/SOMEFILEkubectl config set-contextkubectl config use-context kubernetes集群的管理方式1、命令式: create, run, expose, delete, edit, …2、命令式配置文件:create -f /PATH/TO/RESOURCE_CONFIGURATION_FILE, delete -f , replace -f3、声明式配置文件: apply -f,path, docker 常用的四种网络模型 bridge/joined/open/none Kubernetes网络通信: （1）容器间通信: 同一个Pod内的多个容器间的通信，lo （2）Pod通信: Pod IP &lt;–&gt; Pod IP （3）Pod与Service通信:PodIP &lt;–&gt; ClusterIP （4）Service与集群外部客户端的通信CNI: Container Network Interface flanner calico canel kube-router …解决方案: 虚拟网桥 多路复用: MacVLAN 硬件交换: SR-IOVkubelet, /etc/cni/net.d/flannel: 支持多种后端: VxLAN （1）vxlan （2）Directrouting host-gw: Host Gateway UDPflannel的配置参数 Network: flannel使用的CIDR格式的网络地址，用于为Pod的配置网络功能; master:10.244.0.0/24 node01:10.244.1.0/24 … node255:10.244.255.0/24 SubneteLen:把Network切分子网供各节点使用时，使用多长的掩码进行切分，默认为28位; SubnetMin:10.244.10.0/24 开始 SubnetMax:10.244.100.0/24 结束 Backend:vxlan, host-gw, udp vxlan:网络策略: 名称空间: 拒绝所有出站，入站; 放行所有出站目标本名称空间内的所有Pod; 调度器: 预选策略: CheckNodeCondition GeneralPredicates: HostName: 检查Pod对象是否定义了pod.spec.hostname PodFitsHostPorts:pods.spec.containers.ports.hostPort MatchNodeSelector:pod.spec.nodeSelector PodFitsResources:检查Pod的资源需求是否能被节点所满足; NoDiskConflict:检查Pod依赖的存储卷是否能满足需求; PodToleratesNodeTaints:检查Pod的specl.tolerations可容容忍的污点是否完全包含节点上的污点; PodToleratesNodeNoExecuteTaints: 对应的行为是默认不检查的; CheckNodeLabelPresence: 检查节点指定标签的存在性; CheckServiceAffinity: 亲和性，将同一Service的Pod尽可能放在一块; MaxEBSVolumeCount MaxGCEPDVolumeCount MaxAzureDiskVolumeCount CheckVolumeBinding NoVolumeZoneConflict CheckNodeMemoryPressure: 检查内存节点是否存在压力; CheckNodePIDPressure: 检查PID数量是否过多; CheckNodeDiskPressure: 检查磁盘压力是否过大; MatchInterPodAffity: 检查节点是否满pod足亲和性与反亲和性优选函数 LeastRequested:(cpu((capacity-sum(requested))10/capacity)+memory((capacity-sum(requested))10/capacity)) BalancedResourceAllocation: CPU和内存资源被占用率相近的胜出; NodePreferAvoidPods:节点注解信息”scheduler.alpha.kubernetes.io/perferAvoidPods” TaintToleration: 将Pod对象的spec.tolerations列表项与节点的 taints列表项进行匹配度检查，匹配条目越多，得分越低; SeletorSpreading:与当前Pod对象同属的标签选择器选择适配的其它选择其Pod对象所在的节点，越多的表示越低，否则越高; NodeAffinity:基于节点亲和性的; InterPodAffinity:遍历Pod对象的亲和性条目，并将能匹配到给定节点的条目的权重相加，结果值越大的，表示越高; MostRequested:跟LeastRequested正好相反;NodeLabel:标签越多，得分越高;ImageLocality: 镜像越多，得分越高，根据满足当前Pod对象需求的已有镜像体积大小之和; 1kubectl describe nodes node node01.ssjinyao.com 节点选择器:nodeSelector, nodeName节点亲和调度: nodeAffinity taint的effect定义对Pod排斥效果: NoSchedule: 仅影响调度过程，对现存的Pod对象不产生影响; NoExecute: 即影响调度过程，也影响现存的Pod对象;不容忍的Pod对象将被驱逐; PreferNoSchedule:不能容忍被调度过来，但是实在没有别的节点运行，也可被调度，是NoSchedule的柔性版; 12345678910111213141516171819202122232425262728293031apiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deploy namespace: defaultspec: replicas: 3 selector: matchLabels: app: myapp release: canary template: metadata: labels: app:myapp release:canary spec: containers: - name: myapp image: ikubernetes/myapp:v2 ports: - name: myapp image: ikubernetes/myapp: v2 ports: - name: http containerPort: 80 tolerations: - key: &quot;node-type&quot; operator: &quot;Equal&quot; value: &quot;production&quot; effect: &quot;NoSchedule&quot; 容器的资源需求，资源限制 requests: 需求，最低保障; limits: 限制，最高消耗区间，硬限制; CPU: 1颗逻辑CPU 1=1000微核心,millicores 500m=0.5CPU 内存: E、P、T、G、M、K Ei、Pi、Ti、Gi、Mi、Ki QoS: Guranteed: 每个容器同时设置CPU和内存的requests和limits; cpu.limits=cpu.requests memory.limits=memory.request Burstable:至少一个容器设置CPU或者内存资源的requests属性; BestEffort:没有任何一个容器设置了requests或limits属性;最低优先级别;资源指标:metrics-server自定义指标:prometheus，k8s-prometheus-adapter新一代架架构: 核心指标流水线: 由kubelet、metrics-server以及由API server 提供的api组成;CPU累积使用率、内存实时使用率、Pod的资源占用率及容器的磁盘占用率; 监控流水线:用于从系统收集各种指标数据并提供终端用户、存储系统以及HPA，它们包含核心指标及许多非核心指标。非核心指标本身不能被k8s所解析, metrics-server:API-serverHelm: 核心术语: Chart: 一个helm程序包的; Repository: Charts仓库，https/http服务器; Release: 特定的Chart部署于目标集群上的一个实例; Chart –&gt; Config –&gt; Release 程序架构: helm:客户端，管理本地的Chart仓库，管理Chart，与Tiller服务器交互，发送Chart，实例安装、查询、卸载等操作; Tiller: 服务端，可以运行在kubernetes之上，也可以运行在kubernetes之外、接收helm发来的Charts与Config，合并生成release; RBAC配置文件示例: https://github.com/helm/helm/blob/master/docs/rbac.md 官方可用的Chart列表: https://hub.kubeapps.com helm常用命令: release管理 12345678910# helm search jenkins# helm inspect jenkins# helm list # helm install# helm delete# helm upgrade# helm rollback# helm history # release的部署历史;# helm status # 获取release状态信息;# helm install --name redis -f ./values.yaml stable/redis chart管理 123456# helm create# helm fetch# helm get # helm inspect# helm package 打包chart 文件# helm verify 1234567# helm lint ../myapp # 检查语法错语# helm package myapp/# helm delete --purge mapp3 # helm delete --purge mapp2# helm delete --purge mapp1# helm repo add --help # helm repo list Chart –&gt; helm,tiller serviceChart –&gt; Config –&gt;ReleaseConfig:values.yaml ELK: E:elasticsearch L:logstash K: kibana日志收集的组件（Logstash、Filebeat、Fluentd） 当pod出现挂了的情况，查看pod日志时不方便查看。因此，应该将日志提前放到一个存储中。kubernetes集群应提供一个日志收集器。完整的kubernetes 集群 (kubdns| kubcurl ,ingress controller,heapster| metrics-server prometheus, dashboard)四大组件组成部分，另外附加附件efk; /var/log –&gt; /var/log/containers/k8s系统关键组件:Core Infrastructure –&gt; Network(SDN) Storage (Provisioning Congfiguration ) –&gt; Kubernetes Cluster –&gt; Containerzed Worload (image registry)额外的系统:Logging Monitoring硬件及负载、软件及负载:LoadBalancer存储位置:Artifact factory构建自动化:Build Automation (CI,CD)自动化发布:Rlease Automation]]></content>
      <tags>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker笔记(二)]]></title>
    <url>%2F2018%2F10%2F02%2Fdocker%E7%AC%94%E8%AE%B0%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[docker 笔记(二) Docker Data Volume关闭并重启容器，其数据不受影响; 但删除Docker容器，则其更将会全部丢失;存在的问题存储于联合文件系统中，不易于宿主机访问;容器间数据共享不便;删除容其数据会全部丢失;解决方案:”卷(volume)” “卷”是容器上的一个或多个”目录”，此类目录可绕过联合文件系统，与宿主机上的某目录”绑定(关联)”Volume 于容器初始化之时即会创建，由base image提供的卷中的数据会于此期间完成复制Volume 的初衷是独立于容器的生命周期实现数据持久化，因此删除容器时即不会删除卷，也不会对哪怕未被引用的卷做垃圾回收操作; Docker有两种类型的卷，每种类型都在容器中存在一个挂载点，但其在宿主机上的位置有所不同; 1# docker run --name b2 -it -v /data busybox 打开另一个终端查看Mount信息 1234567891011121314# docker inspect b2 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;5d2aaa4a60dd5724bed6011c92d71df8eb093de43bae2038c992f746f97f6e7d&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/5d2aaa4a60dd5724bed6011c92d71df8eb093de43bae2038c992f746f97f6e7d/_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ],# echo &quot;hello container&quot; &gt;&gt; /var/lib/docker/volumes/5d2aaa4a60dd5724bed6011c92d71df8eb093de43bae2038c992f746f97f6e7d/_data/test.html 在容器中查看 123/ # cat data/test.htmlhello container/ # echo &quot;test rj&quot; &gt;&gt; data/test.html 在宿主机上查看 123# cat /var/lib/docker/volumes/5d2aaa4a60dd5724bed6011c92d71df8eb093de43bae2038c992f746f97f6e7d/_data/test.htmlhello containertest rj 当容器退出并删除后，数据依然存在 1234# docker run --name b2 -it --rm -v /data/volumes/b2:/data busybox# docker inspect b2 | grep volume &quot;/data/volumes/b2:/data&quot; &quot;Source&quot;: &quot;/data/volumes/b2&quot;, 查看inspect元素 12# docker inspect -f &#123;&#123;.Mounts&#125;&#125; b2[&#123;bind /data/volumes/b2 /data true rprivate&#125;] 注: 两个容器可以共享同一个存储卷 12# docker run -it --name c1 -v /docker/volumes/v1:/data busybox# docker run -it --name c2 -v /docker/volumes/v1:/data busybox 复制使用其它容器的卷，为docker run 命令使用 –volumes-from选项 12# docker run -it --name bbox1 -v /docker/volumes/v1:/data busybox # docker run -it --name bbox2 --volumes-from bbox1 busybox docker fileFROMFROM的指令是最重的一个且必须为Dockefile文件开篇的第一个非注释行，用于为映像文件构建过程指定基准镜像，后续的指令运行于此基准镜像所提供的运行环境。实践中，基准镜像可以是任何可用镜像文件，默认情况下，docker build会在docker 主机上查找指定的镜像文件，在其不存在时，则会从Docker HubRegistry上拉取所需要的镜像文件如果找不到指定的镜像文件，docker build会返回一个错误信息。 Syntax FROM [:]或FROM @ 1234567891011121314151617181920# vim Dockerfile#Deskription: test imageFROM busybox:latestMAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot;# LABEL maintainer=&quot;ssjinyao&quot;COPY index.html /data/web/html# vim index.html &lt;h1&gt; ssjinyao httpd server.&lt;/h1&gt;# docker build -t ssjinyaohttpd-img:v0.1-1 ./Sending build context to Docker daemon 3.072kBStep 1/3 : FROM busybox:latest ---&gt; e1ddd7948a1cStep 2/3 : MAINTAINER &quot;Jinyao &lt;renjin@ssjinyao.com&gt;&quot; ---&gt; Running in aa9838facca1Removing intermediate container aa9838facca1 ---&gt; 71258688ebebStep 3/3 : COPY index.html /data/web/html ---&gt; b23d8149125aSuccessfully built b23d8149125aSuccessfully tagged ssjinyaohttpd-img:v0.1-1 验证 12# docker run --name ssjinyao-web1 --rm ssjinyaohttpd-img:v0.1-1 cat /data/web/html/index.html&lt;h1&gt; ssjinyao httpd server.&lt;/h1&gt; 复制目录 123456789101112131415161718192021222324252627282930313233FROM busybox:latestMAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot;# LABEL maintainer=&quot;ssjinyao&quot;COPY index.html /data/web/html/COPY yum.repos.d /etc/yum.repos.d/# lsDockerfile index.html yum.repos.d# docker build -t tinyhttpd:v0.1-2 ./# docker build -t tinyhttpd:v0.1-2 ./Sending build context to Docker daemon 26.11kBStep 1/4 : FROM busybox:latest ---&gt; e1ddd7948a1cStep 2/4 : MAINTAINER &quot;ssjinayo &lt;renjin@ssjinyao.com&gt;&quot; ---&gt; Using cache ---&gt; 708bad816b72Step 3/4 : COPY index.html /data/web/html/ ---&gt; Using cache ---&gt; 758051947b4dStep 4/4 : COPY yum.repos.d /etc/yum.repos.d/ ---&gt; a4c01bf4fe8dSuccessfully built a4c01bf4fe8dSuccessfully tagged tinyhttpd:v0.1-2# docker run --name tinyweb1 --rm tinyhttpd:v0.1-2 ls /etc/yum.repos.d/CentOS-Base.repoCentOS-CR.repoCentOS-Debuginfo.repoCentOS-Media.repoCentOS-Sources.repoCentOS-Vault.repoCentOS-fasttrack.repodocker-ce.repoepel-testing.repoepel.repo ADD 指令的使用 12345678910111213141516171819202122232425262728# vim Dockerfile#Deskription: test imageFROM busybox:latestMAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot;# LABEL maintainer=&quot;ssjinyao&quot;COPY index.html /data/web/html/COPY yum.repos.d /etc/yum.repos.d/ADD http://nginx.org/download/nginx-1.15.5.tar.gz /usr/local/src/# docker build -t tinyhttpd:v0.1-3 ./Sending build context to Docker daemon 26.11kBStep 1/5 : FROM busybox:latest ---&gt; e1ddd7948a1cStep 2/5 : MAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot; ---&gt; Using cache ---&gt; 708bad816b72Step 3/5 : COPY index.html /data/web/html/ ---&gt; Using cache ---&gt; 758051947b4dStep 4/5 : COPY yum.repos.d /etc/yum.repos.d/ ---&gt; Using cache ---&gt; a4c01bf4fe8dStep 5/5 : ADD http://nginx.org/download/nginx-1.15.5.tar.gz /usr/local/src/Downloading 1.025MB/1.025MB ---&gt; 884e8bf3725fSuccessfully built 884e8bf3725fSuccessfully tagged tinyhttpd:v0.1-3# docker run --name tinyweb1 --rm tinyhttpd:v0.1-3 ls /usr/local/src/nginx-1.15.5.tar.gz 12345678910111213#Deskription: test imageFROM busybox:latestMAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot;# LABEL maintainer=&quot;ssjinyao&quot;COPY index.html /data/web/html/COPY yum.repos.d /etc/yum.repos.d/#ADD http://nginx.org/download/nginx-1.15.5.tar.gz /usr/local/src/ADD nginx-1.15.5.tar.gz /usr/local/src/# lsDockerfile index.html nginx-1.15.5.tar.gz yum.repos.d# docker build -t tinyhttpd:v0.1-4 ./# docker run --name tinyweb --rm tinyhttpd:v0.1-4 ls /usr/local/srcnginx-1.15.5 另外一种写法 12345678910# vim Dockerfile#Deskription: test imageFROM busybox:latestMAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot;# LABEL maintainer=&quot;ssjinyao&quot;COPY index.html /data/web/html/COPY yum.repos.d /etc/yum.repos.d/#ADD http://nginx.org/download/nginx-1.15.5.tar.gz /usr/local/src/WORKDIR /usr/local/src/ADD nginx-1.15.5.tar.gz ./ #这里的./相当于WORKDIR指定的目录 12345678910111213141516171819202122232425262728293031323334353637#Deskription: test imageFROM busybox:latestMAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot;# LABEL maintainer=&quot;ssjinyao&quot;COPY index.html /data/web/html/COPY yum.repos.d /etc/yum.repos.d/#ADD http://nginx.org/download/nginx-1.15.5.tar.gz /usr/local/src/WORKDIR /usr/local/ADD nginx-1.15.5.tar.gz ./src/VOLUME /data/mysql/# docker build -t tinyhttpd:v0.1-5 ./Sending build context to Docker daemon 1.052MBStep 1/7 : FROM busybox:latest ---&gt; e1ddd7948a1cStep 2/7 : MAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot; ---&gt; Running in 206968a461e1Removing intermediate container 206968a461e1 ---&gt; acce38db09a6Step 3/7 : COPY index.html /data/web/html/ ---&gt; cfac93db1094Step 4/7 : COPY yum.repos.d /etc/yum.repos.d/ ---&gt; ccbddff1520bStep 5/7 : WORKDIR /usr/local/ ---&gt; Running in 8bbda4faa5a4Removing intermediate container 8bbda4faa5a4 ---&gt; 1660db5c8614Step 6/7 : ADD nginx-1.15.5.tar.gz ./src/ ---&gt; cfd686660ff8Step 7/7 : VOLUME /data/mysql/ ---&gt; Running in e85008cba000Removing intermediate container e85008cba000 ---&gt; 529be777da05Successfully built 529be777da05Successfully tagged tinyhttpd:v0.1-5# docker run --name tinweb1 --rm tinyhttpd:v0.1-5 mount | grep data/dev/mapper/centos-root on /data/mysql type xfs (rw,seclabel,relatime,attr2,inode64,noquota) EXPOSE 指令使用 1EXPOSE 1211/udp 11211/tcp # 启动镜像是要使用-P选项 ENV 用于为镜像定义所需要的环境变量，并可被Dockerfile文件中位于其后其它指令(ENV,ADD,COPY等)所调用 123456789101112131415#Deskription: test imageFROM busybox:latestMAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot;# LABEL maintainer=&quot;ssjinyao&quot;ENV DOC_ROOT /data/web/htmlCOPY index.html $DOC_ROOTCOPY yum.repos.d /etc/yum.repos.d/#ADD http://nginx.org/download/nginx-1.15.5.tar.gz /usr/local/src/WORKDIR /usr/local/ADD nginx-1.15.5.tar.gz ./src/VOLUME /data/mysql/EXPOSE 80/tcp 12# docker run --name tinyweb1 --rm -P tinyhttpd:v0.1-7 printenv # 打印输出环境变量# docker run --name tinyweb --rm -P -e WEB_SERVER_PACKAGE=&quot;nginx-1.15.1&quot; tinyhttpd:v0.1-7 printenv # -e 可以外部更改或指定环境变量的 1234567891011121314151617181920#Deskription: test imageFROM busybox:latestMAINTAINER &quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot;# LABEL maintainer=&quot;ssjinyao&quot;ENV DOC_ROOT=/data/web/html/ \ WEB_SERVER_PACKAGE=&quot;nginx-1.15.5.gz&quot;#当没有COPY index.html $&#123;DOC_ROOT: -/data/web/html/&#125;COPY yum.repos.d /etc/yum.repos.d/ADD http://nginx.org/download/$&#123;WEB_SERVER_PACKAGE&#125; /usr/local/src/WORKDIR /usr/local/#ADD $&#123;WEB_SERVER_PACKAGE&#125;.tar.gz ./src/VOLUME /data/mysql/EXPOSE 80/tcpRUN cd /usr/local/src &amp;&amp; \ tar xvf $&#123;WEB_SERVER_PACKAGE&#125; 1234567891011FROM busyboxLABEL maintainer=&quot;ssjinyao &lt;renjin@ssjinyao.com&gt;&quot; app=&quot;httpd&quot;ENV WEB_DOC_ROOT=&quot;/data/web/html&quot;RUN mkdir -p $WEB_DOC_ROOT &amp;&amp; \ echo &apos;&lt;h1&gt;Busybox httpd server.&lt;/h1&gt;&apos; &gt; $&#123;WEB_DOC_ROOT&#125;/index.html# COM /bin/httpd -f -h $&#123;WEB_DOC_ROOT&#125;CMD [&quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $&#123;EWB_DOC_ROOT&#125;&quot;]ENTRYPOINT /bin/sh -c Dockerfile Nginx镜像 示例 1234567891011121314151617181920212223242526272829303132333435363738394041# mkdir img_nginx# cd img_nginx# vim DockerfileFROM nginx:1.14-alpineARG author=&quot;ssjinyao &lt;rejin@ssjinyao.com&gt;&quot;LABEL maintainer=&quot;$&#123;author&#125;&quot;ENV NGX_DOC_ROOT=&quot;/data/web/html/&quot;ADD index.html $&#123;NGX_DOC_ROOT&#125;ADD entrypoint.sh /bin/EXPOSE 80/tcpHEALTHCHECK --start-period=3s CMD wget -O - -q http://$&#123;IP:-0.0.0.0&#125;:$&#123;PORT:-80&#125;/CMD [&quot;/usr/sbin/nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]ENTRYPOINT [&quot;/bin/entrypoint.sh&quot;]# vim index.html&lt;h1&gt; Dockerfile Nginx Test Page.&lt;/h1&gt;# vim entrypoint.sh#!/bin/sh#cat &gt; /etc/nginx/conf.d/www.conf &lt;&lt;EOFserver &#123; server_name $&#123;HOSTNAME&#125;; listen $&#123;IP:-0.0.0.0&#125;:$&#123;PORT:-80&#125;; root $&#123;NGINX_DOC_ROOT:-/usr/share/nginx/html&#125;;&#125;EOFexec &quot;$@&quot;# docker run --name myweb1 --rm -P -e &quot;PORT=8080&quot; nginx_web:v0.0-1127.0.0.1 - - [03/Oct/2018:07:43:31 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;Wget&quot; &quot;-&quot;127.0.0.1 - - [03/Oct/2018:07:44:01 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;Wget&quot; &quot;-&quot; 自建docker-registry123456# yum -y install docker-registry# rpm -ql docker-distribution/etc/docker-distribution/registry/config.yml/usr/bin/registry/usr/lib/systemd/system/docker-distribution.service/var/lib/registry 注: docker push 客户端默认是https工作的，因此在客户端配置不加密传输 12345678910111213# vim /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;:[&quot;https://registry.docker-cn.com&quot;], &quot;bip&quot;: &quot;10.0.0.1/16&quot;, &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2375&quot;,&quot;unix:///var/run/docker.sock&quot;], &quot;insecure-registries&quot;: [&quot;node2:5000&quot;]&#125;# docker tag ssjinyao/httpd:v0.1.1.1-2 node2:5000/ssjinayo-web:v0.1.1.1-2# docker push node2:5000/ssjinayo-webThe push refers to repository [node2:5000/ssjinayo-web]e6baf59e35e7: Pushedf9d9e4e6e2f0: Pushedv0.1.1.1-2: digest: sha256:2f3d6d2f468ee189b4b43ff2b9f99a6e3895d9832b606522176f804cba738037 size: 734 服务端镜像默认保存的路径 12# ls /var/lib/registry/docker/registry/v2/repositories/ssjinayo-web_layers _manifests _uploads 私有docker 源pull 使用, 前提也要配置不加密传输 1234# docker pull node2:5000/ssjinayo-web:v0.1.1.1-2v0.1.1.1-2: Pulling from ssjinayo-webDigest: sha256:2f3d6d2f468ee189b4b43ff2b9f99a6e3895d9832b606522176f804cba738037Status: Downloaded newer image for node2:5000/ssjinayo-web:v0.1.1.1-2 vmware-harbor私有源的安装与使用vmware/harbor安装vmware/harbor下载 Resource Capacity Description CPU minimal 2 CPU 4 CPU is prefered Mem minimal 4GB 8GB is prefered Disk minimal 40GB 160GB is prefered 12345# yum -y install docker-compose# vim harbor.cfg # 这里根据自己的需求更改配置文件# vim docker-compose.yml # # cd /usr/local/src/harbor# ./install 123456789CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf01090bf5ba1 goharbor/nginx-photon:v1.6.0 &quot;nginx -g &apos;daemon of…&quot; 3 minutes ago Up 3 minutes (healthy) 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp nginx7e4849fcb12a goharbor/harbor-jobservice:v1.6.0 &quot;/harbor/start.sh&quot; 3 minutes ago Up 3 minutes harbor-jobservice0d8ceb3ec5c0 goharbor/harbor-ui:v1.6.0 &quot;/harbor/start.sh&quot; 3 minutes ago Up 3 minutes (healthy) harbor-uic5780037bc8f goharbor/harbor-adminserver:v1.6.0 &quot;/harbor/start.sh&quot; 3 minutes ago Up 3 minutes (healthy) harbor-adminserverb184110cfac2 goharbor/registry-photon:v2.6.2-v1.6.0 &quot;/entrypoint.sh /etc…&quot; 3 minutes ago Up 3 minutes (healthy) 5000/tcp registry83b4b2ea3b2e goharbor/redis-photon:v1.6.0 &quot;docker-entrypoint.s…&quot; 3 minutes ago Up 3 minutes 6379/tcp redis9055f4dcdaeb goharbor/harbor-db:v1.6.0 &quot;/entrypoint.sh post…&quot; 3 minutes ago Up 3 minutes (healthy) 5432/tcp harbor-db583dd6d3dc30 goharbor/harbor-log:v1.6.0 &quot;/bin/sh -c /usr/loc…&quot; 3 minutes ago Up 3 minutes (healthy) 127.0.0.1:1514-&gt;10514/tcp harbor-log 登录管理员后台 在 docker-vmware-harbor中创建普通用户，在普通用户中创建项目 1234567891011121314151617181920# vim /etc/docker/daemon.json&#123; &quot;insecure-registries&quot;: [&quot;blog.ssjinyao.com&quot;]&#125;# docker login blog.ssjinyao.comUsername: ssjinyaoPassword:WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded[root@ssjinyao-node2:~]# docker push blog.ssjinyao.com/devel/ssjinyao-httpdThe push refers to repository [blog.ssjinyao.com/devel/ssjinyao-httpd]e6baf59e35e7: Pushedf9d9e4e6e2f0: Pushedv0.1.1.1-1: digest: sha256:7248231aa495c62947519646d25acb453fd2caf3ed6bf778b41e6201bd3e31fc size: 734e6baf59e35e7: Layer already existsf9d9e4e6e2f0: Layer already existsv0.1.1.1-2: digest: sha256:2f3d6d2f468ee189b4b43ff2b9f99a6e3895d9832b606522176f804cba738037 size: 734 push 镜像前可以查看vmware-harbor的打标签提示 1234# docker-compose pause 暂停# docker-compose unpause 运行# docker-compose stop 停止# docker-compose start 启动 docker 资源限制OOME一旦发生OOME，任何进程都有可能被杀死，包括docker daemon在内为此，Dokcer特地调整了docker daemon的OOM优先级，以名它被内核”正法”但容器的优先级并未被调整 –memory-swap –memory 功能 正数S 正数M 容器可用总空间为S,其中ram为M,swap为(S-M)若S=M,则无可用swap资源 0 正数M 相当于未设置 swap(unset) unset 正数M 若主机(Docker Host)启用了swap,则容器的可用swap为2*M -1 正数M 若主机(Docker Host)启用了swap,则容器可使用最大至主机上所的所有swap空间的资源 注意: 在容器使用free命令可以看到的swap空间并不是具有其所展现出的空间指示意义 pull 一个压测镜像 123# docker pull lorel/docker-stress-ng# docker run --name stress -it --rm lorel/docker-stress-ng:latest stress --help# docker run --name stree -it --rm -m 256m lorel/docker-stress-ng:latest stress --vm 2 查看启用的docker进程 查看stress 容器的分配内存状态 同样的，当对cpu做压测时，指定上限为两个cpu，也就是使用率为200%，当压测为8个cpu时，cpu最高占用为200% 123456# docker run --name stress -it --rm --cpus 2 lorel/docker-stress-ng:latest stress --cpu 8# docker run --name stress -it --cpuset-cpus 0,2 --rm lorel/docker-stress-ng:latest stress --cpu 8 #设定只运行在第0和2个cpu上# docker run --name stress -it --cpus 2 --rm lorel/docker-stress-ng:latest stresss --cpu8 #设定cpus 2 ，说明所有核心都能用到，但是最多只能使用200%# docker run --name stress -it --cpu-shares 1024 --rm lorel/docker-stress-ng:latest stress --cpu 8 # 设定限制为尽可能多的分配cpu资源,最后这种模式，当再启一个容器时，会实时按比例分配cpu资源分到另一个容器，# docker run --name stress2 -it --cpu-shares 512 --rm lorel/docker-stress-ng:latest stress --cpu 8]]></content>
      <tags>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker笔记(一)]]></title>
    <url>%2F2018%2F09%2F28%2Fdocker%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[docker笔记(一) Virtualization And Container主机级虚拟化 Type-I 直接在硬件上做虚拟化; Type-II 启动系统后，再做虚拟化; 真正能产生生产力的，是应用层面; 系统运行两颗树:进程树和文件系统树; 基于用户层面的隔离(UTS,Mount,IPC,PID,User,Net); namespaces:名称空间，系统调用，向外输出(clone(),setns()); Linux Namespaces namespace 系统调用参数 隔离内容 内核版本 UTS CLONE_NEWUTS 主机名和域名 2.6.19 IPC CLONE_NEWIPC 信号量、消息队列和共享内存 2.6.19 PID CLONE_NEWPID 进程编号 2.6.24 Network CLONE_NEWNET 网络设备、网络栈、端口号等 2.6.29 Mount CLONE_NEWNS 挂载点(文件系统) 2.4.19 User CLONE_NEWUSER 用户和用户组 3.8 Control Groups(cGroups)把系统级的资源分成多个组 lxc-create,template nmp machine+swarm+compose mesos+marathon kubernetes -&gt; k8s libcontainer -&gt; runC Moby, CNCF docker中的容器 lxc -&gt; libcontainer -&gt; runC OCI Open Container Initiative 旨在围绕容器式和运行时制定一个开放的式业化标准 the Runtime Specification(runtime-spec) the Image Specification(image-spec) runC Open Container Format https:hub.docker.com docker 的两个版本docker-eedocker-ce docker architecture The Docker daemon The Docker client Docker registries yum 中的仓库 repository,repo docker 中的仓库 repository, repo镜像名称 nginx:1.10 以此来命令镜像，nginx:1.15 nginx:latest 而镜像的默认版是最新版的nginx:1.14 nginx:stable 最新稳定版镜像：静态;容器：动态，有生命周期，特别类似于程序;容器常用资源: images, containers, networks, volumes, plugins, 安装及使用docker 依赖的环境 64 bits CPU Linux Kernel 3.10+ Linux Kernel cgrups and namespace CentOS 7 “Extras” repository Docker Daemon systemctl start docker.service Docker Client docker[OPTIONS] COMMAND [arg …] 123456# cd /etc/yum.repos.d/# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# yum makecache# yum repolist# yum remove docker docker-common container-selinux docker-selinux docker-engine# yum install docker-ce 仓库配置文件: https://dowland.docker.com/linux/centos/docker-ce.repo Docker组件: docker程序环境: 12345678910环境配置文件: /etc/sysconfig/docker-network /etc/sysconfig/docker-storage /etc/sysconfig/dockerUnit FIle: /usr/lib/systemd/system/docker.serivceDocker Registry配置文件 /etc/contalners/registries.conf docker-ce: 配置文件:/etc/docker/daemon.json 注册阿里云账号，专用加速器地址获得路径: https://cr.console.aliyun.com/#/accelerator Docker镜像加速 123456 docker cn 阿里云加速器 中国科技大学&#123; &quot;registry-mirrors&quot;:[&quot;https://registry.docker-cn.com&quot;]&#125; 123456# mkdir /etc/docker# vim /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;:[&quot;https://registry.docker-cn.com&quot;]&#125;# systemctl start docker 查看docker 版本信息 1234567891011121314151617181920# docker versionClient: Version: 18.06.1-ce API version: 1.38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:23:03 2018 OS/Arch: linux/amd64 Experimental: falseServer: Engine: Version: 18.06.1-ce API version: 1.38 (minimum version 1.12) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:25:29 2018 OS/Arch: linux/amd64 Experimental: false# docker info 常用操作12345678910111213141516171819202122232425262728docker search : 搜索镜像# docker search nginxdocker pull: 下载镜像到本地# docker pull nginx:1.14-alpine-perl# docker pull busybox:latest# docker image pull nginx:1.14-alpine-perl# docker docker images: 列出本地镜像 # docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx 1.14-alpine-perl a47b6006585d 2 weeks ago 51.6MBbusybox latest e1ddd7948a1c 8 weeks ago 1.16MB# docker image rm a47b6006585d # 删除镜像# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEbusybox latest e1ddd7948a1c 8 weeks ago 1.16MB# docker image ls --no-trunc # 列出完整image id信息REPOSITORY TAG IMAGE ID CREATED SIZEnginx 1.14-alpine-perl sha256:a47b6006585d03b999ee55c6eec4331430fb2bcddb5ce8f76f294cc997482ca2 2 weeks ago 51.6MBbusybox latest sha256:e1ddd7948a1c31709a23cc5b7dfe96e55fc364f90e1cebcde0773a1b5a30dcda 8 weeks ago 1.16MB# docker container ls # 列出所有容器# docker ps: 列出所有容器# docker images: 列出所有镜像# docker create: 创建新的container# docker start: Start one or more stopped contaners# docker run: Run a command in a new container# docker attacth: Attach to a running container# docker ps: List containers apline: 能够能程序提供基础环境，但是体积非常小，所以在生产环境中不建议使用apline版;busybox: 能够用一个busybox实现linux系统的多个命令，当链接busybox为ls 时，它可以执行ls命令; 链接成pwd时，可以实现pwd命令。kernel+busybox可以实现一个微linux系统; 所畏的android系统也是linux+busybox+jvm所运行的系统; 容器使用12345678910# docker run --name b2 -it busybox:latest/ ## docker run --name b1 -it busybox:latest/ # mkdir /data/www -p/ # vi /data/www/index.html&lt;h1&gt;www.ssjinyao.com&lt;/h1&gt;/ # httpd -f -h /data/www/# docker inspect b1 # 查看 docker 容器的启动信息 # 在另一个终端中访问 curl 172.17.0.2&lt;h1&gt;www.ssjinyao.com&lt;/h1&gt; docker 再启动 1234# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES57c80d23f0e5 busybox:latest &quot;sh&quot; 6 minutes ago Exited (130) 4 minutes ago b1# docker container start -i -a b1 docker 容器终止 12# docker kill b1# docker stop b1 docker 启动nginx镜像 12345678910111213141516171819202122232425262728# docker run --name web1 -d nginx:1.14-alpine-perl # docker inspect web1# [root@ssjinyao-node1:~]# curl 172.17.0.2&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 注: 一个容器就是为了运行一个程序，如果程序跑后台运行，那么容器认为程序终止了。因为，如果程序在容器运行在后台，那么程序一启动，容器就会终止。直接搜索下载镜像并运行 1# docker run --name kvstor1 -d redis:4-alpine 绕过容器的边界，交互式接入进去 123456# docker exec -it kvstor1 /bin/sh/data # psPID USER TIME COMMAND 1 redis 0:00 redis-server 12 root 0:00 /bin/sh 16 root 0:00 ps 查看docker启动容器后的日志信息 1# docker logs web1 docker event state Docker 镜像的使用与管理Docker:码头工人一般我们部署应用程序时，我们都是散装的。而docker可以进行集装的; Docker 镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器 1234567采用分层构建机制，最底层为bootfs,其之为rootfs bootfs: 用于系统引导的文件系统，包括bootloader和kernel， 容器启动完成后会被卸载以节约内在资源 rootfs: 位于bootfs之上，表现为docker容器的根文件系统: 传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为&quot;只读&quot;模式, 完整性自检后将其重新挂载为读写模式; docker中,rootfs由内核挂载为&quot;只读&quot;模式，而后通过&quot;联合挂载&quot;技术额外提供一个可写层; Aufs: advnaced multi-layered unification filesystem: 高级多层统一文件系统CentOS 为求稳定，不整合此文件系统overlayfs 从3.18版本开始被合并到Linux内核; 123# docker info # 可以看出前端用的文件系统是overlay2，而后端用的是xfs Storage Driver: overlay2 Backing Filesystem: xfs Docker Registry启动容器时，docker daemon 会试图从本地获取镜像; 本地镜像不存在时 将Registry 中的镜像下载保存到本地; Docker Registry 分类Registry用于保存docker镜像，包括镜像的层次结构和元数据;用户可自建Registry，也可以用官方的Docker Hub 分类Sponsor Registry: 第三方的registry, 供客户和Docker社区使用Mirror Registry: 第三方的registry,只让客户使用Vendor Registry: 由发布Docker镜像的供应商提供的registryPrivate Rgeistry: 通过设有防火墙和客外的安全层的私有实体提供的registry Repository 12345由某特定的docker镜像的所有迭代版本组成的镜像仓库一个Registry中可能存在多个Repository Repository 可分为&quot;顶层仓库&quot; 和 &quot;用户仓库&quot; 用户仓库名称格式为&quot;用户名/仓库名&quot;每个仓库可以包含多个Tag(标签)，每个标签对应一个镜像 Index 12维护用户帐户、镜像的校验以及公共命名空间的信息; 相当于为Registry提 相当于为Registry提供了一个完成用户认证等功能 Docker Registry中的镜像通常由开发人员制作，而后推送至”公共”或”私有”Registry上保存;供其他人员使用，例如”部署”到生产环境; 1# docker pull registry&gt;[:&lt;prot&gt;]/[&lt;namespace&gt;/]&lt;name&gt;:&lt;tag&gt; quay.io 也可以下载多种镜像 1# docker pull quay.io/coreos/flannel:v0.10.0-amd64 #指定站点pull镜像 镜像制作镜像的生成途径Dockerfile基于容器制作Docker Hub automated builds Namespace Example(/) organization redhat/kubernets login(user name) alice/application, bob/application role devel/database, test/database, prod/database 123456# docker container run --name busybox1 -it busyboxWARNING: IPv4 forwarding is disabled. Networking will not work./ #/ #/ # mkdir -p /data/html/ # echo &quot;&lt;h1&gt;www.ssjinyao.com&lt;/h1&gt;&quot; &gt; /data/html/index.html 暂时不关闭容器，再打开一个终端来制作镜像 12345678910111213141516171819202122# docker commit -p busybox1# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; d5ab408117c0 8 seconds ago 1.16MBredis 4-alpine db23f46600bc 2 weeks ago 30MBnginx 1.14-alpine-perl a47b6006585d 2 weeks ago 51.6MBbusybox latest e1ddd7948a1c 2 months ago 1.16MBquay.io/coreos/flannel v0.10.0-amd64 f0fad859c909 8 months ago 44.6MB# 再给标签打标签# docker tag d5ab408117c0 ssjinyao/httpd:v0.1.1-1# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEssjinyao/httpd v0.1.1-1 d5ab408117c0 About a minute ago 1.16MBredis 4-alpine db23f46600bc 2 weeks ago 30MBnginx 1.14-alpine-perl a47b6006585d 2 weeks ago 51.6MBbusybox latest e1ddd7948a1c 2 months ago 1.16MBquay.io/coreos/flannel v0.10.0-amd64 f0fad859c909 8 months ago 44.6MB# docker tag ssjinyao/httpd:v0.1.1-1 ssjinyao/httpd:latest# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEssjinyao/httpd latest d5ab408117c0 3 minutes ago 1.16MBssjinyao/httpd v0.1.1-1 d5ab408117c0 3 minutes ago 1.16MB 一个IMAGE ID 对应多个Tag时，删除 Tag 不会删除镜像，而像软链一下，删除链接 123456789101112131415161718# docker image rm ssjinyao/httpd:latestUntagged: ssjinyao/httpd:latest# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEssjinyao/httpd v0.1.1-1 d5ab408117c0 5 minutes ago 1.16MBredis 4-alpine db23f46600bc 2 weeks ago 30MBnginx 1.14-alpine-perl a47b6006585d 2 weeks ago 51.6MBbusybox latest e1ddd7948a1c 2 months ago 1.16MBquay.io/coreos/flannel v0.10.0-amd64 f0fad859c909 8 months ago 44.6MB# docker tag ssjinyao/httpd:v0.1.1-1 ssjinyao/httpd:latest# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEssjinyao/httpd latest d5ab408117c0 6 minutes ago 1.16MBssjinyao/httpd v0.1.1-1 d5ab408117c0 6 minutes ago 1.16MBredis 4-alpine db23f46600bc 2 weeks ago 30MBnginx 1.14-alpine-perl a47b6006585d 2 weeks ago 51.6MBbusybox latest e1ddd7948a1c 2 months ago 1.16MBquay.io/coreos/flannel v0.10.0-amd64 f0fad859c909 8 months ago 44.6MB 制作镜像加入Command指令 1234567891011121314# docker commit -a &quot;ssjinyao&quot; -c &apos;CMD [&quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h&quot;,&quot;/data/html&quot;]&apos; -p busybox1 ssjinyao/httpd:v0.1.1.1-2# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEssjinyao/httpd v0.1.1.1-2 0ec8103a1bb2 53 seconds ago 1.16MB# docker run --name busybox2 ssjinyao/httpd:v0.1.1.1-2 # 肯据创建的镜像启动容器# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES27403687efa0 ssjinyao/httpd:v0.1.1.1-2 &quot;/bin/httpd -f -h /d…&quot; 30 seconds ago Up 29 seconds busybox26373ae374a7a redis:4-alpine &quot;docker-entrypoint.s…&quot; 4 days ago Up 4 days 6379/tcp kvstor1a5ffdd373b90 nginx:1.14-alpine-perl &quot;nginx -g &apos;daemon of…&quot; 4 days ago Up 4 days 80/tcp web1# docker inspect # 查看容器信息# curl 172.17.0.4&lt;h1&gt;www.ssjinyao.com&lt;/h1&gt; 在 docker hub 建立帐号，并创建REPOSITORY 1234567# docker login -u ssjinyaoPassword:WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded 往 hub.docker.com 上面推镜像 1# docker push ssjinyao/httpd 可以看到，上传的镜像 国内比较常用的镜像地址在阿里云docker 镜像站点中创建REPOSITORY上传本地的镜像 123456789101112# docker tag ssjinyao/httpd:v0.1.1.1-2 registry.cn-qingdao.aliyuncs.com/ssjinyao/httpd# docker logoutRemoving login credentials for https://index.docker.io/v1/# docker login --username=ssjinyao registry.cn-qingdao.aliyuncs.comPassword:WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded# docker push registry.cn-qingdao.aliyuncs.com/ssjinyao/httpd docker 镜像的导入和导出 1234# docker save -o ssjinyao-busybox-image.gz ssjinyao/httpd:v0.1.1.1-3 ssjinyao/httpd:v0.1.1.1-2# 将镜像复制到另一台服务器# scp ssjinyao-busybox-image.gz root@node2:/root/ssjinyao-busybox-image.gz 100% 1370KB 23.8MB/s 00:00 在另一台服务器上导入镜像 123456789101112131415# docker load -i ssjinyao-busybox-image.gzf9d9e4e6e2f0: Loading layer 1.378MB/1.378MBe6baf59e35e7: Loading layer 4.608kB/4.608kB# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEssjinyao/httpd v0.1.1.1-3 cfa66f44c384 About an hour ago 1.16MBssjinyao/httpd v0.1.1.1-2 3dc1b07020fd About an hour ago 1.16MB# docker run --name busybox ssjinyao/httpd:v0.1.1.1-2# 再开启一个终端# # docker inspect busybox | grep &quot;IPAddress&quot; &quot;SecondaryIPAddresses&quot;: null, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,# curl 172.17.0.2&lt;h1&gt;www.ssjinyao.com&lt;/h1&gt; 虚拟化网络管理6种名称空间: UTS, User, Mount, IPC, Pid, Net;Linux 内核支持二层和三层设备的模拟;OVS: Open VSwitch; 12345# yum -y install bridge-utils# brctl showbridge name bridge id STP enabled interfacesdocker0 8000.024288c640ef no veth5097b16# ip link show #可以看到docker虚拟网卡信 在同一台服务器上启动两个容器 123456# docker start 27403687efa0# docker container run --name busybox3 -it ssjinyao/httpd:v0.1.1.1-3# 查看两个容器间基于nat的通信 # docker exec -it busybox2 /bin/sh/ # wget -O - -q http://172.17.0.5&lt;h1&gt;www.ssjinyao.com&lt;/h1&gt; {User,Mount,Pid}, {User,Mount,Pid} –&gt; 共享{UTS,Net,IPC} 让容器使用管理宿主机的网络名称空间 1# docker network inspect bridge ip 名称空间管理 1234567891011# yum -y install iproute# ip netns helpUsage: ip netns list ip netns add NAME ip netns set NAME NETNSID ip [-all] netns delete [NAME] ip netns identify [PID] ip netns pids NAME ip [-all] netns exec [NAME] cmd ... ip netns monitor ip netns list-id 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# ip netns add r1# ip netns add r2# ip netns exec r1 ifconfig -a# ip link add name veth1.1 type veth peer name veth1.2# ip link show | grep veth134: veth1.2@veth1.1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 100035: veth1.1@veth1.2: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 1000# ip link set dev veth1.2 netns r1 # 将设veth1.2 称到名称空间r1 中# ip netns exec r1 ifconfig -alo: flags=8&lt;LOOPBACK&gt; mtu 65536 loop txqueuelen 1 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0veth1.2: flags=4098&lt;BROADCAST,MULTICAST&gt; mtu 1500 ether da:2a:32:c9:1e:e2 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0# ip netns exec r1 ip link set dev veth1.2 name eth0 # 将名称空间中的veth1.2更名为eth0# ip netns exec r1 ifconfig -aeth0: flags=4098&lt;BROADCAST,MULTICAST&gt; mtu 1500 ether da:2a:32:c9:1e:e2 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=8&lt;LOOPBACK&gt; mtu 65536 loop txqueuelen 1 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0# ifconfig veth1.1 10.1.0.1/24 up # 激活网卡veth1.1# ip netns exec r1 ifconfig eth0 10.1.0.2/24 up # 激活r1名称空间中的 eth0# ip netns exec r1 ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 10.1.0.2 netmask 255.255.255.0 broadcast 10.1.0.255 inet6 fe80::d82a:32ff:fec9:1ee2 prefixlen 64 scopeid 0x20&lt;link&gt; ether da:2a:32:c9:1e:e2 txqueuelen 1000 (Ethernet) RX packets 8 bytes 648 (648.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 8 bytes 648 (648.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0# ping 10.1.0.2PING 10.1.0.2 (10.1.0.2) 56(84) bytes of data.64 bytes from 10.1.0.2: icmp_seq=1 ttl=64 time=0.945 ms64 bytes from 10.1.0.2: icmp_seq=2 ttl=64 time=0.061 ms# ip link set dev veth1.1 netns r2 # 将 veth1.1 移到名称空间r2中# ip netns exec r2 ifconfig veth1.1 10.1.0.3/24 up # 启用r2名称空间中的veth1.1# ip netns exec r2 ping 10.1.0.2 # 在名称空间r2中ping 名称空间r1的eth0绑定的ip地址PING 10.1.0.2 (10.1.0.2) 56(84) bytes of data.64 bytes from 10.1.0.2: icmp_seq=1 ttl=64 time=0.214 ms64 bytes from 10.1.0.2: icmp_seq=2 ttl=64 time=0.080 ms--rm 容器停止后，将容器删除# docker run --name t1 -it --network bridge -h www.ssjinyao.com --rm busybox:latest/ # hostnamewww.ssjinyao.com/ # ping www.ssjinyao.comPING www.ssjinyao.com (172.17.0.6): 56 data bytes64 bytes from 172.17.0.6: seq=0 ttl=64 time=0.094 ms--- www.ssjinyao.com ping statistics ---1 packets transmitted, 1 packets received, 0% packet lossround-trip min/avg/max = 0.094/0.094/0.094 ms/ # cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.6 www.ssjinyao.com www/ # cat /etc/resolv.conf# Generated by NetworkManagersearch localdomainnameserver 10.180.66.2 只要配置了正确的域名服务器，可以正解的解析 1234567/ # nslookup -type=A nas.ssjinyao.comServer: 10.180.66.2Address: 10.180.66.2:53Non-authoritative answer:Name: nas.ssjinyao.comAddress: 47.104.201.165 1234567891011121314151617# docker run --name t1 -it --network bridge -h www.ssjinyao.com --dns 114.114.114.114 --dns 8.8.8.8 --rm busybox:latest/ # cat /etc/resolv.confsearch localdomainnameserver 114.114.114.114nameserver 8.8.8.8/ # hostnamewww.ssjinyao.com# docker run --name t1 -it --network bridge -h t1.ssjinyao.com --dns 114.114.114.114 --dns-search ssjinyao.com --add-host www.ssjinyao.com:1.1.1.1 --rm busybox:latest/ # cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters1.1.1.1 www.ssjinyao.com172.17.0.6 t1.ssjinyao.com t1 将容器的端口进行暴露 1234# docker run --name myweb --rm -p 80 ssjinyao/httpd:v0.1.1.1-2# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES97212485437e ssjinyao/httpd:v0.1.1.1-3 &quot;/bin/httpd -f -h /d…&quot; 4 minutes ago Up 4 minutes 0.0.0.0:32773-&gt;80/tcp myweb Opening inbound communication 1234567-p 选项的使用格式 -p &lt;containerPort&gt; 将指定的容器端口映射至主机所有地址的一个动态端口; -p &lt;hostPort&gt;:&lt;containerPort&gt; 将容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt; -p &lt;ip&gt;::&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt; 123# docker run --name myweb --rm -p 10.180.66.11:8080:80 ssjinyao/httpd:v0.1.1.1-3# docker port myweb80/tcp -&gt; 10.180.66.11:8080 Joined container(联盟式容器) 共享b1容器的网络 123456789101112131415161718192021222324252627# docker run --name b1 -it --rm busybox# docker run --name b2 --network container:b1 -it --rm busybox/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:648 (648.0 B) TX bytes:0 (0.0 B)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)/ # echo &quot;Joined container&quot; &gt; /tmp/index.html/ # httpd -h /tmp// # netstat -tnlActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 :::80 :::* LISTEN/ # wget -O - -q 127.0.0.1Joined container 共享宿主机网络 1234567891011121314151617181920212223242526272829# docker run --name b2 --network host -it --rm busybox/ #/ # ifconfigdocker0 Link encap:Ethernet HWaddr 02:42:88:C6:40:EF inet addr:172.17.0.1 Bcast:172.17.255.255 Mask:255.255.0.0 inet6 addr: fe80::42:88ff:fec6:40ef/64 Scope:Link UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:347 errors:0 dropped:0 overruns:0 frame:0 TX packets:371 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:35796 (34.9 KiB) TX bytes:40247 (39.3 KiB)ens33 Link encap:Ethernet HWaddr 00:0C:29:F8:70:D5 inet addr:10.180.66.11 Bcast:10.180.66.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fef8:70d5/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:123421 errors:0 dropped:0 overruns:0 frame:0 TX packets:39524 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:81346864 (77.5 MiB) TX bytes:8253033 (7.8 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:80 errors:0 dropped:0 overruns:0 frame:0 TX packets:80 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:6944 (6.7 KiB) TX bytes:6944 (6.7 KiB) 更改docker0 桥的ip地址 12345678910111213141516# vim /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;:[&quot;https://registry.docker-cn.com&quot;], &quot;bip&quot;: &quot;10.0.0.1/16&quot;, &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2375&quot;,&quot;unix:///var/run/docker.sock&quot;]&#125;# ifconfigdocker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 10.0.0.1 netmask 255.255.0.0 broadcast 10.0.255.255 inet6 fe80::42:88ff:fec6:40ef prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:88:c6:40:ef txqueuelen 0 (Ethernet) RX packets 347 bytes 35796 (34.9 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 371 bytes 40247 (39.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0# docker -H 10.180.66.11:2375 image ls 创建网桥 123456789101112131415161718192021222324# docker network create -d bridge --subnet &quot;172.26.0.0/16&quot; --gateway &quot;172.26.0.1&quot; mbr0# ifconfigbr-76b59a5dfce3: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 172.26.0.1 netmask 255.255.0.0 broadcast 172.26.255.255 ether 02:42:ea:15:d6:9e txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0# ip link set dev br-76b59a5dfce3 name docker1RTNETLINK answers: Device or resource busy# ifconfig br-76b59a5dfce3 down# ifconfig docker1 up # ifconfig docker1 down # 更改名称后默认docker 调用时会找不到docker1这个虚拟网卡# ip link set dev docker1 name br-76b59a5dfce3# docker run --name t1 -it --net mbr0 busybox:latest/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:1A:00:02 inet addr:172.26.0.2 Bcast:172.26.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:3 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:258 (258.0 B) TX bytes:0 (0.0 B) 自定义docker0桥的网络属性信息: /etc/docker/daemon.json文件 12345678&#123; &quot;bip&quot;: &quot;192.168.1.5/24&quot;, &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mtu&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;, &quot;10.20.1.3&quot;] docker守护进程的C/S，其默认监听Unix SOcket格式的地址，/var/run/docker.sock;如果使用TCP套接字， /etc/docker/daemon.json:“hosts”: [“tcp://0.0.0.0:2375”, “unix:///var/run/docker.sock”]]]></content>
      <tags>
        <tag>linux</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 系统定制]]></title>
    <url>%2F2018%2F09%2F01%2Flinux%E7%B3%BB%E7%BB%9F%E5%AE%9A%E5%88%B6%2F</url>
    <content type="text"><![CDATA[linux系统与应用定制linux 系统层面工作原结构 必需要熟悉系统启动流程 CentOS 6 系统启动流程 CentOS 7 系统启动流程 环境准备 服务器 系统环境 主机名 内核版本 必装环境 宿主机 CentOS 6.9 Node11 Kernel 2.6.32-696.el6.x86_64 Development Tools 制作机 ssjinyao Linux Node21 Kernel linux-4.18.4 Busybox 1.29 将下载的包上传到服务器中 12~ ➤ scp ~/Downloads/linux-4.18.4.tar.xz root@node11:/usr/local/src/ ~ ➤ scp ~/Downloads/busybox-1.29.2.tar.bz2 root@node11:/usr/local/src/ 安装宿主机所需要编译环境 1[root@ssjinyao-node11:~]# yum groupinstall &quot;Development tools&quot; &quot;Desktop Platform Development&quot; -y 内核编译解压文件123456[root@ssjinyao-node11:~]# cd /usr/local/src/[root@ssjinyao-node11:~]# ln -s linux-4.18.4 linux[root@ssjinyao-node11:~]# cd linux[root@ssjinyao-node11:~]# make help # 查看make帮助# 如果在centos不能解压时，需要执行# yum -y install xz 因为在CentOS 6 的环境中 tar 解压xz文件调用的是xz命令 1234[root@ssjinyao-node11:/usr/local/src/linux]# make allnoconfig# 把原默认配置都清空，根据我们的需要选则编译[root@ssjinyao-node11:/usr/local/src/linux]# make menuconfig# 根据自己的需求，选则内核需要支持模块 默认配置 全局配置 kernel-config-general-setup kernel-config-enable-loadble-module kernel-config-device-drivers kernel-config-file-systems 详细配置与操作过程如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061* 启用 64-bit kernel # 让内核支持 64位架构* 启用 Enable loadable module support # 支持内核模块装载* 点进 Enable loadable module support --&gt; Module unloading # 让内核支持动态装卸载* 点进 Enable loadable module support --&gt; Module signature verification # 让内核校验装载的模块是否是已经认证的公司，避免内核被污染，以确保内核层面的安全* 点进 Processor type and features --&gt; processor family(Generic-x86-64) ---&gt; Generic-x86-64 # 支持通用cpu，当然也可以对应选则适合自己的* 点进 Processor type and features --&gt; Symmetric multi-processing support # 支持多核cpu* 点进 Bus options (PCI etc.) --&gt; PCI support # 选中支持* 启用 Enable the block layer # 选中支持* 点进 Device Drivers --&gt; SCSI device support # 选中支持* 点进 Device Drivers --&gt; SCSI disk support # 选中支持* 点进 Device Drivers --&gt; Fusion MPT device support（启用） ---&gt; Fusion MPT ScsiHost drivers for SPI # 选中支持* 点进 Device Drivers --&gt; Fusion MPT device support（启用） ---&gt; Fusion MPT ScsiHost drivers for SAS # 选中支持* 点进 Device Drivers --&gt; Fusion MPT device support（启用） ---&gt; Fusion MPT misc device (ioctl) driver # 选中支持* 点进 Device Drivers --&gt; Fusion MPT device support（启用） ---&gt; Fusion MPT logging facility # 选中支持* 点进 Device Drivers --&gt; Input device support ---&gt; Keyboards (NEW) (启用 ) ----&gt; &lt;*&gt; AT keyboard (NEW) # 选中支持 * 点进 Device Drivers --&gt; Input device support ---&gt; Mouse interface # 选中支持* 点进 Device Drivers --&gt; Input device support ---&gt; Provide legacy /dev/psaux device # 选中支持 * 点进 Device Drivers --&gt; USB support ---&gt; Support for Host-side USB # 选中支持* 点进 Device Drivers --&gt; USB support ---&gt; Enable USB persist by default (NEW) # 选中支持 * 点进 Device Drivers --&gt; USB support ---&gt; xHCI HCD (USB 3.0) support # 选中支持* 点进 Device Drivers --&gt; USB support ---&gt; Generic xHCI driver for a platform device # 选中支持 * 点进 Device Drivers --&gt; USB support ---&gt; EHCI HCD (USB 2.0) support # 选中支持 * 点进 Device Drivers --&gt; USB support ---&gt; Root Hub Transaction Translators # 选中支持* 点进 Device Drivers --&gt; USB support ---&gt; Improved Transaction Translator scheduling (NEW) # 选中支持 * 点进 Device Drivers --&gt; USB support ---&gt; OHCI HCD (USB 1.1) support # 选中支持 * 点进 Device Drivers --&gt; USB support ---&gt; OHCI support for PCI-bus USB controllers (NEW) # 选中支持 * 点进 Device Drivers --&gt; Generic Driver Options ---&gt; Maintain a devtmpfs filesystem to mount at /dev # 选中支持* 点进 Device Drivers --&gt; Generic Driver Options ---&gt; Automount devtmpfs at /dev, after the kernel mounted the rootfs # 选中支持* 点进 File systems --&gt; Second extended fs support # 选中支持* 点进 File systems --&gt; Ext2 extended attributes # 选中支持* 点进 File systems --&gt; Ext2 POSIX Access Control Lists # 选中支持 * 点进 File systems --&gt; Ext2 Security Labels # 选中支持 * 点进 File systems --&gt; The Extended 3 (ext3) filesystem # 选中支持* 点进 File systems --&gt; Ext3 POSIX Access Control Lists # 选中支持 * 点进 File systems --&gt; Ext3 Security Labels # 选中支持* 点进 File systems --&gt; The Extended 4 (ext4) filesystem # 选中支持 * 点进 File systems --&gt; Ext4 POSIX Access Control Lists # 选中支持 * 点进 File systems --&gt; Ext4 Security Labels # 选中支持 * 点进 File systems --&gt; Ext4 Encryption # 选中支持 * 点进 File systems --&gt; XFS filesystem support # 选中支持 * 点进 File systems --&gt; XFS Quota support # 选中支持 * 点进 File systems --&gt; XFS POSIX ACL support # 选中支持 * 点进 File systems --&gt; XFS Realtime subvolume support # 选中支持* 点进 File systems --&gt; XFS online metadata check support # 选中支持 * 点进 File systems --&gt; XFS online metadata repair support # 选中支持* 点进 File systems --&gt; XFS Debugging support # 选中支持* 点进 File systems --&gt; XFS fatal asserts (NEW) # 选中支持 # 注：这里选择文件系统时可以选择自己常用的一种就好，我这里为方便以后使用，都加入进去了# 一般xfs 文件系统类型是目前性能最好的文件系统，而ext3 ext4 则有较成熟的数据恢复技术，如ext3grep* 点进 Executable file formats / Emulations --&gt; Kernel support for ELF binaries # 选中支持* 点进 Executable file formats / Emulations --&gt; Kernel support for scripts starting with #! # 选中支持，即文件系统shell支持机制 * 点进 Executable file formats / Emulations --&gt; Kernel support for MISC binaries # 选中支持* Networking support (启用) --&gt; Networking options ---&gt; TCP/IP networking # 选中支持，为以后做实验或者使用方便。将TCP/IP networking 下面的核心项即tcp/ip 与devel项安装* Device Drivers --&gt; Network device support ---&gt; Ethernet driver support (NEW) ----&gt; (启用) ----&gt; Intel devices (NEW)(启用) -----&gt; Intel(R) PRO/1000 Gigabit * * Device Drivers --&gt; Network device support ---&gt; Ethernet driver support (NEW) ----&gt; (启用) ----&gt; AMD devices(启用) -----&gt; AMD相关的我这里全部勾选 Ethernet support # 添加模块 , 其它的所有 Ethernet driver support 可以取消，依据自己的需求选则* 点进 General setup --&gt; (huatu-ssjinyao-kernel) Local version - append to kernel release # 点加Kernel release * 点进 General setup --&gt; (huatu-ssjinyao) Default hostname 编译内核是个比较复杂的过程，这里的大家如果一直编译不成功，或者编译完内核后不有成功启动系统可以使用我这里给大家建立的模板 建立可以使用的内核配置模板 1# cp kernel-config-ok-net-all-ok /usr/local/src/linux/.config # 可以使用这个模板来进行编译生成内核文件 123456789101112131415161718192021222324252627[root@ssjinyao-node11:/usr/local/src/linux-4.18.4]# cat init/main.c | grep -C 8 ' !try_to_run_init_process("/etc/init")' if (execute_command) &#123; ret = run_init_process(execute_command); if (!ret) return 0; panic("Requested init %s failed (error %d).", execute_command, ret); &#125; if (!try_to_run_init_process("/sbin/init") || !try_to_run_init_process("/etc/init") || !try_to_run_init_process("/bin/init") || !try_to_run_init_process("/bin/sh")) return 0; panic("No working init found. Try passing init= option to kernel. " "See Linux Documentation/admin-guide/init.rst for guidance.");&#125;[root@ssjinyao-node11:/usr/local/src/linux-4.18.4]# pwd/usr/local/src/linux-4.18.4# 注: 通过查看这段内核源码，则可以看到系统启动时查到init的流程 先找 /sbin/init --&gt; 若不存在 再找 /etc/init --&gt; 若不存在 再找 /bin/init --&gt; 若不存在 再找 /bin/sh --&gt; 若不存在 启动报内核恐慌当然也可以在grub 的配置文件中指定 init= 来指定init的位置 123[root@ssjinyao-node11:/usr/local/src/linux]# make -j 4 bzImage[root@ssjinyao-node11:/usr/local/src/linux]# du -sh arch/x86/boot/bzImage3.0M arch/x86/boot/bzImage 编译单个网卡模块12345[root@ssjinyao-node11:/usr/local/src/linux]# ls drivers/net/ethernet/intel/e1000/e1000_ethtool.c e1000.h e1000_hw.c e1000_hw.h e1000_main.c e1000_osdep.h e1000_param.c Makefileroot@ssjinyao-node11:/usr/local/src/linux]# ls drivers/net/ethernet/intel/e1000/e1000.kodrivers/net/ethernet/intel/e1000/e1000.ko# insmod /lib64/modules/e1000.ko 安装 编译安装busybox因静态编译依赖于软件包 glibc-static, 因此在编译busybox时需要安装 glibc-static 1234[root@ssjinyao-node11:/usr/local/src]# tar -xvf busybox-1.29.2.tar.bz2[root@ssjinyao-node11:/usr/local/src]# cd busybox-1.29.2[root@ssjinyao-node11:/usr/local/src]# yum -y install glibc-static[root@ssjinyao-node11:/usr/local/src/busybox-1.29.2]# make menuconfig 123Settings --&gt; --- Build Options 标题栏中 Build static binary (no shared libs) # 选中支持Settings --&gt; --- Installation Options (&quot;make install&quot; behavior) What kind of applet links to install (as soft-links) ---&gt; 这个默认的 as soft-links 就可以了 Settings --&gt; --- Installation Options (&quot;make install&quot; behavior) (./_install) Destination path for &apos;make install&apos; ---&gt; 这个也选用默认的编译安装完到默认当前路径 1make install # 注编译出错的时候要去了 Coreutils --&gt; sync 后面需要再同步过去 利用busybox 制作initrd123456789101112131415161718192021[root@ssjinyao-node11:/usr/local/src/busybox-1.29.2]# mkdir /tmp/busybox[root@ssjinyao-node11:/usr/local/src/busybox-1.29.2]# cp -a ./_install/*bin/ linuxrc sbin/ usr/[root@ssjinyao-node11:/usr/local/src/busybox-1.29.2]# cp -a ./_install/* /tmp/busybox/[root@ssjinyao-node11:/usr/local/src/busybox-1.29.2]# cd /tmp/busybox/[root@ssjinyao-node11:/tmp/busybox]#[root@ssjinyao-node11:/tmp/busybox]# mkdir -pv proc sys etc/init.d tmp dev mnt/sysroot [root@ssjinyao-node11:/tmp/busybox]# vim init#!/bin/ashecho -e &quot;\t\033[32m Now start init and switch root ! \033[0m &quot;mount -t proc proc /procmount -t sysfs sysfs /sysmdev -smount -t xfs /dev/sda2 /mnt/sysrootexec switch_root /mnt/sysroot /sbin/init[root@ssjinyao-node11:/tmp/busybox]# chmod +x init[root@ssjinyao-node11:/tmp/busybox]# mknod dev/console c 5 1[root@ssjinyao-node11:/tmp/busybox]# mknod dev/null c 1 3[root@ssjinyao-node11:/tmp/busybox]# find . | cpio --quiet -H newc -o | gzip -9 -n &gt; ./huatu-ssjinyao-initrd.gz[root@ssjinyao-node11:/tmp/busybox]# du -sh huatu-ssjinyao-initrd.gz1.3M huatu-ssjinyao-initrd.gz 安装grub,整合内核与initrd此时将宿主机关掉，挂载一块scsi磁盘，用于将grub,内核,initrd写嵌入我这里用的是vmware fusion 虚拟工具，windows大家习惯用vmware workstation只要给虚拟机添加一块磁盘即可,如下图 注意: 现在挂载磁盘一定是要和宿主机共享磁盘，不然的话信息不会实时同步 ;也是说，添加的这块磁盘是为宿主机和制作机之间同步数据使用，也就是说共用一块虚拟磁盘;添加完后将宿主服务器启动 12345678[root@ssjinyao-node11:~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 20G 0 disk├─sda1 8:1 0 500M 0 part /boot└─sda2 8:2 0 19.5G 0 part ├─vg_ssjinyaonode11-lv_root (dm-0) 253:0 0 17.6G 0 lvm / └─vg_ssjinyaonode11-lv_swap (dm-1) 253:1 0 2G 0 lvm [SWAP]sdb 8:16 0 38G 0 disk 由上可以看出，已经添加了一块磁盘 sdb,将磁盘分区并挂载至/mnt目录下boot,与sysroot 1234567891011121314151617181920212223242526272829303132333435363738[root@ssjinyao-node11:~]# mkdir /mnt/&#123;boot,sysroot&#125;[root@ssjinyao-node11:~]# fdisk /dev/sdbDevice contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabelBuilding a new DOS disklabel with disk identifier 0x42ed0c1e.Changes will remain in memory only, until you decide to write them.After that, of course, the previous content won&apos;t be recoverable.Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)WARNING: DOS-compatible mode is deprecated. It&apos;s strongly recommended to switch off the mode (command &apos;c&apos;) and change display units to sectors (command &apos;u&apos;).Command (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-4960, default 1): 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-4960, default 4960): +300MCommand (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 2First cylinder (40-4960, default 40): 40Last cylinder, +cylinders or +size&#123;K,M,G&#125; (40-4960, default 4960): 4960Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.[root@ssjinyao-node11:~]# mkfs.xfs /dev/sdb1[root@ssjinyao-node11:~]# mkfs.xfs /dev/sdb2 123456# mkdir /mnt/&#123;boot,sysroot&#125;# mount /dev/sdb1 /mnt/boot# mount /dev/sdb2 /mnt/sysroot[root@ssjinyao-node11:~]# mount /dev/sdb1 /mnt/boot/[root@ssjinyao-node11:~]# mount /dev/sdb2 /mnt/sysroot/[root@ssjinyao-node11:~]# cd /tmp/busybox/ 将编译好的内核与制作好的initrd入到boot启动目录 12[root@ssjinyao-node11:/tmp/busybox]# cp huatu-ssjinyao-initrd.gz /mnt/boot/[root@ssjinyao-node11:~]# cp /usr/local/src/linux/arch/x86/boot/bzImage /mnt/boot/huatu-ssjinyao-kernel 安装 grub 至新添加的硬盘 1[root@ssjinyao-node11:/tmp/busybox]# grub-install --root-directory=/mnt/ /dev/sdb 提供 grub 配置文件 12345678[root@ssjinyao-node11:/mnt/sysroot]# vim /mnt/boot/grub/grub.confdefault 0timeout 3color light-green/black light-magenta/blacktitle huatu-ssinyao-kernel 4.18.5 root (hd0,0) kernel /huatu-ssjinyao-kernel ro root=/dev/sda2 vga=877 quiet initrd /huatu-ssjinyao-initrd.gz vga=877 这里是根据我的屏目分辨率而调整的适应的;这里可以在启动 vga=ask grub开机时会给你一个列表，让你选择自己的分辨率;最后可以选择自己屏幕的分辨率大小; 如，这里的我的分辨率是 1400x900，这里选的是36D，再将16进制36D转换为十进制数，即是我在grub.conf中配置的vga=877 其它项配置项 1234567default 配置这个项目为0默认启动项;timeout 配置超过3秒不选则，则自动选则第一个title启动;color 配置grub菜单栏颜色;title 配置启动项标题;root (hd0,0) 配置root先识别第一块盘的第一个分区;kernel 配置指定启动内核，这里即是我们编译好的内核，root 指定启动后的根分区;initrd 配置启动虚根，与第一个进程; 建立真实文件系统123[root@ssjinyao-node11:/mnt/sysroot]# cp /usr/local/src/busybox-1.29.2/_install/* . -a[root@ssjinyao-node11:/mnt/sysroot]# rm -f linuxrc[root@ssjinyao-node11:/mnt/sysroot]# mkdir -pv etc dev proc sys bin sbin usr/&#123;bin,sbin,lib,lib64,local&#125; lib64 lib/modules home var/&#123;log,run,lock&#125; tmp mnt media root boot 12345678910111213141516[root@ssjinyao-node11:/mnt/sysroot]# vim etc/inittab# console:respawn:-/bin/ash# tty1::askfirst:/bin/ash# tty2::askfirst:/bin/ash# tty3::askfirst:/bin/ash::sysinit:/etc/rc.d/rc.sysinit::respawn:/sbin/getty 9600 tty1::respawn:/sbin/getty 9600 tty2::respawn:/sbin/getty 9600 tty3::respawn:/sbin/getty 9600 tty4::respawn:/sbin/getty 9600 tty5::respawn:/sbin/getty 9600 tty6::respawn:/sbin/getty 9600 tty7::ctrlaltdel:/sbin/reboot::shutdown:/bin/umount -a -r &amp;&gt; /dev/null[root@ssjinyao-node11:/mnt/sysroot]# chmod +x etc/inittab 123456789101112131415161718192021222324252627282930313233343536373839404142#[root@ssjinyao-node11:/mnt/sysroot]# mkdir etc/rc.d/#[root@ssjinyao-node11:/mnt/sysroot]# vim etc/rc.d/rc.sysinit#!/bin/shecho -e "\t welcome to \033[31m HuaTu SSJinYao \033[0m Linux"mount -t proc proc /procmount -t sysfs sysfs /sysecho "scan /sys and to populate to /dev..."mdev -smount -o remount,rw /dev/sda2 /echo "mounting all filesystems..."mount -aifconfig eth0 10.180.66.31 netmask 255.255.255.0ifconfig lo 127.0.0.1route add default gw 10.180.66.2echo -e "\033[31m Start Network Manager.........................\033[0m \033[32m [OK] \033[0m"/usr/local/sbin/dropbear -E -F &amp;&gt; /var/log/dropbear/sshd.log &amp;echo -e "\033[31m Start dropbear sshd ..........................\033[0m \033[32m [OK] \033[0m"/usr/local/nginx/sbin/nginxecho -e "\033[31m Start Nginx Service ..........................\033[0m \033[32m [OK] \033[0m"/usr/local/keepalived/sbin/keepalived -D -S 0 -f /usr/local/keepalived/etc/keepalived/keepalived.confecho -e "\033[31m Start Keepalived Service .....................\033[0m \033[32m [OK] \033[0m"rsync.sh &amp;&gt; /dev/null &amp;echo -e "\033[31m Start Rsync Service ..........................\033[0m \033[32m [OK] \033[0m"echo -e "\033[31m \ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \ ** ** // // ** ** ****** ****** ** ** ******* //** ** ****** ****** **//// **//// /**/**//**///** //*** //////** **////** //***** //***** /**/** /** /** /** ******* /** /** /////** /////** **/**/** /** /** ** **////** /** /** ****** ****** //*** /** *** /** ** //********//****** ////// ////// /// // /// // // //////// ////// \\ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \\\033[0m"# chmod +x etc/rc.d/rc.sysinit 建系统系统挂载目录 fstab 12345678[root@ssjinyao-node11:/mnt/sysroot]# mkdir /dev/pts# 注: 在此之前一定要有 dev/pts 目录 [root@ssjinyao-node11:/mnt/sysroot]# vim etc/fstab sysfs /sys sysfs defaults 0 0 proc /proc proc defaults 0 0 devpts /dev/pts devpts mode=620 0 0 /dev/sda1 /boot xfs defaults 0 0 /dev/sda2 / xfs defaults 0 0 添加登录后脚本/etc/profile 12export PS1='[\[\033[01;36m\]\u\[\033[00m\]@\[\033[01;34m\]\h\[\033[00m\]:\[\033[01;32m\]\w\[\033[00m\]]\[\033[01;34m\]\$\[\033[00m\] 'export PATH=/usr/local/bin:/usr/local/sbin/:/sbin:/bin:/usr/bin:/usr/sbin 123456[root@ssjinyao-node11:/mnt/sysroot]# vim etc/shells /bin/sh/bin/ash/bin/hush/bin/bash/sbin/nologin 12345[root@ssjinyao-node11:/mnt/sysroot]# etc/nsswitch.confpasswd: filesgrup: filesshadow: fileshosts: files dns 编译安装dropbear注 dropbear 可以在dropbear官网下载 12345678[root@ssjinyao-node11:/usr/local/src]# tar -xvf dropbear-2018.76.tar.bz2[root@ssjinyao-node11:/usr/local/src]# cd dropbear-2018.76[root@ssjinyao-node11:/usr/local/src/dropbear-2018.76]# make PROGRAMS=&quot;dropbear dbclient dropbearkey dropbearconvert scp&quot; install[root@ssjinyao-node11:/mnt/sysroot]# cd /mnt/sysroot/etc/dropbear/[root@ssjinyao-node11:/mnt/sysroot/etc/dropbear/]# openssl passwd -1 -salt $(openssl rand -hex 4)[root@ssjinyao-node11:/mnt/sysroot/etc/dropbear/]# dropbearkey -t rsa -s 2048 -f dropbear_rsa_host_key[root@ssjinyao-node11:/mnt/sysroot/etc/dropbear/]# dropbearkey -t dss -f dropbear_dss_host_key[root@ssjinyao-node11:/mnt/sysroot/etc/dropbear/]# dropbear -E -F 启动 移植系统认证、登录、解析相关的依赖库123456[root@ssjinyao-node11:/mnt/sysroot] mkdir usr/lib64/[root@ssjinyao-node11:/mnt/sysroot] cp -d /lib64/libnss_files* lib64/[root@ssjinyao-node11:/mnt/sysroot] cp -d /usr/lib64/libnss3.so usr/lib64/[root@ssjinyao-node11:/mnt/sysroot] cp -d /usr/lib64/libnss_files.so* usr/lib64/[root@ssjinyao-node11:/mnt/sysroot] cp -d /lib64/libresolv* lib64/[root@ssjinyao-node11:/mnt/sysroot] cp -d /lib64/libnss_dns* lib64/ 编译安装nginx12345[root@ssjinyao-node11:/usr/local/src]# cd /usr/local/src/[root@ssjinyao-node11:/usr/local/src]# tar -xvf nginx-1.14.0.tar.gz./configure --prefix=/usr/local/nginx --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --with-http_gzip_static_module --with-http_stub_status_module --with-http_ssl_module --user=root --group=root[root@ssjinyao-node11:/usr/local/src]# cp -a /usr/local/nginx/sbin/nginx /usr/sbin/[root@ssjinyao-node11:/usr/local/src]# cp -a /usr/local/nginx/ /mnt/sysroot/usr/local/ 编译安装inotify并移植12345[root@ssjinyao-node11:/usr/local]# cd /usr/local/src/[root@ssjinyao-node11:/usr/local/src]# tar -xvf inotify-tools-3.14.tar.gz[root@ssjinyao-node11:/usr/local/src]# cd inotify-tools-3.14[root@ssjinyao-node11:/usr/local/src/inotify-tools-3.14]# ./configure --prefix=/usr/local/inotify/[root@ssjinyao-node11:/usr/local/src/inotify-tools-3.14]# cp -a /usr/local/inotify/ /mnt/sysroot/usr/local 编译安装keepalived注: keepalived 依赖net-tools psmisc 两个工具包，因此需要将这两个工具包的命令移植 12345678910111213141516171819[root@laoba-10-17:/usr/local/src/linux-4.18.5]# rpm -ql net-tools | grep bin &amp;&amp; rpm -ql psmisc | grep bin/bin/netstat/sbin/arp/sbin/ether-wake/sbin/ifconfig/sbin/ipmaddr/sbin/iptunnel/sbin/mii-diag/sbin/mii-tool/sbin/nameif/sbin/plipconfig/sbin/route/sbin/slattach/usr/bin/killall/usr/bin/peekfd/usr/bin/prtstat/usr/bin/pstree/usr/bin/pstree.x11/usr/sbin/fuser 12345[root@ssjinyao-node11:/usr/local/src]# tar -xvf keepalived-2.0.6.tar.gz[root@ssjinyao-node11:/usr/local/src]# cd keepalived-2.0.6[root@ssjinyao-node11:/usr/local/src]# cp /usr/local/keepalived/sbin/keepalived /usr/sbin/[root@ssjinyao-node11:/usr/local/src/keepalived-2.0.6]# ./configure --prefix=/usr/local/keepalived/[root@ssjinyao-node11:/usr/local/src]# cp -a /usr/local/keepalived/ /mnt/sysroot/usr/local 编写bincp 脚本ldd 命令可以查看命令所依赖的库的位置 1[root@ssjinyao-node11:/mnt/sysroot]# ldd /bin/cp 编写脚本，将需要的命令同步到/mnt/sysroot 目录 1234567891011121314151617181920212223242526272829303132333435363738[root@ssjinyao-node11:/mnt/sysroot]# mkdir /root/bin[root@ssjinyao-node11:/mnt/sysroot]# vim /root/bin/bincp.sh[root@ssjinyao-node11:/mnt/sysroot]# chmod +x /root/bin/bincp.sh#!/bin/bash#The scripts can copy bin file and that bin libs#author renjin#date 2016 11 19#version 3.0echo "acquiesce copy bin file in /mnt/sysroot!! "MNT="/mnt/sysroot"BIN_FILE() &#123; bindir=`dirname $file` [ -e $MNT ] || mkdir -p $MNT [ -e $MNT$bindir ] || mkdir -p $MNT$bindir if [ -e $MNT$file ] ; then echo "you will copy bin file exsit !" else cp $file $MNT$bindir fi &#125;LIB_FILE() &#123; lib=`ldd $file | grep -Eo "/.*lib(64)&#123;0,1&#125;/[^[:space:]]&#123;1,&#125;"` for lib64 in $lib; do libdir=`dirname $lib64` if [ ! -e $MNT$libdir ]; then mkdir -p $MNT$libdir elif [ -e $MNT$lib64 ] ; then echo "you will copy lib file exsit " &amp;&amp; continue else cp $lib $MNT$libdir fi done &#125;read -p "please input your will copy bin file name,or input quit quitng: " BINuntil [ $BIN == 'quit' -o $BIN == 'q' ]; do! which $BIN 2&gt; /dev/null &amp;&amp; read -p "you input command no exsit,please again input or input quit ,quiting " BIN &amp;&amp; continuefile=`which --skip-alias $BIN 2&gt; /dev/null | grep "/.*[^[:space:]]" ` BIN_FILE $BIN &amp;&amp; LIB_FILE $BINread -p "continue!,or input quit ,quting: " BINdone 1234# chmod +x /root/bincp.sh &amp;&amp; cp /root/bincp.sh /bin[root@ssjinyao-node11:/usr/local/src]# bincp.shacquiesce copy bin file in /mnt/sysroot!!please input your will copy bin file name,or input quit quitng: 需要移植的命令有 1bash dropbear ssh scp rysnc dbclient dropbearconvert dropbearkey genhash nginx 等等 利上这个脚本将自己需要的命令拷贝到/mnt/sysroot中 添加root用户 1234# adduser root # passwd root这里要注意把 root id 在 /etc/passwd 中改0在Linux内核中，系统权限只对应id 微系统 keepaived+nginx+rsync+inotify的实现keepalived+nginx+rsync+intofity 在之前的文章中有实现大家可以再克隆一个小系统，来实现keepalived的双主 系统启动后如下图]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python日常练习]]></title>
    <url>%2F2018%2F08%2F23%2Fpython%20%E6%97%A5%E5%B8%B8%E7%BB%83%E4%B9%A008-23%2F</url>
    <content type="text"><![CDATA[python 日常练习 和并两个有序列表，并且保持合并后的两个列表有序123456789101112131415161718In [11]: l1 = [1,2,3,4]In [12]: l2 = [2,3,7,9]In [13]: l3 = []In [14]: for x in l1: ...: while len(l2) &gt; 0 : ...: if x &gt; l2[0]: ...: l3.append(l2.pop(0)) ...: else: ...: l3.append(x) ...: break ...: if len(l2) &lt;= 0: ...: l3.append(x) ...: l3.append(l2) ...: ...:In [15]:In [15]: l3Out[15]: [1, 2, 2, 3, 3, 4, [7, 9]] 按单词反转字符串， 如’I love Linux’ 反转为 ‘Linux love I’1234567In [30]: ' '.join(s.split()[::-1])Out[30]: 'Linux love I'In [31]: s = "I love Linux"In [32]: ' '.join(s.split()[::-1])Out[32]: 'Linux love I'In [33]: s.split()[::-1]Out[33]: ['Linux', 'love', 'I'] 找出一个列表中只出现了一次的数字，并且保持原来的次序，例如[1,2,1,3,2,5]，结果为[3,5]123456Number（数字）String（字符串）List（列表）Tuple（元组）Set（集合）Dictionary（字典） 有bug的代码 1234567891011121314# 例如，当1 出现三次时，会把1也记录下来In [59]: lst_setOut[59]: [1, 2, 3, 5]In [60]: lst = [1,1,2,1,3,2,5]In [61]: ret = []In [62]: for x in lst: ...: if x in ret: ...: ret.remove(x) ...: else: ...: ret.append(x) ...:In [63]: retOut[63]: [1, 3, 5] 123456789# 去除bug后In [51]: lst = [1,1,2,1,3,2,5]In [52]: ret = []In [53]: for x in lst: ...: if lst.count(x) == 1: ...: ret.append(x) ...:In [54]: retOut[54]: [3, 5] 1234567891011121314# 当重复的数过大的时，不便重复的元素每个都遍历，如10w个1重复In [77]: lst = [1,1,1,1,1,1,2,1,3,2,5]In [78]: lst_set = list(set(lst))In [79]: lst_setOut[79]: [1, 2, 3, 5]In [80]: ret = []In [81]: retOut[81]: []In [84]: for x in lst_set: ...: if lst.count(x) == 1: ...: ret.append(x) ...:In [85]: retOut[85]: [3, 5] 取出一个列表中的最大值123In [86]: lst = [1,3,5,8,10,101,301]In [87]: max(lst)Out[87]: 301 12345678In [93]: lst = [1,3,5,8,10,101,301]In [94]: m = lst[0]In [96]: for x in lst: ...: if x &gt; m: ...: m = x ...:In [97]: mOut[97]: 301 写一个程序，把字符串转化为数字，不允许使用函数和模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354In [138]: s = '123.456'In [139]: integer, decimals=s.split('.')In [140]: list(enumerate(integer))Out[140]: [(0, '1'), (1, '2'), (2, '3')]In [141]: integer_length = len(integer)In [142]: result = 0 ...: for i, x in enumerate(integer): ...: if x == '0': ...: result += 0 * 10 ** (integer_length -i -1) ...: if x == '1': ...: result += 1 * 10 ** (integer_length -i -1) ...: if x == '2': ...: result += 2 * 10 ** (integer_length -i -1) ...: if x == '3': ...: result += 3 * 10 ** (integer_length -i -1) ...: if x == '4': ...: result += 4 * 10 ** (integer_length -i -1) ...: if x == '5': ...: result += 5 * 10 ** (integer_length -i -1) ...: if x == '6': ...: result += 6 * 10 ** (integer_length -i -1) ...: if x == '7': ...: result += 7 * 10 ** (integer_length -i -1) ...: if x == '8': ...: result += 8 * 10 ** (integer_length -i -1) ...: if x == '9': ...: result += 9 * 10 ** (integer_length -i -1) ...:In [143]: for i, x in enumerate(decimals): ...: if x == '0': ...: result += 0 * 10 ** (-1 * (i+1)) ...: if x == '1': ...: result += 1 * 10 ** (-1 * (i+1)) ...: if x == '2': ...: result += 2 * 10 ** (-1 * (i+1)) ...: if x == '3': ...: result += 3 * 10 ** (-1 * (i+1)) ...: if x == '4': ...: result += 4 * 10 ** (-1 * (i+1)) ...: if x == '5': ...: result += 5 * 10 ** (-1 * (i+1)) ...: if x == '6': ...: result += 6 * 10 ** (-1 * (i+1)) ...: if x == '7': ...: result += 7 * 10 ** (-1 * (i+1)) ...: if x == '8': ...: result += 8 * 10 ** (-1 * (i+1)) ...: if x == '9': ...: result += 9 * 10 ** (-1 * (i+1)) ...:In [144]: resultOut[144]: 123.456In [145]: type(result)Out[145]: float]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python输出格式]]></title>
    <url>%2F2018%2F08%2F20%2Fpython%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[列表的封装与解压12345678910In [10]: lst = [1,[2,3,6,7,8,10],4]In [11]: a, (b, *_, c),d = lstIn [12]: aOut[12]: 1In [13]: bOut[13]: 2In [14]: cOut[14]: 10In [15]: dOut[15]: 4 输出格式练习123456In [18]: 'i am %s' %('renjin')Out[18]: 'i am renjin'In [24]: 'i am %(name)s' %&#123;'name':'renjin'&#125;Out[24]: 'i am renjin'In [29]: 'i am %s my name is %s' %('ssjinyao','renjin')Out[29]: 'i am ssjinyao my name is renjin' format 输出格式123456789101112In [3]: 'I am &#123;&#125;'.format('ssjinyao')Out[3]: 'I am ssjinyao'In [4]: 'I am &#123;&#125; my age is &#123;&#125;'.format('ssjinyao',23)Out[4]: 'I am ssjinyao my age is 23'In [5]: 'I am &#123;1&#125; my age is &#123;0&#125;'.format(23,'ssjinyao')Out[5]: 'I am ssjinyao my age is 23'In [6]: 'I am &#123;name&#125; my age is &#123;age&#125;'.format(age='23',name='ssjinyao')Out[6]: 'I am ssjinyao my age is 23'In [8]: 'I am &#123;0&#125; my name is &#123;0&#125;'.format('ssjinyao')Out[8]: 'I am ssjinyao my name is ssjinyao'In [15]: '&#123;&#125; name &#123;&#125; and age is &#123;age&#125;'.format('renjin','ssjinyao',age='23')Out[15]: 'renjin name ssjinyao and age is 23' 1234567891011121314In [16]: class A(): ...: def __init__(self): ...: self.x=1 ...: self.y=2 ...:In [17]: a = A()In [18]: a.xOut[18]: 1In [19]: a.yOut[19]: 2In [24]: '&#123;inst.x&#125;'.format(inst=a)Out[24]: '1'In [20]: '&#123;0.x&#125; &#123;0.y&#125;'.format(a)Out[20]: '1 2' 1234567891011121314In [26]: '&#123;0!a&#125;'.format('逝水锦遥')Out[26]: "'\\u901d\\u6c34\\u9526\\u9065'"In [27]: '&#123;0:^80&#125;'.format('逝水锦遥')Out[27]: ' 逝水锦遥 'In [29]: '&#123;0:&lt;80&#125;'.format('逝水锦遥')Out[29]: '逝水锦遥 'In [30]: '&#123;0:&gt;80&#125;'.format('逝水锦遥')Out[30]: ' 逝水锦遥'In [34]: '&#123;0:&#123;fill&#125;^&#123;width&#125;&#125;'.format('逝水锦遥',width='80',fill='*')Out[34]: '**************************************逝水锦遥**************************************'In [35]: '&#123;message:&#123;fill&#125;^&#123;width&#125;&#125;'.format(message='逝水锦遥',width='80',fill='*')Out[35]: '**************************************逝水锦遥**************************************' 123456789101112131415161718192021222324252627282930313233343536373839404142In [41]: s = '逝水锦遥'In [42]: b = s.encode()In [43]: for x in s: ...: print (x) ...:逝水锦遥In [44]: for x in b: ...: print (x) ...:233128157230176180233148166233129165In [44]: for x in b: ...: print (x) ...:233128157230176180233148166233129165In [45]: b.decode()Out[45]: '逝水锦遥' python3 格式转换123456789101112131415(py3_env) [root@laoba-10-17:~/mypython/python3]# cat &lt;&lt;EOF &gt;&gt; utf-8.txt逝水锦遥EOF(py3_env) [root@laoba-10-17:~/mypython/python3]# iconv -f UTF-8 -f UTF-8 -t GBK utf-8.txt��ˮ��ң(py3_env) [root@laoba-10-17:~/mypython/python3]# iconv -f UTF-8 -f UTF-8 -t GBK utf-8.txt &gt; gbk.txt(py3_env) [root@laoba-10-17:~/mypython/python3]# cat gbk.txt��ˮ��ңIn [6]: f = open('/root/mypython/python3/gbk.txt','rb')In [7]: buf = f.read()In [8]: buf.decode('GBK')Out[8]: '逝水锦遥\n'In [9]: name = buf.decode('GBK')In [10]: print (name)逝水锦遥 基于socket 之间的编码格式转换123456# 服务端In [14]: import socketIn [15]: s = socket.socket(family=socket.AF_INET, type=socket.SOCK_STREAM)In [16]: s.bind(('0.0.0.0',3000))In [17]: s.listen()In [18]: fd, addr = s.accept() 123456# 客户端In [1]: import socketIn [2]: s = socket.socket(family=socket.AF_INET, type=socket.SOCK_STREAM)In [4]: so = s.connect(('127.0.0.1',3000))In [5]: s.send('逝水锦遥'.encode())Out[5]: 12 123# 服务端In [33]: fd.recv(1024)Out[33]: b'\xe9\x80\x9d\xe6\xb0\xb4\xe9\x94\xa6\xe9\x81\xa5' 123# 客户端In [22]: s.send('逝水锦遥'.encode())Out[22]: 12 1234# 服务端In [40]: buf = fd.recv(1024)In [41]: buf.decode()Out[41]: '逝水锦遥' 123# 客户端In [23]: s.send('乐乐在线'.encode())Out[23]: 12 1234# 服务端In [42]: buf = fd.recv(1024)In [43]: buf.decode()Out[43]: '乐乐在线' 123# 客户端In [24]: s.send('逝水锦遥，乐乐在线'.encode())Out[24]: 27 1234# 服务端In [45]: buf = fd.recv(1024)In [46]: buf.decode()Out[46]: '逝水锦遥，乐乐在线' 基于 socket 之间的json格式传输 123456789# 客户端生成json格式的数据并发送In [26]: import jsonIn [27]: data = &#123;'name':'ssjinyao',&#125;In [28]: data = &#123;'name':'ssjinyao','owner':'renjin'&#125;In [30]: json.dumps(data)Out[30]: '&#123;"name": "ssjinyao", "owner": "renjin"&#125;'In [31]: js = json.dumps(data)In [32]: s.send(js.encode())Out[32]: 39 1234# 服务端接收发送过来的json数据In [47]: buf = fd.recv(1024)In [48]: buf.decode()Out[48]: '&#123;"name": "ssjinyao", "owner": "renjin"&#125;' 123# 一般发送端会指定编码In [34]: s.send(js.encode('UTF-8'))Out[34]: 39 123# 接收端也会指定编码，这样不会出现乱码、In [50]: buf.decode('UTF-8')Out[50]: '&#123;"name": "ssjinyao", "owner": "renjin"&#125;']]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived+nginx+inotify+rsync的实现]]></title>
    <url>%2F2018%2F08%2F08%2Fkeepalived%2Bnginx%2Binotify%2Brsync%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[环境架构与实现实验环境介绍 服务器ip 操作系统 主机名 用途 10.180.66.11 CentOS7.4 node1 ansible自动推送 10.180.66.12 CentOS7.4 node2 keepalived+nginx+rsync客户端 10.180.66.13 CentOS7.4 node3 keepalived+nginx+rsync服务端 实现逻辑架构图注: 上图node{1..7}是指nginx upstream 的各节点 ansible 环境准备node1 ansible 环境的准备 1234567891011# vim /etc/hosts10.180.66.11 node1 node1.ssjinyao.com10.180.66.12 node2 node2.ssjinyao.com10.180.66.13 node3 node3.ssjinyao.com# for i in &#123;1..3&#125;; do ssh-copy-id -i ~/.ssh/id_rsa.pub root@node$i ; done # 双机互信# yum -y install epel-release# yum -y install ansible# vim /etc/ansible/hosts[keepalived]10.180.66.1210.180.66.13 keepalived 手动安装node2 与 node3 keepalived手动安装 123456789101112131415# yum -y install gcc \ openssl-devel \ libnl3-devel \ ipset-devel \ iptables-devel \ libnfnetlink-devel \ net-snmp-devel \ procps-ng \ psmisc \ lsof \ grep# ntpdate ntp.aliyun.com# timedatectl set-timezone Asia/Shanghai# cd /usr/local/src# 上传keepalived-2.0.6.tar.gz 没有keepavlied包的当然也可以在keepalived 官网下载 12345678910# cd /usr/local/src/keepalived-2.0.6# ./configure --prefix=/usr/local/keepalived # make &amp;&amp; make install# mkdir /var/log/keepalived/# vim /etc/rsyslog.conf # 最后加入local0.* /var/log/keepalived/keepalived.log# # systemctl restart rsyslog# vim /usr/local/keepalived/etc/sysconfig/keepalived # 将最后一行改为KEEPALIVED_OPTIONS=&quot;-D -S 0 -f /usr/local/keepalived/etc/keepalived/keepalived.conf&quot; node2 keepalived 的配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445# vim /usr/local/keepalived/etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node2 &#125;vrrp_script chk_nginx &#123; script &quot;/bin/bash /usr/local/keepalived/etc/keepalived/nginx_check.sh&quot; interval 5 weight -20&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 55 priority 80 nopreempt advert_int 1 notify_master &quot;/usr/local/keepalived/etc/keepalived/message.sh master&quot; notify_backup &quot;/usr/local/keepalived/etc/keepalived/message.sh backup&quot; notify_fault &quot;/usr/local/keepalived/etc/keepalived/message.sh fault&quot; unicast_src_ip 10.180.66.12 unicast_peer &#123; 10.180.66.13 &#125; track_script &#123; chk_nginx &#125; authentication &#123; auth_type PASS auth_pass testLLb &#125; virtual_ipaddress &#123; 10.180.66.100 &#125;&#125; node3 keepalived 的配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445# vim /usr/local/keepalived/etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node2 &#125;vrrp_script chk_nginx &#123; script &quot;/bin/bash /usr/local/keepalived/etc/keepalived/nginx_check.sh&quot; interval 5 weight -20&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 55 priority 80 nopreempt advert_int 1 notify_master &quot;/usr/local/keepalived/etc/keepalived/message.sh master&quot; notify_backup &quot;/usr/local/keepalived/etc/keepalived/message.sh backup&quot; notify_fault &quot;/usr/local/keepalived/etc/keepalived/message.sh fault&quot; unicast_src_ip 10.180.66.13 unicast_peer &#123; 10.180.66.12 &#125; track_script &#123; chk_nginx &#125; authentication &#123; auth_type PASS auth_pass testLLb &#125; virtual_ipaddress &#123; 10.180.66.100 &#125;&#125; 安装启用nginx 123456# yum -y install nginx # systemctl start nginx # systemctl enable nginx node2 # echo &quot;node2.ssjinyao.com&quot; &gt; /usr/share/nginx/html/index.htmlnode3 # echo &quot;node3.ssjinyao.com&quot; &gt; /usr/share/nginx/html/index.html# 至于配置nginx的负载均衡之前写的文章有提到过 node2,node3 缩写keepalived nginx服务监测脚本 1234567891011121314151617181920212223242526272829303132333435363738394041# vim /usr/local/keepalived/etc/keepalived/nginx_check.sh#!/bin/bashpackage() &#123; rpm -qf /bin/ps &amp;&gt; /dev/null || yum -y install procps-ng &amp;&gt; /dev/null rpm -qf /bin/grep &amp;&gt; /dev/null || yum -y install grep &amp;&gt; /dev/null rpm -qf /usr/bin/killall &amp; &gt; /dev/null || yum -y install psmisc &amp;&gt; /dev/null&#125;packagenginx_state () &#123; ps aux | grep nginx &amp;&gt; /dev/null &amp;&amp; ps -C nginx --no-header &amp;&gt; /dev/null&#125;nginx_state ; nginx_state_num=$? ; echo $nginx_state_numnginx_port () &#123; netstat -tnlup | egrep ":80\&gt;" &amp;&gt; /dev/null&#125;kill_keepalived () &#123; kill -9 `cat /var/run/keepalived.pid`&#125;if [ $nginx_state_num -ne 0 ] ; then echo "`date +"%Y-%m-%d-%H-%M-%S"` nginx_status_one_check problem " &gt;&gt; /var/log/keepalived/check_nginx.log nginx_port ; nginx_port_num=$? ; echo $nginx_port_num if [ $nginx_port_num -ne 0 ] ; then echo "`date +"%Y-%m-%d-%H-%M-%S"` nginx_port_one_check problem" &gt;&gt; /var/log/keepalived/check_nginx.log systemctl restart nginx sleep 2 fifinginx_state ; nginx_state_num=$? ; echo $nginx_state_numif [ $nginx_state_num -ne 0 ] ; then echo "`date +"%Y-%m-%d-%H-%M-%S"` restart nginx and nginx_status_two_check problem " &gt;&gt; /var/log/keepalived/check_nginx.log nginx_port ; nginx_port_num=$? ; echo $nginx_port_num if [ $nginx_port_num -ne 0 ] ; then echo "`date +"%Y-%m-%d-%H-%M-%S"` restart nginx and nginx_port_two_check problem " &gt;&gt; /var/log/keepalived/check_nginx.log kill_keepalived fifi 注: keepalived 中调用命令时不要用lsof;当访问量较高时，lsof 查询进程很慢，会造成keepalived频繁切换; node2,node3 上的keepalived 现在可以启动了 12345# systemctl start keepalived# systemctl stop keepalived注:需要关闭selinux 和iptables # iptables -F# setenforce 0 测试效果目前ip 在node2上 tcmpdump 监测单播心跳信息当把node2上的nginx停止时当node2上的nginx用监测脚本无法自动恢复时当node2 nginx恢复时可以多次服务宕了时，规范划的检查nginx的启动日志 ansible 编写keepalived 自动化roles在 node1 上编写 keepalived 自动化脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136# tree.├── keepalived.yml└── roles └── keepalived ├── files │ ├── keepalived │ ├── keepalived-2.0.6.tar.gz │ ├── keepalived.conf.bak │ ├── message.sh │ ├── nginx_check.sh │ └── rsyslog.conf ├── tasks │ └── main.yml ├── templates │ └── keepalived.conf └── vars └── main.yml6 directories, 10 files# vim keepalived.yml---- hosts: "&#123;&#123; keepalivedhosts &#125;&#125;" remote_user: root roles: - keepalived# vim roles/keepalived/tasks/main.yml--- - name: set off selinux shell: setenforce 0 - name: set of iptables shell: iptables -F - name: install required packges yum: name=&#123;&#123; item &#125;&#125; state=present with_items: - gcc - openssl-devel - libnl3-devel - ipset-devel - iptables-devel - libnfnetlink-devel - net-snmp-devel - procps-ng - psmisc - lsof - grep - name: ntpdate time to keepavlied hosts shell: ntpdate ntp.aliyun.com - name: site time zone to Asia/Shanghai shell: timedatectl set-timezone Asia/Shanghai - name: copy keepalived_file to remote servers copy: src=keepalived-&#123;&#123; keepalivedversion &#125;&#125;.tar.gz dest=&#123;&#123; keepalivedsrc &#125;&#125; - name: decompression keepalived Source code package shell: cd /usr/local/src/ &amp;&amp; tar -xvf keepalived-2.0.6.tar.gz - name: make install keepalived shell: cd /usr/local/src/keepalived-&#123;&#123; keepalivedversion &#125;&#125; &amp;&amp; ./configure --prefix=/usr/local/keepalived &amp;&amp; make &amp;&amp; make install - name: mkdir keepalived log floder shell: mkdir &#123;&#123; keepalivedlogpath &#125;&#125; -pv - name: copy rsyslog config to keepalived copy: src=rsyslog.conf dest=/etc - name: restart rsyslog service: name=rsyslog state=restarted - name: copy keepalived sysconfig file to remote server copy: src=keepalived dest=/usr/local/keepalived/etc/sysconfig - name: copy keepalived nginx monitor bash script to remote server copy: src=nginx_check.sh dest=&#123;&#123; keepalivedpath &#125;&#125;etc/keepalived/ - name: copy keepalived nginx messge bash script to remote server copy: src=message.sh dest=&#123;&#123; keepalivedpath &#125;&#125;etc/keepalived/ mode=755 - name: copy keepalived config file to remote server template: src=keepalived.conf dest=&#123;&#123; keepalivedpath &#125;&#125;etc/keepalived/# vim roles/keepalived/vars/main.yml---keepalivedhosts: keepalivedkeepalivedversion: 2.0.6keepalivedpath: /usr/local/keepalived/keepalivedsrc: /usr/local/src/keepalivedlogpath: /var/log/keepalived/priority: 100unicast_src_ip: keepalivedunicast_peer1: 10.180.66.13unicast_peer2: 10.180.66.12virtual_ipaddress: 10.180.66.100# vim roles/keepalived/templates/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node2 &#125;vrrp_script chk_nginx &#123; script "/bin/bash /usr/local/keepalived/etc/keepalived/nginx_check.sh" interval 5 weight -20&#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 55 priority &#123;&#123; priority &#125;&#125; nopreempt advert_int 1 notify_master "/usr/local/keepalived/etc/keepalived/message.sh master" notify_backup "/usr/local/keepalived/etc/keepalived/message.sh backup" notify_fault "/usr/local/keepalived/etc/keepalived/message.sh fault" unicast_src_ip xxx.xx.xxx.xx unicast_peer &#123; xxx.xx.xxx.xx &#125; track_script &#123; chk_nginx &#125; authentication &#123; auth_type PASS auth_pass zE2kNsRQ &#125; virtual_ipaddress &#123; xxx.xx.xxx.xxx &#125;&#125;# 注：为避免意外停止生产中的nginx服务，在生产中，最好先把有关nginx监测配置的注释了# vim roles/keepalived/files/message.sh#!/bin/bash/usr/bin/echo "`date +"%Y-%m-%d-%H-%M-%S"` node2 notify $1 " &gt;&gt; /var/log/keepalived/shell-message.log# 其余文keepalived、keepalived-2.0.6.tar.gz、keepalived.conf.bak、message.sh、nginx_check.sh、rsyslog.conf件与以上的使用的一样 接下来把node2,node3恢复快照到初始状态跑一次试试为避免生产中出现突发情况，检查变更完keepalived 主配置文件后手动启动服务 rsync+inotify nginx配置文件实时同步主服务器配置10.180.66.131、 安装rsync 1234567# cd /usr/local/src# 上传rsync源码包# tar -xvf rsync-3.0.9.tar.gz# cd /usr/local/src/rsync-3.0.9# ./configure --prefix=/usr/local/rsync# make # make install 2、 建立密码认证文件 12345# echo &apos;Tpz99YJV1p&apos; &gt;&gt; /usr/local/rsync/rsync.passwd# cd /usr/local/rsync/# chown root.root rsync.passwd# chmod 600 rsync.passwd# ll rsync.passwd # 查看文件权限是否正确 3、 安装 inotify 1234567# cd /usr/local/src/# 上传inotify 源码包# tar -xvf inotify-tools-3.14.tar.gz# cd /usr/local/src/inotify-tools-3.14# ./configure --prefix=/usr/local/inotify# make# make install 4、创建 rsync复制脚本(要注意同步的方向与操作) 12345678910111213#!/bin/bashhost=10.180.66.13src=/etc/nginx/des=webuser=usernodesrc_ssl=/tmp/des_ssl=ssl/usr/local/inotify/bin/inotifywait -mrq --timefmt '%d/%m/%y %H:%M' --format '%T %w%f%e' -e modify,delete,create,attrib $src $src_ssl | while read filesdo/usr/local/rsync/bin/rsync -vzrtopg --delete --progress --password-file=/usr/local/rsync/rsync.passwd $src $user@$host::$des/usr/local/rsync/bin/rsync -vzrtopg --delete --progress --password-file=/usr/local/rsync/rsync.passwd $src_ssl $user@$host::$des_sslecho "$&#123;files&#125; was rsynced" &amp;&gt;&gt; /var/log/rsync.logdone 12# echo &apos;bash /root/rsync.sh &amp;&gt; /dev/null &amp;&apos; &gt;&gt; /etc/rc.local# chmod +x /etc/rc.d/rc.local 备服务器同步配置10.180.66.13 1、 安装rsync(备服务器只安装rsync，也就是说同步文件的目标服务) 1234567# cd /usr/local/src# 上传rsync源码包# tar -xvf rsync-3.0.9.tar.gz# cd /usr/local/src/rsync-3.0.9# ./configure --prefix=/usr/local/rsync# make # make install 2、 建立用户与密码认证文件 12345# cd /usr/local/rsync/# echo &apos;usernode:Tpz99YJV1p&apos; &gt;&gt; rsync.passwd# chown root.root rsync.passwd# chmod 600 rsync.passwd# ll # 查看文件权限是否正确 3、 建立rsync的启动配置文件 12# cd /usr/local/rsync# vim rsync.conf 1234567891011121314151617181920212223242526272829303132333435uid = rootgid = rootuse chroot = nomax connections = 10strict modes = yespid file = /var/run/rsyncd.pidlock file = /var/run/rsync.locklog file = /var/log/rsyncd.log[web]path = /etc/nginx/comment = web fileignore errorsread only = nowrite only = nohosts allow = 10.180.66.12hosts deny = *list = falseuid = rootgid = rootauth users = usernodesecrets file = /usr/local/rsync/rsync.passwd[ssl]path = /tmp/comment = ssl fileignore errorsread only = nowrite only = nohosts allow = 10.180.66.12hosts deny = *list = falseuid = rootgid = rootauth users = usernodesecrets file = /usr/local/rsync/rsync.passwd 1# /usr/local/rsync/bin/rsync --daemon --config=/usr/local/rsync/rsync.conf 12# echo &apos;/usr/local/rsync/bin/rsync --daemon --config=/usr/local/rsync/rsync.conf&apos; &gt;&gt; /etc/rc.d/rc.local# chmod +x /etc/rc.d/rc.local 在10.180.66.12 开始往 10.180.66.13上面同步1# bash /root/rsync.sh &amp;&gt; /dev/null &amp; 注: shell 配置同步结果如下 注意:nginx 同步配置的源地址与目标地址一定要注意，如果对以上配置不是很清楚，一定要测试无误后 再上生产环境， 不要把生产中的配置替换了keepalived 在自动化初始化时，不要启用nginx监测，另外注意在生产中的虚拟ip冲突;]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop学习笔记]]></title>
    <url>%2F2018%2F07%2F29%2Fhadoop%2F</url>
    <content type="text"><![CDATA[hadoop学习笔记 Bigdata 结构化数据: 约束 半结构化数据: 非结构化数据: 没有元数据； 搜索引擎：搜索组件、索引组件共同组成 蜘蛛程序: 存储： 分析处理： 2003年: The Google File System 2004年: MapReduce: Simplified Data Processing On large Cluster 2006年: BigTable: A Distributed Strorage System for Structure Data HDFS + MapReduce = Hadoop HBase Nutch MapRduce 是批处理程序: DN: Data Node NN: Name Node SNN: Secondary Name Node 函数式编程: Lisp, ML函数式编程语言；高阶函数； map, fold map: 一个任务映射为多个map(f()) map: 接受一个函数为参数，并将其应用于列表中的所有元素，从而生成一个结果列表; fold: 接受两个能数：函数，初始值fold(g(), init) mapreduce: mapper, reducer mapper:统计、排序 k-v(键值数据) 统计一本书每个单词出现的次数: mapper:每100页一个单位， 5 mappers 用于拆分成为单词:10000000 reducer: reducer1, reducer2 mapper: this 1, is 1 ,this1 ,how1 同一个键的数据只能发往同一个reducer reducer: this 500 is MRv1(Hadoop2) --&gt; MRv2(Hadoop2) MRv1: Cluster resource manager,Data processing MRv2: YARN: Cluster resource manager MRv2: Data processing MR: batch Tez: execution engine RM: Resource Manager NM: Node Manager AM: Application Master container: mr任务 Ambari Hadoop Distribution: Cloudera: CDH Hortonworks: HDP Intel: IDH MapR: 安装使用Hadoop单机模型: 测试使用;伪分布式模型: 运行于单机;分布式模型: 集群模型;Hadoop，基于Java语言;需要配置jvm和jvm home环境; jdk: 1.6, 1.7, 1.8 hadoop-2.6.2 jdk 1.6+ 123456# yum -y install java-1.7.0-openjdk.x86_64# vim /etc/profile.d/java.shexport JAVA_HOME=/usr# chmod +x /etc/profile.d/java.sh# source /etc/profile.d/java.sh# yum -y install java-1.7.0-openjdk-devel 12# cd /usr/local/src &amp;&amp; # wget https://archive.apache.org/dist/hadoop/core/hadoop-2.6.1/hadoop-2.6.1.tar.gz#]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hyperledger Fabric 1.0部署与使用]]></title>
    <url>%2F2018%2F07%2F19%2FHyperledger%E7%9A%84%E9%83%A8%E7%BD%B2%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Hyperledger Fabric 1.0部署与使用 1.环境构建与测试本文中用到的宿主环境是CentOS，版本为CentOS.x86_64(7.4);通过Dcoker容器来运行Fabric的节点，版本为v1.0;因此，启动Fabric网络的节点需要先安装 Docker、Docker-compose和Go语言环境;然后在网上摘取相关的Docker镜像，再能过配置compose文件来启动各个节点; 1.1: CentOS yum源的配置公司内网，可以让服务器以桥接方式接入网络; a、备份原有的yum源配置 1234# 注:若系统环境是初始化安装的，最好先安装以下软件包# yum -y install wget screen vim# cd /etc/yum.repos.d/ &amp;&amp; mkdir bak# mv *repo bak b、设置阿里yum源 1# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo c、清理缓存并生成新的缓存 12# yum clean all # yum makecache d、更新yum库 1# yum update 此操作的目的是为更新所有的内置库到最新版;因为docker最新版的安装需要所对应的依赖都是最新版;为了避免安装时软件包依赖的坑，故如此操作; 1.2: Docker安装进入docker官网 a、GetDocker–&gt; CentOS –&gt; Get CE 社区版 –&gt; Get Docker CE on CentOS –&gt; Install Docker CE on CentOS. b、若服务器上存在旧的docker版本，需要先执行以下操作: 1# yum -y remove docker docker-common docker-selinux docker-engine c、随后开始安装Docker CE目前Docker官方最新版为docker-ce-17.12.1.ce-1.el7.centos.x86_64.rpm;可以在docker rpm包中下载并安装 1234# mkdir -p /tmp/rpm/docker# cd /tmp/rpm/docker # wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-17.12.1.ce-1.el7.centos.x86_64.rpm# yum -y install *docker*rpm d、检查docker是否安装成功 12# docker --versionDocker version 17.12.1-ce, build 7390fc6 e、启动docker服务 1# systemctl start docker f、设置docker为开机自启 1# systemctl enable docker 1.3: Docker-Compose安装 Docker-Compose的离线安装相对于curl安装比较麻烦；需要在官网提供的github中下载最新的docker-compose;将其clone /tmp/rpm/docker/下； a、执行以下命令后完成安装 1# curl -L https://github.com/docker/compose/releases/download/1.20.0-rc1/docker-compose-`uname -s`-`uname -m` -o /tmp/rpm/docker/docker-compose b、移植docker-compose到PATH变量环境中 12# chmod +x docker-compose # cp -a docker-compose /usr/bin/ c、移植后查看安装的版本信息 12# docker-compose --versiondocker-compose version 1.20.0-rc1, build 86428af 到此docker环境已准备完毕 1.4 Go环境准备a、参照go官网，下载最新的Go语言包;b、直接通过链接下载 Go官网连接 12345# mkdir -p /tmp/rpm/go &amp;&amp; cd /tmp/rpm/go# wget https://test-inner.transfereasy.com/go1.8.3.linux-amd64.tar.gz# 注: 目前这个包已经置于内网环境中# 注: 可以通过ssjinyao网站下载# wget https://rjyy.ssjinyao.com/go1.8.3.linux-amd64.tar.gz c、解压二进制程序到/usr/local目录下; 123456789101112131415161718192021# tar -xvf go1.8.3.linux-amd64.tar.gz -C /usr/local/ # ll /usr/local/go/总用量 136drwxr-xr-x. 2 root root 205 5月 25 2017 api-rw-r--r--. 1 root root 33243 5月 25 2017 AUTHORSdrwxr-xr-x. 2 root root 42 5月 25 2017 bindrwxr-xr-x. 4 root root 37 5月 25 2017 blog-rw-r--r--. 1 root root 1366 5月 25 2017 CONTRIBUTING.md-rw-r--r--. 1 root root 45710 5月 25 2017 CONTRIBUTORSdrwxr-xr-x. 8 root root 4096 5月 25 2017 doc-rw-r--r--. 1 root root 5686 5月 25 2017 favicon.icodrwxr-xr-x. 3 root root 18 5月 25 2017 lib-rw-r--r--. 1 root root 1479 5月 25 2017 LICENSEdrwxr-xr-x. 14 root root 190 5月 25 2017 misc-rw-r--r--. 1 root root 1303 5月 25 2017 PATENTSdrwxr-xr-x. 7 root root 87 5月 25 2017 pkg-rw-r--r--. 1 root root 1399 5月 25 2017 README.md-rw-r--r--. 1 root root 26 5月 25 2017 robots.txtdrwxr-xr-x. 46 root root 4096 5月 25 2017 srcdrwxr-xr-x. 17 root root 8192 5月 25 2017 test-rw-r--r--. 1 root root 7 5月 25 2017 VERSION d、配置go环境变量 12345678# echo &quot;export PATH=$PATH:/usr/local/go/bin&quot; &gt; /etc/profile.d/go.sh# echo &quot;export GOPATH=/opt/gopath&quot; &gt;&gt; /etc/profile.d/go.sh# chmod +x /etc/profile.d/go.sh# source /etc/profile.d/go.sh# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/srv/jdk1.8.0_66/bin:/root/bin:/usr/local/go/bin# go versiongo version go1.8.3 linux/amd64 至此go环境变量已经配置完毕 2.Fabric源码及镜像文件处理2.1下载Fabric源码 下载Fabric源是因为要用到源码中提到的例子和工具;工具编译需要用到go语言环境;因此需要把源码目录放到$GOPATH环境变量下;通过1.4中的安装配置 $GOPATH设置为/opt/gopath; 这里，我们可以使用git clone源码也可以使用go get 命令 12345# go get github.com/hyperledger/fabric或者是# mkdir -p /opt/gopath/src/github.com/hyperledger/ # cd /opt/gopath/src/github.com/hyperledger/ &amp;&amp; git clone https://github.com/hyperledger/fabric.git# cd /opt/gopath/src/github.com/hyperledger/fabric &amp;&amp; git checkout -b v1.0.0 1234567891011121314151617181920212223242526272829303132333435363738# 最后的工程结构如下# cd /opt/gopath/src/github.com/hyperledger# tree -L 1 fabric/fabric/├── bccsp├── bddtests├── CHANGELOG.md├── ci.properties├── common├── CONTRIBUTING.md├── core├── devenv├── docker-env.mk├── docs├── events├── examples├── gossip├── gotools├── images├── LICENSE├── Makefile├── mkdocs.yml├── msp├── orderer├── peer├── proposals├── protos├── README.md├── release├── release_notes├── sampleconfig├── scripts├── settings.gradle├── test├── unit-test└── vendor23 directories, 9 files 2.2下载Fabric相关镜像文件 该操作有多种方式进行，如果是测试Fabric集群方案;直接进入fabric/examples/e2e_cli目录下，运行./dowload-dockerimages.sh;即可下载该工程必要的镜像文件;一般情况下，为了保证镜像与下载到hyperledger中的源码demo版本号相对应;该处方法属于较为妥当的方案; 检索 HyperLedger,以hyperledger/fabric-peer为例，进入下载页面;官方给出的下载方式如下: 1# docker pull hyperledger/fabric-peer 但由于docker镜像下载在没有给出tag的情况下会默认使用latest;所以该方案最终可能会下载失败,因此需在fabric-peer下载页选中其tags标签;查看当前fabric-peer最新版本号，根据我们所使用的操作系统情况，选择x86_64-1.0.0版本；故最终执行的docker下载命令如下: 1234567891011121314# docker pull hyperledger/fabric-peer:x86_64-1.0.0x86_64-1.0.0: Pulling from hyperledger/fabric-peeraafe6b5e13de: Pull complete 0a2b43a72660: Pull complete 18bdd1e546d2: Pull complete 8198342c3e05: Pull complete f56970a44fd4: Pull complete e32b597e7839: Pull complete a6e362fc71c4: Pull complete f107ea6d90f4: Pull complete 72c8e84de237: Pull complete 776cc74c9f73: Pull complete Digest: sha256:b7c1c2a6b356996c3dbe2b9554055cd2b63194cd7a492a83de2dbabf7f7e3c65Status: Downloaded newer image for hyperledger/fabric-peer:x86_64-1.0.0 根据上述方案，可以将这些必要的镜像由docker服务全部下载至本地;并最终使用docker-compose来启动对应的镜像服务;为了方便docker-compose的配置，将甩的镜像tag都改为latest，执行如下格式; 1# docker tag IMAGEID(镜像id) REPOSITORY:TAG(仓库:标签) 1234567891011121314151617181920212223# cd /opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli/# bash download-dockerimages.sh 注:也可以用后面所提到shell建立# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhyperledger/fabric-peer x86_64-1.0.0 6830dcd7b9b5 8 months ago 182MBhyperledger/fabric-tools latest ae6b0f53cb70 9 months ago 1.32GBhyperledger/fabric-tools x86_64-1.0.0-beta ae6b0f53cb70 9 months ago 1.32GBhyperledger/fabric-couchdb latest 31bbbec3d853 9 months ago 1.48GBhyperledger/fabric-couchdb x86_64-1.0.0-beta 31bbbec3d853 9 months ago 1.48GBhyperledger/fabric-kafka latest c4ac1c9a4797 9 months ago 1.3GBhyperledger/fabric-kafka x86_64-1.0.0-beta c4ac1c9a4797 9 months ago 1.3GBhyperledger/fabric-zookeeper latest 2c4ebacb6f00 9 months ago 1.31GBhyperledger/fabric-zookeeper x86_64-1.0.0-beta 2c4ebacb6f00 9 months ago 1.31GBhyperledger/fabric-orderer latest 11ff350dd297 9 months ago 179MBhyperledger/fabric-orderer x86_64-1.0.0-beta 11ff350dd297 9 months ago 179MBhyperledger/fabric-peer latest e01c2b645f11 9 months ago 182MBhyperledger/fabric-peer x86_64-1.0.0-beta e01c2b645f11 9 months ago 182MBhyperledger/fabric-javaenv latest 61c188dca542 9 months ago 1.42GBhyperledger/fabric-javaenv x86_64-1.0.0-beta 61c188dca542 9 months ago 1.42GBhyperledger/fabric-ccenv latest 7034cca1918d 9 months ago 1.29GBhyperledger/fabric-ccenv x86_64-1.0.0-beta 7034cca1918d 9 months ago 1.29GBhyperledger/fabric-ca latest e549e8c53c2e 9 months ago 238MBhyperledger/fabric-ca x86_64-1.0.0-beta e549e8c53c2e 9 months ago 238MB 2.3补充镜像备份和迁移上述HperLedger/Fabric 镜像数量较多且容量需求大，一套基本的服务镜像可达10G左右;如果在多台服务器上部署，会耽误很多时间。因此，对于上述已下载的镜像;我们需要使用docker save命令来备份，并通过scp命令来把这些文件拷贝至其它服务器； 123456789101112131415# cat dk_image_bak.sh #!/bin/bash## 开始自动备份镜像im=`docker images | grep latest | wc -l` for i in `seq $im` ;do id=` docker images | grep latest | grep fabric | awk '&#123;print $3&#125;' | sed -n $i\p` fn=` docker images | grep latest | grep fabric | awk -F "/" '&#123;print $2&#125;' | awk '&#123;print $1&#125;' | sed -n $i\p ` dir=` docker images | grep latest | grep fabric | awk -F "/" '&#123;print $1&#125;'` mkdir -p /tmp/images/docker/$dir/ docker save $id &gt; /tmp/images/docker/$dir/$fn.gz done ## 至此id已经保存镜像完毕## 开始远程同步与迁移 ssh root@10.180.55.126 "mkdir -p /tmp/images/docker/$dir/"scp /tmp/images/docker/$fn/*gz root@10.180.55.126:/tmp/images/docker/$dir/ 当远端服务器接收到所有的镜像之后，可以执行如下命令来加载这些镜像文件 1# docker load &lt; /tmp/images/docker/hyperledger/fabric-ccenv.gz 以上2.3镜像的备份和迁移是可选方案; 3.运行测试e2e3.1 运行fabric-sample的问题 一般情况下，我们会参照官网来完成第一个网络测试;在该在线文档中会让我们去下载一个fabric-sample;下载地址在github上;我们需要将其下载至本地是一个fabric-sample-release的文件,将其更名为fabric-samples随后将其移到opt/gopath/src目录下; 按照官网提示执行的命令是无法运行起first-network这个项目;该demo需要先下载Platform-specific Binaries(特定的二进制文件);按照官文档中的描述，需要执行如下命令; 官方提供bash脚本如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# cd /root/ &amp;&amp; vim dk_bin.sh加入以下执行程序#!/bin/bash## Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0## current version of fabric releasedexport VERSION=$&#123;1:-1.0.4&#125;# current version of fabric-ca releasedexport CA_VERSION=$&#123;2:-$VERSION&#125;# current version of thirdparty images (couchdb, kafka and zookeeper) releasedexport THIRDPARTY_IMAGE_VERSION=0.4.6export ARCH=$(echo "$(uname -s|tr '[:upper:]' '[:lower:]'|sed 's/mingw64_nt.*/windows/')-$(uname -m | sed 's/x86_64/amd64/g')" | awk '&#123;print tolower($0)&#125;')#Set MARCH variable i.e ppc64le,s390x,x86_64,i386MARCH=`uname -m`dockerFabricPull() &#123; local FABRIC_TAG=$1 for IMAGES in peer orderer ccenv javaenv tools; do echo "==&gt; FABRIC IMAGE: $IMAGES" echo docker pull hyperledger/fabric-$IMAGES:$FABRIC_TAG docker tag hyperledger/fabric-$IMAGES:$FABRIC_TAG hyperledger/fabric-$IMAGES done&#125;dockerThirdPartyImagesPull() &#123; local THIRDPARTY_TAG=$1 for IMAGES in couchdb kafka zookeeper; do echo "==&gt; THIRDPARTY DOCKER IMAGE: $IMAGES" echo docker pull hyperledger/fabric-$IMAGES:$THIRDPARTY_TAG docker tag hyperledger/fabric-$IMAGES:$THIRDPARTY_TAG hyperledger/fabric-$IMAGES done&#125;dockerCaPull() &#123; local CA_TAG=$1 echo "==&gt; FABRIC CA IMAGE" echo docker pull hyperledger/fabric-ca:$CA_TAG docker tag hyperledger/fabric-ca:$CA_TAG hyperledger/fabric-ca&#125;: $&#123;CA_TAG:="$MARCH-$CA_VERSION"&#125;: $&#123;FABRIC_TAG:="$MARCH-$VERSION"&#125;: $&#123;THIRDPARTY_TAG:="$MARCH-$THIRDPARTY_IMAGE_VERSION"&#125;echo "===&gt; Downloading platform specific fabric binaries"curl https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric/hyperledger-fabric/$&#123;ARCH&#125;-$&#123;VERSION&#125;/hyperledger-fabric-$&#123;ARCH&#125;-$&#123;VERSION&#125;.tar.gz | tar xzecho "===&gt; Downloading platform specific fabric-ca-client binary"curl https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric-ca/hyperledger-fabric-ca/$&#123;ARCH&#125;-$&#123;VERSION&#125;/hyperledger-fabric-ca-$&#123;ARCH&#125;-$&#123;VERSION&#125;.tar.gz | tar xzif [ $? != 0 ]; then echo echo "------&gt; $VERSION fabric-ca-client binary is not available to download (Avaialble from 1.1.0-rc1) &lt;----" echofiecho "===&gt; Pulling fabric Images"dockerFabricPull $&#123;FABRIC_TAG&#125;echo "===&gt; Pulling fabric ca Image"dockerCaPull $&#123;CA_TAG&#125;echo "===&gt; Pulling thirdparty docker images"dockerThirdPartyImagesPull $&#123;THIRDPARTY_TAG&#125;echoecho "===&gt; List out hyperledger docker images"docker images | grep hyperledger*# chmod + x /root/dk_bin.sh# bash /root/dk_bin.sh 运行时效果如下; 注:若是内网环境，则可能执行时间较长;12345# bash /root/dk_bin.sh ===&gt; Downloading platform specific fabric binaries % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 18 22.6M 18 4312k 0 0 6860 0 0:57:45 0:10:43 0:47:02 5364 3.2运行e2e_cli项目进入到/opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli/目录; a、目录结构如下图; 12345678910111213141516171819202122232425# tree ../e2e_cli/../e2e_cli/├── base│ ├── docker-compose-base.yaml│ └── peer-base.yaml├── channel-artifacts├── configtx.yaml├── crypto-config.yaml├── docker-compose-cli.yaml├── docker-compose-couch.yaml├── docker-compose-e2e-template.yaml├── docker-compose-e2e.yaml├── download-dockerimages.sh├── end-to-end.rst├── examples│ └── chaincode│ └── go│ └── chaincode_example02│ └── chaincode_example02.go├── generateArtifacts.sh├── network_setup.sh└── scripts └── script.sh7 directories, 14 files network_setup.sh是一个测试脚本，该脚本启动5个docker容器;其中4个容器运行peer节点和1个容器运行orderer节点，它组成一个fabric集群;另外还有一个cli容器用于创建channle、加入channel、安装和执行chaincode等操作;测试用的chaincode定义了两个变量，在实例化的时候会给这两个变量赋予了初始值;并能过invoke操作可以使用两个变量的值发生变化; b、通过以下命令进行测试; 12# cd /opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli/# bash network_setup.sh up c、当出现以下界面时，说明已经测试通了 12345678910112018-03-13 09:38:21.185 UTC [main] main -&gt; INFO 008 Exiting.....===================== Query on PEER3 on channel &apos;mychannel&apos; is successful ===================== ===================== All GOOD, End-2-End execution completed ===================== _____ _ _ ____ _____ ____ _____ | ____| | \ | | | _ \ | ____| |___ \ | ____|| _| | \| | | | | | _____ | _| __) | | _| | |___ | |\ | | |_| | |_____| | |___ / __/ | |___ |_____| |_| \_| |____/ |_____| |_____| |_____| d、如果上一步有报错，若没有部署其它应用，可以考虑将内核升级; 12345678910111213# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm# yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; list available# yum --enablerepo=elrepo-kernel install kernel-ml# vim /etc/default/grubGRUB_TIMEOUT=5GRUB_DISTRIBUTOR=&quot;$(sed &apos;s, release .*$,,g&apos; /etc/system-release)&quot;GRUB_DEFAULT=0GRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=&quot;console&quot;GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet&quot;GRUB_DISABLE_RECOVERY=&quot;true&quot;# grub2-mkconfig -o /boot/grub2/grub.cfg 4.创建Fabric多节点集群4.1配置说明 首先可以根据官方Fabric自带的e2e_cli例子中的集群方案来生成集群;与案例不同的是我们需要把容器分配到不同的服务器上；各容器之间通过网络来进行通信，网络构建完成后进行相关的channel和chanincode操作;目前用有五台服务器， 所有的服务器均是按照上述e2e_cli环境与测试步骤配置;计划其中的四台服务器运行peer节点，另外一台服务器运行orderer节点;为其它四个节点提供order服务; 名称 ip 节点标识 节点Hostname Organization Hyperledger 10.180.55.123 orderer orderer.example.com Orderer Fabric1 10.180.55.124 sp0 peer0.org1.example.com Org1 Fabric2 10.180.55.125 sp1 peer1.org1.example.com Org1 Fabric3 10.180.55.126 sp2 peer0.org2.example.com Org2 Fabric4 10.180.55.128 sp3 peer0.org3.example.com Org2 环境如下 4.2 生成公私钥、证书、创巨区块公/私钥和证书是用于Server与Server之间的安全通信;另外要创建channel并让其它节点加入channle就需要创世区块;这些必要文件都可以通过一条命令生,并且官方已经给出脚本; 脚本在以下目录中; 12# cd /opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli/# ls generateArtifacts.sh 使generateArtifacts.sh生成证书和config.tx，具体执行命令如下; 1# bash generateArtifacts.sh mychannel 这里创建了3台服务器，在任意一台服务器的该目录下执行此项命令即可；将会生成两个目录，分别为channel-artifacs、crypto-config 1234567channel-artifacts/├── channel.tx├── genesis.block├── Org1MSPanchors.tx└── Org2MSPanchors.tx0 directories, 4 files 在上述目录里的文件用于orderer创建channle，它们根据configex.yaml的配置生成; 12345crypto-config├── ordererOrganizations└── peerOrganizations2 directories, 0 files 在上述目录里有orderer和peer的证书、私钥和用于通信的加密的tls证书文件;它通过configex.yaml配置文件生成; 4.3 配置多服务器根据4.2的方案，以及之前所述的gopath目录等配置方案;我们假定所有的服务器都按照该文档的配置来操作;所有服务器都有Fabric源码,且目录为 如4.2所述,该命令只需要在某一台服务器上运行一次即可，其它服务器无需再次运行; 在运行该命令的服务器/opt/gopath/src/github.com/hyperledger/fabric/example/e2e_cli;该目录下会生成channel-artifacts和crypto-config目录;需要把它们拷贝至其它服务器相同的e2e_cli目录下，如果在其它服务器中已经在该目录,则需要先把它删除; 当所有服务器都有同一个channel-artifacts和crypto-config目录后;开始配置compose文件; 1234567开始向其它两个服务器同步以上两个目录;# cd /opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli/# tar -cvf ctfile.tar.gz channel-artifacts crypto-config# scp ctfile.tar.gz root@10.180.55.124:/opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli# scp ctfile.tar.gz root@10.180.55.125:/opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli# ssh root@10.180.55.124 &quot;cd /opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli &amp;&amp; tar -xvf ctfile.tar.gz&quot;# ssh root@10.180.55.125 &quot;cd /opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli &amp;&amp; tar -xvf ctfile.tar.gz&quot; 4.4 设置peer0.arg1.example.com节点的docker-compose文件 e2e_cli中提供了多个yaml文件，我们可以基于docker-compose-cli.yaml文件创建; 修改docker-compose-peer.yaml，去掉orderer的配置；只保留一个peer和cli，因为需要多级部署，节点与节点之间又是通过主机名通讯;所以需要修改容器中的host文件,也就是xtra_hosts设置;修改后的peer配置如下； 同样的,cli也需要能够和各个节点通讯，所以cli下面也需要添加extra_hosts设置;去掉无效的依赖，并且去掉command这一行，因为每个peer都会有个对应的客户端;也是就是cli； 所以只需要去手动执行一次命令，而不是自动执行; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# cd base/# cp docker-compose-base.yaml&#123;,.bak&#125;# vim base/docker-compose-base.yaml# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'services: peer0.org1.example.com: container_name: peer0.org1.example.com extends: file: base/docker-compose-base.yaml service: peer0.org1.example.com extra_hosts: - "orderer.example.com:10.180.55.123" cli: container_name: cli image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ../chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/examples/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer0.org1.example.com extra_hosts: - "orderer.example.com:10.180.55.123" - "peer0.org1.example.com:10.180.55.124" - "peer1.org1.example.com:10.180.55.125" - "peer0.org2.example.com:10.180.55.126" - "peer1.org2.example.com:10.180.55.128" 在3.2示例单机模式下，4个peer支映射主机不同的端口;但是在多机部署的时候不需要映射不同端口的;所以需要修改base/docker-compose-base.yaml文件，将所有peer的端口映射都改为相同的; 1234567# cd base/# cp docker-compose-base.yaml&#123;,.bak&#125;# vim base/docker-compose-base.yaml ports: - 7051:7051 - 7052:7052 - 7053:7053 4.5、 设置peer1.org1.example.com节点的docker-compose文件与peer0.org1.example.com节点compose文件配置一样;不过压岁要将启动的容器改为peer1.org1.example.com;并且添加peer0.org1.example.com的IP映射;对应的cli中改成对peer1.org1.example.com的依赖;修改如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# cd /opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli/# cp docker-compose-cli.yaml docker-compose-peer.yaml# vim docker-compose-peer.yaml # Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'services: peer1.org1.example.com: container_name: peer1.org1.example.com extends: file: base/docker-compose-base.yaml service: peer1.org1.example.com extra_hosts: - "orderer.example.com:10.180.55.123" - "peer0.org1.example.com:10.180.55.124" cli: container_name: cli image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ../chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/examples/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer1.org1.example.com extra_hosts: - "orderer.example.com:10.180.55.123" - "peer0.org1.example.com:10.180.55.124" - "peer1.org1.example.com:10.180.55.125" - "peer0.org2.example.com:10.180.55.126" - "peer1.org2.example.com:10.180.55.128" 1234567# cd base/# cp docker-compose-base.yaml&#123;,.bak&#125;# vim base/docker-compose-base.yaml ports: - 7051:7051 - 7052:7052 - 7053:7053 org2的两个结点配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# cat docker-compose-peer.yaml # Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'services: peer0.org2.example.com: container_name: peer0.org2.example.com extends: file: base/docker-compose-base.yaml service: peer0.org2.example.com extra_hosts: - "orderer.example.com:10.180.55.123" - "peer0.org1.example.com:10.180.55.124" cli: container_name: cli image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ../chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/examples/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer0.org2.example.com extra_hosts: - "orderer.example.com:10.180.55.123" - "peer0.org1.example.com:10.180.55.124" - "peer1.org1.example.com:10.180.55.125" - "peer0.org2.example.com:10.180.55.126" - "peer1.org2.example.com:10.180.55.128" 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# cat docker-compose-peer.yaml # Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'services: peer1.org2.example.com: container_name: peer1.org2.example.com extends: file: base/docker-compose-base.yaml service: peer1.org2.example.com extra_hosts: - "orderer.example.com:10.180.55.123" - "peer0.org1.example.com:10.180.55.124" cli: container_name: cli image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ../chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/examples/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer1.org2.example.com extra_hosts: - "orderer.example.com:10.180.55.123" - "peer0.org1.example.com:10.180.55.124" - "peer1.org1.example.com:10.180.55.125" - "peer0.org2.example.com:10.180.55.126" - "peer1.org2.example.com:10.180.55.128" 4.6 设置order节点的docker-compose文件与创建peer的配置文件类似，需要复制一个yaml文件出来修改; 12# cd /opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli# cp docker-compose-cli.yaml docker-compose-orderer.yaml orderer服务器上我们只需要保留order设置;其他peer和cli设置都可以删除。order可以不设置extra_hosts; 12345orderer.example.com: extends: file: base/docker-compose-base.yaml service: orderer.example.com container_name: orderer.example.com 12#启动报错，单纯的报命令调用用法错误docker rm -f $(docker ps -aq) 若部署环境在内网，则需要修改5台服务器的/etc/hosts文件;确保服务器之间可以基于主机名互相通信； 123456# vim /etc/hosts 10.180.55.123 orderer.example.com10.180.55.124 peer0.org1.example.com10.180.55.125 peer1.org1.example.com10.180.55.126 peer0.org2.example.com10.180.55.128 peer1.org2.example.com 5.启动Fabric多节点集群5.1启动orderere节点服务操作完成后，此时节点的compose配置文件及证书难目录都已经准备完成;可以开始尝试启动多机Fabric集群;首先要启orderer节点，切换至orderer.example.com服务器;即前文指定的10.180.55.123的服务器，执行如下命令进入启docker进程; 1# docker-compose -f docker-compose-orderer.yaml up -d 运行完毕后我们可以使用docker ps看到运行了一个名字为orderer.example.com的节点; 123# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf188590553b7 hyperledger/fabric-orderer &quot;orderer&quot; 25 seconds ago Up 22 seconds 0.0.0.0:7050-&gt;7050/tcp orderer.example.com 5.2启动peer节点服务切换到peer0.org1.example.com服务器，即前文指定的10.180.55.124服务器;启动本服务器的peer节点和cli; 1# docker-compose -f docker-compose-peer.yaml up -d 1234# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2f49281a48c9 hyperledger/fabric-tools &quot;/bin/bash&quot; 38 minutes ago Up 38 minutes cli8ef009a57457 hyperledger/fabric-peer &quot;peer node start&quot; 38 minutes ago Up 38 minutes 0.0.0.0:7051-7053-&gt;7051-7053/tcp peer0.org1.example.com 注: 其它三个peer结点与以上结点的启动/验证方式相同遇到的坑:在CentOS中要把iptables关闭;selinux为开机关闭确保5个结点间域名和端口都能telnet 通; 例telnet peer1.org2.example.com 7051; 现在整个Fabric4+1服务器网络已经成型; 5.3创建channle和运行chaincode切换到peer0.org1.example.com服务器上;使用该服务器的cli来运行创建Channel和运行ChainCode的操作; 1# docker exec -it cli bash 进入容器后 1root@078471f17d9a:/opt/gopath/src/github.com/hyperledger/fabric/peer# ./scripts/script.sh mychannel 该脚本会一步步的完成创建通道,将其他节点加入通道，更新锚节点;创建ChainCode，初始化帐户，查询，转帐，再次查询等链上操作的自动化; 12345678910112018-03-19 03:00:03.146 UTC [main] main -&gt; INFO 007 Exiting.....===================== Query on PEER3 on channel &apos;mychannel&apos; is successful ===================== ===================== All GOOD, End-2-End execution completed ===================== _____ _ _ ____ _____ ____ _____ | ____| | \ | | | _ \ | ____| |___ \ | ____|| _| | \| | | | | | _____ | _| __) | | _| | |___ | |\ | | |_| | |_____| | |___ / __/ | |___ |_____| |_| \_| |____/ |_____| |_____| |_____| 出现以上结果出明4+1的Fabric多级部署已经成功;在peer0.org1.example.com的cli容器内;之前的2个容器，已经因ChainCode创建了3个容器; E2E 运行后查询与转帐测试123# 查询# docker exec -it cli bashroot@078471f17d9a:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode query -C mychannel -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; 12# 转帐20到b# peer chaincode invoke -o orderer.example.com:7050 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;20&quot;]&#125;&apos;]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python日常练习]]></title>
    <url>%2F2018%2F07%2F19%2Fpython%20%E6%97%A5%E5%B8%B8%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[python 日常练习 解压序赋值给多个变量现有一个包含N个元素的元组或者是序列，将它里面的值解压后同时赋值给N个变量 1234567891011121314151617181920212223242526272829303132In [22]: p = (1,2)In [23]: a,b = pIn [24]: aOut[24]: 1In [25]: bOut[25]: 2In [26]: date = [&apos;test&apos;,&apos;frum&apos;,&apos;bind&apos;,&apos;lance&apos;,(201,202,203)]In [27]: te,fr,bi,la,data = dateIn [28]: teOut[28]: &apos;test&apos;In [29]: frOut[29]: &apos;frum&apos;In [30]: biOut[30]: &apos;bind&apos;In [31]: dateOut[31]: [&apos;test&apos;, &apos;frum&apos;, &apos;bind&apos;, &apos;lance&apos;, (201, 202, 203)]In [32]: dataOut[32]: (201, 202, 203)In [41]: a = &apos;Hello&apos;In [42]: b,c,d,e,f = aIn [43]: bOut[43]: &apos;H&apos;In [44]: cOut[44]: &apos;e&apos;In [45]: dOut[45]: &apos;l&apos;In [46]: fOut[46]: &apos;o&apos; 初级练习题给一个半径，求圆的面积和周长。圆周率3.14123456789from math import pir=int(input(&apos;r=&apos;))print(&apos;area=&apos;+str(pi*r*r))print(&apos;circumference=&apos;+str(2*pi*r))(py3_env) kernel ➤ python test.py r=10area=314.1592653589793circumference=62.83185307179586 输入两个数，比较大小后，从小到大升序打印123456789101112a = input(&apos;first: &apos;)b = input(&apos;second: &apos;)if a &gt; b: print(b,a)else: print(a,b)(py3_env) kernel ➤ python test.py first: 10second: 1110 11 输入n个数，求每次输入后的算数平均数123456789101112n = 0sum = 0while True: i = input(&quot;&gt;&gt;&gt;&quot;) if i == &apos;quit&apos;: break n += 1 sum += int(i) avg = sum/n print(avg) 打印九九乘法表123456789101112131415for i in range(1,10): for j in range(1,i+1): print(str(j)+&apos;x&apos;+ str(i) +&quot;=&quot; +str(i*j),end=&apos; &apos;)for i in range(1,10): for j in range(1,i+1): product = i*j if j &gt; 1 and product &lt;10: product = str(product) + &apos; &apos; else: product = str(product) print(str(j)+&apos;x&apos;+str(i)+&quot;=&quot;+str(product),end=&apos; &apos;) print() 打印菱形1234567for i in range(-3,4): if i&lt;0: prespace = -i else: prespace = i print(&apos; &apos;*prespace + &apos;*&apos;*(7-prespace*2)) 斐波那契数列，100以内123456789101112131415161718192021222324252627斐波那契数列:1,1,2,3,5,8,13,21,34,55,89,144,...a = 0b = 1while True: c = a+b if c &gt; 100: break a=b b=c print(c)a = 1b = 1index = 2print(&apos;&#123;0&#125;,&#123;1&#125;&apos;.format(0,0))print(&apos;&#123;0&#125;,&#123;1&#125;&apos;.format(1,1))print(&apos;&#123;0&#125;,&#123;1&#125;&apos;.format(2,1))while True: c = a + b a = b b = c index +=1 print(&apos;&#123;0&#125;,&#123;1&#125;&apos;.format(index,c)) if index == 101: break pip 简单使用123456789101112131415# 配置国内的源~ ➤ cat ~/.pip/pip.conf[global]index-url=http://mirrors.aliyun.com/pypi/simpletrusted-host=mirrors.aliyun.com# pip 常用命令# pip install xxx yyy# pip list # pip search keyword 或者 pypi# pip help install # pip install jupyter # pip -V # pip freeze &gt; requirement# pip install -r requirement# virtualenv ~/Desktop/MyPython/py3_env --python=python3 猜数字的游戏12345678910111213141516NUM = 35count = 0while count &lt; 3: user_input = int(input(&apos;请你输入一个数字: &apos;)) if user_input == NUM : print(&apos;你猜对了&apos;) break elif user_input &lt; NUM: print(&apos;你输入的数比这个数要小&apos;) else: print(&apos;你输入的数比这个要大&apos;) count +=1else: print(&apos;你已经超过了三次机会&apos;) 不用变量时，把变量放空 123456789101112for _ in range(0,3): user_input = int(input(&apos;请你输入一个数字: &apos;)) if user_input == NUM : print(&apos;你猜对了&apos;) break elif user_input &lt; NUM: print(&apos;你输入的数比这个数要小&apos;) else: print(&apos;你输入的数比这个要大&apos;) count +=1else: print(&apos;你已经超过了三次机会&apos;) 打印扬辉三角python 中求阶乘的方法 12import math math.factorial(5) # 5 的阶乘 1234567891011121314151617import mathlines = 10for n in range(0,lines): if n == 0: for _ in range(0, lines // 2): print(&apos; &apos;,end=&apos; &apos;) print(1) else: for _ in range(0,lines //2): print(&apos; &apos;,end=&apos; &apos;) for m in range(0, n+1): num = math.factorial(n) //(math.factorial(m) * math.factorial(n-m)) print(num, end=&apos; &apos;) print() 1234567host = &#123;&quot;host%d&quot;%i: &quot;192.168.1.%d&quot;%i for i in range(2,11)&#125;for i in host.values(): print (i) lst = list(range(1,101))lst[0::2] [::-1]lst[1::2] [::-1] python 与用户交互输入位数生成若干随机数，求若干随机数的最大值，最小值12345678910111213141516#!/usr/bin/env python3from fabric.colors import red,blue,green,cyanimport randoma=int(input(red(&apos;您要获取多少个随机数: &apos;)))b=int(input(red(&apos;您要获取的随机数位数: &apos;))) + 1num_two = []for i in range(int(a)): num = random.randrange(0,b) print(cyan(&apos;第&apos;) + blue(i + 1) + cyan(&apos;个随机数为&apos;),blue(num)) num_two.append(num)print(cyan(&apos;您获取了&apos;) + blue(i + 1) + cyan(&apos;个随机数&apos;))print(cyan(&apos;您的第&apos;) + blue(num_two.index(max(num_two)) +1 ) + cyan(&apos;个随机数为最大值:&apos;), green(max(num_two)))print(cyan(&apos;您的第&apos;) + blue(num_two.index(min(num_two)) +1 ) + cyan(&apos;个随机数为最小值:&apos;), green(min(num_two))) 方法二 123456789101112131415161718#!/usr/bin/env python3# -*- coding: utf-8 -*-from fabric.colors import red,blue,green,cyanimport randoma=int(input(red(&apos;您要获取多少个随机数: &apos;)))b=int(input(red(&apos;您要獲取的隨機數範圍: &apos;))) + 1range_init = list(range(1,int(a)+1))print (range_init)num_two = []for i in range_init: num = random.randrange(0,b) num = random.randrange(0,b) print(cyan(&apos;第&apos;) + blue(i) + cyan(&apos;个随机数为&apos;),blue(num)) num_two.append(num)print(cyan(&apos;您获取了&apos;) + blue(i) + cyan(&apos;个随机数&apos;))print(cyan(&apos;您的第&apos;) + blue(num_two.index(max(num_two))+1) + cyan(&apos;个随机数为最大值:&apos;), green(max(num_two)))print(cyan(&apos;您的第&apos;) + blue(num_two.index(min(num_two))+1) + cyan(&apos;个随机数为最小值:&apos;), green(min(num_two)))]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk 的练习]]></title>
    <url>%2F2018%2F06%2F18%2Fawk%E7%9A%84%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[awk每日练 先熟练一些操作1、 以空格做为分格符，打印passwd 文件的第一列1# awk &apos;&#123;print $1&#125;&apos; /etc/passwd 2、 以冒号做分格符，打印passwd 文件的第一列,即获取当前系统中存在的所有用户1# awk -F: &apos;&#123;print $1&#125;&apos; /etc/passwd 3、 以管道方式，打印passwd 文件的第三列，即共获取当前系统中所有用户的id号1# cat /etc/passwd | awk -F : &apos;&#123;print $3&#125;&apos; 4、 以输入重定向方式，打印 passwd 文件的第1列，即获取当前系统中存在的所有用户1# awk -F: &apos;&#123;print $1&#125;&apos; &lt; /etc/passwd 5、用awk 自带BEGIN打印 hello awk 字符串1# awk &apos;BEGIN&#123;print &quot;hello awk&quot;&#125;&apos; 执行只办输出hello awk 6、 用awk 获取df 命令的filesystem 与userd %12345678910111213141516171819202122232425# df | awk &apos;&#123;print $1,$5&#125;&apos; # df | awk &apos;&#123;print $1 $5&#125;&apos; # 注意这样输出信息就连接到一块了 FilesystemUse% /dev/vda113% devtmpfs0% tmpfs0% tmpfs1% tmpfs0% tmpfs0%# df | awk &apos;&#123;print $1&quot;===&quot;$5&#125;&apos; # 在两个位置变量的中间加入三个=== 号 Filesystem===Use% /dev/vda1===13% devtmpfs===0% tmpfs===0% tmpfs===1% tmpfs===0% tmpfs===0% # df | awk &apos;&#123;print $1&quot;\t&quot;$5&#125;&apos; # 在两个位置变量的中间加入一个tab 键 Filesystem Use% /dev/vda1 13% devtmpfs 0% tmpfs 0% tmpfs 1% tmpfs 0% tmpfs 0% 7、 结合tail 命令来进行字符串切割1# tail -4 /etc/fstab | awk &apos;&#123;print $3,$4&#125;&apos; 8、 手动指定分隔符为: ，打印第一列:第三列，FS 即指定分隔符1# awk -v FS=&quot;:&quot; &apos;&#123;print $1,FS,$3&#125;&apos; /etc/passwd 9、将列出分符，改为其它的字符1# awk -v FS=&quot;:&quot; -v OFS=&quot;uid is &quot; &apos;&#123;print $1,FS,$3&#125;&apos; /etc/passwd 10 、以空格做为换行符，取其第一个字段1# awk -v RS=&quot; &quot; &apos;&#123;print $1&#125;&apos; text.txt 11、 将记录输出分隔符默认值”\n”，换成”===”1# awk -v FS=&quot;:&quot; -v ORS&quot;===&quot; &apos;&#123;print $1&#125;&apos; /etc/passwd 12、 截取/etc/passwd 的登录shell1# awk -v FS=&quot;:&quot; &apos;&#123;print $NF-1&#125;&apos; /etc/passwd 13、 截取 /etc/passwd 的家目录1# awk -v FS=&quot;:&quot; &apos;&#123;print $(NF-1)&#125;&apos; /etc/passwd 14、截取指定字段并打印awk 内置变量1# awk -v RS=&quot;:&quot; &apos;&#123;print RS,NR,$0&#125;&apos; /etc/passwd 15、 以冒号分隔记录当前字段个数并进行计算1# awk -v FS=&quot;:&quot; &apos;&#123;print NF*5&#125;&apos; /etc/passwd 16、统计当前输入文件的个数1# awk -F: &apos;&#123;print FNR&#125;&apos; /etc/passwd /etc/shadow 17、 打印两文件输出的行数1# awk -F: &apos;&#123;print FNR,$1&#125;&apos; /etc/passwd /etc/shadow 18、输出两文件的文件名行号及对应用的用户名1# awk -F: &apos;&#123;print FILENAME,FNR,$1&#125;&apos; /etc/passwd /etc/shadow 19、 统计命令行参数的个数12# awk -F: &apos;BEGIN&#123;print ARGC&#125;&apos; /etc/passwd /etc/group 3 20、 打印命令行参数的内容12# awk -F: &apos;BEGIN&#123;print ARGV[2]&#125;&apos; /etc/passwd /etc/group /etc/group awk变量 自定义变量区分大小写 21、 指定变量调用打印1# awk -F: -v name=&quot;username&quot; &apos;&#123;print name&quot;:&quot;$1&#125;&apos; /etc/passwd 22 、 指定多个变量调用打印，并加入制表符12# awk -F: -v name=&quot;username&quot; -v uid=&quot;uid &quot; &apos;&#123;print name&quot;:&quot;$1&quot;\t&quot;uid&quot;:&quot;$3&#125;&apos; /etc/passwd# awk -F: &apos;&#123;n=&quot;username&quot;;uid=&quot;userid&quot;; print n &quot;:&quot;$1&quot;\t&quot;uid&quot;:&quot;$3&#125;&apos; /etc/passwd 了解一下以下的练习awk -F: ‘{n=”haha”; print n,m;m=”xixi”}’ /etc/passwd 变量后定义也行（表面上可用，但实际上有问题：第一次循环）awk -F: ‘BEGIN{n=”haha”;hehe=100;m=200;print n,m}’ /etc/passwd 23、 printf 指定输出格式1234567# awk -F: &apos;&#123;printf &quot;%s == %d\n&quot;,$1,$3&#125;&apos; /etc/passwd %格式与$字符必须一一对应# awk -F: &apos;&#123;printf &quot;%s20s == %d\n&quot;,$1,$3&#125;&apos; /etc/passwd 右对齐# awk -F: &apos;&#123;printf &quot;%s-20s == %d\n&quot;,$1,$3&#125;&apos; /etc/passwd 左对齐# awk -F: &apos;&#123;printf &quot;%s-20s == %10.3f\n&quot;,$1,$3&#125;&apos; /etc/passwd 小数位的宽度# awk -F: &apos;&#123;printf &quot;%s-20s == %+df\n&quot;,$1,$3&#125;&apos; /etc/passwd# awk -F : &apos;&#123;printf &quot;%s\n&quot;,$1&#125;&apos; /etc/passwd # awk -F : &apos;&#123;printf &quot;Username: %s\n&quot;,$1&#125;&apos; /etc/passwd 24、awk 数术运算操作1234567891011# awk &apos;BEGIN&#123;print 2^10&#125;&apos;# awk &apos;BEGIN&#123;n=1;m=2;print m+=n&#125;&apos; # awk &apos;BEGIN&#123;n=1;m=2;print m++;print m&#125;&apos; # awk &apos;BEGIN&#123;n=1;m=2;print ++m;print m&#125;&apos; # awk -F: &apos;$3 &gt; 1000&#123;print $1,$3&#125;&apos; /etc/passwd # awk -F: &apos;$3==0&#123;print $1,$3&#125;&apos; /etc/passwd # awk -F: &apos;$0~&quot;root&quot;&#123;print $1,$3&#125;&apos; /etc/passwd ~包涵# awk -F: &apos;$0~/root/&#123;print $0&#125;&apos; /etc/passwd # awk -F: &apos;$0~/^root/&#123;print $0&#125;&apos; /etc/passwd # awk -F: &apos;$0 !~/^root/&#123;print $0&#125;&apos; /etc/passwd # awk -F : &apos;$0 ~ /root/&apos; /etc/passwd 25、操作符 &amp;&amp; 两都执行 ||123# awk -F: &apos;$3==0 || $3 &gt;=1000 &#123;print $1&#125;&apos; /etc/passwd # awk -F: !(&apos;$3==0 || $3 &gt;=1000) &#123;print $1&#125;&apos; /etc/passwd or # awk -F : &apos;$3&gt;1 &amp;&amp; $3 &lt;1000 &#123;print $1&#125;&apos; /etc/passwd 26、条件表达式三目1# awk -F: &apos;$3&lt;1000?var=&quot;sysuser&quot;: var=&quot;commonuser&quot;&#123;print var&quot;:&quot;$1,$3&#125;&apos; /etc/passwd 27、常用语法练习12345678910111213141516# awk -F: &apos;&#123;print $1&#125;&apos; /etc/passwd # awk -F: &apos;/^root/&#123;print $0&#125;&apos; /etc/passwd # awk &apos;/^U/&#123;print $1&#125;&apos; /etc/fstab # awk &apos;!/^U/&#123;print $1&#125;&apos; /etc/fstab # awk &apos;&quot; &quot;&#123;print $0&#125;&apos; /etc/fstab # awk &apos;i=1;j=1&#123;print i,j&#125;&apos; /etc/fstab 把文件打印两次# awk ‘i=1;j=0&#123;print i,j&#125;’ /etc/fstab # awk &apos;i=1;j=1&#123;print i,j&#125;&apos; /etc/fstab # awk &apos;!2&apos; /etc/fstab # awk &apos;&quot;abc&quot;&apos; /etc/fstab # awk -F: &apos;$NF==&quot;/bin/bash&quot;&apos; /etc/passwd # awk -F: &apos;$NF~&quot;/bin/bash&quot; /etc/passwd # awk -F: &apos;$NF!~&quot;/bin/bash&quot; /etc/passwd # awk -F: &apos;/^root/,/^ftp/&apos; /etc/passwd # awk -F: &apos;/^root\&gt;/,/^ftp/&apos; /etc/passwd 注：\b 不行# awk -F: &apos;NR&gt;=10&amp;&amp;NR&lt;=30&#123;print NR&#125;&apos; /etc/passwd 28、比较绕的练习123456789# awk -F: &apos;NR&gt;=10&amp;&amp;NR&lt;=30&#123;print NR,$0&#125;&apos; /etc/passswd # awk -F: &apos;BEGIN&#123;print &quot;linenumber usernmae&quot;&#125;NR&gt;=10&amp;&amp;NR&lt;=30&#123;print NR,$1&#125;&apos; /etc/passwd # awk -F: &apos;BEGIN&#123;print &quot;linenumber username&quot;&#125;NR&gt;=10&amp;&amp;NR&lt;=30&#123;print NR,$1&#125; END print &quot;end&quot;&#125;&apos; /etc/passwd # awk -F: &apos;&#123;print &quot;linenumber username&quot;;print NR,$1&#125;END&#123;print &quot;end&quot;&#125;&apos; /etc/passwd# awk -F: &apos;&#123;print &quot;linenumber username\n-------------&quot;;print $1&#125;END&#123;print &quot;end&quot;&#125;&apos; /etc/passwd # seq 10 | awk &apos;&#123;i=!i;print i&#125;&apos;# seq 10 | awk &apos;i=!i&apos;# seq 10 | awk &apos;!(i=!i)&apos;# seq 10 | awk -v -i=1 &apos;i=!i&apos; 29、常见循环与用法12345678910111213141516# awk &apos;BEGIN&#123;for(i=1;i&lt;=100;i++)sum+=i;print sum&#125;&apos;# echo &#123;1..100&#125;|sed &apos;s/ /+/g&apos;|bc# echo &#123;1..100&#125;| tr &quot; &quot; &quot;+&quot; |bc #!/bin/bashnum=0for i in `seq 100`; do num=$[$num+$i] echo $idoneecho $num#!/usr/bin/env python2.7num=0for i in range(1,101): print i num = num + iprint num AWK 基础 awk：Aho, Weinberger, Kernighan，报告生成器，格式化文本输出 有多种版本：New awk（nawk）,GNU awk（gawk） gawk：模式扫描和处理语言 基本用法123# awk [options] &apos;program&apos; var=value file…# awk [options] -f programfile var=value file…# awk [options] &apos;BEGIN&#123; action;… &#125; pattern&#123; action;… &#125; END&#123; action;… &#125;&apos; file ... awk程序通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块，共3部分组成 program通常是被单引号或双引号中 选项： -F:指明输入时用到的字段分隔符 -v var=value:自定义变量 awk语言 基本格式：awk [options] ‘program’ file… program:pattern{action statements;..} pattern和action：pattern部分决定动作语句何时触发及触发事件BEGIN,END action statements 对数据进行处理，放在{}内指明print, printf 分割符、域和记录 awk执行时，由分隔符分隔的字段（域）标记$1,$2..$n称为域标识。$0为所有域，注意：和shell中变量$符含义不同 文件的每一行称为记录 省略action行，则默认执行print $0的操作 awk工作原理第一步：执行BEGIN{action;… } 语句块中的语句第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ action;… } 语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。 第三步：当读至输入流末尾时，执行END{action;…}语句块 BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中 END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块 pattern语句块中的通用命令是最重要的部分，也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块 awk 格式 要点： (1)逗号分隔符 (2)输出的各item可以字符串，也可以是数值；当前记录的字段、变量或awk的表达式 (3)如省略item，相当于print $0 示例: 1234567# awk &apos;&#123;print &quot;hello,awk&quot;&#125;&apos;# awk -F: &apos;&#123;print&#125;&apos; /etc/passwd# awk -F: &apos;&#123;print &quot;wang&quot;&#125;&apos; /etc/passwd# awk -F: &apos;&#123;print $1&#125;&apos; /etc/passwd# awk -F: &apos;&#123;print $0&#125;&apos; /etc/passwd# awk -F: &apos;&#123;print $1&quot;\t&quot;$3&#125;&apos; /etc/passwd# tail -3 /etc/fstab |awk &apos;&#123;print $2,$4&#125;&apos; awk 变量 变量：内置和自定义变量 模式 例子 匹配 BEGIN BEGIN 输入被读取之前 END END 所有输入被读取之后 expression $3&gt;100 第三个字段大于100 string-matching /Asia/ 含有Asia的行 compound \$3&lt;100 &amp;&amp; $4 ==”Asia” 第三个字段小于100且第四个字段含有Asia的行 range NR == 10,NR==20 输入的第10行到20行 变量 意义 默认值 FS 控制输入行的字段分隔符 “ “ OFS 输出字段分隔符 “ “ RS 控制着输入行的记录分隔符 “\n” NF 当前记录的字段个数 - NR 到目前为止读的记录数量 - FNR 当前输入文件的记录个数 - ARGC 命令行参数的个数 - ARGV 命令行参数数组 - FILENAME 当前输入文件名 - OFMT 数值的输出格式 “%.6g” RLENGTE 被函数match匹配的字符串的长度 - RSTART 被函数match匹配的字符串的开始 - SUBSEP 下标分隔符 “\034” FS：输入字段分隔符，默认为空白字符 123# awk -v FS=&apos;:&apos; &apos;&#123;print $1,FS,$3&#125;&apos; /etc/passwd# awk -F: &apos;&#123;print $1,$3,$7&#125;&apos; /etc/passwd# s=:;awk -v FS=$s &apos;&#123;print $1 FS $3&#125;&apos; /etc/passwd OFS：输出字段分隔符，默认为空白字符 1# awk -v FS=&apos;:&apos; -v OFS=&apos;:&apos; &apos;&#123;print $1,$3,$7&#125;&apos; /etc/passwd RS：输入记录分隔符，指定输入时的换行符，原换行符仍有效 1# awk -v RS=&apos; &apos; &apos;&#123;print &#125;&apos; /etc/passwd ORS：输出记录分隔符，输出时用指定符号代替换行符 1# awk -v RS=&apos; &apos; -v ORS=&apos;###&apos;‘&#123;print&#125;’ /etc/passwd NF：字段数量 12# awk -F:&apos;&#123;print NF&#125;&apos; /etc/fstab, 引用内置变量不用$# awk -F: &apos;&#123;print $(NF-1)&#125;&apos; /etc/passwd NR：行号 1# awk &apos;&#123;print NR&#125;&apos; /etc/fstab; awk END&apos;&#123;print NR&#125;&apos; /etc/fstab FNR：各文件分别计数, 行号 1# awk &apos;&#123;print FNR&#125;&apos; /etc/fstab /etc/inittab FILENAME：当前文件名 1# awk &apos;&#123;print FILENAME&#125;&apos; /etc/fstab ARGC：命令行参数的个数 12# awk &apos;&#123;print ARGC&#125;&apos; /etc/fstab /etc/inittab# awk &apos;BEGIN &#123;print ARGC&#125;&apos; /etc/fstab /etc/inittab ARGV：数组，保存的是命令行所给定的各参数 12# awk &apos;BEGIN &#123;print ARGV[0]&#125;&apos; /etc/fstab /etc/inittab# awk &apos;BEGIN &#123;print ARGV[1]&#125;&apos; /etc/fstab /etc/inittab 自定义变量(区分字符大小写) (1) -v var=value (2) 在program中直接定义 示例: 1234567# awk -v test=&apos;hello gawk&apos; &apos;&#123;print test&#125;&apos; /etc/fstab# awk -v test=&apos;hello gawk&apos; &apos;BEGIN&#123;print test&#125;&apos;# awk &apos;BEGIN&#123;test=&quot;hello,gawk&quot;;print test&#125;&apos;# awk -F:‘&#123;sex=“male”;print $1,sex,age;age=18&#125;’ /etc/passwd# cat awkscript &#123;print script,$1,$2&#125; awk -F: -f awkscript script=“awk” /etc/passwd printf 参数 格式化输出：printf “FORMAT”, item1, item2, … (1)必须指定FORMAT (2)不会自动换行，需要显式给出换行控制符，\n (3)FORMAT中需要分别为后面每个item指定格式符 格式符：与item一一对应 格式符 意义 %c 显示字符的ASCII码 %d,%i 显示十进制整数 %e,%E 显示科学计数法数值 %f 显示为浮点数 %g,%G 以科学计数法或浮点形式显示数值 %s 显示字符串 %u 无符号整数 %% 显示%自身 修饰符：[.#]：第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f-: 左对齐（默认右对齐） %-15s+：显示数值的正负符号 %+d printf示例1234567# awk -F: '&#123;printf "%s",$1&#125;' /etc/passwd# awk -F: '&#123;printf "%s\n",$1&#125;' /etc/passwd# awk -F: '&#123;printf "%-20s %10d\n",$1,$3&#125;' /etc/passwd# awk -F: '&#123;printf "Username: %s\n",$1&#125;' /etc/passwd# awk -F: '&#123;printf “Username: %s,UID:%d\n",$1,$3&#125;’ /etc/passwd# awk -F: '&#123;printf "Username: %15s,UID:%d\n",$1,$3&#125;' /etc/passwd# awk -F: '&#123;printf "Username: %-15s,UID:%d\n",$1,$3&#125;' /etc/passwd 操作符表达式 初等表达式包括 数值与字符串常量, 变量, 字段, 函数调用, 数组元素. 可以把表达式组合起来的运算符包括 赋值运算符 = += -= = /= %= ^= 条件表达式 ?: 逻辑运算符 || (OR), &amp;&amp; (AND), ! (NOT) 匹配运算符 ~ 和!~ 关系运算符 &lt; &lt;= == != &gt; &gt;= 拼接运算符 (没有显式的拼接运算符) 算术运算符 + - / % ^ 单目运算符 +和- 自增与自减运算符++和–(包括前缀与后缀)括号 (用于分组) 操作 运算符 例子 例子的含义 赋值 = += -= *= /= %= ^= x *= 2 x = x * 2 条件表达式 ?: x ? y : z 若x为真,则 y,否则z 逻辑与 &amp;&amp; x &amp;&amp; y 若x与y都为真, 则为1,否则为0 数组成员 in i in a 如果a[i]存在, 则为1,否则为0 匹配 ~ !~ $1 ~ /x/ 如果第一个字段包含x,则为1,否则为0 关系运算 &lt; &lt;= == != &gt;= &gt; x == y 如果x等于y,则为1, 否则为0 拼接 “a” “bc” “abc” 不存在显式的拼接运算符 减法, 加法 + - x + y x与y的和 乘法, 除法, 取模 * / % x % y x除以y的余数 单目加, 单目减 + - -x x的相反数 逻辑非 ! !$1 若$1为空或为0, 则为1,否则为0 指数运算 ^ x ^ y x的y次方 自增, 自减 ++ – ++x, x++ 为x加1 字段 $ $i+1 1加上第i个字段的值 组 ( ) ($i)++ 给第i个字段的值加1 算术操作符： x+y, x-y, x*y, x/y, x^y, x%y -x:转换为负数 +x:转换为数值 字符串操作符：没有符号的操作符，字符串连接 赋值操作符： =, +=, -=, *=, /=, %=, ^= ++, – 比较操作符： ==, !=, &gt;, &gt;=, &lt;, &lt;= 模式匹配符 ~：左边是否和右边匹配包含 !~ ：是否不匹配 示例： 1234# awk –F: &apos;$0 ~ /root/&#123;print $1&#125;‘ /etc/passwd# awk &apos;$0~&quot;^root&quot;&apos; /etc/passwd# awk &apos;$0 !~ /root/&apos; /etc/passwd# awk -F: &apos;$3==0&apos; /etc/passwd 逻辑操作符： &amp;&amp; 与 || 或 ！ 非 示例： 12345# awk -F: &apos;$3&gt;=0 &amp;&amp; $3&lt;=1000 &#123;print $1&#125;&apos; /etc/passwd# awk -F: &apos;$3==0 || $3&gt;=1000 &#123;print $1&#125;&apos; /etc/passwd# awk -F: ‘!($3==0) &#123;print $1&#125;&apos; /etc/passwd# awk -F: ‘!($3&gt;=500) &#123;print $3&#125;&apos; /etc/passwd# awk -F: &apos;$3 &gt; 100 &amp;&amp; $3&lt;1000 &#123;print $1,$3&#125;&apos; passwd 函数调用123function_name(argu1, argu2, ...)条件表达式（三目表达式） selector?if-true-expression:if-false-expression 示例： 123awk -F: &apos;&#123;$3&gt;=1000?usertype=&quot;Common User&quot;:usertype=&quot;Sysadmin or SysUser&quot;;printf &quot;%15s:%-s\n&quot;,$1,usertype&#125;&apos; /etc/passwdawk -F: &apos;&#123;$3&gt;1000?username=&quot;common user:&quot;:username=&quot;sysuser:&quot;;printf &quot;%s %-30s %d\n&quot;,username,$1,$3&#125;&apos; passwd 正则表达式 正则表达式的元字符包括： \ ^ $ . [] | () * + ? 一个基本的正则表达式包括以下几种： 一个不是元字符的字符，例如A，这个正则表达式匹配的就是它本身； 一个匹配特殊字符的转义字符：\t匹配一个制表符 一个被引用的元字符，例如*，按字面意义匹配元字符 ^ 匹配一行的开始 $ 匹配一行的结束 . 匹配任意一个字符 一个字符类:[ABC]匹配字符A、B或C 字符类可能包能包含缩写格式：[A-Za-z]匹配单个字母 一个互补的字符类:[^0-9] 匹配任意一个字符，但除了数字 运算符组合起来使用 选择：A|B 匹配A或B 拼接：AB匹配后面紧跟着B的A 闭包：A*匹配0个或多个A 正必包：A+匹配一个或多个A 零或一：A？匹配空字符串或A 括号：被(r)匹配的字符串，与r所匹配的字符串相同 优先级 选择运算符|优先级最低，然后是拼接运算，最后是重复运算+，*与？； 转义序列 序列 意义 \b 退格 \f 换页 \n 换行 \r 回车 \t 制表符 \ddd 八进制数ddd.ddd含有1到3个数字，每个数字的值在0-7之间 \c 其他字面意义上的c（如\表示,”表示双引号） ###示例 123456789^[^^] 匹配不以脱字符开始的字符串/^[0-9]+$/ 匹配含有且只含有数字的输入行/^[0-9][0-9][0-9]$/ 输入行有且仅有 3 个数字./^(\+|-)?[0-9]+\.?[0-9]*$/ 十进制小数, 符号与小数部分是可选的./^[+-]?[0-9]+[.]?[0-9]*$/ 也是匹配十进制小数, 带有可选的符号与小数部分./^[+-]?([0-9]+[.]?[0-9]*|[.][0-9]+)([eE][+-]?[0-9]+)?$/ 浮点数, 符号与指数部分是可选的./^[A-Za-z][A-Za-z0-9]*$/ 一个字母, 后面再跟着任意多个字母或数字 (比如awk的变量名)./^[A-Za-z]$|^[A-Za-z][0-9]$/ 一个字母, 又或者是一个后面跟着一个数字的字母 (比如 Basic 的变量名)./^[A-Za-z][0-9]?$/ 同样是一个字母, 又或者是一个后面跟着一个数字的字母 awk PATTERN PATTERN: 根据pattern条件，过滤匹配的行，再做处理 (1) 如果未指定：空模式，匹配每一行 (2) /regular expression/ ：仅处理能够模式匹配到的行，需要用/ / 括起来awk &apos;/^UUID/{print $1}&apos; /etc/fstab awk &apos;!/^UUID/{print $1}&apos; /etc/fstab (3) relational expression: 关系表达式，结果为“真”才会被处理真：结果为非0值，非空字符串 假：结果为空字符串或0值 示例 123456# awk -F: &apos;i=1;j=1&#123;print i,j&#125;&apos; /etc/passwd# awk ‘!0’ /etc/passwd ; awk ‘!1’ /etc/passwd# awk –F: &apos;$3&gt;=1000&#123;print $1,$3&#125;&apos; /etc/passwd# awk -F: &apos;$3&lt;1000&#123;print $1,$3&#125;&apos; /etc/passwd# awk -F: &apos;$NF==&quot;/bin/bash&quot;&#123;print $1,$NF&#125;&apos; /etc/passwd# awk -F: &apos;$NF ~ /bash$/&#123;print $1,$NF&#125;&apos; /etc/passwd (4) line ranges：行范围 12345startline,endline /pat1/,/pat2/# awk -F: &apos;/^root\&gt;/,/^nobody\&gt;/&#123;print $1&#125;&apos; /etc/passwd注意：不支持直接给出数字格式# awk -F: &apos;(NR&gt;=10&amp;&amp;NR&lt;=20)&#123;print NR,$1&#125;&apos; /etc/passwd (5) BEGIN/END 模式 BEGIN{}: 仅在开始处理文件中的文本之前执行一次 END{}： 仅在文本处理完成之后执行一次 示例 12345678910# awk -F : &apos;BEGIN &#123;print &quot;USER USERID&quot;&#125; &#123;print $1&quot;:&quot;$3&#125; END&#123;print &quot;end file&quot;&#125;&apos; /etc/passwd# awk -F : &apos;&#123;print &quot;USER USERID“;print $1&quot;:&quot;$3&#125; END&#123;print &quot;end file&quot;&#125;&apos; /etc/passwd# awk -F: &apos;BEGIN&#123;print &quot; USER UID \n--------------- &quot;&#125;&#123;print $1,$3&#125;&apos; /etc/passwd# awk -F: &apos;BEGIN&#123;print &quot; USER UID \n--------------- &quot;&#125;&#123;print $1,$3&#125;&apos;END&#123;print &quot;==============&quot;&#125; /etc/passwd # seq 10 |awk ‘i=0’# seq 10 |awk ‘i=1’# seq 10 | awk &apos;i=!i‘# seq 10 | awk &apos;&#123;i=!i;print i&#125;‘# seq 10 | awk ‘!(i=!i)’# seq 10 |awk -v i=1 &apos;i=!i&apos; 模式总结 模式 例子 匹配 BEGIN BEGIN 输入被读取之前 END END 所有输入被读取之后 expression $3&gt;100 第三个字段大于100 string-matching /Asia/ 含有Asia的行 compound $3&lt;100 &amp;&amp; $4 ==”Asia” 第三个字段小于100且第四个字段含有Asia的行 range NR == 10,NR==20 输入的第10行到20行 awk action123456常用的action分类 (1) Expressions: 算术，比较表达式等 (2) Control statements：if,while等 (3) Compound statements：组合语句 (4) input statements (5) output statements：print等 awk控制语句12345678910111213&#123; statements;… &#125; 组合语句 if(condition) &#123;statements;…&#125; if(condition) &#123;statements;…&#125; else &#123;statements;…&#125; while(conditon) &#123;statments;…&#125; do &#123;statements;…&#125; while(condition) for(expr1;expr2;expr3) &#123;statements;…&#125; break continue next 开始输入主循环的下一次迭代 delete array[index] delete array exit exit expression 马上执行END 动作; 如果已经在END动作内, 那就退出程序. 将expression作为程序的退出状态返回. if-else123456789101112131415语法： if(condition)&#123;statement;…&#125;[else statement] if(condition1)&#123;statement1&#125;else if(condition2)&#123;statement2&#125; else&#123;statement3&#125; 使用场景：对awk取得的整行或某个字段做条件判断 示例： # awk -F: &apos;&#123;if($3&gt;=1000)print $1,$3&#125;&apos; /etc/passwd # awk -F: &apos;&#123;if($NF==&quot;/bin/bash&quot;) print $1&#125;&apos; /etc/passwd # awk &apos;&#123;if(NF&gt;5) print $0&#125;&apos; /etc/fstab # awk -F: &apos;&#123;if($3&gt;=1000) &#123;printf &quot;Common user: %s\n&quot;,$1&#125; else &#123;printf &quot;root or Sysuser: %s\n&quot;,$1&#125;&#125;&apos; /etc/passwd # awk -F: &apos;&#123;if($3&gt;=1000) printf &quot;Common user: %s\n&quot;,$1; else printf &quot;root or Sysuser: %s\n&quot;,$1&#125;&apos; /etc/passwd df -h|awk -F% &apos;/^\/dev/&#123;print $1&#125;&apos;|awk &apos;$NF&gt;=80&#123;print $1,$5&#125;‘ # awk &apos;BEGIN&#123; test=100;if(test&gt;90)&#123;print &quot;very good&quot;&#125; else if(test&gt;60)&#123; print &quot;good&quot;&#125;else&#123;print &quot;no pass&quot;&#125;&#125;&apos; while循环12345678语法： while(condition)&#123;statement;…&#125; 条件“真”，进入循环；条件“假”， 退出循环 使用场景： 对一行内的多个字段逐一类似处理时使用 对数组中的各元素逐一处理时使用 示例： awk &apos;/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF) &#123;print $i,length($i); i++&#125;&#125;&apos; /etc/grub2.cfg do-while循环12345678语法： do &#123;statement;…&#125;while(condition) 意义：无论真假，至少执行一次循环体 示例： # awk &apos;BEGIN&#123; total=0;i=0;do&#123; total+=i;i++;&#125;while(i&lt;=100);print total&#125;&apos; 思考：下面两语句有何不同？ # awk &apos;BEGIN&#123;i=0;print ++i,i&#125;&apos; # awk &apos;BEGIN&#123;i=0;print i++,i&#125;&apos; for循环12345678910111213141516171819语法： for(expr1;expr2;expr3) &#123;statement;…&#125; 常见用法： for(variable assignment;condition;iteration process) &#123;for-body&#125; 特殊用法：能够遍历数组中的元素 语法：for(var in array) &#123;for-body&#125; 示例： awk &apos;/^[[:space:]]*linux16/&#123;for(i=1;i&lt;=NF;i++) &#123;print $i,length($i)&#125;&#125;&apos; /etc/grub2.cfg空语句 单独一个分号表示一个空语句 在下面这个程序里, for的循环体是一个空语句. BEGIN &#123; FS = &quot;\t&quot; &#125; &#123; for (i = 1; i &lt;= NF &amp;&amp; $i != &quot;&quot;; i++); if (i &lt;= NF) print &#125; 这个程序打印所有的, 包含空字段的行. 循环性能比较1234time (awk &apos;BEGIN&#123;total=0;for(i=0;i&lt;=10000;i++)&#123;total+=i;&#125;;print total;&#125;&apos;)time(total=0;for i in &#123;1..10000&#125;;do total=$(($total+i));done;echo $total)time(for ((i=0;i&lt;=10000;i++));do let total+=i;done;echo $total)time(seq -s ”+” 10000|bc) switch语句12语法： switch(expression) &#123;case VALUE1 or /REGEXP/: statement1; case VALUE2 or /REGEXP2/: statement2; ...; default: statementn&#125; break 和continue 12# awk ‘BEGIN&#123;sum=0;for(i=1;i&lt;=100;i++) &#123;if(i%2==0)continue;sum+=i&#125;print sum&#125;‘# awk ‘BEGIN&#123;sum=0;for(i=1;i&lt;=100;i++) &#123;if(i==66)break;sum+=i&#125;print sum&#125;‘ break [n] continue [n] next:提前结束对本行处理而直接进入下一行处理（awk自身循环） 1# awk -F: &apos;&#123;if($3%2!=0) next; print $1,$3&#125;&apos; /etc/passwd awk数组 关联数组：array[index-expression]index-expression: (1)可使用任意字符串；字符串要使用双引号括起来 (2)如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串” 若要判断数组中是否存在某元素，要使用“index in array”格式进行遍历 示例： 12345weekdays[“mon”]=&quot;Monday“# awk &apos;BEGIN&#123;weekdays[&quot;mon&quot;]=&quot;Monday&quot;;weekdays[&quot;tue&quot;]=&quot;Tuesday&quot;;print weekdays[&quot;mon&quot;]&#125;&apos;&apos;# awk &apos;BEGIN&#123;weekdays[&quot;mon&quot;]=&quot;Monday&quot;;weekdays[&quot;tue&quot;]=&quot;tuesday&quot;;for(i in weekdays) print weekdays[i]&#125;&apos; # awk ‘!arr[$0]++’ dupfile 重复的行只显示一次# awk &apos;&#123;!arr[$0]++;print $0, arr[$0]&#125;&apos; dupfile 若要遍历数组中的每个元素，要使用for循环 for(var in array) {for-body} 注意：var会遍历array的每个索引示例： 1234# awk &apos;BEGIN&#123;weekdays[&quot;mon&quot;]=&quot;Monday&quot;;weekdays[&quot;tue&quot;] =&quot;Tuesday&quot;;for(i in weekdays) &#123;print weekdays[i]&#125;&#125;&apos;# netstat -tan | awk &apos;/^tcp/&#123;state[$NF]++&#125;END &#123;for(i in state) &#123; print i,state[i]&#125;&#125;&apos;# awk &apos;&#123;ip[$1]++&#125;END&#123;for(i in ip) &#123;print i,ip[i]&#125;&#125;&apos; /var/log/httpd/access_log awk函数数值处理:rand()：返回0和1之间一个随机数 awk ‘BEGIN{rand(); for (i=1;i&lt;=10;i++)print int(rand()*100) }’ 内建算术函数 函数 返回值 atan2(y,x) y/x的反正切值, 定义域在 −π到π之间 cos(x) x的余弦值, x以弧度为单位 exp(x) x的指数函数,e x int(x) x的整数部分; 当x大于0时, 向 0取整 log(x) x的自然对数(以e为底) rand() 返回一个随机数r, 0 ≤ r &lt; 1 sin(x) x的正弦值, x以弧度为单位. sqrt(x) x的方根 srand(x) x是rand() 的新的随机数种子 自定义函数12345678910111213格式： function name ( parameter, parameter, ... ) &#123; statements return expression &#125; 示例： cat fun.awk function max(v1,v2) &#123; v1&gt;v2?var=v1:var=v2 return var &#125; BEGIN&#123;a=3;b=2;print max(a,b)&#125; awk -f fun.awk awk中调用shell命令1234system命令空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用空格分隔，或者说除了awk的变量外其他一律用&quot;&quot;引用起来。# awk BEGIN&apos;&#123;system(&quot;hostname&quot;) &#125;&apos;# awk &apos;BEGIN&#123;score=100; system(&quot;echo your score is &quot; score) &#125;&apos; awk脚本1234567891011将awk程序写成脚本，直接调用或执行示例：# cat f1.awk&#123;if($3&gt;=1000)print $1,$3&#125;# awk -F: -f f1.awk /etc/passwd# cat f2.awk #!/bin/awk -f #this is a awk script &#123;if($3&gt;=1000)print $1,$3&#125;#chmod +x f2.awk# f2.awk -F: /etc/passwd 向awk脚本传递参数123格式： awkfile var=value var2=value2... Inputfile 注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通过-v参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变量都需要一个-v参数 示例12345# cat test.awk #!/bin/awk -f &#123;if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3&#125; chmod +x test.awk# test.awk -F: min=100 max=200 /etc/passwd]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 常用功能]]></title>
    <url>%2F2018%2F04%2F27%2Fredis%2F</url>
    <content type="text"><![CDATA[redis 常用功能KV cache and storeREmote DIctionary Server(远程字典服务器)redis 运行都在内存中来实现，周期性的写入磁盘，来实现持久功能; 基本知识123456789101112131415161718192021222324252627282930KV cache and store in-memory; 持久化 ; 主从(借助于sentinal实现一定意义上的HA); Clustering(分布式);数据结构服务器: String, List, Hash, Set, Sorted Set, Bitmap,HperLoglogs;Memcached 与 Redis的区别: 1、Memcached 是一个分布式的内存对象缓存系统; 2、Reis 可以实现持久存储的; 3、Mecached 是一个LUR 缓存，将过期数据清理出去; 4、Redis支持更多的数据类型; 5、Memcached 是多线程; 6、Redis是单线程; 7、二者的性能不相上下;Redis 3.0的LRU算法的改进: 预设随机取5个样本，插入并排序至一个pool， 移除最佳者，如此反复; 走到内存用理小于maxmemory的设定; 样本5比先前的3多; 从局部最优趋向全局最优;存储系统三类: RDBMS NoSQL: KV NoSQL: redis Column Family NoSQL: HBase Documentation NoSQL: MongoDB Graph NoSQL: Neo4j NewSQL(支持分布式)Redis的组件: redis.io(官方站点) Commands1234567redis-serverredis-cli Command line interface redis-benchmark Benchmarking utilityredis-check-dump &amp; redis-check-aof Corrupted RDB/AOF files utilities Redis守护进程12345678910111213141516171819202122232425262728# vim /etc/redis.conf监听6379端口;tcp-backlog 511 #是redis守护进程的等队列,当并发较高时，再找位置来缓存新请求;bind # 是指监听的地址;bind 127.0.0.1 172.16.55.128unixsocket /tmp/redis.sock # 当服务和redis在一台服务器上使用socket来通信，提高效率;unixsocketperm 700timeout #当一个客端连接多久后，认为超时，0表示禁用，认为一直存在;tcp-keepaoive 0loglevel noticelogfile /var/log/redis/redis.logdatabases 16 # 表示可以使用多少个数据库;save &lt;sencods&gt; &lt;changes&gt; # 如果多少秒发生多少变化则存储，因此这取决于业务模型;save &quot;&quot; #这样写表示禁用redis持久化功能;save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yes rdbcompression yesdbcheksum yesdbfilename dump.rdbdir /var/lib/redis# 配置以为成为从服务器salveof ip # 这里指定主服务器的ip即可;maxclients 100000appendonly yes # 开启appendonly 持久化功能;appendfsync everysec # 是否使用fsync来持久化;# redis服务端的参数，大多可以在redis-cli连接到服务器后进行动态修复或修改的; redis-cli 常用命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112# redis-cli -p 25612 127.0.0.1:25612&gt; AUTH xxxxxxx127.0.0.1:25612&gt; HELP APPEND # help 用来查看帮助127.0.0.1:25612&gt; CLIENT LISTid=3 addr=127.0.0.1:25666 fd=5 name= age=275 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client127.0.0.1:25612&gt; SELECT 1 # 第开第几个数据库，也可以理解成为名称空间;127.0.0.1:25612&gt; SELECT 1OK127.0.0.1:25612[1]&gt; SET disto fedoraOK127.0.0.1:25612[1]&gt; GET disto&quot;fedora&quot;127.0.0.1:25612[1]&gt; SET disto centosOK127.0.0.1:25612[1]&gt; STRLEN disto(integer) 6127.0.0.1:25612[1]&gt; DECR count(integer) -1127.0.0.1:25612[1]&gt; DECR count(integer) -2127.0.0.1:25612[1]&gt; DECR count(integer) -3127.0.0.1:25612[1]&gt; SET disto gentoo NX # 显示为未能执行的操作,该值不存在则设定;(nil)127.0.0.1:25612[1]&gt; SET foo bar XX # 该值则在则设定;(nil)127.0.0.1:25612[1]&gt; SADD w1 mon tue wed thu sat sun(integer) 6127.0.0.1:25612[1]&gt; SADD w1 mon tue wed thu fre sat sun(integer) 1127.0.0.1:25612[1]&gt; 127.0.0.1:25612[1]&gt; SADD w2 tue thu day127.0.0.1:25612[1]&gt; ZADD weekday1 1 mon 2 tue 3 wed(integer) 3127.0.0.1:25612[1]&gt; ZCARD weekday1(integer) 3127.0.0.1:25612[1]&gt; ZRANK weekday1 tue(integer) 1127.0.0.1:25612[1]&gt; ZRANK weekday1 mon(integer) 0 (integer) 3127.0.0.1:25612[1]&gt; SINTER w1 w2 # 求两个集合的交集;1) &quot;thu&quot;2) &quot;tue&quot;127.0.0.1:25612[1]&gt; SUNION w1 w2 # 求两个集合的并集;1) &quot;sun&quot;2) &quot;wed&quot;3) &quot;sat&quot;4) &quot;day&quot;5) &quot;tue&quot;6) &quot;thu&quot;7) &quot;mon&quot;8) &quot;fre&quot;127.0.0.1:25612[1]&gt; SPOP w1 # 弹出一个元素 ;&quot;tue&quot;127.0.0.1:25612[1]&gt; SPOP w1&quot;sun&quot;127.0.0.1:25612[1]&gt; SISMEMBER w1 day # 表示已经没有这个元素;(integer) 0127.0.0.1:25612[1]&gt; SISMEMBER w1 sat(integer) 1127.0.0.1:25612[1]&gt; ZRANGE weekday1 0 11) &quot;mon&quot;2) &quot;tue&quot;127.0.0.1:25612[1]&gt; HSET h1 a mon(integer) 0127.0.0.1:25612[1]&gt; HGET h1 a&quot;mon&quot;127.0.0.1:25612[1]&gt; HSET h1 b tue(integer) 1127.0.0.1:25612[1]&gt; HGET h1 a &quot;mon&quot;127.0.0.1:25612[1]&gt; HGET h1 b &quot;tue&quot;127.0.0.1:25612[1]&gt; HVALS h11) &quot;mon&quot;2) &quot;tue&quot;127.0.0.1:25612[1]&gt; HKEYS h11) &quot;a&quot;2) &quot;b&quot;Strings: 字串 SET key value [EX #] [NX|XX] GET INCR DECR EXISTLists: 列表 LPUSH RPUSH LDROP RPOP LINDEX LSETSets: 集合 SADD SINTER SUNTON SPOP SISMEMBERSorted Sets 有序集合， 其命令都以Z开头 ZADD ZRANGE ZCARD ZRANKHashes： 一组关联数的集合 HSET HSETNX HGET HKEYS HVALS HDEL 认证实现方法1234(1) redis.conf requirepass PASSWORD(2) redis-cli AUTH PASSWD 清空数据库12# FLUSHDB: 清空当前库# FLUSHALL: 清空所有库 事务1234567891011121314151617181920212223242526272829303132333435363738394041424344# 通过MULTI, EXEC, WATCH等命令实现事务功能;# 将一个或多个命令归并为一个操作提请服务器按顺序执行的机制;# Redis数据不支持回滚操作;# MULTI: 启动一个事务，中间的所有命令会放置在队列中;# EXEC: 执行事务;# 一次性将事务中的所有操作执行完成后返回给客户端;127.0.0.1:25612&gt; MULTIOK127.0.0.1:25612&gt; SET ip 172.16.55.123QUEUED127.0.0.1:25612&gt; GET ip QUEUED127.0.0.1:25612&gt; SET port 8080QUEUED127.0.0.1:25612&gt; GET port QUEUED127.0.0.1:25612&gt; EXEC1) OK2) &quot;172.16.55.123&quot;3) OK4) &quot;8080&quot;# WATCH: 乐观锁， 在EXEC命令执行之间有用于监视指定数量键; #如果监视中的某任意键数据被修改，则服务器拒绝执行事务;# 打开两个终端term1127.0.0.1:25612&gt; WATCH ipOK127.0.0.1:25612&gt; MULTIOK127.0.0.1:25612&gt; SET ip 10.0.0.1QUEUED127.0.0.1:25612&gt; GET ipQUEUEDterm2 127.0.0.1:25612&gt; GET ip &quot;172.16.55.123&quot;127.0.0.1:25612&gt; SET ip 172.16.55.123OK127.0.0.1:25612&gt; GET ip &quot;172.16.55.123&quot;term1127.0.0.1:25612&gt; EXEC(nil)# 监控的一个键，EXEC之前键发生了改动，EXEC将拒绝提交; Connection相关的命令:123456789101112131415AUTH127.0.0.1:25612&gt; HELP PING PING [message] summary: Ping the server since: 1.0.0 group: connection127.0.0.1:25612&gt; PINGPONG127.0.0.1:25612&gt; ECHO &quot;hello redis&quot;&quot;hello redis&quot;127.0.0.1:25612&gt; QUIT127.0.0.1:25612&gt; HELP @connection Server相关的命令123456789101112131415161718192021222324252627CLIENT GETNAMECLIENT KILL ip:port127.0.0.1:25612&gt; CLIENT SETNAME localconnOK127.0.0.1:25612&gt; CLIENT GETNAME&quot;localconn&quot;127.0.0.1:25612&gt; HELP INFO # 获取当前服务器的状态及信息; INFO [section] summary: Get information and statistics about the server since: 1.0.0 group: server127.0.0.1:25612&gt; INFO CPU# CPUused_cpu_sys:474.20used_cpu_user:258.88used_cpu_sys_children:0.01used_cpu_user_children:0.00CONFIG RESETSTATCONFIG SET PARAMETER valueCONFIG REWRITE DBSIZE# 跟持久化相关的数据 BGSAVE SAVELASTSAVEmonitor # 实时监控对数据的请求SHUTDOWN SAVE #将数据安全的同步到磁盘后关闭redis-server redis 发布与订阅功能(publish/subscribe)12345678910111213141516171819202122232425262728293031323334353637383940414243# 频道: 消息队列# SUBSCRIBE: 订阅一个或多个队列;# PUBLISH: 向频道发布消息;# UNSUBSCRIBE: 退订此前订阅的频道;# PSUBSCRIBE: 模式订阅;# term1 中开始一个频道; 127.0.0.1:25612&gt; SUBSCRIBE newsReading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;news&quot;3) (integer) 1# term2 中向一个频道中发布消息;127.0.0.1:25612&gt; PUBLISH news &quot;hello renjin&quot;(integer) 1# term1 中可以收到消息;1) &quot;message&quot;2) &quot;news&quot;3) &quot;hello renjin&quot;# term1 中使用扩展模式开启两个频道;127.0.0.1:25612&gt; PSUBSCRIBE &quot;rj.i[to]&quot;Reading messages... (press Ctrl-C to quit)1) &quot;psubscribe&quot;2) &quot;rj.i[to]&quot;3) (integer) 1# term2 中向两个频道发布消息;127.0.0.1:25612&gt; PUBLISH rj.io &quot;hello RenJin&quot;(integer) 1127.0.0.1:25612&gt; PUBLISH rj.it &quot;hello SSJinYao&quot;(integer) 1# term1 中可以收到两条消息;1) &quot;pmessage&quot;2) &quot;rj.i[to]&quot;3) &quot;rj.io&quot;4) &quot;hello RenJin&quot;1) &quot;pmessage&quot;2) &quot;rj.i[to]&quot;3) &quot;rj.it&quot;4) &quot;hello SSJinYao&quot; Redis 的持久化:1234567891011121314151617181920212223242526272829303132333435363738394041424344# 提供了RDB和AOF两种机制; RDB: snapshot: 二进制格式; 按事先定制的策略，周期性地将数据保存至磁盘:数据文件默认为dump.rdb; 客户端 也可以使用SAVE或BGSAVE命令启快照保存机制; SAVE：同步,在主线程中保存快照; 此时会阻塞所有客户端请求; BGSAVE: 异步， AOF:Aappend Only Fil 记录每一次写操作至指定 的文件尾部实现持久化; 当redis重启时，可通过重新执行文件中的命令在内存重建数据库; BGREWRITEAOF: AOF文件重写: 不会读取正在使用的AOF文件，而通过将内存中的数据以命令的方式保存到临时文件中，完之后替换原来的AOF文件; RDB:默认保存策略，取决于磁盘IO能力，与客户端对redis的读写; SAVE 900 1 SAVE 300 10 SAVE 60 1000 stop-writes-on-bgsave-error yes # 在进行快照备份时，监控到持久化发现错误时，是否停止下来; 会报告一个访问错误;rdbcompression yes # 是否采用压缩来节省使有空间，当然消耗cpu使用周期;rdbchecksum yes # 是否对rdb做校验码操作;dbfilename dump.rdb # 指明文件名;dir /var/lib/redis #指明保存文件的位置;127.0.0.1:25612&gt; CONFIG GET dir1) &quot;dir&quot;2) &quot;/var/lib/redis&quot; AOF: 重写过程: (1) redis 主进程通过fork创建子进程; (2) 子进程根据redis内存中的数据创建数据库重建命令序列于临时文件中; (3) 父进程继承client的请求时，并会把这些请求中的写操作继续追加至原来的AOF文件; 额外地，这些新的写请求还会被放置于一个缓冲队列中; (4) 子进程重写完成，会通知父进程，父进程把缓冲中的命令写到临时文件中; (5) 父进程用临时文件替换老的aof文件; appenonly no #没有开启AOF 功能; appendfilename &quot;appendonly.aof&quot; # 文件名 appendfsync eversec # 每秒中写一次 no-appedfsync-no-rewrite no # 对新的操作不做fsync，而是放在缓存队列中的; auto-aof-rewrite-percentage 100 # 当前afo 文件是上次的两倍时，再重新触发重写操作; auto-aof-rewrite-min-size 64mb # 127.0.0.1:25612&gt; CONFIG SET appendonly yesOK# 注意: 持久本身不能取代备份: 还应该制定备份策略,对redis数据库进行定期备份;# RDB与AOF同时启用: (1) BGSAVE和BGREWRITEAOF 不会同是执行; (2) 在Redis服务器启用于恢复数据时，会优先使用AOF; Redis复制:12345678910111213特点: 一个Master 可以有多个Slave; 支持链式复制; Master以非阻塞方式同步数据至slave; 注:主服务器不建议关闭持久化;slave: &gt; SLAVEOF MASTER_IP MASTER_PORT min-salves-to-write 3 # 至少应该有三个从节点，小于三个，禁止主服务器写操作; min-salves-max-lag # 从服务器必需不能滞后于服务器10秒以上;注意: 如果master使用requirespass开启了认证功能，从服务器要使用masterauth &lt;PASSWORD&gt;; 来连入服务请求使用此密码进行认证; sentinal: 万一主服务器岩了，那么它会从从服务器节点中选则一台服务器成为主节点; 万sentinal 故障，或者连接不上主节点时，需要sentinal配置多个节点; sentinel:1234567891011121314151617181920212223242526272829303132333435用于管理多个redis服务实现HA; 监控; 通知; 自动故障转移; 本质上，sentinel也是redis的分布式功能; 使用流言协议、投票协议;程序: redis-sentinel /path/to/file.conf redis-server /path/to/file.conf(1) 服务器自身初始化，运行redis-server中专用于sentinel功能的代码;(2) 初始化sentinel状态，根据给定的配置文件，初始化监控的master服务器列表;(3) 创建连向master的连接；专用配置文件: /etc/redis-sentinel.conf(1) # sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; sentinel monitor mymaster 127.0.0.1 6379 2(2) # sentinel down-after-millisenconds &lt;master-name&gt; &lt;millisends&gt; sentinel down-afer-millisenconds mymaster 3000(3) # sentinel parellel-syncs &lt;master-name&gt; &lt;numslaves&gt; seninel parallel-syncs mymaster 1 (4) # sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt; sentinel failover-timeout mymaster 180000主观下线,客观下线: 主观下线: 一个sentinel实例判断出某节点下线: 客观下线:多个seninel 节点协商后判断出某节点下线:专用命令: SENTINEL masters SENTINEL slaves &lt;master name&gt; SENTINEL get-master-addr-by-name &lt;master name&gt; SENTINEL reset SENTINEL failover &lt;master name&gt;Clustering: 分布式数据库，通过分片机制进行数据分布，clustering内的每个子节点仅数据库的一部分数据;]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx的常用架构]]></title>
    <url>%2F2018%2F04%2F26%2Fnginx%E5%B8%B8%E7%94%A8%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Nginx 常用架构 LB Cluster12345678910提升系统容量的方式: scale up: scale out:session保持方法: session绑定:sh session复制: session服务器: memchached redis (key-value,kv store) 对url 做hash 计算后，做为key 对url 对应的内容做为value I/O：12345678910111213141516同步/异步:被调用者，在收到调用请求后，是否立即返回。还是得到最终结果后才返回； 阻塞/非阻塞:调用者发起调用之后，在收到响应结果之前，是否会被挂起，被挂起，被称为阻塞，非挂起为非阻塞;I/O网络编程模型中，常用网络模型有5种;1、同步阻塞 2、同步非阻塞3、复用型I/O4、(Event Driver) 事件驱动5、异步I/Olibevent: 项目 epoll()可以对nginx进程对CPU的核心数来进行绑定;LRU:最近最少缓存条目算法;平滑升级，平滑故障处理，或者灰度发布;对于web服务器来说，日志至关重要，需要对日志进行分析;CacheManager: 缓存的失效，过期检验及清理操作; Nginx 配置123456789101112131415main, event, http 基于c语言风格；httpd&#123; drective server&#123; listen server_name location&#123; if &#123; &#125; &#125; &#125; server &#123; &#125;&#125; nginx 的安装包1234567891011# 这里采用的采用的是阿里云的epel源# cd /etc/yum.repos.d/epel.repo[epel]name=Extra Packages for Enterprise Linux 7 - $basearchenabled=1failovermethod=prioritybaseurl=http://mirrors.cloud.aliyuncs.com/epel/7/$basearchgpgcheck=0gpgkey=http://mirrors.cloud.aliyuncs.com/epel/RPM-GPG-KEY-EPEL-7# yum -y install nginx# rpm -q --scripts nginx # 查看nginx 的安装前脚本，卸载后脚本; ngx_http_proxy_module 模块1234567891011121314server &#123; listen server_name location /&#123; proxy_pass http://172.16.55.180:80/ proxy_set_header Host $host # 设定请求报文的，Host首部，一般apache基于主机名解析的重要首部信息; proxy_set_header X-Real-IP $remote_addr; &#125;&#125;# 请求到代理服务器的过程，Ningx把报文拆除，了解请求的内容是什么;# 于是Nginx需要重新构建请求报文 ，来送到的后端服务器;# cip（客户端 ip） --&gt; pip(代理ip) --&gt; lip(本地ip) --&gt; uip(后端服务器ip);http://www.ssjinyao.comhttp://mysql.ssjinyao.com 12345678910111213141516171819202122232425262728293031# 在node1中配置一台httpd服务# echo &quot;&lt;h1&gt;node1&lt;/h1&gt;&quot; &gt; /var/www/html/index.html# systemctl start httpd # 在node2中 配置一台httpd 服务echo &quot;&lt;h1&gt;node2&lt;/h1&gt;&quot; &gt; /var/www/html/index.html# systemctl start httpd 格式: localtion /uri &#123; proxy_pass http://back_server:port/newuri; &#125; # 这样的配置 uri 将补到newuri的后面 location /uri &#123; rewrite http://back_server:port/newuri # proxy_pass http://back_server:port/newuri &#125; # 这样的配置 uri 将重写到newuri /uri --&gt; /newuri# cd /etc/nginx/conf.d/# cp defalt.conf&#123;,.bak&#125;# vim default.confserver_name www.ssjinyao.com;location / &#123; proxy_ass http://172.16.55.128/; index index.htm index.html ;&#125;# systemctl restart nginx# tial -f /var/log/nginx/access.log 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 在node2 apache 端进行编辑# mkdir /var/www/html/bbs# echo &quot;&lt;h1&gt; bbs on node2 &lt;/h1&gt;&quot; /var/www/html/bbs/index.html# 对应的在nginx 端location /bbs/ &#123; proxy_pass http://172.16.55.128/bbs/;&#125;# nginx -t or # sevice nginx configtest # systemctl rsload nginx # 或者可以使用forumlocation /forum/ &#123; proxy_cache mycache; proxy_cache_valid 200 1h; proxy_cache_valid 301 302 10m; proxy_cache_valid any 1m; proxy_cache_use_statle error timeout invalid_header http_500 http_502 http_503 http504; # 什么情况下使用过期缓存 proxy_pass http://172.16.55.128/bbs/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr;&#125;# nginx -t # systemctl reload nginxlocation ~* \.(jpg|png|gif)$ &#123; proxy_pass http://172.16.55.128; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr;&#125;# nginx -t # systemctl reload nginx # 注意 在location 进行正则匹配的模式匹配时# proxy_pass 加http://172.16.55.128; 这个位置这后什么都不能带的，/ 也不能带的，否则会报语法错误; # apache 记录客户端请求的日志,向后端发送特定首部;需要在Logformat中加入 将第一个值 %h 换成%&#123;X-Real-IP&#125;i# systemctl restart httpd # 定义proxy缓存 # 在nginx httpd 段中配置cache path;# vim /etc/nginx/nginx.confproxy_cache_path /cache/nginx/ level=1:1:1 keys_zone=mycache:32m;# mkdir -pv /cache/nginx# chown -R nginx.nginx /cache/nginxproxy_connect_timeout: nginx proxy 请求连接到后端连接请求的超时时长;proxy_hide_header: 设定响应到客户端时需要隐藏的首部信息;‘proxy_buffers 8k; 指定缓冲大小 upstream(负载均衡) 模块upstream 模块只能使用在http段中 例子 1234567891011121314151617181920212223# 注 启用负载均衡时要把缓存关了upstream backend &#123; server www.ssjinyao.com weight=5 server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3; server backup1.ssjinyao.com backup;&#125; upstream upservers &#123; ip hash; server 172.16.55.127 max_fail=2 fail_timeout=2 # 自带健康状态检测功能; # server 172.16.55.128 weight=2; server 172.16.55.129 bakup;&#125;server_name www.ssjinyao.com;location / &#123; proxy_pass http://upservers/;&#125;# nginx -t # systemctl reload nginx SNAT模式的大量的Client1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253基于sticky实现session绑定: cookie 而我们一般常用的是基于cookie的绑定; route learn() 需要Nginx 在 1.8 版本以上;example:upstream backend &#123; server backend1.example.com; server backend2.example.com; sticky cookie srv_id expires=1h domain=.example.com path=/;&#125;least_conn:调度方法，最少连接;upstream memcached_backend &#123; server 127.0.0.1:11211; server 172.16.55.121:11211; keepavlie 32;&#125;server &#123; ... location /memcached/ &#123; set $memcached_key $uri; memcached_pass memcached_backend; &#125; &#125;location / &#123; proxy_pass http://backend; health_check;&#125; helth_check; 即健康状态检查; 建议: 关闭访问日志; http &#123; server &#123; ... location / &#123; proxy_pass http://backend; health_check match=welcome; # 做字符串匹配; &#125; &#125; metch welcome &#123; status 200; header Content-Type = text/html; body ~ &quot;Welcome to nginx&quot;; &#125;&#125; Nginx 自定义首部给客户端123456789101112131415161718192021222324# 代理服务器响应给客户端时，如何自定义响应首部; listen 443; server_name www.ssjinyao.com; add_header SSJinYao-Server &apos;Next-SSJinYao&apos;; add_header SSJinYao-IP $server_addr; add_header X-Cache $upstream_cache_status; add_header Name &apos;ssjinyao&apos;; # curl -I https://www.ssjinyao.com # 定义完响应首部后，进行验证;HTTP/1.1 200 OKServer: nginxDate: Tue, 24 Apr 2018 07:24:37 GMTContent-Type: text/html; charset=UTF-8Content-Length: 39777Connection: keep-aliveVary: Accept-EncodingLast-Modified: Thu, 19 Apr 2018 09:14:18 GMTETag: &quot;9b61-56a2fff0c14a1&quot;SSJinYao-Server: Next-SSJinYaoSSJinYao-IP: 172.31.253.156X-Cache: HITName: ssjinyaoAccept-Ranges: bytes fast-cgi 使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374LNMP# yum -y install php-fpm# rpm -ql php-fpm # vim /etc/php-fpm.d/www.conf# systemctl start php-fpm # vim /etc/nginx.conf.d/default.conflocation / &#123; root /usr/share/nginx/html; index index.php index.html index.htm;&#125;location ~\.php$ &#123; fastcgi_cache fcgicache; fastcgi_cache_valid 200 10m; fastcgi_cache_valid 302 3m; fastcgi_cache_valid any 1m; root /usr/share/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index indexphp; fastcgi_param SCRIPT_FILENAME /scripts$fastcgi-script_naame; indclude fastcgi_paramgs;&#125;# systemctl restart nginx# 若调用fastcgi 失败 # 编辑/etc/nginx/fastcgi_params，将其内容更改为如下内容：fastcgi_param GATEWAY_INTERFACE CGI/1.1;fastcgi_param SERVER_SOFTWARE nginx;fastcgi_param QUERY_STRING $query_string;fastcgi_param REQUEST_METHOD $request_method;fastcgi_param CONTENT_TYPE $content_type;fastcgi_param CONTENT_LENGTH $content_length;fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;fastcgi_param SCRIPT_NAME $fastcgi_script_name;fastcgi_param REQUEST_URI $request_uri;fastcgi_param DOCUMENT_URI $document_uri;fastcgi_param DOCUMENT_ROOT $document_root;fastcgi_param SERVER_PROTOCOL $server_protocol;fastcgi_param REMOTE_ADDR $remote_addr;fastcgi_param REMOTE_PORT $remote_port;fastcgi_param SERVER_ADDR $server_addr;fastcgi_param SERVER_PORT $server_port;fastcgi_param SERVER_NAME $server_name;# nginx -s reload# yum -y install php-mysql mariadb maraidb-server# cd /usr/share/nginx/html# vim index.php&lt;?php $conn = mysql_connect(&apos;127.0.0.1&apos;,&apos;root&apos;,&apos;&apos;); if ($conn) echo succ else echo fail; mysql_close();?&gt;# 当LNMP 环境跑起来时，可以通匹配反像代理来实现动静分离;(1) root为同一路径;(2) root为不同路径; location \.php$&#123; root /web/app/wp; &#125; location / &#123; root /web/htdocs; &#125; (3) fpm server 为另一主机 ; location \.php$&#123; fastcgi_pass fastcgi://172.16.55.129:9000; &#125; location / &#123; root /web/htdocs; &#125;# 注: 如果动态内容能过缓存来进行加速的话，加速效果是非常明显示的;]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB NOSQL的使用、分布式搭建、切片存储]]></title>
    <url>%2F2018%2F04%2F17%2FMongoDB%20NoSQL%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[MongoDB NoSQL使用NoSQL: Not Only SQL 常用需求及实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980大数据问题: BigData 并行数据库系统，无共享体系结构中，采用关系结构模型，像MySQL的水平切片技术,分区查询; NoSQL数据库管理系统: 不是一种单一单纯的技术，非关系模型、分布式、不支持ACID数据库设计范式; 简单数据模型; 元数据和数据分离; 弱一致性; 高吞吐量; 高水平扩展能力和低端硬件集群; NewSQL数据库管理系统 相关产品: Clustrix、 GenleDB 、ScaleBase、NimbusDB、mysql(NDBCluster、Drizzle) 云数据管理系统: 相关产品: DBAAS,RDS大数据的分析处理: 常见的有MapReduce机制:将大的数据映射成键值对，而后对各各键值对处理后进行聚合; 而hadoop 就是类似于这种系统; habase也是NoSQL的一种; CAP: 强一致性;可用性;分区容错性(出现脑裂的时候可否处理业务需求); 最终一致性细分: 困果一致性; 读自己写一致性; 会话一致性; 单调读一致性; 时间轴一致性; ACID &amp; BASE Atomicity 原子性; Consistency 一致性; Isolation 隔离性 ; Durability 持久性; BASE 基本可用; ACID特性: 强一致性、隔离性、采用悲观保守的方法、难以变化; BASE特性: 弱一致性、可用性优先、采用乐观的方法、更简单、更快; 数据一致性的实现技术: NRW 2PC Paxos Vecotr Clock 数据存储模型: www.nosql-databases.org 列式存储模型 文档存储模型 键值数据模型 图式数据模型 列式模型: 应用场景: 在分布式文件系统之上提供支持随机读写分布式数据存储; 典型产品: HBase、Hypertable、Cassandra 数据模型: 以&quot;列&quot;为中心进行存储 ，将同一列数据存储在一起; 优点: 快速查询、高可扩展性、易于实现分布式扩展; 文档模型: 应用场景:非强事务需求的web应用; 典型产品:MongoDB、ElasticSearch(构建的搜索引擎工具)、CouchDB、CouchBase Server 数据模型: 键值模型，存储为文档; 优点: 数据模型无需事先定义 键值模型: 应用场景: 内容缓存，用于大量并行数据访问高载场景; 典型产品: Redis、DynamoDB、Riak、Redis; 数据模型: 基于哈希表实现的key-value模型; 优点: 查询迅速， 缺点：数据没有结构; 图式模型: 应用场景: 社交网络、推荐系统、关系图普 典型产品: Neo4J 、TITAN 、 Infinite Graph 数据模型: 图式结构 优点: 适应于图式计算场景MongoDB: NoSQL、文档存储、Json数据模型 适用场景: Websites Caching High volume, low value High scalability Storage of program objects and json 不适用场景: Hightly transactional Ad-hoc business intelligence Problems requiring SQL mongo 的安装与使用12345678910 # vim /etc/yum.repos.d/mongodb.repo [mongodb-org-3.4] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc# yum clean all# yum makeacahe# yum -y install mongodb-org server包生成的关键文件12345678# rpm -ql mongodb-org-server/etc/mongod.conf/lib/systemd/system/mongod.service/usr/bin/mongod/var/lib/mongo/var/log/mongodb/var/log/mongodb/mongod.log/var/run/mongodb shell包生成的关键文件12# rpm -ql mongodb-org-shell/usr/bin/mongo tools包生成的关键文件1234567891011# rpm -ql mongodb-org-tools/usr/bin/bsondump/usr/bin/mongodump/usr/bin/mongoexport/usr/bin/mongofiles/usr/bin/mongoimport/usr/bin/mongooplog/usr/bin/mongoperf/usr/bin/mongorestore/usr/bin/mongostat/usr/bin/mongotop server端配置项1# vim /etc/mongod.conf Mongo基本操作123456789101112131415help # 查看常用的使用帮助命令;db.help() # 查看对库操作的使用帮助;db.mycoll.cind().help()db.mycoll.help()show dbs # 查看目前存在哪些库;show collections # 列出列表;use testdb # 切换至哪个库，或者新建哪个库 db.status() #查看当前库的状态;db.version() # 查看当前库的版本;db.serverStatus() # 查看当前MongoDB服务的状态;show users # 查看当前存在哪些用户;show logs # 查看Mongo开启了哪些日志记录;user db.help() # 查寻帮助;db.getCollectionNames() # 查看列表名称;db.students.status() #查看某个库，某张表的状态; 12# Collection Query Criteria Modifierdb.users.find( &#123;age: &#123;$gt: 18&#125; &#125; ).sort( &#123;age: 1&#125; ) 123JSON: JavaScript Object Notation 名称/值对象的集合; 值的有序列表; 123456789db.students.inert( &#123;name:&quot;tome&quot;, age:23&#125; )show clollectionsshow dbsdb.statusdb.students.stats()db.getCollectionNames()db.students.insert([name:&apos;&apos;renjin&quot;,age:23,gender:&quot;M&quot;])db.students.find() db.students.insert([name:&quot;ssjinyao&quot;,Age:23,Course:&quot;PieXieJianFa&quot;]) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546find() 的高级用法: 比较操作: $gt, 语法格式&#123;filed: &#123;$gt VALUE&#125;&#125;db.statuents.find(&#123;Age:&#123;$gt 23&#125;&#125;) $gte $lt $lte $ne $in,语法格式&#123;filed: &#123;$in: [&apos;value&apos;]&#125;&#125;db.students.find&#123;Age:&#123;$in: [20,23]&#125;&#125;组合条件: 逻辑运算 $or: 或运算，语法格式&#123;$or: &#123;&lt;expression1&gt;,...&#125;&#125;db.students.find(&#123;$or: &#123;Age: &#123;$nin: [20,40], age &#123;$nin:[20,40]&#125;&#125;&#125;)db.students.find(&#123;$or: [&#123;Age: &#123;$nin: [20,40]&#125;&#125;, &#123;age: &#123;$nin: [20,40]&#125;&#125;]&#125;) $and: 与运算 $not: 非运算 $nor: 反运算,返回不符指定件的所有文档元素查询: 根据文档中是否存在指定的字段进行查询; $exists: 语法格式&#123;$filed:&#123;$exists:&lt;boolean&gt;&#125;&#125; db.students.find(&#123;gender: &#123;$exits: false&#125;&#125;) $mod: $type: 返回指定的字段的值的类型为指定类型的文档,语法格式&#123;field:&#123;$type: &lt;BSON type&gt;&#125;&#125; Double,String,Object, Arrary, Binary data, Undefined, Boolean,Data ,Null, Regular Expression, JavaScript, Timestamp更新操作: db.mycoll.update() $set: 修改字段的值为新指定的值: 语法格式&#123;filed: value&#125;, &#123;$set: &#123;filed: new_value&#125;&#125;) $unset: 删除指定字段;语法格式(&#123;filed: value&#125;, &#123;$unset:&#123;filed1, field2,....&#125;&#125;) db.students.update(&#123;name: &quot;renjin&quot;&#125;, &#123;$set: &#123;age: 22&#125;&#125;) $rename: 更改字段名,语法格式(&#123;$rename: &#123;oldname: newname, oldname: newname&#125;&#125;) db.students.update(&#123;$rename: &#123;age:Age&#125;) $inc删除操作: db.mycoll.remove(&lt;query&gt;,&lt;justOne&gt;) db.students.remove(&#123;age:21&#125;) db.students.findOne(&#123;Age: &#123;$gt:10&#125;&#125;)删除collection: db.mycoll.drop() db.studetns.drop()删除database: db.dropDatabase()php+mongodb php的mongo扩展 MongoDB Indexes and Administration索引类型: B+ Tree、hash、空间索引、全文索引 1234567891011121314151617MongoDB索引类型 单字段索引 组合索引(多字段索引) 多键索引 空间索引 文本索引 hash索引 hash 索引只支持精确值查找 db.people.ensureIndex(&#123; zipcode:1&#125;, &#123;background: ture&#125;) db.account.ensureIndex( &#123; username: 1 &#125; , &#123;unique: ture, dropDups: true &#125;) MongoDB与索引相关的方法: db.mycoll.ensureIndex(field[,options]) name、unique、dropDups、sparse db.mycoll.dropIndex(index_name) db.mycoll.dropIndexes() db.mycoll.getIndexes() db.mycoll.reIndex() mongodb 用for 循环来连续插入数据12345678910111213141516171819202122232425use testdbfor (i=1; i&lt;=1000;i++) db.students.insert(&#123;name:&quot;student&quot;+i, age:(i%120), address:&quot;#85 Wenhua Road, Zhengzhou, China&quot;&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d56c&quot;), &quot;name&quot; : &quot;student1&quot;, &quot;age&quot; : 1, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d56d&quot;), &quot;name&quot; : &quot;student2&quot;, &quot;age&quot; : 2, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d56e&quot;), &quot;name&quot; : &quot;student3&quot;, &quot;age&quot; : 3, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d56f&quot;), &quot;name&quot; : &quot;student4&quot;, &quot;age&quot; : 4, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d570&quot;), &quot;name&quot; : &quot;student5&quot;, &quot;age&quot; : 5, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d571&quot;), &quot;name&quot; : &quot;student6&quot;, &quot;age&quot; : 6, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d572&quot;), &quot;name&quot; : &quot;student7&quot;, &quot;age&quot; : 7, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d573&quot;), &quot;name&quot; : &quot;student8&quot;, &quot;age&quot; : 8, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d574&quot;), &quot;name&quot; : &quot;student9&quot;, &quot;age&quot; : 9, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d575&quot;), &quot;name&quot; : &quot;student10&quot;, &quot;age&quot; : 10, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d576&quot;), &quot;name&quot; : &quot;student11&quot;, &quot;age&quot; : 11, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d577&quot;), &quot;name&quot; : &quot;student12&quot;, &quot;age&quot; : 12, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d578&quot;), &quot;name&quot; : &quot;student13&quot;, &quot;age&quot; : 13, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d579&quot;), &quot;name&quot; : &quot;student14&quot;, &quot;age&quot; : 14, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d57a&quot;), &quot;name&quot; : &quot;student15&quot;, &quot;age&quot; : 15, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d57b&quot;), &quot;name&quot; : &quot;student16&quot;, &quot;age&quot; : 16, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d57c&quot;), &quot;name&quot; : &quot;student17&quot;, &quot;age&quot; : 17, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d57d&quot;), &quot;name&quot; : &quot;student18&quot;, &quot;age&quot; : 18, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d57e&quot;), &quot;name&quot; : &quot;student19&quot;, &quot;age&quot; : 19, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d57f&quot;), &quot;name&quot; : &quot;student20&quot;, &quot;age&quot; : 20, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;Type &quot;it&quot; for more&gt; it# mongo为了结省服务器资源，不会将所有的字段一下子列出来，而需要输入it来翻页查看，与more类似 在name 1 上构建升序索引1234567891011121314151617181920212223242526 db.students.ensureIndex(&#123;name: 1&#125;)&#123; &quot;createdCollectionAutomatically&quot; : false, &quot;numIndexesBefore&quot; : 1, &quot;numIndexesAfter&quot; : 2, &quot;ok&quot; : 1&#125; db.students.getIndexes()[ &#123; &quot;v&quot; : 2, &quot;key&quot; : &#123; &quot;_id&quot; : 1 &#125;, &quot;name&quot; : &quot;_id_&quot;, &quot;ns&quot; : &quot;testdb.students&quot; &#125;, &#123; &quot;v&quot; : 2, &quot;key&quot; : &#123; &quot;name&quot; : 1 &#125;, &quot;name&quot; : &quot;name_1&quot;, &quot;ns&quot; : &quot;testdb.students&quot; &#125;] 移除之前建立的索引12db.students.dropIndex(&quot;name_1&quot;)&#123; &quot;nIndexesWas&quot; : 2, &quot;ok&quot; : 1 &#125; 查看索引是否被移除1234567891011 db.students.getIndexes()[ &#123; &quot;v&quot; : 2, &quot;key&quot; : &#123; &quot;_id&quot; : 1 &#125;, &quot;name&quot; : &quot;_id_&quot;, &quot;ns&quot; : &quot;testdb.students&quot; &#125;] 建立维一键索引1234567891011121314151617181920212223242526272829db.students.ensureIndex(&#123;name: 1&#125;,&#123;unique: true&#125;)&#123; &quot;createdCollectionAutomatically&quot; : false, &quot;numIndexesBefore&quot; : 1, &quot;numIndexesAfter&quot; : 2, &quot;ok&quot; : 1&#125;&gt; &gt; &gt; db.students.getIndexes()[ &#123; &quot;v&quot; : 2, &quot;key&quot; : &#123; &quot;_id&quot; : 1 &#125;, &quot;name&quot; : &quot;_id_&quot;, &quot;ns&quot; : &quot;testdb.students&quot; &#125;, &#123; &quot;v&quot; : 2, &quot;unique&quot; : true, &quot;key&quot; : &#123; &quot;name&quot; : 1 &#125;, &quot;name&quot; : &quot;name_1&quot;, &quot;ns&quot; : &quot;testdb.students&quot; &#125;] 利用索引快速查询123db.students.find(&#123;name: &quot;student500&quot;&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;5acdb56cdf2f304c1068d75f&quot;), &quot;name&quot; : &quot;student500&quot;, &quot;age&quot; : 20, &quot;address&quot; : &quot;#85 Wenhua Road, Zhengzhou, China&quot; &#125;db.students.find(&#123;name: &quot;student500&quot;&#125;).explain() 查看索引执行过程1234567891011121314151617181920212223242526272829303132333435363738394041424344&#123; &quot;queryPlanner&quot; : &#123; &quot;plannerVersion&quot; : 1, &quot;namespace&quot; : &quot;testdb.students&quot;, &quot;indexFilterSet&quot; : false, &quot;parsedQuery&quot; : &#123; &quot;name&quot; : &#123; &quot;$eq&quot; : &quot;student500&quot; &#125; &#125;, &quot;winningPlan&quot; : &#123; &quot;stage&quot; : &quot;FETCH&quot;, &quot;inputStage&quot; : &#123; &quot;stage&quot; : &quot;IXSCAN&quot;, &quot;keyPattern&quot; : &#123; &quot;name&quot; : 1 &#125;, &quot;indexName&quot; : &quot;name_1&quot;, &quot;isMultiKey&quot; : false, &quot;multiKeyPaths&quot; : &#123; &quot;name&quot; : [ ] &#125;, &quot;isUnique&quot; : true, &quot;isSparse&quot; : false, &quot;isPartial&quot; : false, &quot;indexVersion&quot; : 2, &quot;direction&quot; : &quot;forward&quot;, &quot;indexBounds&quot; : &#123; &quot;name&quot; : [ &quot;[\&quot;student500\&quot;, \&quot;student500\&quot;]&quot; ] &#125; &#125; &#125;, &quot;rejectedPlans&quot; : [ ] &#125;, &quot;serverInfo&quot; : &#123; &quot;host&quot; : &quot;ssjinyao&quot;, &quot;port&quot; : 27017, &quot;version&quot; : &quot;3.4.14&quot;, &quot;gitVersion&quot; : &quot;fd954412dfc10e4d1e3e2dd4fac040f8b476b268&quot; &#125;, &quot;ok&quot; : 1&#125; Mongod的常用先项:123456789101112131415161718General option: 通用选项 fork = &#123;true|false&#125;: mongod是否运行在后台; bind_ip = IP: 指定监听的地址; port=PORT:指定监听的端口，默认为27017，httpd访问28017; maxConns=: 并发最大连接数; pidfilepath=: pid 文件位置; httpinterface=:内置httpd统计信息等; keyFile=:主从同步基于密钥的认证; auth: 是否开启认证功能; repair: 服务器意外重启，或未正重关闭时，要使用repair来修复; journal:是否启用日志功能; jounalCommit: 日志提交的时间间隔; cpu: 间断性的显示内存CPU的使用率; slowms arg: 超出指定值后采用慢查询; Replication options 复制选项Master/slvae options 主从复制选项Replica set options 复制集选项Sharding options 跟切片相关的选项 MongoDB的复制功能123456789101112131415161718192021222324252627282930313233343536373839两种类型: master/slave replica set: 复制集、副本集 两种类型: 主节点支持读写操作，而从节点仅支持读操作; 服务于同一数据集的多个mongodb实例; 主节点操作数据修改操作保存至oplog中; arbiter: 仲裁者，即便用不上三个节点，也添加三个节点，以避免脑裂;工作特性:至少三个，且应该为奇数据个节点;可以使用arbiter来参与选举; hertbeat(默认2s传递一次),自动失效转移(通过选举方式实现)复制集的中节点分类的集中类型: 0优先级的节点: 准备节点,这种节点不会选举成为主节点，但可以参与选举过程; 被隐藏的从节点: 首先是一个0优先级的从节点，且地客户端不可见; 延迟复制的从节点: 当在主节点误删除数据时，可以立即断开主从，可保留从节点上未改变的数据; 首先是一个0优先级的从节点，且复制时间落后于主节点一个固定时长; arbiter:MongoDB的复制架构: oplog heartbeat oplog: 大小固定的文件，存储在local数据库中; 即便从节点有aplog也不会使用; 初始同步(initial sync) 回滚后追赶(post-rollback catch-up) 切分块迁移(sharding chunk migrations) local: 存放了副本集的所有元数据和oplog: 用于存储aplog的是一个名为oplog.rs的collection aplog.rs 的大小依赖于OS 及文件系统 ; Mongo的数同步类型 : 初始同步: 节点没有任何数据时 节点丢失副本复制历史 复制 初始同步的步骤: 1、克隆所有数据; 2、应用数据集的所有改变，复制oplog并应用于本地; 3、为所有collection构建索引; Mongod 数据同步过程123456789初始同步: 节点没有任何数据 从节点丢失复本，复制历史数据;初始同步的步骤: 1、克隆所有数据库; 2、应用数据集的所有改变;复制oplog并应用在本地; 3、为所有的collection构建索引;这样初始同步就完成了;优于MySQL的地方， MongoDB 支持多线程复制功能; 12345# vim /etc/mongd.confreplSet=testSetreplIndexPrefetch=_id_only# systemctl mongod restart 123show dbsuse localshow collections 12345# node2的配置# 将需要安装的rpm 包复制到第二个节点上，或者在另一台服务器上配置mongo的yum源;# yum -y install mongodb-org-server# mkdir -pv /mongodb/data# chown -R mongod.mongod /mongodb 12345# node3的配置# 将需要安装的rpm 包复制到第三个节点上，或者在另一台服务器上配置mongo的yum源;# yum -y install mongodb-org-server# mkdir -pv /mongodb/data # chown -R mongod.mongod /mongodb 123# scp /etc/mongod.conf root@node2:/etc/ # scp /etc/mongod.conf root@node3:/etc/# 保证三个节点的配置文件一致，并将服务器启动; 1234567891011121314rs.conf()rs.status()rs.initiate()rs.status()rs.help() # 查找mongo的帮助文档，查看如何添加主机进来, rs. 主要指mongo的分布式配置;rs.add(&quot;172.16.55.128&quot;) # 在主节点的mongo中执行;show dbs # 从节点默认是不支持查询的，因此需要手动开启;# 在node2 节点中，将当前服务器节点改为从节点;rs.salveOK() rs.status()rs.isMaster() # 查看自己是否为主节点;# 因此，当服务器改为从节点之后可以在从节点上查询信息; # db.statudents.findOne(); 12345# 第三个节点rs.add(&quot;172.16.55.129&quot;) # 在主节点的mongo中执行# 在 node3 节点中，将当前服务器节点改为从节点；rs.salveOK()# 注要写数据的时候，还是要到主节点中支写; 1234567db.classes.insert(&#123;class: &quot;One&quot;, nostu: 40&#125;) # 尝试在主节点中插入数据;show collections # 这里主服务器对应的数据已经有了;db.classes.findOne() # 尝试在从服务器中查找数据，如查有数据，则说明数据同步没有问题;# 从节点中是不能写入数据;rs.stepDown() # 将主节点强制成为从节点;rs.status() # 可以看出，其中有一个节点会自动成为主节点;db.printReplicationInfo() # 查看产中事件的间时，大小; 副本集的重新先举的影响条件:12345心跳信息优先级optime网络连接网络分区 先举机制:1234567触发选举的事件 新副本集初始化时; 从节点联系不到主节点时; 主节点&quot;下台&quot;时; 主节点收到stepDown()命令时; 某从节点有更高的优先级且已经满足了成主节点的其它所有条件; 主节点无法联系到副本集的&quot;多数方&quot;； 1234567891011cfg= rs.conf() # 保存当前mongo的配置；cfg.member[1].priority=2rs.conf() # 这时的配置依然是1rs.reconfig(cfg) # 生效配置则必需要在主节点中进行;# 触发新的选举机制；cfg = rs.confg()cfg.member[2].abiterOnly=ture # 设置abiterOnly 属性;rs.reconfgi(cfg)rs.conf()rs.printSlaveReplicationInfo() # 同时也可以看是每个从节点是否落后于主节点; MongoDB的分片:12345678910111213141516171819sharding 分片 # 随着公司业务的分展，数据集会变的越来越大； # 会在某一个时刻，CPU，内存，IO 等单机上出现瓶颈; # 因此向上外向外扩展，向上扩展是经济形势的解决方案，而从技术角度，我们可以向外扩展;MySQL: Gizzard, HivedDB(独立的项目，转门来对MySQL来实现分片的)，MySQL Proxy + HSACLE, Hibernate Shared Pyshards # 分片架构中的角色: mongos: Router; config server: 元数据服务器; shard: 数据节点，也称mongod实例节点; 负责将数据存下来，并响应客户端的; zookeeper: 通常用于分布式节点的协调; # 基于范围切片 range # 基于列表切片 list # 基于hash切片 hash 写离散，读要集中 分片式架构配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# rm -rf /mongodb/data/ # 注: 在生产中，这个操作非常危险！需要将数据库用mongodump 备份；# 将mongodb 安装的rpm包，或者yum的配置文件用ansible 或scp 同步到其它四个节点上去;# 在四个节点将mongodb 相关软件包都安装好# 先要配置config server --&gt; mongos --&gt; Shard1 --&gt; Shard2-------------------------&gt; confiserver 服务器配置# vim /etc/mongod.conf# replSet=testSet# replIndexPrefetch=id_only # dbpath=/mongodb/dataconfigsvr=true# chown -R mongod.mongod /mongodb# install -o mongod -g mongod -d /mongodb/data # 建立数据库的元数据 ;# systemctl start mongod mongo # config server 默认监听在27019的端口上; -----------------------&gt; mongofs 服务器配置# yum -y insetall mongodb-org-mongos # # 启动 mongofs 节点# mongos --configdb=172.16.55.172.16.55.128 --fork --logpath=/var/log/mongodb/mongo.log# mongo --host 172.16.55.127helpsh.status() # 以下节点起动后sh.addShard(&quot;172.16.55.129&quot;)ss.addShard(&quot;172.16.55.120&quot;)sh.enableShareding(&quot;testdb&quot;) # 在testdb中启有shard功能;sh.help() # 查找shards集群相关的配置项;sh.enableSharding(dbname) # 在哪个节点起用sharding;sh.shardCollection(fullName,key,unique) # 在collection哪个键，索引上做sharding ;sh.shardCollection(&quot;students&quot;, &#123;&quot;age&quot; : 1 &#125;)sh.status() # 此时就可以查看分片信息了;use testdb;for (i=1; i&lt;=100000;i++) db.students.insert(&#123;name:&quot;studentt&quot;+i, age:(i%120),classes:&quot;class&quot;+(i%10),address:&quot;www.ssjinyao.com, Magedu, #85 WenhuaRoad, BeiJin, China&quot;&#125;) # 批量插入测试数据;use testdbdb.students.find().count()sh.status() # 可以看到分片存储的信息;db.databases.find(&quot;partitioned&quot;:true)db.runCommands(&quot;listShards&quot;)use admindb.runCommand(&quot;listShards&quot;)db.printShardingStatus()sh.isBalancerRunning() # 查看均衡器状态，它会在需要时自动启动;sh.getBalancerState() # 查看BlancerSate的状态;-----------------------&gt; Shard1 服务器配置# vim /etc/mongod.conf# replSet=testSet# replIndexPrefetch=id_only # 注释以上配置# dbpath=/mongodb/data# chown -R mongod.mongod /mongodb# systemctl start mongod-----------------------&gt; Shard2 服务器配置# vim /etc/mongod.conf# replSet=testSet# replIndexPrefetch=id_only # 注释以上配置# dbpath=/mongodb/data# chown -R mongod.mongod /mongodb# systemctl start mongod]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible 自动化运维]]></title>
    <url>%2F2018%2F04%2F09%2Fansible%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[ansible 自动化运维 运维工具12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849OS Provisioning: PXE, Cobbler(repository, distritution, profile) PXE: dhcp, tftp,(http,ftp) dnsmsq:dhcp,dnsOS Config: puppet, saltstack, func Task Excute: fabric, func,saltstackDeployment: fabric,运维工具分类: agent: puppet, func 这些工具必需要有agent端; agentless: ansible, fabirc 这些工具必需启用ssh服务;Properties: Minimal learning curve, auditability: 入门曲线非常平缓; No bootstrapping: 无需agent; No DAG ordering, Fails Fast: 没有次序; No agents(other than sshd) -o resource consumption when not in use: 没有代理; No Server: 也没有服务端； No additional PKI : 无需证书等功能; Modules in any language: 模块可以使用任意编程语言来编写; YAML, not code: 使用yaml配置文件; SSH by default: 使用ssh默认接口; Strong multi-tier solution: 支持多级使用方案;Host Inventory: 定义可被 ansible管控的主机; Core Modules: 可被调用的核心模块，可以完成大部作的任务;Custom Modules: 自定义模块，当ansible实现不了时，可以使用任意编程语言来编写模块;Connection Plugins: ansible 可以支持一些插件来实现一些功能，如发送邮件功能;ansible的核心线件: ansible core host iventory core modules custom modules playbook (yaml, jinjia2) connect pluginansible特性: 基于Python语言实现，由Paramiko模块实现，PyYAML和Jinia2 三个关键的模块构建python特性:,agentless; 默认使用SSH协议: 会有安全隐患; 基于密钥认证来连接到各节点操作; 主从模式: master: ansible, ssh client; savle: ssh server结点; 支持自定义模块:支持各种编程语言; 支持Playbook 基于&quot;模块&quot;完成各种&quot;任务&quot;; ansible 的安装和使用12345678910111213141516171819202122232425# ansible 在于epel源中# yum list all *ansible*ansible.noarch 2.4.2.0-2.el7 @extras# 安装依赖于epel源 配置文件 /etc/ansible/ansible.cfg Invertory: /etc/ansible/hosts# vim /etc/ansible # 保留以下配置[dbserver]172.16.55.123[webserver]172.16.55.124172.1655.125# 在ansible主机生成一组密钥# ssh-keygen# 实现双机互信# for i in &#123;3..5&#125; ; do ssh-copy-id -i ~/.ssh/id_rsa.pub root@172.16.55.12$i; done# for i in &#123;3..5&#125; ; do ssh root@172.16.55.12$i &quot;date&quot; &amp;&amp; echo &quot;The Messages From 172.16.55.12$i&quot;; done2018年 04月 09日 星期一 09:47:09 CSTThe Messages From 172.16.55.1232018年 04月 09日 星期一 09:47:10 CSTThe Messages From 172.16.55.1242018年 04月 09日 星期一 09:47:10 CSTThe Messages From 172.16.55.125# 此时ansbile所在的服务器可以实现对各结点的控制 asnbile-doc 的使用1234# ansible-doc # 用来查看asnbile 模块的使用查询;# ansible-doc -l # 例出所有可用的模块; # ansible-doc -s MODULE_NAME; # 查看某个模块的使用用法;# ansible-doc -s yum ansible命令的应用基础12345ansible命令应用基础: 语法: ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args] -f forks: 启动的并发线程数; -m module_name: 要使用的模块; -a args: 模块特有的参数; 常见的模块:command: 命令模块，默认模块，用于在远程命令;123456789101112131415161718192021222324252627282930# ansible 172.16.55.124 -m command -a &quot;date&quot;172.16.55.124 | SUCCESS | rc=0 &gt;&gt;2018年 04月 09日 星期一 09:57:39 CST# ansible dbserver -m command -a &quot;date&quot; 172.16.55.123 | SUCCESS | rc=0 &gt;&gt;2018年 04月 09日 星期一 09:58:02 CST# ansible all -m command -a &quot;date&quot; 172.16.55.124 | SUCCESS | rc=0 &gt;&gt;2018年 04月 09日 星期一 09:58:24 CST172.16.55.123 | SUCCESS | rc=0 &gt;&gt;2018年 04月 09日 星期一 09:58:24 CST172.16.55.125 | SUCCESS | rc=0 &gt;&gt;2018年 04月 09日 星期一 09:58:32 CST# ansible all -m command -a &quot;tail -2 /var/log/messages&quot;172.16.55.124 | SUCCESS | rc=0 &gt;&gt;Apr 9 09:58:24 fabric1 ansible-command: Invoked with warn=True executable=None _uses_shell=False _raw_params=date removes=None creates=None chdir=None stdin=NoneApr 9 09:59:22 fabric1 ansible-command: Invoked with warn=True executable=None _uses_shell=False _raw_params=tail -2 /var/log/messages removes=None creates=None chdir=None stdin=None172.16.55.123 | SUCCESS | rc=0 &gt;&gt;Apr 9 09:58:24 hyperledger ansible-command: Invoked with warn=True executable=None _uses_shell=False _raw_params=date removes=None creates=None chdir=None stdin=NoneApr 9 09:59:23 hyperledger ansible-command: Invoked with warn=True executable=None _uses_shell=False _raw_params=tail -2 /var/log/messages removes=None creates=None chdir=None stdin=None172.16.55.125 | SUCCESS | rc=0 &gt;&gt;Apr 9 09:58:31 fabric2 ansible-command: Invoked with warn=True executable=None _uses_shell=False _raw_params=date removes=None creates=None chdir=None stdin=NoneApr 9 09:59:23 fabric2 ansible-command: Invoked with warn=True executable=None _uses_shell=False _raw_params=tail -2 /var/log/messages removes=None creates=None chdir=None stdin=None cron 模块:可以使被管理节点自动生成一生任务计划;state所有属性: present: 安装 absent: 移除 12345678910111213141516171819202122 */10 * * * * /bin/echo &quot;Test Message&quot;# ansible webserver -m cron -a &apos;minute=&quot;*/10&quot; job=&quot;/bin/echo Test Message&quot; name=&quot;Test Cron Job&quot;&apos; 172.16.55.124 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;Test Cron Job&quot; ]&#125;172.16.55.125 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;Test Cron Job&quot; ]&#125;# 执行完之后登录以上的某一台服务器进行验证# crontab -l#Ansible: Test Cron Job*/10 * * * * /bin/echo Test Message# ansible webserver -m cron -a &apos;minute=&quot;*/10&quot; job=&quot;/bin/echo Test Message&quot; name=&quot;Test Cron Job&quot; state=&quot;absent&quot;&apos;# 将以上建立的定时任务计划移除 user模块: 用于建立用户；name=: 指明需要建立用户的用户名; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# ansible all -m user -a &apos;user=&quot;user1&quot;&apos;172.16.55.124 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;createhome&quot;: true, &quot;group&quot;: 1001, &quot;home&quot;: &quot;/home/user1&quot;, &quot;name&quot;: &quot;user1&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: false, &quot;uid&quot;: 1001&#125;172.16.55.123 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;createhome&quot;: true, &quot;group&quot;: 1001, &quot;home&quot;: &quot;/home/user1&quot;, &quot;name&quot;: &quot;user1&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: false, &quot;uid&quot;: 1001&#125;172.16.55.125 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;createhome&quot;: true, &quot;group&quot;: 1001, &quot;home&quot;: &quot;/home/user1&quot;, &quot;name&quot;: &quot;user1&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: false, &quot;uid&quot;: 1001&#125;# 验证是否创建了用户# id user1# 将以上建立的用户删除# ansible all -m user -a &apos;user=&quot;user1&quot; state=&quot;absent&quot;&apos;# 创建系统用户系统组# ansible all -m group -a &apos;name=&quot;mysql&quot; gid=&quot;306&quot; system=&quot;yes&quot;&apos; # ansible all -m user -a &apos;name=&quot;mysqld&quot; uid=&quot;306&quot; group=&quot;mysql&quot; system=&quot;yes&quot;&apos; 172.16.55.123 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;createhome&quot;: true, &quot;group&quot;: 306, &quot;home&quot;: &quot;/home/mysqld&quot;, &quot;name&quot;: &quot;mysqld&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: true, &quot;uid&quot;: 306&#125;172.16.55.125 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;createhome&quot;: true, &quot;group&quot;: 306, &quot;home&quot;: &quot;/home/mysqld&quot;, &quot;name&quot;: &quot;mysqld&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: true, &quot;uid&quot;: 306&#125;172.16.55.124 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;createhome&quot;: true, &quot;group&quot;: 306, &quot;home&quot;: &quot;/home/mysqld&quot;, &quot;name&quot;: &quot;mysqld&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: true, &quot;uid&quot;: 306&#125; copy模块: 用于文件的远程传输; src=: 定义本地源文件路径; dest=: 定义远程目标文件路径，但不支持绝对路径; content=: 取代src=,表示直接用此处指定的信息生成目标文件, 但这里要注意的是，会把节点主机的源文件覆盖，类似于 echo &gt; /path/to/file 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# ansible all -m copy -a &apos;src=/etc/fstab dest=/tmp/fstab.ansible owner=root mode=&quot;640&quot;&apos; 172.16.55.123 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;3858e5b009a8c0828cb529780a2ad547411d8d94&quot;, &quot;dest&quot;: &quot;/tmp/fstab.ansible&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;01ea40602497b8cfe5a53743054fa04d&quot;, &quot;mode&quot;: &quot;0640&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 541, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1523241179.42-225211025896206/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;172.16.55.125 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;3858e5b009a8c0828cb529780a2ad547411d8d94&quot;, &quot;dest&quot;: &quot;/tmp/fstab.ansible&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;01ea40602497b8cfe5a53743054fa04d&quot;, &quot;mode&quot;: &quot;0640&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;secontext&quot;: &quot;unconfined_u:object_r:admin_home_t:s0&quot;, &quot;size&quot;: 541, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1523241179.42-108291746173038/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;172.16.55.124 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;3858e5b009a8c0828cb529780a2ad547411d8d94&quot;, &quot;dest&quot;: &quot;/tmp/fstab.ansible&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;01ea40602497b8cfe5a53743054fa04d&quot;, &quot;mode&quot;: &quot;0640&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 541, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1523241179.35-169240840464627/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;# ansible all -m copy -a &apos;content=&quot;Hellow Ansible\nWelcome to ssjinyao\n&quot; dest=&quot;/tmp/ssjinyao&quot;&apos;172.16.55.123 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;06759ebeeffb1ec2ba32b71d0440258a2ec812ca&quot;, &quot;dest&quot;: &quot;/tmp/ssjinyao&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;7da4c3d419470482101fa8cfa338c882&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 35, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1523241579.59-247115936338069/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;172.16.55.124 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;06759ebeeffb1ec2ba32b71d0440258a2ec812ca&quot;, &quot;dest&quot;: &quot;/tmp/ssjinyao&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;7da4c3d419470482101fa8cfa338c882&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 35, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1523241579.53-265190945061484/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;172.16.55.125 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;06759ebeeffb1ec2ba32b71d0440258a2ec812ca&quot;, &quot;dest&quot;: &quot;/tmp/ssjinyao&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;7da4c3d419470482101fa8cfa338c882&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;secontext&quot;: &quot;unconfined_u:object_r:admin_home_t:s0&quot;, &quot;size&quot;: 35, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1523241579.58-230356470158720/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;# cat /tmp/ssjinyao Hellow AnsibleWelcome to ssjinyao file: 用于设定文件属性; path=: 指定文件路径, 可以使用name 或dest来替换; 创建文件的符号链接; src=:指明源文件; path=: 指明符号链接文件路径; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# ansible all -m file -a &apos;owner=&quot;mysql&quot; group=&quot;mysql&quot; mode=&quot;644&quot; path=&quot;/tmp/ssjinyao&quot;&apos; 172.16.55.123 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;gid&quot;: 306, &quot;group&quot;: &quot;mysql&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;mysql&quot;, &quot;path&quot;: &quot;/tmp/ssjinyao&quot;, &quot;size&quot;: 35, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 27&#125;172.16.55.124 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;gid&quot;: 306, &quot;group&quot;: &quot;mysql&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;mysql&quot;, &quot;path&quot;: &quot;/tmp/ssjinyao&quot;, &quot;size&quot;: 35, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 27&#125;172.16.55.125 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;gid&quot;: 306, &quot;group&quot;: &quot;mysql&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;mysql&quot;, &quot;path&quot;: &quot;/tmp/ssjinyao&quot;, &quot;secontext&quot;: &quot;unconfined_u:object_r:admin_home_t:s0&quot;, &quot;size&quot;: 35, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 27&#125;# ansible all -m file -a &apos;path=&quot;/tmp/ssjinyao.link&quot; src=&quot;/tmp/ssjinyao&quot; state=&quot;link&quot;&apos;172.16.55.123 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;dest&quot;: &quot;/tmp/ssjinyao.link&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0777&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 13, &quot;src&quot;: &quot;/tmp/172.16&quot;, &quot;state&quot;: &quot;link&quot;, &quot;uid&quot;: 0&#125;172.16.55.124 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;dest&quot;: &quot;/tmp/ssjinyao.link&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0777&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 13, &quot;src&quot;: &quot;/tmp/ssjinyao&quot;, &quot;state&quot;: &quot;link&quot;, &quot;uid&quot;: 0&#125;172.16.55.125 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;dest&quot;: &quot;/tmp/ssjinyao.link&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0777&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;secontext&quot;: &quot;unconfined_u:object_r:user_tmp_t:s0&quot;, &quot;size&quot;: 13, &quot;src&quot;: &quot;/tmp/ssjinyao&quot;, &quot;state&quot;: &quot;link&quot;, &quot;uid&quot;: 0&#125; ping: 测试远程主机的连接性;12345678910111213# ansible all -m ping 172.16.55.123 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.55.124 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.55.125 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; service: 指定运行状态; enabled=: 是否开机自动启动; name =: 服务名称; state =: 状态，取值有started, stopped, restarted; 1# ansible webserver -m service -a &quot;enabled=true name=httpd state=started&quot; shell: 在远程主机运行命令;尤其是用到管道等复杂命令 123456789101112# ansible all -m shell -a &apos;echo &quot;xxxxxxxx&quot; | passwd --stdin user1 &apos; 172.16.55.123 | SUCCESS | rc=0 &gt;&gt;更改用户 user1 的密码 。passwd：所有的身份验证令牌已经成功更新。172.16.55.124 | SUCCESS | rc=0 &gt;&gt;更改用户 user1 的密码 。passwd：所有的身份验证令牌已经成功更新。172.16.55.125 | SUCCESS | rc=0 &gt;&gt;更改用户 user1 的密码 。passwd：所有的身份验证令牌已经成功更新。 script: 将本地脚本复制到远程主机上并运行之;注意: 要使用相对路径指定脚本; 12345678910111213141516171819202122232425262728293031323334353637# cat test.sh #!/bin/bashsum=0for i in &#123;1..100&#125;; do sum=$[$sum+$i]done echo $sum # chmod +x test.sh # ansible all -m script -a &quot;/tmp/test.sh&quot;172.16.55.123 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;rc&quot;: 0, &quot;stderr&quot;: &quot;Shared connection to 172.16.55.123 closed.\r\n&quot;, &quot;stdout&quot;: &quot;5050\r\n&quot;, &quot;stdout_lines&quot;: [ &quot;5050&quot; ]&#125;172.16.55.124 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;rc&quot;: 0, &quot;stderr&quot;: &quot;Shared connection to 172.16.55.124 closed.\r\n&quot;, &quot;stdout&quot;: &quot;5050\r\n&quot;, &quot;stdout_lines&quot;: [ &quot;5050&quot; ]&#125;172.16.55.125 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;rc&quot;: 0, &quot;stderr&quot;: &quot;Shared connection to 172.16.55.125 closed.\r\n&quot;, &quot;stdout&quot;: &quot;5050\r\n&quot;, &quot;stdout_lines&quot;: [ &quot;5050&quot; ]&#125; yum: 安装程序包; name=: 指明要安装的程序包，可以带上版本号; state=: present, latest表示安装，absent表示卸载; 12# ansible all -m yum -a &apos;name=&quot;zsh&quot; state=&quot;present&quot;&apos;# ansible all -m yum -a &apos;name=&quot;zsh&quot; state=&quot;absent&quot;&apos; setup: 收集远程主机的facts; 每个被管理节点在接收并运行管理命令之前，会将自己主机相关信息； 如操作系统版本、IP地址等报告给远程的ansible主机; 12# 查看远程节点的服务器信息，方便我们调用配置# ansible all -m setup ansible-playbook(剧本) 的使用playbook的核心元素; taskfs:任务 variadble: 变量 templates: 模板 handlers: 处理器 roles:角色 YAML 介绍;1234567891011121314YAML 是一个可读性高的用来表达资料序列的格式，YAML参考了其他多处语言;包括:XML、C语言、Python、Perl以及电子邮件格式等Clark Evans在2001年首次发表了这种语言YAML Ain&apos;t Markup Language, 即YAML不是XML。不过，在开发的这种语言时;YAML的意思其实是:&quot;Yet Another Markup Language(仍是一种标记语言)。&quot;其特性:YAML的可读性好YAML 和脚本语言的交互性好YAML 使用实现语言的数据类型YAML 有一个一致的信息模型YAML 易于实现YAML 可以基于流来处理YAML 表达能力强，扩展性好 12YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构; 其结构(Structure)通过空格来展示，序列(Sequence)里的项用&quot;-&quot;来代表，Map里的键值用&quot;;&quot;分隔 ansible变量:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111变量命名 变量名仅能由字母、数字和下划线组成，且只能以字母开头; facts facts是由正在通信的远程目标主机发回的信息，这些信息被保存在ansible变量中; 要获取指定的远程主机所支持的所有facts，可使用如下命令进行;# ansible hostname -m setupregister把任务的输出定义为变量，然后用于其他任务，示例如下: tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True - hosts: websrvs remote_user: root tasks: - name: copy file copy: content=&quot;&#123;&#123; ansible_all_ipv4_address &#125;&#125;&quot; dest=/tmp/var.dns通过命令行传递变量在运行playbook的时候也可以传递一些变量供playbook使用，示例如下： ansible-playbook test.yml --extra-vars &quot;hosts=www user=ssjinyao&quot;通过roles传递变量当给一个主机应用角色的时候可以传递变量，然后在角色内使用这些变量，示例如下： - hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: &apos;/web/htdocs/a.com&apos;, port: 8080 &#125;Inventory ansible的主要功用在于批量主机操作，为了便捷地使用其中的部分主机; 可以在inventory file中将其分组命名，默认的inventory file为/etc/ansible/hosts; inventory file可以有多个，且也可以通过Dynamic Inventory来动态生成;inventory文件格式 inventory文件遵循INI文件风格，中括号中的字符为组名; 可以将同一个主机同时归并到多个不同的组中； 此外，当如若目标主机使用了非默认的SSH端口，还可以在主机名称之后使用冒号加端口号来标明; [webservers] web1.ssjinyao.com:25181 web2.ssjinyao.com [dbservers] db1.ssjinyao db2.ssjinyao.com db3.ssjinyao.com 如果主机名称遵循相似的命名模式，还可以使用列表的方式标识各主机，例如： [webservers] www[01:50].ssjinyao.com [databases] db-[a:f].ssjinyao.com主机变量 可以在inventory中定义主机时为其添加主机变量以便于在playbook中使用。例如： [webservers] web1.ssjinyao.com http_port=80 maxRequestsPerChild=808 web2.ssjinyao.com http_port=8080 maxRequestsPerChild=909组变量 组变量是指赋予给指定组内所有主机上的在playbook中可用的变量。例如： [webservers] web1.ssjinyao.com web2.ssjinyao.com [webservers:vars] ntp_server=web1.ssjinyao.com nfs_server=web2.ssjinyao.com组嵌套 在inventory中组还可以包含其它的组，并且也可以向组中的主机指定变量; 不过，这些变量只能在ansible-playbook中使用，而ansible不支持; [apache]httpd1.ssjinyao.comhttpd2.ssjinyao.com[nginx]nginx1.ssjinyao.comnginx2.ssjinyao.com[webservers:children]apachenginx[webservers:vars]ntp_server=ntp.ssjinyao.com inventory参数 ansible基于ssh连接inventory中指定的远程主机时，还可以通过参数指定其交互方式；这些参数如下所示： ansible_ssh_host The name of the host to connect to, if different from the alias you wish to give to it. ansible_ssh_port The ssh port number, if not 22 ansible_ssh_user The default ssh user name to use. ansible_ssh_pass The ssh password to use (this is insecure, we strongly recommend using --ask-pass or SSH keys) ansible_sudo_pass The sudo password to use (this is insecure, we strongly recommend using --ask-sudo-pass) ansible_connection Connection type of the host. Candidates are local, ssh or paramiko. The default is paramiko before Ansible 1.2, and &apos;smart&apos; afterwards which detects whether usage of &apos;ssh&apos; would be feasible based on whether ControlPersist is supported. ansible_ssh_private_key_file Private key file used by ssh. Useful if using multiple keys and you don&apos;t want to use SSH agent.ansible_shell_type The shell type of the target system. By default commands are formatted using &apos;sh&apos;-style syntax by default. Setting this to &apos;csh&apos; or &apos;fish&apos; will cause commands executed on target systems to follow those shell&apos;s syntax instead. ansible_python_interpreter The target host python path. This is useful for systems with more than one Python or not located at &quot;/usr/bin/python&quot; such as \*BSD, or where /usr/bin/python is not a 2.X series Python. We do not use the &quot;/usr/bin/env&quot; mechanism as that requires the remote user&apos;s path to be set right and also assumes the &quot;python&quot; executable is named python, where the executable might be named something like &quot;python26&quot;. ansible\_\*\_interpreter Works for anything such as ruby or perl and works just like ansible_python_interpreter. This replaces shebang of modules which will run on that host. 条件测试如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试; when语句在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法 123456789101112131415161718192021222324 - name: &quot;shutdown Debian flavored systems&quot; command: /sbin/shutdown -h now when: ansible_os_family == &quot;Debian&quot;# when语句中还可以使用Jinja2的大多“filter”;# 例如要忽略此前某语句的错误并基于其结果（failed或者sucess）运行后面指定的语句tasks: - command: /bin/false register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped- hosts: all remote_user: root vars: - username: user10 tasks: - name: create &#123;&#123; username &#125;&#125; user user: name=&#123;&#123;username&#125;&#125; when: ansible_fqdn == &quot;fabric2&quot;# when语句中还可以使用facts或playbook中定义的变量; 迭代123456789101112131415161718# 当有需要重复性执行的任务时，可以使用迭代机制;# 其使用格式为将需要迭代的内容定义为item变量引用，并通过with_items语句来指明迭代的元素列表- name: add several users user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel with_items: - testuser1 - testuser2# 上面语句功能等同于下面语句的功能- name: add user testuser1 user: name=testuser1 state=present groups=wheel- name: add user testuser2 user: name=testuser2 state=present groups=wheel# with_items中可以使用元素还可为hashes- name: add several users user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_items: - &#123; name: &apos;testuser1&apos;, groups: &apos;wheel&apos; &#125; - &#123; name: &apos;testuser2&apos;, groups: &apos;root&apos; &#125; Host和User1234567891011121314151617# playbook中的每一个play的目的都是为了让某个或某些主机以某个指定的用户身份执行任务;# hosts用于指定要执行指定任务的主机，其可以是一个或多个由冒号分隔主机组# remote_user则用于指定远程主机上的执行任务的用户; -hosts: webnodes remote_user: root# remote_user也可用于各task中;# 也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务;# 可以在sudo时使用sudo_user指定sudo时切换的用户。 - hosts: webnodes remote_user: ssjinyao tasks: - name: test connection ping: remote_user: ssjinyao sudo: yes 任务列表与action1234567891011121314151617181920212223242526# play的主体部分是task list;# task list中的各任务按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个任务后再开始第二个# 在运行自下而下某playbook时，如果中途发生错误，所有已执行任务都将回滚，因此，在更正playbook后重新执行一次即可;# task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量;# 模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致;# 每个task都应该有其name，用于playbook的执行结果输出;# 建议其内容尽可能清晰地描述任务执行步骤,如果未提供name，则action的结果将用于输出。# 定义task的可以使用“action: module options”或“module: options”的格式，推荐使用后者以实现向后兼容;# 如果action一行的内容过多，也中使用在行首使用几个空白字符进行换行。 tasks: - name: make sure apache is running service: name=httpd state=running# 在众多模块中，只有command和shell模块仅需要给定一个列表而无需使用“key=value”格式，例如： tasks: - name: disable selinux command: /sbin/setenforce 0# 如果命令或脚本的退出码不为零，可以使用如下方式替代： tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true# 或者使用ignore_errors来忽略错误信息： tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True handlers12345678910111213141516# 用于当关注的资源发生变化时采取一定的操作;# “notify”这个action可用于在每个play的最后被触发;# 这样可以避免多次有改变发生时每次都执行指定的操作，取而代之;# 仅在所有的变化发生完成后一次性地执行指定操作;# 在notify中列出的操作称为handler，也即notify中调用handler中定义的操作; - name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: - restart memcached - restart apache # handler是task列表，这些task与前述的task并没有本质上的不同; handlers: - name: restart memcached service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted roles12345678910111213141516171819202122232425262728293031323334353637383940414243444546# ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook;# roles能够根据层次型结构自动装载变量文件、tasks以及handlers等;# 要使用roles只需要在playbook中使用include指令即可;# roles就是通过分别将变量、文件、任务、模块及处理器放置于单独的目录中;# 并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中; 一个roles的案例如下所示： site.yml webservers.yml fooservers.yml roles/ common/ files/ templates/ tasks/ handlers/ vars/ meta/ webservers/ files/ templates/ tasks/ handlers/ vars/ meta/而在playbook中，可以这样使用roles： --- - hosts: webservers roles: - common - webservers 也可以向roles传递参数，例如： --- - hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: &apos;/opt/a&apos;, port: 5000 &#125; - &#123; role: foo_app_instance, dir: &apos;/opt/b&apos;, port: 5001 &#125; 甚至也可以条件式地使用roles，例如： --- - hosts: webservers roles: - &#123; role: some_role, when: &quot;ansible_os_family == &apos;RedHat&apos;&quot; &#125; 创建role的步骤 创建以roles命名的目录； 在roles目录中分别创建以各角色名称命名的目录，如webservers等； 在每个角色命名的目录中分别创建files、handlers、meta、tasks、templates和vars目录； 用不到的目录可以创建为空目录，也可以不创建； 在playbook文件中，调用各角色； role内各目录中可用的文件 tasks目录：至少应该包含一个名为main.yml的文件，其定义了此角色的任务列表；此文件可以使用include包含其它的位于此目录中的task文件; files目录：存放由copy或script等模块调用的文件; templates目录：template模块会自动在此目录中寻找Jinja2模板文件; handlers目录：此目录中应当包含一个main.yml文件，用于定义此角色用到的各handler；在handler中使用include包含的其它的handler文件也应该位于此目录中; vars目录：应当包含一个main.yml文件，用于定义此角色用到的变量; meta目录：应当包含一个main.yml文件，用于定义此角色的特殊设定及其依赖关系; ansible 1.3及其以后的版本才支持; default目录：为当前角色设定默认变量时使用此目录；应当包含一个main.yml文件; Tags1234tags用于让用户选择运行或路过playbook中的部分代码;ansible具有幂等性，因此会自动跳过没有变化的部分;有些代码为测试其确实没有发生变化的时间依然会非常地长;此时，如果确信其没有变化，就可以通过tags跳过此些代码片断。 目录名同角色名; 目录结构有固定格式; files: 表态文件; templates: Jinjia2模板文件; tasks:至少有main.yml文件，定义各tasks; handlers: 至少有一个main.yml文件，定义各handlers; vars:至少有一个mian.yml文件，定义变量; meta:定义依赖关系等信息; site.yml中定义playbook，额外也可以有其它的yml文件; ansible-playbook使用示例在webserver中执行简单管理类命令12345678910111213test.yml - hosts: webserver remote_user: root tasks: - name: create nginx group group: name=nginx system=yes gid=208 - name: create nginx user user: name=nginx uid=208 group=nginx system=yes- hosts: dbserver remote_user: root tasks: - name: copy file to db_servers copy: src=/etc/inittab dest=/tmp/inittab.ans## ansible-playbook test.yml heartbeat 部署12345678910111213141516171819heartbeat.yaml- hosts: hbhosts remote_user: root tasks: - name: ensure heartbeat latest version yum: name=heartbeat state=present - name: authkeys configure file copy: src=/root/hb_conf/authkeys dest=/etc/ha.d/authkeys - name: authkeys mode 600 file: path=/etc/ha.d/authkeys mode=600 notify: - restart heartbeat - name: ha.cf configure file copy: src=/root/hb_conf/ha.cf dest=/etc/ha.d/ha.cf notify: - restart heartbeat handlers: - name: restart heartbeat service: name=heartbeat state=restarted 系统环境初始化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137--- - hosts: all tasks: - name: Add mongodb 3.4 yum repo template: src=./yum/mongo34.repo dest=/etc/yum.repos.d/ - name: Yum remove old mongodb yum: name=mongodb state=removed update_cache=true - name: Yum install mongodb 3.4 yum: name=mongodb-org state=installed update_cache=true - name: Mongo shell edit shell: | killall mongod echo &apos;never&apos; &gt; /sys/kernel/mm/transparent_hugepage/enabled echo &apos;never&apos; &gt; /sys/kernel/mm/transparent_hugepage/defrag - name: start mongodb service: name=mongod state=restarted - name: Create mongo user and passwd admin xxxxxx mongodb_user: name: &quot;admin&quot; password: &quot;xxxxxxssjinyao.com&quot; database: &quot;admin&quot; roles: &quot;userAdminAnyDatabase&quot; state: &quot;present&quot; yum: name=mod_ssl state=installed update_cache=true - name: Install git yum: name=git state=installed update_cache=true - name: Install tree yum: name=tree state=installed update_cache=true - name: Install any packages yum: name=&#123;&#123;item&#125;&#125; state=installed update_cache=true with_items: - libffi - libffi-devel - openssl - openssl-devel - libxml2 - libxml2-devel - libjpeg-turbo - libjpeg-turbo-devel - name: Install any packages2 yum: name=&#123;&#123;item&#125;&#125; state=installed update_cache=true with_items: - zlib - zlib-devel - vim - httpd - mariadb-server - redis - php - php-intl - php-pear - php-devel - libicu - libicu-devel - git - centos-release-scl - name: Install any packages3 yum: name=&#123;&#123;item&#125;&#125; state=present update_cache=true with_items: - python-pip - python-devel - gcc - gcc-c++ - kernel-devel - make - MySQL-python - php-mysql - php-gd - mysql-devel - libcurl - libcurl-devel - python-lxml - name: Install any packages4 yum: name=&#123;&#123;item&#125;&#125; state=present update_cache=true with_items: - php55 - php-pecl-mongo - php55-php - php55-php-gd - php55-php-mbstring - php55-php-devel - php55-php-mysqlnd - php55-php-ldap - php55-php-intl - php55-php-pear - php55-php-mongo - unzip - name: Install any packages5 other, you can add yum: name=&#123;&#123;item&#125;&#125; state=present update_cache=true with_items: - readline-devel - patch - name: Copy php-55 config file to etc copy: remote_src=True src=/opt/rh/httpd24/root/etc/httpd/conf.d/php55-php.conf dest=/etc/httpd/conf.d/ - name: Copy php-55 httpd modules to etc copy: remote_src=True src=/opt/rh/httpd24/root/etc/httpd/conf.modules.d/10-php55-php.conf dest=/etc/httpd/conf.d/ - name: Copy php-55 httpd moduels to etc copy: remote_src=True src=/opt/rh/httpd24/root/etc/httpd/modules/libphp55-php5.so dest=/etc/httpd/modules/ - name: pip install any packages pip: name=&#123;&#123;item&#125;&#125; state=present with_items: - supervisor - virtualenv - celery - flower - mongo - redis - name: echo a messages shell: | ifconfig &amp;&gt; /tmp/test.ifconfig netstat -ant &amp;&gt; /tmp/test.netstat exit 0 notify: - start nginx - name: Add redis config file template: src=./redis/redis.conf dest=/etc/ - name: start redis service: name=redis state=started - name: stop apache service: name=httpd state=stopped handlers: - name: start nginx service: name=nginx state=started - name: restart httpd service: name=httpd state=restarted]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控实现文档]]></title>
    <url>%2F2018%2F04%2F02%2Fzabbix%E9%85%8D%E7%BD%AE%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[Zabbix 监控实现文档 理论知识了解123456789101112131415传感器;数据采集 --&gt; 数据存储 --&gt; 数据展示; 报警: 采集到的数据超出阈值时，通常会执行报警操作; 时间序列数据;大规模的监控: 开源监控工具: Nagios有两种结点类型: NMS(网络监控系统)，周期性的完成数据采集,且最重要的是要完成存储，不仅仅是主机。更重要的路由器; SNMP 对其它物理设备进行监控, Simple Network Management Protocol 一般而言要对其它结点中安装agent端; SNMP的工作模式: NMS向agent采集数据; agent向NMS报告数据; NMS请求agent修改配置; SNMP的组件MIB: management information base;SMI: MIB表示符号;SNMP协议中的 NMS;SNMP协议的版本; 123v1,v2,v3v2c:NMS --&gt; agentv3:认证、加密、 解密 NMS 可以发起的操作: 12345678910111213141516Get, GetNext，Set, Trap(捕获);agent: Response,返回一个或者多个值;UDP NMS:161端口 agent:162端口;cacti: 可以调用编程接口，利用SNMP，即时绘制展示图形;cacti: 报警能力是非常弱的; 万一服务莫名奇妙的的关闭了，可以尝试启动服务，启动不了后再执行报警操作; 为避免误判，应要多次采样;Nagios: 可以调用各种报警工具来执行报警操作; 报警次数据和报警范围，报警范围的操作; 代码上线的时候不需要报警，且要定义不报警时间段; Nagios 可以理解为一个非常强大的报警工具; NMS 可能要监控数万个指标，那么会对NMS 的磁盘IO,网络带宽，CPU负载等造成较大的压力; 我们可以对设备与网络划分，部署多套监控系统，而且它们是用不同的方法实现的; 但这样对我们的针对式管理就会带来巨大的麻烦; 完成状态转换，并完成报警; cacti 完成数据收集和展示，但对于报警能力比较薄弱; Zabbix:结合了以上两种工具的功能; 1231、zabbix 会自己先解决2、zabbix 解决不了报警给部门负责人3、zabbix 继续报警升级，报警给部门负责人, 部门领导 著名的开源监控工具: zabbix, zennos, opennms, cacti, nagios(icinga),ganglia (NMS linux) (被监控端 Linux主机) 监控功能的实现:12341、agent 2、ssh3、SIMP4、IPMI 智慧平台管理接口 1234567891011zabbix NMS 与 agent 端双方支持的协议(JSON,XML)视图(读操作/写操作各定义一个团体)在linux上要使用snmp功能要使用&quot;Linux: net-snmp程序包&quot;zabbix：有专用agent的监控工具; 监控主机: linux、windows、FreeBSD 网络设置、路由交换设备，可以用SNMP这种协议来进行监控; 采集网卡流量，可以将多个网卡流量都加起来进行计算; 报警，需要添加报警策略，另外需要报警跟踪，报警连动; 对监控系统要做系统评估;zabbix 是由php实现的，所以可以实现功能的二次开发; 监控对象12345678设备和软件 设备:服务器、路由器 、交换机、IO系统 软件: OS、网络、应用程序偶发性故障 主机down机、服务不可用、主机不可达严重故障主机性能批标趋势:时间序列数据 数据存储123456789101112131415cacti: rrd(round robin database) 强大的集成工具zabbix: mysql,pgsql企业级的监控解决方案; 如果定义了触发器，超出了预值，则执行脚本，而后再执行报警，报警升级操作; zabbix可以做分布式; zabbix可以部署中心节点，与分布式节点; 要关注系统有多大的压力，需要什么样的组件; 基于Zabbix agent,SNMP Agent, IPMI Agent,SSH.ping，Database Monitoring ,自定义监控脚本; 监控目标: CPU, Memeory, Network, Disk, Service, Log, File, Other 对Web做监控时，可以知道响应的时间，速度，及获取的内容; 获取通知: 邮件，短信，电话等等; Zabbix 的四个主要功能 Data gathering: 数据的收集 Data storage: 数据的存储 Alerting: 报警 Visualisation:可视化 zabbix 架构中的组件1、zabbix之间的通信 12345678910111213141516zabbix-server: 使用C语言研发的OS zabbix-agent: 使用C语言研发的zabbix-web: GUI,用于实现zabbix设定和展示zabbix-proxy:分布式监控环境中的专用组件因此工作性能也是相当不错的架构通信协议: agent架构使用zabbix agent协议进行通信 web pagess 使用http协议 ICMP/IPMI/SNMP: Devicezabbix dabases: MySQL,PGSQL(postgreSQL),DB2,Orcale,SQLite zabbix-server(zabbix-get) 与 zabbix-agentd 进行通信 zabbix-get与zabbix-agentd(zabbix-sender) 进行通信 zabbix-server 的日志保存在 /var/log/zabbix/zabbix-server.log中 zabbix-agentd 的日志保存在 /var/log/zabbix/zabbix-agentd.log中 zabbix-gui 接口需要一个lamp平台来运行 2、 zabbix的部署分类 1234a、可以将zabbix-server，zabbix-gui web (lamp),database分别放在一台服务器上; 然而,zabbix-server与database通信， zabbix-gui也只需要与database通信就可以了;b、可以将zabbix-server, zabbix-gui web(lamp),database 统一放在一台服务器上;d、可以将以上组件，两两部署在一台服务器上; zabbix常用术语 主机Host: 要监控的网络设备; 主机组Host Group: 分类监控的服务器，一组模板(监控项，触发器，等等); 监控项item: zabbix进行数据收集的核心，一个指定的监控指标; 触发器trigger: 是指一个表达式，评估item收集的数据是否在合理范围内; 事件event: 即发生一件值得关注的事情，例如trigger状态由problem转为ok状态; 动作action: 即预先定义的处理方法，通过定义的动作，发送邮件，知信等等; 报警升级escalation:发送报警，或者执行远程命令，每五分钟发一次，共发5次等; 媒介media: 发送通知的手段或通道，如Email、Jobber、SMS 或者微信等等; 通知notification:通过选定的媒介向用户发送有关的某件事情; 远程命令(remote command): 预定义的命令，可以在被监控的主机处于某特定条件下时自动执行; 模板(template): 用于快度定义被监控主机的的预设条目集合，通常包含了item、trigeer、graph、screen; 另外，模板可以直接链接至单个主机; 应用(application):一组item的集合; web场景(web scennario):用于检测web站点可用性的一个或多个HTTP请求; 前端(frontend): zabbix的web接口; 可根据系统类型 ，业务需求，设备类型等等将服务器分组; zabbix server 实现 watchdog 负责运行的进程是否在运行中; housekeeper 管家，指明你的数据将要被保存多久; alerter 执行警报操作的; poller 监控进程； httppoler 监控web页面的专用poller; discover 高级的发现机制，可以自动加载进来，但它的工作相当占用资源; escalator 报警升级; timer 计时器; nodewatcher 监控各节点的; db_data_syncer 数据库的数据同步器; db_config_syncer 数据库的数据同步器; pinger 能过ping操作查看各主机是否在线的工具; zabbix 监控实现的硬件需求 Name Platform CPU/Memory Database Monitored Hosts Small Ubuntu Linux PII 350MHZ 256MB SQLite 20 Medium Ubuntu linux 64 bit AMD Athlon 320 + 2GB MySQL InnoDB 500 Large Ubuntu Linux 64 bit Inter Dual Core 6400 + 6GB RAID 10 MySQL InnoDB or PostgreSQL &gt;1000 Verfy Large RedHat Enterprise Inter Xeon 2xCPU 8G FAST RAID 10 MySQl InnoDB or PostgreSQL &gt;10000 zabbix产生的数据组成共有四部分 配置数据; 历史数据 50Bytes; 历史趋势数据 128Bytes; 事件数据130Bytes; Zabbix 目前部署在Linux服务器最为常见 zabbix 官方源码 zabbix的安装与使用zabbix-server 的安装与使用123456789101112131415161718192021222324252627282930# yum -y install mariadb-server mariadb # systemctl enable mariadb# systemctl start mariadb# mysql MariaDB [(none)]&gt; CREATE DATABASE zabbix CHARACTER SET utf8;MariaDB [(none)]&gt; GRANT ALL on zabbix.* TO &apos;zbxuser&apos;@&apos;127.0.0.1&apos; IDENTIFIED BY &apos;xxxxxxx%3&apos;; Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; GRANT ALL on zabbix.* TO &apos;zbxuser&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;xxxxxxx%3&apos;; Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; FLUSH PRIVILEGES ;Query OK, 0 rows affected (0.00 sec)Welcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 3Server version: 5.5.56-MariaDB MariaDB ServerCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || test || zabbix |+--------------------+3 rows in set (0.00 sec)MariaDB [(none)]&gt; 这里选用 zabbix 2.2 的包来安装;之后会附zabbix 2.2 升级3.4 的文档 12345678910# rpm -i http://repo.zabbix.com/zabbix/2.2/rhel/7/x86_64/zabbix-release-2.2-1.el7.noarch.rpm# yum clean all# yum -y install zabbix zabbix-server zabbix-server-mysql zabbix-get zabbix-web zabbix-web-mysql zabbix-agent zabbix-sender # systemctl start httpd# systemctl enable httpd Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service.# cd /usr/share/doc/zabbix-server-mysql-2.2.21/create/# mysql zabbix &lt; schema.sql # mysql zabbix &lt; images.sql # mysql zabbix &lt; data.sql 1234567891011121314151617181920212223242526# vim /etc/zabbix/zabbix_server.conf# 参数说明ListenPort = 10051 指定端口 LogFile = 指定日志文件LogFileSize =0 表示不做滚动DebugLevel = 3 PidFile = /var/run/zabbix/zabbix_server.pid DBHost = localhost DBName = zabbix DBUser = zbxuserDBPassword = xxxxxxx%3DBSocket = /tmp/mysql.sockStartPollers = 5 随时等待的进程有多少个SNMPTrapperFile = /var/log/snmppt/snmptt.logMaxHousekeeperDelete=500 最多删除多少个CacheUpdateFrequency= 60 cache 最大的更新频率StartDBsyncers=4 DB同步进程多少个StartDiscoverers =1 是启动自动添加模板功能的StartHTTPPollers =1 作为http浏览器来请求被监控页面的StartTimers =1 启动计时器 JavaGateway = 1 监控java网关的一般默认的缓存值不用调 AlertScriptsPath=/usr/lib/zabbix/alertscripts/ 报警脚本的存放位置ExternalScripts=/usr/lib/zabbix/externalscripts/ 外部脚本的存放位置FpingLocation=/usr/sbin/fping 并行发送多个请求，可以当作攻击命令SSLCerLocation = 如果启用SSL的话则配配置该项 1234567# systemctl start zabbix-server# vim /etc/php.inidate.timezone = Asia/Chongqingmax_input_time = 600max_execution_time = 600post_max_size = 28M# systemctl restart httpd 如果使用编译安装123456789101112131415# 同时安装 server 和agent ，并支持将数据放入myql数据中，可使用类似如下配置命令;# ./configure --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-ssh2 # 如果仅安装 server,并支持将数据放入mysql数据中，可使用似如下配置命令; # ./configure --enable-server --with-mysql --with-net-snmp --with-libcurl# 如果仅安装 proxy，并支持将数据放入mysql数据中，可使用类似如下配置命令; # ./configure --profix=/usr --enable-proxy --with-net-snmp --with-mysql --with-ssh2# 如果仅安装 agent，可以使用类似如下配置命令;# ./configure --enable-agent # 而后编译安装zabbix 即可;# make # make install zabbix agent 的安装和使用12345# vim /etc/zabbix/zabbix_agentd.conf ServerActive=127.0.0.1,172.16.55.123Hostname=zabbix-test-server# systemctl start zabbix-agentCongiguration --&gt; Hosts --&gt; (将zabbix-server端的agent服务启用) zabbix 添加额外的agent端在一台需要被监控的服务器上安装 zabbix-agent 12345678910111213141516# rpm -i http://repo.zabbix.com/zabbix/2.2/rhel/7/x86_64/zabbix-release-2.2-1.el7.noarch.rpm# yum clean all # yum -y install zabbix zabbix-agent zabbix-sender# vim /etc/zabbix/zabbix_agentd.conf Server=172.16.55.123ServerActive=172.16.55.123Hostname= zabbix-agent-node1# systemctl start zabbix-agent# netstat -tnlup | grep zabbixtcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 30383/zabbix_agentd tcp6 0 0 :::10050 :::* LISTEN 30383/zabbix_agentd 注: 最好在zabbix-server 做一下探测，确保在zabbix-server 端可以探测通agent的端口# telnet 172.16.55.124 10050Trying 172.16.55.124...Connected to 172.16.55.124.Escape character is &apos;^]&apos;. 登录zabbix-server 的web接口 123456789101112Configuration --&gt; Hosts --&gt; Create Hosts --&gt;[Host name: zabbix-agent-node1Visible name: zabbix-agent-node1Group In goups : Linux serversAgent interfaces: 这里选用的是ip-&gt; 172.16.55.124Templates -&gt; Template OS Linux --&gt; Add -&gt; Save --&gt; IPMI -&gt; 先留空Macros -&gt; 先留空Host inventory -&gt; 先留空]Host &lt;-- Save zabbix on CentOS712345678910Linux开源监控系统: nagios cacti zabbix: 内nagios，cacti ganglia: 内置强大的聚合功能，这个功能zabbix是不具备的 在大公司能了解到更好规范; 在小公司能够得到更多的经验;# vim /etc/my.cnfinnodb_file_per_table = 1 skip_name_reslove = 1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253CentOS 7.1 安装~]# yum install zabbix-2.4.6-1.el7.x86_64.rpm zabbix-server-2.4.6-1.el7.x86_64.rpm zabbix-server-mysql-2.4.6-1.el7.x86_64.rpm zabbix-agent-2.4.6-1.el7.x86_64.rpm zabbix-sender-2.4.6-1.el7.x86_64.rpm zabbix-web-2.4.6-1.el7.noarch.rpm zabbix-get-2.4.6-1.el7.x86_64.rpm zabbix-web-mysql-2.4.6-1.el7.noarch.rpm trousers-0.3.11.2-4.el7_1.x86_64.rpm说明：CentOS 7.1安装zabbix-2.4.6-1.el7，其与trousers-0.3.11.2-3不兼容，需要升级trousers至0.3.11.2-4.el7_1。如果没有zabbix rpm包，可以在官网查找安装yum源rpm包 ，类似以上的安装方法创建数据库： server和proxy的运行都依赖于数据库，agent则不需要。 以MySQL数据库为例： shell&gt; mysql -uroot -p&lt;password&gt; mysql&gt; create database zabbix character set utf8 collate utf8_bin; mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by '&lt;password&gt;'; mysql&gt; quit; shell&gt; mysql -uzabbix -p&lt;password&gt; zabbix &lt; database/mysql/schema.sql # stop here if you are creating database for Zabbix proxy shell&gt; mysql -uzabbix -p&lt;password&gt; zabbix &lt; database/mysql/images.sql shell&gt; mysql -uzabbix -p&lt;password&gt; zabbix &lt; database/mysql/data.sql配置zabbix： (1) zabbix_server server的配置文件为zabbix_server.conf，至少应该为其配置数据库等相关的信息；例如： LogFile=/var/log/zabbix/zabbix_server.log LogFileSize=0 PidFile=/var/run/zabbix/zabbix_server.pid DBHost=172.16.100.67 DBName=zabbix DBUser=zbxuser DBPassword=zbxpass DBSocket=/var/lib/mysql/mysql.sock SNMPTrapperFile=/var/log/snmptt/snmptt.log AlertScriptsPath=/usr/lib/zabbix/alertscripts ExternalScripts=/usr/lib/zabbix/externalscripts (2) 配置php环境 编辑/etc/httpd/conf.d/zabbix.conf，添加如下项。 php_value date.timezone Asia/Shanghai 启动httpd服务：systemctl start httpd.service 访问zabbix web http://your_host/zabbix 登录：Admin/zabbix (3) 配置zabbix_agent agent的配置文件为zaabix_agentd.conf，至少应该为其指定server的IP地址； 12345678910111213141516171819202122zabbix组件 zabbix zabbix-server zabbix-database zabbix-web zabbix-agent zabbix-proxyzabbix 逻辑组件 主机组、主机 item(监控项)、appliction(应用) trigger(触发器) even(事件) action notice command media users(media) 监控系统: 数据采集、数据存储、报警、数据可视化 zabbix: database --&gt; zabbix-server (zabbix_server.conf)--&gt; zabbix-web(LAMP平台) --&gt; http://zabbix-web-server/zabbix/zabbix-agent (zabix-agent.conf) zabbix 报警入门配置注: 在添加主机的时候如果要想让支持snmp协议，则安装yum -y install net-snmp 12# vim /etc/snmp/snmp.conf# service snmpd start 1234567# 查看支持的key MariaDB [zabbix]&gt; SELECT key_,type FROM items ;# 查看支持的items MariaDB [zabbix]&gt; SELECT * FROM items\G;# zabbix_get -h 向指定的主机获取指定的值的# zabbix_get -s 172.16.55.124 -k &quot;net.if.out[ens3]&quot;1161497309# zabbix_get -s 172.16.55.124 -k &quot;net.if.in[ens3]&quot; 1390144843 1234# 手动创建item# 先在zabbix服务器端尝试获取CPU中断数 # zabbix_get -s 172.16.55.124 -k &quot;system.cpu.intr&quot;597504908 12345678910111213141516171819Configuration --&gt; Hosts --&gt; 选定主机的Items Name: cpu interrupts Type: zabbix Key:system.cpu.intrHost interface:172.16.100.8:10050Type of information: Numeric(unsigned) : 数据类型决定以下配置是否可用Data type : Decimal Units:Use custom multipier: 做单位换算New flexible interval Interval(in sec)：指定监控时间History storage period (in days): 历史数据的存放天数，只要满足需要了，尽可能不可时长过多 90Treand storage period (in days): 历史采样的数据 365历史数据:采样生成的数据;历史趋势数据 :每小时的最大值 、最小值 、平均值、统计值Sotre valus: 数据存储的结果 As is，不做任何处理; Delta(sppd per second): (value -per_value)/(time - pre_time) 10: 1200 , 20: 13000添加完以上信息之后，添add即可; 可以在hosts中查看到状态是enabled同样的方式可以创建 其它Item 手动创建一个图形 12345678910Configuration --&gt; Hosts --&gt; --&gt; 选定主机的Graph Name: cpu interrupts Width: 900Heig: 200Graph type: Normal Show legend Show working time Show triggersadd ItemsPreview ，配置完之后，可以预览后添加; 触发器状态严重性，级别 123456Not classfiled Grey 无分类Information Light green 资讯Warning Yellow 警告Average Orange 觉见问题High red 高危Disaster bright red 毁灭 创建触发器 1234567891011121314Configuration --&gt; Hosts --&gt; 选定主机的TriggerName too many interruptsExpression add --&gt; node1:cpu intterrupts --&gt; last(most recent)T value is &gt; N --&gt; Last of (T) --&gt; Time shift --&gt; N 50 --&gt; addDescription 名称中可以使用宏: &#123;HOST.HOST&#125;,&#123;HOST.NAME&#125;,&#123;HOST.IP&#125;,&#123;HOST.COMN&#125;,&#123;HOST.DNS&#125; URL: 可以留空，也可以添加一个url，报警则说明由哪个url触发的 1234# yum -y install hping3 多个hping3可以实现DDOS攻击# hping3 172.16.55.124 --faster 可以在124上看到,cpu上下文切换速度非常的快,cpu中断飙升# vmstat 1 定义报媒介 12345678910Administration --&gt; Media types --&gt; Name Email --&gt; Type Email --&gt; SMTP Server 可以指定到邮件服务器 --&gt; SMTP helo localhost 指定收件人 --&gt; SMTP email zabbix@xxxxx.com 指定发件人 # 定义报警用户 这里建议不创建报警用户，直接使用admin发Media 可以实现报警升级功能;在admin用户中配置报警媒介 配置Actions 123456Configure --&gt; Actions--&gt; Create Actions Action--&gt; names 信息采用宏，启用报故障恢复后发送信息; Conditions 条定执行条件Operations 定义报警升级 (每一次可有多个跨度区间) zabbix 常用配置由zabbix监控某关注的指标 123host group --&gt; host --&gt; item(存储于MySQL) --&gt; graph (zabbix-web)--&gt; trigger(触发器) --&gt; action(conditon+operation)application: 把功能相近的一组item归类在一起统一进行管理组件: 123ServerActive= 172.16.55.124 ; 这里在agent中如果指定了，则说明是主动的监控方式;Actions 可以接收事件，可以发送动作而用来报警;(Events,Actions,Trigger) 是zabbix的核心组件 Zabbix 完整的监控配置流程大体由如下组成: 123456Host group --&gt; Hosts --&gt; Applications --&gt; Items --&gt; Triggers --&gt; Events --&gt; Actions (发警告) --&gt; User group --&gt; Users --&gt; Mediasgraph, screen 依赖关系: Host --&gt; Item --&gt; Trigger --&gt; Action 添加主机到zabbix server: 1一定不要让没有监控的服务器上线 123定义好discoevery: 可以根据给定的网段，自动描网段，并添加，此种方式是服务器端主动auto_registrion: 被监控主机，自动向服务端注册low level discovery: 区别不同的底层设备的 模板(template): 1一般模板是套在主机之上的;(item,application,trigger,graph,action) Item 1234567891011121314151617181920212223242526272829303132默认的Iems有多种类型 Zabbix-agent 工作模式: passive, active 网卡流量相关: net.if.in[if,&lt;mode&gt;] if: 接口，如eth0 mode:bytes, packets, errors, dropped net.if.out[if,&lt;mode&gt;] net.if.total[if.&lt;mode&gt;] 端口相关: net.tcp.listen[port] net.tcp.port[&lt;ip&gt;,port] net.tcp.service[service,&lt;ip&gt;,&lt;port&gt;] net.udp.listen[port] 监控端口是否处于监听状态 进程相关: kernel.maxfiles 内核打开的文件数 kernel.maxproc 内核打开的最大进程数 CPU相关: system.cpu.intr 中断次数 system.cpu.load[&lt;cpu&gt;,&lt;mode&gt;] cpu负载 system.cpu.num[type] cpu个数 system.cpu.switches cpu切换频率 system.cpu.util [&lt;cpu&gt;,&lt;type&gt;,&lt;mode&gt;] cpu哪个指标的利用率 磁盘IO相关: vfs.dev.read[&lt;device&gt;,&lt;type&gt;,&lt;mode&gt;] vfs.dev.write[&lt;device&gt;,&lt;type&gt;,&lt;mode&gt;] vfs.fs.inode [fs,&lt;mode&gt;] 用户可自定义item: 12关键:选取一个惟一的key;命令:收集数据 的命令或脚本; Trigger: 123456789101112状态: OK: 事件转为正状态; PROBLEM：表示有事件发生; zabbix server 每次接收到items的新数据时就会对Item的当前采样值进行判断，即与trigger的表达式进行比较;一个trigger只能属于一个Item，但一个Item可有有多个Trigger;Severity: No classfied: 未知级别，灰色; Information: 一般信息，亮绿; Warning: 警告信息，黄色; Average: 一般故障，红色; Disater:致命故障，亮红; Action: 12345触发条件一般为事件: Trigger events: OK --&gt; PROBLEM; Discovery events: zabbix的network discovery工作; Auto registration events: 主动模式的agent注册时产生的事件; Internal events: Item变成不再被支持，或Trigger变成为未知道状态]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix使用进阶]]></title>
    <url>%2F2018%2F04%2F02%2Fzabbix%E9%AB%98%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[zabbix 高级用法 zabbix 报警媒介12345# 对于邮件报警接口，CentOS默认邮件服务就是启动的，但是，只能服务本地到本地发邮件; # 如果需要往互联网上发邮件，需要把服务器配置成邮件服务器;# 但一般来讲，自建邮件系统，付出的成本和技术都较高，因此，我们可以考虑网联上的邮件服务;# 而对于报警的内容，一般是我们在zabbix服务端配置的宏所定义的内容;# 没有item的配置，那么将意味着没有监控数据; Zabbix术语与操作注意项123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121Item Key 命名求: 只能使用字母、数字、下划线、点号、连接符; 接受参数: system.cpu.load[&lt;cpu&gt;,&lt;mode&gt;], net.if.inbound[if,&lt;mode&gt;] 注意: 每一个key背后都应该有一个命令或者脚本来负责实现数据收集；命令或者脚本可以调用传递给key的参数，调用方式为$1,$2,... 在zabbix中定义item时调用某key，还需要额外定义数据采集频率(每30秒采集一次)、历史数据的保存时长等;Trigger: 触发器表达式: &#123;&lt;Server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)&#125;&lt;operator&gt;&lt;constant&gt; 例: &#123;api.transfereasy.com:net.tcp.listen[9991].last()&#125;#1 &lt;function&gt;: 评估采集到的数据是否在合理范围内时所使用的函数，共评估过程可以根据采集到的数据、当前时间或其它因素; avg:平均值; count:指定时间内的统计; change:返回最近返回的值，与之前一次的差值; date:当天的值; dayofweek:返回本周的第几天的值; dayofmonth:返回本月的第几天的值; delta:指定时间范围内最大值与最小值之差; diff:当文件不一样时; iregexp:忽略大小写它符的正则表达式; last:最近一次采样; max:最近采样的最大值; min:最近采样的最小值; nodata: 表示没有数据; sum:最后一次采样数据之和; regexp:检查最后一次采样的值是否能够被指定的模式所匹配: 1、表示匹配, 0表示不匹配; now:返回自Unix元年至此刻经历的秒数; prev:倒数第二个采样值: str:从最后一次的采样中查找到此处指定的子串: strlen: 做字符串的长度比较; prev:倒数第二个采样值 &lt;operator&gt;: &gt;, &lt;, =, #(表示不等于)事实上我们可以让表达式的值直接来做算术运算的; / ,* ,- ,+ &amp;(与),|(或) 触发器之间的关系 Action: message: condition: 一般由event触发: trigger discover: Service Up ,Srvice Down ,Host up ,Host down, Service Discovered,Service Lost,Host Discovered, Host Lost auto-registration operation: send message Medis Type Email (常用),SMS ,Jabber, Scripts(常用), EZ Texting Usser remote command(远程命令) 运行zabbix进程的用户是zabix用户 所以这里要注意，zabbix未必有权限执行 (1) 给zabbix 定义sudo规则: zabbix ALL=(ALL) ALL (2) 不支持active模式的agent: (3) 不支持代理模式: (4) 命令长度不得超过255个字符: (5) 可以使用宏: (6) zabbix-server仅执行命令，而不关命令是否执行成功: 前提: zabbix-agent要配置为支持执行远程命令: EanbleRemoteCommands =1 LogRemoteCammands =1 # 启用执行远程命令后记录 # vim /etc/sudoers 或者 visudo zabbix ALL=(ALL) NOPASSWD:ALL 注: 以上服务器权限的是操作是非常用风限性的; Actions --&gt; Operations --&gt; New --&gt; Operation type Remote Command: --&gt; Host 挑远出远程主机 --&gt; Global script --&gt;在方框中加入远程命令 Hosts --&gt; Applications --&gt; Create Applications --&gt; Http Hosts --&gt; Items --&gt; Create Items --&gt; Name http server --&gt; Type zabbix aggent --&gt; Key net.tcp.listen[80] --&gt; Applications http service Add Items &lt;-- Host --&gt; Triger --&gt; Create Triger --&gt; Name http service is on Expresion --&gt; add --&gt;Item node2: http service --&gt; Function: Previous value is =1 --&gt; Last of(T) 1 --&gt; N 0 --&gt; 严重级别先Hight Configuration --&gt; Actions --&gt; Create Action --&gt; Action Name http service Conditions --&gt; New condition Trigger == node1: httpd serivce is value Operations --&gt; 定义报警升级 --&gt; 可以定义由第一步到第几步执行什么样的操作 注意: (1) 如果用到以某它用户身份运行其它命令的话，要加 sudo 来运行; sudo systemctl restart httpd (2) 在各gent上的sudoers 文件中，要注释如下行，否则命令依旧无法正常运行; # Default requiretty Script: Alert Script 放置于特定目录中: AlertScriptsPath=/usr/lib/zabbix/alertscripts zabbix_server.conf配置文件中的参数: 脚本中使用$1,$2,$3来调用Action先项卡中的收件人地址, Default Subject , Default Massage: # vim alert_message.sh #!/bin/bash to=$1 subject=&quot;$2&quot; body=&quot;$3&quot; echo &quot;$body&quot; | mail -s &quot;$subject&quot; &quot;$to&quot; # chmod +x alert_message.sh 当然这里是一个最简单的实现脚本，这里也可以使用python,bash,ruby,perl 等脚本 注意: 新放入此目录中的脚本，只有重启zabbix 方能被实别; Administration --&gt; Mdedia types --&gt; --&gt; Name AlterScript --&gt; Type Script --&gt; Script name alert_message.sh Administration --&gt; Users ---&gt; --&gt; Media --&gt; add --&gt; AlterScripts root@localhost 这样的话，通过两种方式都能收到邮件Escalation TemplateWeb Scennario Zabbix服务器进程123456789housekeeper 用来清理过期数据的;alter 专门用来发送警告的进程;discoverer 实现主机发现的; httppoller 对web服务器进行监控时;Poller 主动去被监控节点去拉取数据;Pinger 基于ping命令来探测主机是否在线;db_config_syncer 服务器配置同步的; timer 计时器;escaltor 报警升级器; zabbix 可视化自定义图形属性 123456Name: 图形的独有名称;Width: 图形的宽度，单位为像素;仅适用于&quot;预览(perview)&quot; 模式、饼图或分离型饼图; Height: 图形的类型, 共有四种，即&quot;线状图normal&quot;、&quot;堆叠面积图&quot;、&quot;饼图(pie)&quot;、 分离型饼图(exploded);Show legend: 是否显示图例，即图形数据序列说明;Show working time: 是否高亮显示工作时间区域;选定时，非工作时间区间的背景为灰色;此功能不用于pie和exploded;Show Triggers: 是否显示触发器;此功能不适用于pie和exploded; 多图形合并显示 123456Configuration --&gt; Screen --&gt; Create Screen --&gt; Name Test Screen--&gt; Columns 3 # 列--&gt; Row 2 # 行 --&gt; Test Screen --&gt; change 这里就可以看到一个2行3列的表格，然后往里面添加图片; 多屏翻转 123Slide showsName Default delay(in seconds) 可视化: graph ,screen, slide shows,map 宏(macros) 1234567891011121314151617181920212223# 宏其实说白了就是变量，类型通常为文本类型; # 为了更强的灵活性,zabbix还支持在全局、模板或主机级别使用用户自定义宏(user macro);# 用户自定义宏要使用&quot;&#123;$MACRO&#125;&quot;这种特殊的语法格式; # 宏可以应用在item keys 和descriptions、 trigger 名称和表达式、主机接口IP/DNS及端口、 discovery机制的SNMP协议的相关信息等;# 宏的名称只能使用大写字母、数字及下划线;# 两类: 内建: &#123;MACRO_NAME&#125; 自定义:&#123;$MACRO_NAME&#125;# 可以在三个级别使用: Global, Template, Host# 优先级: Host --&gt; Template --&gt; Global 在某级别找到后将直接使用: 将不再查找 全局宏: Adminstration --&gt; General --&gt; Macrios(在先项卡中) 主机宏: Configuration --&gt; Hosts --&gt; Macrios 主机级别的宏优先级最高; Template: Configuration --&gt; Complation --&gt; Macrios 模板(Templats)一系列配置的集合，此些配置可以通过”链接”的方式应用于指定的主机:application, item, trigger, graph, scree 及发现规则; 添加例行惯常的维护时间; 1Configuration --&gt; maintenance --&gt; Maintenance User Parameters: 123456789101112# zabbix 内置了许多item key:实现用户自定义 item key ,实现特有数据指标监控;语法: UserParameter=&lt;key&gt;,&lt;command&gt;# vim /etc/zabbix/zabbix_agentd.d/os.confUserParameter=os.memory.used, free -m | awk &apos;/^Mem/ &#123;print $3&#125;&apos;UserParameter=os.memory.used, free -m | awk &apos;/^Mem/ &#123;print $3&#125;&apos;UserParameter=os.memory.used, free -m | awk &apos;/^Mem/ &#123;print $3&#125;&apos;注: 需要重启zabbix-agent 才能使用# systemctl restart zabbix-agent这个时候定义的zabbix-agent key就可以使用了,在server web 接口中添加; 如果找不到key 则直接输入即可 os.memory.used 监控nginx statusnginx status 开启方法: 12345678910server &#123; ... location /status &#123; stub_status on; access_log off; allow 172.16.55.123; # 允许访问的IP allow 127.0.0.1; deny all; &#125;&#125; 123456789101112131415161718192021222324252627282930状态页面各项数据的意义;active connections - 当前Nginx 正处理的活动连接数;serveraccepts handled requests - 总共处理了 233851个连接，成功创建 233851次握手(证明中间没有失败的) 总共处了 687942个请求(平均每次扬处理了 2.94 个数据请求)。 reading -nginx 读取到客户端的Header信息数; writing -nginx 返回给客户端的Header 信息数; waiting - 开启 keep-alive 的情况下，这个值等于 active- (reading +wrting) 意思就是Nginx 已经处理完正等候一次请求指令的驻留连接;UserParameter=Mysql.dml[*], /usr/local/mysql/bin/mysql -h$1 -u$2 -p$3 -e &apos;SHOW GLOBAL STATUS&apos; | awk &apos;/Com_$4\&gt;/&#123;print $$2&#125;&apos; # 在/etc/init.d/zabbix_agentd.d/xx.conf中定义了以上项后; 在zabbix-server 终端zabbix_get -s 172.16.55.124 -p 10050 -k &quot;Mysql.dml[172.16.55.124,root,password,delete]&quot; #注意mysql用户的授权zabbix_get -s 172.16.55.124 -p 10050 -k &quot;Mysql.dml[172.16.55.124]&quot;UserParameter=Nginx.active[*], /usr/bin/curl -s &quot;http://$1:$2/status&quot; | awk &apos;/^Active/ &#123;print $NF&#125;&apos;UserParameter=Nginx.reading[*], /usr/bin/curl -s &quot;http://$1:$2/status&quot; | grep &apos;Reading&apos; | cut -d&quot; &quot; -f2UserParameter=Nginx.writing[*], /usr/bin/curl -s &quot;http://$1:$2/status&quot; | grep &apos;Writing&apos; | cut -d&quot; &quot; -f4UserParameter=Nginx.waiting[*], /usr/bin/curl -s &quot;http://$1:$2/status&quot; | grep &apos;Waiting&apos; | cut -d&quot; &quot; -f6UserParameter=Nginx.accepted[*], /usr/bin/curl -s &quot;http://$1:$2/status&quot; | awk &apos;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ &#123;print $$1&#125;&apos;UserParameter=Nginx.handled[*], /usr/bin/curl -s &quot;http://$1:$2/status&quot; | awk &apos;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ &#123;print $$2&#125;&apos;UserParameter=Nginx.requests[*], /usr/bin/curl -s &quot;http://$1:$2/status&quot; | awk &apos;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ &#123;print $$3&#125;&apos;UserParameter=nginx.access_countaccess, /usr/lib/zabbix/externalscripts/logcheck_nginx.accesslog totalaccessUserParameter=nginx.access_count200, /usr/lib/zabbix/externalscripts/logcheck_nginx.accesslog 200accessUserParameter=nginx.access_count202, /usr/lib/zabbix/externalscripts/logcheck_nginx.accesslog 202accessUserParameter=nginx.access_count4xx, /usr/lib/zabbix/externalscripts/logcheck_nginx.accesslog 4xxaccessUserParameter=nginx.access_count3xx, /usr/lib/zabbix/externalscripts/logcheck_nginx.accesslog 3xxaccessUserParameter=nginx.access_count5xx, /usr/lib/zabbix/externalscripts/logcheck_nginx.accesslog 5xxaccessUserParameter=varnish.stat[*], /usr/lib/zabbix/externalscripts/varnishstatus varnish_stat $1UserParameter=varnish.count[*], /usr/lib/zabbix/externalscripts/varnishstatus varnish_count $1UserParameter=varnish.hitrate, /usr/lib/zabbix/externalscripts/varnishstatus varnish_hitrate zabbix 自动发现功能12345678910111213141516171819202122232425262728293031323334353637zabbix 提供网络发现功能: network discovery 基于HTTP、 ICMP、 SSH、 LDAP、 TCP、 SNMP、 Telnet、 Zabbix_agent扫描指定网内的主机; 一旦主机被发现，如何对其进行操作，将由action来决定; LLD: low leverl Discovery (底级网络发现功能) 此二者的功能: 自动添加主机、链接至模板/移除链接、自动分组、自动添加监控项、定义触发器等、执行远程脚本; Discovery中的事件: Service Up, Service Down, Host Up, Host Down, Service Discovered, Service Lost, Host Discovererd, Host Lost 网络发现有两个步骤: discovery --&gt; action actions: Sending notifications Adding/removting hosts Enabling/disabling hosts Adding hosts to a group Removing hosts from a group Linking hosts to/unlinking from a template Executing remote scripts 自动发现功能的使用，首先要将server端和agentu端的时间自动同步; # vim /etc/zabbix/zabbix_agentd.conf Server = 172.16.55.124 ServerActive = 172.16.55.124 Hostname = test.xxxxxx.com LogRemoteCommand = 1 # systectl start zabbix-agent Configure --&gt; Discovery --&gt; Create discovery rule --&gt; Name Local Linux Servers --&gt; IP range 172.16.55.125-127 Delay(in sec) 3600 --&gt; Checks Check type ICMP ping(最易于实现的方式) --&gt; Add --&gt; Device uniqueness criteria IP address --&gt; Enabled Add &lt;-- # 当返回到Discovery 时，可以看到服务器已经被自动发现; 12345678910111213141516171819202122232425 # 创建动作 Configuration --&gt; Actions --&gt; Discovery(和以往action不同，在选项卡中先择) 主机发现的条件 Conditions: New condition Host IP = 或者指定网络的发现规则来定义 Operations: 这里就可以定义对应的操作（添加到组中） Configuration --&gt; Templates --&gt; --&gt; Template name Linux Server Memory Stats --&gt; Visible anme --&gt; Groups In groups test group Add &lt;--# 另外需要自己定义好一个模板Configuration --&gt; Actions --&gt; Create Action--&gt; Conditions --&gt; Type of calculation And/Or --&gt; Conditions --&gt; Host IP = 172.16.55.125-128 --&gt;Discovery rule = Local Linux Servers --&gt; Discovery status = Discovered--&gt; Operations --&gt; New --&gt; Add To host group (Test group) # 添加到组中 --&gt; Link to template Linux Server Memory status add ADD &lt;--在网络的自动发现中，我们可以使用zabbix-agent来发现 在网络的主动发现中，由于是zabbix主动扫描，因此这种模型是非常消耗性能的 在mariadb中查看支持的key 123MariaDB&gt; use zabbix;MariaDB&gt; SELECT key_ FROM items;使用agent-ping 来做实现主机探测; auto_registation 主动注册功能123456789Active Agent Auto-Registration# 首先主机之间要时间同步; # 安装zabbix-agent 端;# vim /etc/zabbix/zabbix-agent.conf# ServerActive=172.16.100.6# Hostname=test.xxxxx.com# ListenIp=172.16.55.126# HostMetdata = test4 (只用于自动注册主机的唯一标识) # systemctl restart zabbix-agent 123456# 添加自动注册的动作Configuration --&gt; Actions --&gt; (Event source Autoregistration) --&gt; Create Action--&gt; Actions: auto registration --&gt; Condition: Hostname like node4 (比如主机名中包中包涵node4) --&gt; Add--&gt; Operations Add to Host groups --&gt; Link with templates 链接至模板# 支持使用agent(active)类型的item key: 1234567891011# 配置过程: (1)定义agent端: ServerActive= Server= Hostname= ListenIP= 设置为本机某特定IP： ListenPort= HostMetadata= HostMetadataItem= item key， 一般使用system.uname (2) 配置action，要求其事件一源为auto-registation LLD: low Level Discovery 12345678910# 自动发现特定变更的名称 #IFNAME(接口名称) , #FSNAME(文件系统名称)# 主要将本地的一些特殊数据发送到服务端，比如接口类的数据;# 添加针对变理的Items:# 返回值为JSON Configurations --&gt;Templates --&gt; discovery rules --&gt; create discovery rules--&gt; name if lld--&gt; Type zabbix agent --&gt; Key net.if.[#IFNAME,bytes] 123# 登录 zabbix数据库查询对应的key# use zabbix;# SELECT key_ FROM iem WHERE key_ LIKE &apos;%discovery%&apos;; Web 监控 Zabbix 还可以进行web 站点的可用性检测; 创建web监控需要定义一个web方案(scenarios); web方案包括一个或多个HTTP请求或”步骤(step)”; 步骤(step)的执行过程按照预先定义的顺序进行执行; 通过web监控可以实时获取以下信息; 123# 整个web方案中所有的步骤的平均下载速度;# 失败的步骤号;# 失败的报错信息; 在web方案的具体步骤中，可以按需要使用如下信息 123# 该步骤的下载速度;# 回应时间;# 回应状态码; Zabbix也可以检测获取到HTML页面中是否包含预设的字符串，也可以实现登录和页面点击; 12345678# 首先需要定意一个application# Configuration --&gt; Hosts --&gt; Web --&gt; Scenario Zabbix server --&gt; google charme--&gt; Steps --&gt; zabbix home --&gt; http://172.16.55.123/index.html --&gt; Require status code 200 zabbix的监控方式 123456789# zabbix-web 所能够显示的且可指定为监控接口类型的监控方式:Agent: passive activeSNMP: Simple Network Management ProtocolIPMI: 智慧平台管理接口（Interlligent-Platform Management Interface）原本是一种Inter架构的企业系统的周边 设备所采用的一种工业标准; IPMI亦是一开放的免费标准，使用者无需支付额外的费即可使用此标准;JMX: Java Manaement Extensions, 用于通过Java自己的接口对java程序进行监控;zabbix-java-getway用于获取监控数据: SNMP 监控方式 12345678910# 操作: Get, NetNext, Set , Resonse, TrapMIB: 是被 管理对象的集合，而且还额外定义了被管理对象的名称、访问权限、数据类型等属性;MIB视图: MIB的子集;授权:将MIB视图与Community绑定来实现;OID: Object ID 1.3.5.1.2.1 1: system 2: interface 4:ip 6: tcp 7: udp 12345678910111213# yum -y install net-snmp net-snmp-libs net-snmp-utils# vim /etc/snmp/snmpd.conf com2sec notConfigUser default public group notConfigGroup v1 notConfigUser group notConfigGroup v2c notConfigUser view systemview include .1.3.6.1.2.1 view systemview include .1.3.6.1.2.1.25.1.1access notConfigGroup &quot;&quot; any noauth exact systemview none none# service smpd start # 确定udp 的161端口已经启用;# 此时可以使用icmp来收集数据了; JMX监控方式: 1234567891011121314(1) 安装zabbix-java-gateway: 配置文件: /etc/zabbix/zabbix_java_gateway.conf Listen_IP = Listen_PORT = 10052 zabbix server的配置文件 /etc/zabbix/zabbix_server.conf JavaGateWay= JavaGateWayPort= 10052 (2) Java应用程序开户JMX接口: java -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port =10053 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremoe.ssl=false监控Tomcat export CATALINA_OPTS=&quot;$CATALINA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port =10053 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremoe.ssl=false&quot; zabbix 分布式监控概述1234567891011121314151617181920212223# Zabbix能高效地监控分布式IT架构;# 在大型环境中Zabbix提供两种解决方案; 1、使用代理(proxy); 2、使用节点(node);# 代理(proxy)用于本区域数据收集，并将数据发送给server;# 节点(node) 提供完整的Zabbix server用以建立分布式监控中的层级;# Server-Node-Client特性; 解决host过多时单台Server面临性能瓶颈的问题; 使用多个instance; 每个instance是独立的一套zabbix，有database和Frontend(optional); 支持热插拔，Node和Server的连接可以随时断开，但不影响Node的正常运行; Node定时给Server发送configuration, history,event; Server定时给Node发送configurations 所有配置变更只能在Node节点操作，不能再Server操作; 支持树状结构，Node又可以是多个Server;# Proxy vs Node Node本身是一台server,它有完整的web页面，完整的数据库，它将数据源源不断传送给Master; Poxy是只有一个proxy的daemon进程，proxy也有自己的数据库，但它的数据库只会保存一定时间的数据; 它与Master通信是将一批信息打包后发送到Master， Master将这些数据merge入Mater数据库;# Master-Proxy 相比Master-Node的优点有以下 Proxy压力小，数据库只存储一定时间数据; Master压力变小，数据不是源源不断获取，减小IO压力; 架构更清晰，易维护； 123456789101112131415# zabbix-proxy 也需要被监控# yum -y install zabbix-proxy zabbix-proxy-mysql zabbix zabbix-agent# mysql CREATE DATABASE zabbix_proxy CHARACTER SET utf8;GRANT ALL ON zabbix_proxy.* TO zbxuser@&apos;172.16.%.%&apos; IDENTIFIED BY &apos;xxxxxx&apos;;FLUSH PREVILEGES; # vim /etc/zabbix/zabbix_proxy.confServer=172.16.55.123Hostname=test.xxxx.comDBHost=172.16.55.123DBName=zabbix_proxyDBUser=zbxuserDBPassword=xxxxxxConfigFrequency=600 #多久向服务器端拉取一次数据# server zabbix-proxy start 12345Administration --&gt; Proxies Proxy name test.xxxx.comProxy mode ActiveHosts Proxy hosts# 再添加被监控服务器时可以在创建主机时可以指明Monitored by proxy zabbix database需要用到的空间: 12345678960000/60 = 1000条 历史数据=天数x每秒钟处理的数据是x24x3600x50Bytes 90x1000x8600x50Bytes趋势数据: 每一个趋势数据128Bytes, 大小=天数x监控项x24x128Bytes事件数据: 每个占据130Bytes 大小:天数x86400x130]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运行一个简单的Fabric网络]]></title>
    <url>%2F2018%2F03%2F21%2F%E8%BF%90%E8%A1%8C%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84Fabric%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[运行一个简单的Fabric网络设定一个简单的Fabric的网络场景,包括2个organization,每个有2个peer,并使用”solo” ordering服务;网络实体所需的加密材料(x509证书)已预先生成并放到相应目录和配置文件里了。无需修改这些配置; example/e2e_cli文件夹里包含了docker-compose文件和要用来创建和测试的网络的脚本文件; 另外如何使用配置生成工具configtxgen生成网络配置; 前提完成以下安装Fabric源码和编译configtxgen工具: 完成环境，并设置正确的$GOPATH环境变量; 1234在/etc/profile/go.sh 中加入以下内容export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/srv/jdk1.8.0_66/bin:/root/bin:/usr/local/go/binexport GOPATH=/opt/gopathchmod +x /etc/profile/go.sh &amp;&amp; source /etc/profile/go.sh 接取Fabric源码; 1# git clone https://github.com/hyperledger/fabric.git 如果运行在linux，在Fabric目录下执行以下命令: 123456# cd $GOPATH/src/github.com/hyperledger/fabric# make configtxgen # 输出build/bin/configtxgenCGO_CFLAGS=" " GOBIN=/opt/gopath/src/github.com/hyperledger/fabric/build/bin go install -tags "nopkcs11" -ldflags "-X github.com/hyperledger/fabric/common/configtx/tool/configtxgen/metadata.Version=1.0.7-snapshot-84a7e5c" github.com/hyperledger/fabric/common/configtx/tool/configtxgenBinary available as build/bin/configtxgen 如果运行在OSX，先安装Xcode 8.0或者以上版本，然后在Fabric目录下执行以下命令: 1234567891011121314# 安装 Homebrew,若mac上有brew的可以跳过此步骤/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; #添加 gnu-tar# brew install gnu-tar --with-default-name #添加 libtool# brew install libtool# 编译 configtxgen # make confgitxgenbuild/bin/configtxgenCGO_CFLAGS=&quot; &quot; GOBIN=/Users/johndoe/work/src/github.com/hyperledger/fabric/build/bin go install -ldflags &quot;-X github.com/hyperledger/fabric/common/metadata.Version=1.0.0-snapshot-8d3275f -X github.com/hyperledger/fabric/common /metadata.BaseVersion=0.3.0 -X github.com/hyperledger/fabric/common/metadata.BaseDockerLabel=org.hyperledger.fabric&quot; github.com/hyperledger/fabric/common/configtx/tool/configtxgenBinary available as build/bin/configtxgen`` 编译后扫行文件放在Fabric目录下的 build/bin/configtxgen中 执行完整脚本为了加快部署过程，Fabric提供了一个脚本 来执行所有任务。执行该脚本 会生成配置结果、本地网络、Chaincode测试; 进入 examples/e2e_cli目录，首先从Dcoker Hub摘取镜像: 12# 执行脚本# bash ./download-dockerimages.sh 这个执行过程耗时会比较长，脚本执行后输出: 123456789101112131415161718===&gt; List out hyperledger docker imageshyperledger/fabric-ca latest 35311d8617b4 7 days ago 240 MBhyperledger/fabric-ca x86_64-1.0.0-alpha 35311d8617b4 7 days ago 240 MBhyperledger/fabric-couchdb latest f3ce31e25872 7 days ago 1.51 GBhyperledger/fabric-couchdb x86_64-1.0.0-alpha f3ce31e25872 7 days ago 1.51 GBhyperledger/fabric-kafka latest 589dad0b93fc 7 days ago 1.3 GBhyperledger/fabric-kafka x86_64-1.0.0-alpha 589dad0b93fc 7 days ago 1.3 GBhyperledger/fabric-zookeeper latest 9a51f5be29c1 7 days ago 1.31 GBhyperledger/fabric-zookeeper x86_64-1.0.0-alpha 9a51f5be29c1 7 days ago 1.31 GBhyperledger/fabric-orderer latest 5685fd77ab7c 7 days ago 182 MBhyperledger/fabric-orderer x86_64-1.0.0-alpha 5685fd77ab7c 7 days ago 182 MBhyperledger/fabric-peer latest 784c5d41ac1d 7 days ago 184 MBhyperledger/fabric-peer x86_64-1.0.0-alpha 784c5d41ac1d 7 days ago 184 MBhyperledger/fabric-javaenv latest a08f85d8f0a9 7 days ago 1.42 GBhyperledger/fabric-javaenv x86_64-1.0.0-alpha a08f85d8f0a9 7 days ago 1.42 GBhyperledger/fabric-ccenv latest 91792014b61f 7 days ago 1.29 GBhyperledger/fabric-ccenv x86_64-1.0.0-alpha 91792014b61f 7 days ago 1.29 GB现在运行完整脚本： 现在运行完整脚本: 1bash network_setup.sh up mychannel 如果没有设置 channel-ID参数，channel名默认是mychannel。脚本执行成功后输出: 123===================== Query on PEER3 on channel &apos;mychannel&apos; is successful ========================================== All GOOD, End-2-End execution completed ===================== 此时，网络启动运行并测试成功 清理停止网络: 12# 在e2e_cli目录下 # docker rm -f $(docker ps -aq) 然后执行 docker images命令查看Chaincode镜像，类似输出如下: 1234REPOSITORY TAG IMAGE ID CREATED SIZEdev-peer3-mycc-1.0 latest 13f6c8b042c6 5 minutes ago 176 MBdev-peer0-mycc-1.0 latest e27456b2bd92 5 minutes ago 176 MBdev-peer2-mycc-1.0 latest 111098a7c98c 5 minutes ago 176 MB 删除镜像: 1docker rmi &lt;IMAGE ID&gt; &lt;IMAGE ID&gt; &lt;IMAGE ID&gt; 例如: 1# docker rmi -f 13e e122 333 最后删除配置结果， 在crypto/orderer 目录删除 orderer.block和channel.tx; configtxgenconfigtxgen 工具生成两个内容: Orderer的bootstrap block和Fabric的channel configuration transaction; roderer block是ordering服务的创世区块; channel transaction文件在create channel时会被广播给orderer; configtx.yaml包含网络的定义，并给出了网络组件的拓扑结构-2个成员(Org0和Org1)分别管理维护2个peer。 还指出每个网络实体的加密材料的存储位置。crypto目录包含每个实体的admin证书、ca证书、签名证书和私钥; 为了方便使用，官方提供了一个脚本 generateCfgTrx.sh,该脚本整合了configtxgen的执行过程，执行后会生成两个配置结果:orderer.block和channel.tx。如果运行过上边network_setup.sh则这两个配置结果已生成，要先到crypto/orderere目录将之删除; 执行generateCfgTrx.sh脚本在e2e_cli目录下: 1# cd $GOPATH/src/github.com/hyperledger/fabric/examples/e2e_cli generateCfgTrx.sh脚本有个可选能数channel-ID,如果不设此参数，则默认为mychannel； 12# &lt;channel-ID&gt;参数是要可选的# bash generateCfgTrx.sh &lt;channel-ID&gt; 执行成功后输出: 123456782017/02/28 17:01:52 Generating new channel configtx2017/02/28 17:01:52 Creating no-op MSP instance2017/02/28 17:01:52 Obtaining default signing identity2017/02/28 17:01:52 Creating no-op signing identity instance2017/02/28 17:01:52 Serializing identity2017/02/28 17:01:52 signing message2017/02/28 17:01:52 signing message2017/02/28 17:01:52 Writing new channel tx 生成的orderer.block和channel.tx两个文件存放在corypto/orderer目录; orderer.block是ordering服务的创世区块，channel.tx包含新channel的配置信息。如前所述，这俩文件 都来自configtx.yaml及其所包含的加密材料和网络信息的数据; 注: 也可以手动执行脚本generateCfgTrx.sh里的命令。如果傅这种方式，则必需先用e2e_cli目录下的configtx.yaml替换Fabric sampleconfgi目录下默认的configtx.yaml，然后返回fabric目录执行这些命令，前提是删除之前的generateCfgTrx.sh生成的两个文件; 启动网络使用docker-compose启动网络，如果还没有摘取 Fabric镜像，则返回之前的操作去拉取镜像; 脚本scrpit.sh嵌入到docker-compose文件里，该脚本将peer加入到channel并向peer发送read/write请求，如此便可自动执行交易流程。如果还不想使用这个脚本自动执行交易，可以跳到下面”手动执行交易”一节; 在e2e_cli目录下使用docker-compose生成网络实体并执行嵌入的脚本: 1CHANNEL_NAME=&lt;channel-id&gt; docker-compose up -d 如果之前创建了个channel名，就必须将其作为参数，否则使用默认的mychannel。例如: 1CHANNEL_NAME=mychannel dcoker -comopse up -d 等待一会儿，因为背后有交易会发送到peer。执行docker ps查看运行状态的container，可以看到以下内容: 12345678910vagrant@hyperledger-devenv:v0.3.0-4eec836:/opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES45e3e114f7a2 dev-peer3-mycc-1.0 &quot;chaincode -peer.a...&quot; 4 seconds ago Up 4 seconds dev-peer3-mycc-1.05970f740ad2b dev-peer0-mycc-1.0 &quot;chaincode -peer.a...&quot; 24 seconds ago Up 23 seconds dev-peer0-mycc-1.0b84808d66e99 dev-peer2-mycc-1.0 &quot;chaincode -peer.a...&quot; 48 seconds ago Up 47 seconds dev-peer2-mycc-1.016d7d94c8773 hyperledger/fabric-peer &quot;peer node start -...&quot; About a minute ago Up About a minute 0.0.0.0:10051-&gt;7051/tcp, 0.0.0.0:10053-&gt;7053/tcp peer33561a99e35e6 hyperledger/fabric-peer &quot;peer node start -...&quot; About a minute ago Up About a minute 0.0.0.0:9051-&gt;7051/tcp, 0.0.0.0:9053-&gt;7053/tcp peer20baad3047d92 hyperledger/fabric-peer &quot;peer node start -...&quot; About a minute ago Up About a minute 0.0.0.0:8051-&gt;7051/tcp, 0.0.0.0:8053-&gt;7053/tcp peer11216896b7b4f hyperledger/fabric-peer &quot;peer node start -...&quot; About a minute ago Up About a minute 0.0.0.0:7051-&gt;7051/tcp, 0.0.0.0:7053-&gt;7053/tcp peer0155ff8747b4d hyperledger/fabric-orderer &quot;orderer&quot; About a minute ago Up About a minute 0.0.0.0:7050-&gt;7050/tcp orderer 背后发生了什么？ 在CLI容器中执行了脚本script.sh。该脚本用默认的mychannel执行createChannel命令，这个命令用到了之前configtxgen工具生成的channel.tx。 createChannel执行后会生成一个创世区块mychannel.block并保存到当前目录 ; 对4个peer分别执行joinChannel命令，通过初始区块mychannel.block加入channel。 至此有一个channel包含4个peer和2个organzation； PER0和PEER1属于Org0, PEER2和 PEER3属于Org1。这些关系的定义都在confiigtx.yaml中 Chaincodechaincode_example02被 install到PEER0和PEER2 然后Chaincode在PEER2上instantiate。实例化是指启动容器和初始化与Chaincode相关的键值对，本例中的初始值 是[&quot;a&quot;,&quot;100&quot; &quot;b&quot;,&quot;200&quot;]。实例化的结果是一个名为dev-peer2-mycc-1.0的容器启动，注意，这个容器仅是针对PEER2; 实例化时还会带有背书策略参数，本例中背书策略为”-P” OR(‘OrgOMSP.memeber”,Org1MSP.member’)”,意思是任何交易必须由绑定到Org0或者Org1的peer背书; 对于”a”的query请求发慈禧太后到PEER0。在之前Chaincode被install到PEER0了，所以就可以启动一个名为dev-peer0-mycc-1.0的新容器，然后返回查询结果。由于没有write操作发生，所以”a”的值依然是”100”。 从”a”转移”10”给”b”的invoke请求发送到PEER0 Chaincode install 到 PEER3 对”a”的query 请求发关到PEER3。 这启动了第三个名为dev-peer3-mycc-1.0的容器，并返回查询结果90，正确的反应了之前的交易; Chaincode必须被 install到一个peer上才能成功的对这个peer的ledger执行read/write操作。此外，只有当在peer上针对chaincode执行read/writer操作时，这个peer上才会启该chaincode容器(比如，查询”a”的值)交易到容器启动。channel中的所有peer（包括那结没有install chaincode的peer，就像上例中的PEER3）都会维护一个准确的ledger，ledger包含存储了不可变的、有序的交易记录的block，还有维护current state的statedb。在peer上install chaincode之后就可以直接使用该peer上的chaincode了（就像上例中的PEER3），因为之前已经instantiated过了; 查看交易 查看CLI容器的log: 1# docker logs -f cli 输出: 123456789102017-02-28 04:31:20.841 UTC [logging] InitFromViper -&gt; DEBU 001 Setting default logging level to DEBUG for command &apos;chaincode&apos;2017-02-28 04:31:20.842 UTC [msp] GetLocalMSP -&gt; DEBU 002 Returning existing local MSP2017-02-28 04:31:20.842 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 003 Obtaining default signing identity2017-02-28 04:31:20.843 UTC [msp] Sign -&gt; DEBU 004 Sign: plaintext: 0A8F050A59080322096D796368616E6E...6D7963631A0A0A0571756572790A01612017-02-28 04:31:20.843 UTC [msp] Sign -&gt; DEBU 005 Sign: digest: 52F1A41B7B0B08CF3FC94D9D7E916AC4C01C54399E71BC81D551B97F5619AB54Query Result: 902017-02-28 04:31:30.425 UTC [main] main -&gt; INFO 006 Exiting.....===================== Query on chaincode on PEER3 on channel &apos;mychannel&apos; is successful ========================================== All GOOD, End-2-End execution completed ===================== 实时查看日志时，需要打开两个终端; 首先，停止运行着的docker容器: 1# docker rm -f $(docker ps -aq) 在第一个终端启动docker-compose脚本: 1CHANNEL_NAME=&lt;channel-id&gt; docker-compose up -d 在第二个终端查看log： 1# docker logs -f cli 这将实时输出通过script.sh执行的交易信息; 查看chaincode日志对每个chaincode容器单独查看log，输出: 12345678910111213141516$ docker logs dev-peer2-mycc-1.004:30:45.947 [BCCSP_FACTORY] DEBU : Initialize BCCSP [SW]ex02 InitAval = 100, Bval = 200$ docker logs dev-peer0-mycc-1.004:31:10.569 [BCCSP_FACTORY] DEBU : Initialize BCCSP [SW]ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;100&quot;&#125;ex02 InvokeAval = 90, Bval = 210$ docker logs dev-peer3-mycc-1.004:31:30.420 [BCCSP_FACTORY] DEBU : Initialize BCCSP [SW]ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;90&quot;&#125; 手动执行交易停止所有容器: 1# docker rm -f $(docker ps -aq) 然后，执行docker iamge 命令查看chaincode镜像，会有类似以下内容: 1234REPOSITORY TAG IMAGE ID CREATED SIZEdev-peer3-mycc-1.0 latest 13f6c8b042c6 5 minutes ago 176 MBdev-peer0-mycc-1.0 latest e27456b2bd92 5 minutes ago 176 MBdev-peer2-mycc-1.0 latest 111098a7c98c 5 minutes ago 176 MB 删除这些镜像： 1docker rmi &lt;IMAGE ID&gt; &lt;IMAGE ID&gt; &lt;IMAGE ID&gt; 比如: 1# docker rmi -f 12f e27 111 确保之前生成的配置内容还在，如果删除了就再执行脚本: 1./generatecCfgTrx.sh&lt;channel-ID&gt; 或者使用脚本中的命令手动生成; 修改docker-compose文件打开docker-compose文件注释掉执行script.sh脚本的命令，如下: 12working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer# command: /bin/bash -c &apos;./scripts/script.sh $&#123;CHANNEL_NAME&#125;&apos; 保存文件 ，重启网络: 12# 在e2e_cli目录下执行，设置正确的CHANNEL_NAMECHANNEL_NAME=&lt;channel-id&gt; docker-compose up -d 命令语法 参照 script.sh脚本中的creaete和join命令。下面的命令只是针对PEER0的，当对orderer和peer执行命令，需要修改下面给出的四个环境变量的值; 12345# 对PEER0所用的环境变量CORE_PEER_MSPCONFIGPATH=$GOPATH/src/github.com/hyperledger/fabric/peer/crypto/peer/peer0/localMspConfigCORE_PEER_ADDRESS=peer0:7051CORE_PEER_LOCALMSPID=&quot;Org0MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=$GOPATH/src/github.com/hyperledger/fabric/peer/crypto/peer/ peer0/localMspConfig/cacerts/peerOrg0.pem 第个peer的环境变的值都在docker-compose文件中 Create channel进去cli容器: 1# docker exec -it cli bash 执行成功输出: 1root@0d78bb69300d:/opt/gopath/src/github.com/hyperledger/fabric/peer# 用-c指定channel name, -f指定channel configruation transaction(此例中是channel.tx)当然也可以使用不同的名称安装configuration transaction; 12# channel.tx 和 orderer.block 在 cli 容器的 crypto/orderer 目录下peer channel create -o orderer0:7050 -c mychannel -f crypto/orderer/channel.tx --tls $CORE_PEER_TLS_ENABLED --cafile $GOPATH/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem 由于此例的peer channel create命令是针对orderer的，所以需要修改之前的环境变量，因此上边的命令应该是: 1CORE_PEER_MSPCONFIGPATH=$GOPATH/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig CORE_PEER_LOCALMSPID=&quot;OrdererMSP&quot; peer channel create -o orderer0:7050 -c mychannel -f crypto/orderer/channel.tx --tls $CORE_PEER_TLS_ENABLED --cafile $GOPATH/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem 注意:下面的其他命令依然在CLI容中执行，而且要记住命令里每个peer对应的环境变量; 将指定的peer加入到channel: 12#默认只将 PEER0 加入 peer channel join -b mychannel.block 完整的命令应该是: 1CORE_PEER_MSPCONFIGPATH=$GOPATH/src/github.com/hyperledger/fabric/peer/crypto/peer/peer0/localMspConfig CORE_PEER_ADDRESS=peer0:7051 CORE_PEER_LOCALMSPID=&quot;Org0MSP&quot; CORE_PEER_TLS_ROOTCERT_FILE=$GOPATH/src/github.com/hyperledger/fabric/peer/crypto/peer/peer0/localMspConfig/cacerts/peerOrg0.pem peer channel join -b mychannel.block 修改这四个环境变量将其他的peer加入到channel中 将示例chaincode代码安装到四个对等节点中的一个: Install chaincode12# 在命令前面要加上peer对应的四个环境变量peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 在一个peer上实例化chaincode，这将对该peer启动一个chaincode容器，并为该chaincode设置背书策略。此例中定义的策略是有org0或org1中的一个peer背书即可; 123# 在命令前面要加上peer对应的四个环境变量# 用 -C 参数设置正确的channel名，默认是 mychannelpeer chaincode instantiate -o orderer0:7050 --tls $CORE_PEER_TLS_ENABLED --cafile $GOPATH/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem -C mychannel -n mycc -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;, &quot;100&quot;, &quot;b&quot;,&quot;200&quot;]&#125;&apos; -P &quot;OR (&apos;Org0MSP.member&apos;,&apos;Org1MSP.member&apos;)&quot; Invoke chaincode 12# 在命令前面要加上peer对应的四个环境变量peer chaincode invoke -o orderer0:7050 --tls $CORE_PEER_TLS_ENABLED --cafile $GOPATH/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem -C mychannel -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]&#125;&apos; Query chaincode 12# 在命令前面要加上peer对应的四个环境变量peer chaincode query -C mychannel -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; 执行结果: 1Query Result: 90 手动构建镜像构建peer和orderer镜像: 12# 在farbic目录下执行，如果不能顺利生成镜像，则使用vagrant环境# make peer-docker orderer-docker 执行docker images命令输出 123456789101112vagrant@hyperledger-devenv:v0.3.0-4eec836:/opt/gopath/src/github.com/hyperledger/fabric$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhyperledger/fabric-orderer latest 264e45897bfb 10 minutes ago 180 MBhyperledger/fabric-orderer x86_64-0.7.0-snapshot-a0d032b 264e45897bfb 10 minutes ago 180 MBhyperledger/fabric-peer latest b3d44cff07c6 10 minutes ago 184 MBhyperledger/fabric-peer x86_64-0.7.0-snapshot-a0d032b b3d44cff07c6 10 minutes ago 184 MBhyperledger/fabric-javaenv latest 6e2a2adb998a 10 minutes ago 1.42 GBhyperledger/fabric-javaenv x86_64-0.7.0-snapshot-a0d032b 6e2a2adb998a 10 minutes ago 1.42 GBhyperledger/fabric-ccenv latest 0ce0e7dc043f 12 minutes ago 1.29 GBhyperledger/fabric-ccenv x86_64-0.7.0-snapshot-a0d032b 0ce0e7dc043f 12 minutes ago 1.29 GBhyperledger/fabric-baseimage x86_64-0.3.0 f4751a503f02 4 weeks ago 1.27 GBhyperledger/fabric-baseos x86_64-0.3.0 c3a4cf3b3350 4 weeks ago 161 MB 使用本地二进制文件进支vagrant环境 1234cd $GOPATH/src/github.com/hyperledger/fabric/devenv# 第一次启动VM用 vagrant up vagrant ssh 在fabric目录编译peer和orderer: 12make cleanmake native 生成ccenv镜像 1make peer-docker 然后打开两个终端都进入vagrant，至此有三个终端都在vagrant里;首先清空ledger文件/var/hyperledger/ (每次运行后，为避免错误或重复，都要清空): 1rm -rf /var/hyperledger/* 使用configtxgen工具创建orderer创世区块: 1configtxgen -profile SampleMSPSolo -outputBlock orderer.block 用刚生成的创世区块启动orderer: 1ORDERER_GENERAL_GENESISMETHOD=file ORDERER_GENERAL_GENESISFILE=./orderer.block orderer 创建 channel configuration transaction: 1configtxgen -profile SampleSingleMSPSolo -outputCreateChannelTx channel.tx -channelID &lt;channel-ID&gt; 执行成功会在当前目录生成channel.tx 以chanless模块启动peer: 1peer node start --peer-defaultchain-false 以channel.tx为参数创建channel: 1peer channel create -o 127.0.0.1:7050 -c mychannel -f channel.tx 执行后在当前目录生成一个channel的创世区块mychannel.block Join channel通过channel的创世区块mychannel.block加入channel: 1peer channel join -b mychannel.block Install chaincode在peer上安装chaincode: 1peer chaincode install -o 127.0.0.1:7050 -n mycc -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 执行成功后查看文件可以看到mycc.1.0: 1ls /var/hyperledger/production/chaincodes Instantiate chaincode 实例化chaincode: 1peer chaincode instantiate -o 127.0.0.1:7050 -C mychannel -n mycc -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;, &quot;100&quot;, &quot;b&quot;,&quot;200&quot;]&#125;&apos; docker ps查看运行中的容器，如果chaincode启动成功，则显示: 12CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbd9c6bda7560 dev-jdoe-mycc-1.0 &quot;chaincode -peer.a...&quot; 5 seconds ago Up 5 seconds dev-jdoe-mycc-1.0 Invoke chaincode调用chaincode从”a”转移”10”给”b”: 1peer chaincode invoke -o 127.0.0.1:7050 -C mychannel -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]&#125;&apos; Query chaincode查询”a”的值: 12# 返回值应是 90peer chaincode query -o 127.0.0.1:7050 -C mychannel -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; 运行完成后不要忘记清空ledger文件夹/var/hyperledger: 1rm -rf /var/hyperledger/* 使用CouchDB可以将stateDB默认的goleveldb替换成CouchDB。对于CouchDB, chainocde各功能依然可用，但将chaincode数据以JSON方式存储的话就可以使用CouchDB的复杂查询的功能; 为了使用CouchDB，除了最前面的”前提”一节的操作外，还需要下边两步启动CouchDB容器并将之与peer容器关联; 构建 CouchDB镜像 12# make sure you are in the fabric directorymake couchdb 编辑fabric/example/e2e_cli/docker-compose.yaml 和docker-compose.yam 将所有与CouchDB有关的内容取消注释。这样 chaincode_xample02就可以CouchDB下运行了; 注意:如果将CouchDB容器的端口映射的主机，请一定要注意安全，在开发环境 中将端映射出来可以通过CouchDB的web界面可视化操作数据。生产环境中一般不会做端口映射，以限制CouchDB的外部访问; 可以用chaincode_example02在CouldDB下执行上边的chaincode操作，但是为了使用CouchDB的复杂查询功能，chaincode数据一定要以JSON格式存储(例如 fabric/examples/chaincode/go/merbles02); 使用手动执行交易这一节中的步骤install、instantiate、invoke和querymarbles02，执行完成join channel这步后使用下边的命令操作marbles02: 在PEER0上安装实例化chaincode 12peer chaincode install -o orderer0:7050 -n marbles -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/marbles02peer chaincode instantiate -o orderer0:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem -C mychannel -n marbles -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/marbles02 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;]&#125;&apos; -P &quot;OR (&apos;Org0MSP.member&apos;,&apos;Org1MSP.member&apos;)&quot; 创建一些marble并移动它们 123456peer chaincode invoke -o orderer0:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;initMarble&quot;,&quot;marble1&quot;,&quot;blue&quot;,&quot;35&quot;,&quot;tom&quot;]&#125;&apos;peer chaincode invoke -o orderer0:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;initMarble&quot;,&quot;marble2&quot;,&quot;red&quot;,&quot;50&quot;,&quot;tom&quot;]&#125;&apos;peer chaincode invoke -o orderer0:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;initMarble&quot;,&quot;marble3&quot;,&quot;blue&quot;,&quot;70&quot;,&quot;tom&quot;]&#125;&apos;peer chaincode invoke -o orderer0:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;transferMarble&quot;,&quot;marble2&quot;,&quot;jerry&quot;]&#125;&apos;peer chaincode invoke -o orderer0:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;transferMarblesBasedOnColor&quot;,&quot;blue&quot;,&quot;jerry&quot;]&#125;&apos;peer chaincode invoke -o orderer0:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/orderer/localMspConfig/cacerts/ordererOrg0.pem -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;delete&quot;,&quot;marble1&quot;]&#125;&apos; 如果做了CouchDB容器的端口映射，可以通过web界面查看数据，可以看到名为mychannel的数据库及其文档 如果使用的是vagrant环境 1234http://localhost:15984/_utils* 如果不是vagrant环境，使用CouchDB容器指定的端口http://localhost:5984/_utils 有可规律的查询chaincode(例如,读取marble2) peer chaincode query-C mychannel -n marbles -c {“Args”:[“readMarble”,”marble2”]}’ 可以看到mable2的详细信息: 1Query Result: &#123;&quot;color&quot;:&quot;red&quot;,&quot;docType&quot;:&quot;marble&quot;,&quot;name&quot;:&quot;marble2&quot;,&quot;owner&quot;:&quot;jerry&quot;,&quot;size&quot;:50&#125; 获取 marble1的历史 1peer chaincode query -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;getHistoryForMarble&quot;,&quot;marble1&quot;]&#125;&apos; 可以看到操作过marbel1的交易: 1Query Result: [&#123;&quot;TxId&quot;:&quot;1c3d3caf124c89f91a4c0f353723ac736c58155325f02890adebaa15e16e6464&quot;, &quot;Value&quot;:&#123;&quot;docType&quot;:&quot;marble&quot;,&quot;name&quot;:&quot;marble1&quot;,&quot;color&quot;:&quot;blue&quot;,&quot;size&quot;:35,&quot;owner&quot;:&quot;tom&quot;&#125;&#125;,&#123;&quot;TxId&quot;:&quot;755d55c281889eaeebf405586f9e25d71d36eb3d35420af833a20a2f53a3eefd&quot;, &quot;Value&quot;:&#123;&quot;docType&quot;:&quot;marble&quot;,&quot;name&quot;:&quot;marble1&quot;,&quot;color&quot;:&quot;blue&quot;,&quot;size&quot;:35,&quot;owner&quot;:&quot;jerry&quot;&#125;&#125;,&#123;&quot;TxId&quot;:&quot;819451032d813dde6247f85e56a89262555e04f14788ee33e28b232eef36d98f&quot;, &quot;Value&quot;:&#125;] 还可以执行复杂查询,比喻如查询jerry所拥有的marble: 1peer chaincode query -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;queryMarblesByOwner&quot;,&quot;jerry&quot;]&#125;&apos; 查询结果为jerry所拥有的2个marble的信息: 1peer chaincode query -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;queryMarblesByOwner&quot;,&quot;jerry&quot;]&#125;&apos; 查询结果为jerry所拥有的2个marble的信息: 1Query Result: [&#123;&quot;Key&quot;:&quot;marble2&quot;, &quot;Record&quot;:&#123;&quot;color&quot;:&quot;red&quot;,&quot;docType&quot;:&quot;marble&quot;,&quot;name&quot;:&quot;marble2&quot;,&quot;owner&quot;:&quot;jerry&quot;,&quot;size&quot;:50&#125;&#125;,&#123;&quot;Key&quot;:&quot;marble3&quot;, &quot;Record&quot;:&#123;&quot;color&quot;:&quot;blue&quot;,&quot;docType&quot;:&quot;marble&quot;,&quot;name&quot;:&quot;marble3&quot;,&quot;owner&quot;:&quot;jerry&quot;,&quot;size&quot;:70&#125;&#125;] 通过owner字段等于jerry查询: 1peer chaincode query -C mychannel -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;queryMarbles&quot;,&quot;&#123;\&quot;selector\&quot;:&#123;\&quot;owner\&quot;:\&quot;jerry\&quot;&#125;&#125;&quot;]&#125;&apos; 查询结果如下: 1Query Result: [&#123;&quot;Key&quot;:&quot;marble2&quot;, &quot;Record&quot;:&#123;&quot;color&quot;:&quot;red&quot;,&quot;docType&quot;:&quot;marble&quot;,&quot;name&quot;:&quot;marble2&quot;,&quot;owner&quot;:&quot;jerry&quot;,&quot;size&quot;:50&#125;&#125;,&#123;&quot;Key&quot;:&quot;marble3&quot;, &quot;Record&quot;:&#123;&quot;color&quot;:&quot;blue&quot;,&quot;docType&quot;:&quot;marble&quot;,&quot;name&quot;:&quot;marble3&quot;,&quot;owner&quot;:&quot;jerry&quot;,&quot;size&quot;:70&#125;&#125;] 数据持久化如果需要对peer或CouchDB容器的数据持久化，一种是选择是将容器的相关目录挂载到docker主机;例如，将下面两内容器入到docker-compose.yaml文件中的对应peer处: 12volumes: - /var/hyperledger/peer0:/var/hyperledger/production 12volumes:- /var/hyperledger/couchdb0:/opt/couchdb/data 故障排除 每次运行后要清理文件 如果出现docker错误，则删除镜像，从头再操作一遍; 12make clean make peer-docker orderer-docker 如果出现下面的错误 1Error: Error endorsing chaincode: rpc error: code = 2 desc = Error installing chaincode code mycc:1.0(chaincode /var/hyperledger/production/chaincodes/mycc.1.0 exits) chaincode镜像(如dev-peer0-mycc-1.0或dev-peer1-mycc-1.0)可能是以前运行过的，删除它们然后重试; 1docker rmi -f $(docker images | grep peer[0-9]-peer[0-9] | awk &apos;&#123;print $3&#125;&apos;) 使用 down选项清理网络 12./network_setup.sh down Next Previous]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hyperledger Fabric Chaincode for Operators]]></title>
    <url>%2F2018%2F03%2F20%2F%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%2F</url>
    <content type="text"><![CDATA[实操智能合约 什么是Chaincode chaincode是一个程序，它是使用Go语言编写的，最终在Java等其它编程语言中实现了指定的接口；chaincode运行一个被 背书peer进程独立出来的安全的Docker容器中;chaincode通过应用程序提交的事务初始化和管理帐本状态; chaincode通常处理被网络成员认可的业务逻辑;因此它被认为是一种”智能合约”;由chaincode创建的状态只作用于该chaincode，而不能通过另一个chaincode直接访问;但是，在同一个网络中，给定适当的权限;chaincode可以调用另一个chaincode来访问它的状态; 通过区块链通信产品应用方案供应商诺亚的视角来探索chaincode;主要关注诺亚对chaincode生命周期的操作;在区块链网络中，打包，安装，实例化和升级chaincode的过程;是chaincode的操作生命周期的一个功能; Packaging(包)chaincode包由3部分组成: chaincode由chaincode部署规范(ChaincodeDeploymentSpec)或CDS定义码和其他属性(如名称如版本) 定义了chaincode包; 一个可选的实例化策略，他可以在策略上用相同的策略来描述;用于一支持和在背书策略中描述。 由”拥有”chaincode的实体的一组签名; 这些签名有以下目的: 为了建立chaincode的所有权; 允许对包的内容进行验证; 允许检测包是否篡改; 一个channel上的chaincode实例化事务的创建者是通过chaincode的实例化策略来验证的; 创建package(包) 打包chaincode有两种方法。一种是当想要一个chaincode拥有多个所有者时，需要使用多个身份标识为该chaincode签名;这个工作流程需要我们首先创建一个已签名的chaincode(一个签署的CDS);然后通过序列的方式将其传递给其他所有者来签署 ; 更简单的工作流程是正在发行安装事务的节点的身份签名时部署已部署的CDS;首先将处理更复杂的情况，但是，如果不需要担心多个所有者; 那么可以跳过下在的安装chaincode部分; 要创建一个已签名的chaincode包，使用如下命令: 1234567891011121314root@6edc4e6c7b9c:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode package -n mycc -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -v 0 -s -S -i &quot;AND(&apos;OrgA.admin&apos;)&quot; ccpack.out2018-03-20 06:28:29.298 UTC [msp] GetLocalMSP -&gt; DEBU 001 Returning existing local MSP2018-03-20 06:28:29.299 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 002 Obtaining default signing identity2018-03-20 06:28:29.299 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 003 Using default escc2018-03-20 06:28:29.299 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 004 Using default vscc2018-03-20 06:28:29.526 UTC [golang-platform] getCodeFromFS -&gt; DEBU 005 getCodeFromFS github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example022018-03-20 06:28:29.965 UTC [golang-platform] func1 -&gt; DEBU 006 Discarding GOROOT package fmt2018-03-20 06:28:29.965 UTC [golang-platform] func1 -&gt; DEBU 007 Discarding provided package github.com/hyperledger/fabric/core/chaincode/shim2018-03-20 06:28:29.965 UTC [golang-platform] func1 -&gt; DEBU 008 Discarding provided package github.com/hyperledger/fabric/protos/peer2018-03-20 06:28:29.965 UTC [golang-platform] func1 -&gt; DEBU 009 Discarding GOROOT package strconv2018-03-20 06:28:29.965 UTC [golang-platform] GetDeploymentPayload -&gt; DEBU 00a done2018-03-20 06:28:29.968 UTC [msp/identity] Sign -&gt; DEBU 00b Sign: plaintext: 0A58080112520A476769746875622E63...0A2D2D2D2D2D454E44202D2D2D2D2D0A 2018-03-20 06:28:29.968 UTC [msp/identity] Sign -&gt; DEBU 00c Sign: digest: 8A854844B0721EB24D348CC38C19A3D5E182CBE46FDFFE8CB9ECA7C44406F720 2018-03-20 06:28:29.969 UTC [chaincodeCmd] chaincodePackage -&gt; DEBU 00d Packaged chaincode into deployment spec of size &lt;3409&gt;, with args = [ccpack.out] -s 参数是指可以创建一个由多个所有签署的包，而不是简单地创建一个未处理/修饰过的CDS；当指定了-s时，如果其他所有者需要签名，也必需要指定-s参数; 否则，这个进程会创建一个除了CDS实例化策略之外的已签署CDS; -S 参数使用在core.yaml中由localMspid属性值标识的MSP来指示该程序的签名; -S 参数是可选的。但是，如果一个包是在没有签名的情况下创建的，那么它就不能由任何其他所有者使用signpackage来签署; -i 参数是可选的，即指定 chaincode实例化策略。实例化策略与背书策略具有相同的格式；并指定哪些id可以实例化chaincode。在上面的示例中，只允许使用OrgA的admin实例化链代码;如果没有提供策略，则使用默认策略，这将只允许peer中MSP的admin身份来实例化chaincode； 包签名(Package signing)一个已经被签名的chaincode包在被创建时候可以交由其它所有者检查并签名;这个工作流程支持chaincode包带外签署; SignedCDS包含了3个元素; CDS包含了chaincode的源码,即表示背书策略; chaincode的实例化策略，即表示背书策略; chaincode的所有者列表,以背书的方式定义; 注: 当chaincode在某些channel上实例化时，此背书策略是由带外决定的，以提供适当的MSP原则。如果没有指定实例化策略，则默认策略是channel的任何MSP的admin 每个所有都通过将其与所有者的身份(例如证书) 相结合，并签署结合后的结果来为ChaincodeDeploymentSpec背书;一个caincode所有者可以使用下面的命令来签署一个以前创建的签名包: 1234567root@6edc4e6c7b9c:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode signpackage ccpack.out signedccpack.out2018-03-20 06:48:52.479 UTC [msp] GetLocalMSP -&gt; DEBU 001 Returning existing local MSP2018-03-20 06:48:52.479 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 002 Obtaining default signing identity2018-03-20 06:48:52.479 UTC [msp/identity] Sign -&gt; DEBU 003 Sign: plaintext: 0A58080112520A476769746875622E63...0A2D2D2D2D2D454E44202D2D2D2D2D0A 2018-03-20 06:48:52.479 UTC [msp/identity] Sign -&gt; DEBU 004 Sign: digest: 8A854844B0721EB24D348CC38C19A3D5E182CBE46FDFFE8CB9ECA7C44406F720 Wrote signed package to signedccpack.out successfully2018-03-20 06:48:52.480 UTC [main] main -&gt; INFO 005 Exiting..... ccpack.out 和signedccpack.out分别是输入和输出包。signedccpack.out包含了使用的包附加签名; 安装chaincode安装事务将chaincode的源代码打包成一种指定的格式，称为ChaincodeDeploymentSpec(chaincode部署规范或CDS);并将其安装到运行该chaincode的peer节点上; 必须在channel中的每个背书节点上安装chaincode。以运行chaincode; 当安装API被简单地给出一个ChaincodeDeploymentSpec时，它会将默认实例化策略;并包含一个空的所有者列表; chaincode只应该安装在chaincode拥有的成员的背书pper节点上; 以保护网络中其他成员的chaincode逻辑的机密性 那些没有chaincode的成员，不能成为chaincode交易的背书人; 也就是说，它们不能执行chaincode 但是，它们仍然可以难并将事务提交到账本上; 要安装一个chainocde，请将一个签署的提案发送到system chaincode(系统智能合约) 其中被描述为生命周期系统智能合约(lifecycle system chaincode –LSCC) 的部分;例如，要安装使用CLI的简单资产chaincode中描述的sacc示例chaincode，使用如下命令: 1# peer chaincode install -n asset_mgmt -v 1.0 -p sacc CLI容器执行创建的SignedChaincodeDeploymentSpec sacc ，并将其发送给本地peer；本地peer会调用LSCC上的安装方法。对-p选项的参数指定 了chaincode的路径；它必需们位于用户的GOPATH的源码树中，例如 $GOPATH/src/sacc;为了在peer上安装，签署的提案的签名必需来自peer的地本MSP管理员的一个签名 chaincode实例化实例化事务调用生命击期系统chaincode(LSCC)来创建和初始化一个channel的chaincode;这是一个chaincode-chanel绑定过程: chaincode可以绑定到任意数量的channel，并分别在每个channel上独立操作;不管chaincode安装和实例化了多少个其他channel，状态都被隔离到一个事务提交到channel上; 实例化事务的创建者必需满足在SingedCDS中包含的chincode的实例化策略;并且该创建者作为创建该channel配置信息的一部分，也必需是channel上的一个写入者;这对于channel的安全性来说是非常重要的，它可以防止恶意实体部署chaincode或欺骗成员在一个未绑定的channel上执行chaincode; 例如，默认的实例化策略是任何channel的MSP管理员，因此一个chaincode实例化事务的创建者必须是channel管理员的成员;当事务提案到达背书(节点)的时候，它将验证创建者的签名与实例化策略; 并且在将其提交给账本之前;在事务验证期间再次执行此操作; 实例化事务还为channel 上的chaincode设置了背书策略。背书策略描述了交易结果的认证需求;被该channel的所有成员所接受; 例如,使用CLI实例化sacc chaincode，并使用john和0初始化状态，命令如下: 1peer chaincode instantiate -n sacc -v 1.0 -c &apos;&#123;&quot;Args&quot;:[&quot;john&quot;,&quot;0&quot;]&#125;&apos; -P &quot;OR (&apos;Org1.member&apos;,&apos;Org2.member&apos;)&quot; 签注策略(CLI使用波兰表示法)，它需要来自Org1或Org2的任意成员的支持以支持所有的事务到sacc。也就是说，无论是Org1还是Org2都必须签署在sacc上执行调用的结果，以使用事务是有效的 波兰表示法(Polish notation,或波兰记法)，是一种逻辑、算术和代数表示方法;其特点是操作符置于操作数的前面,因此也称做前缀表示法;如果操作符的元数(arity)是固定的，则语法上不需要括号仍然能被无歧义的解析;波兰记法是波兰数学家扬. 武卡谢维奇1920年代引入的。用于简化命题逻辑; 在chaincode成功实例化之后,chaincode在channel上进入活跃状态;并准备处理任何背书事务类武技的事务协议。。这些事务是并发处理的，因为它们到达了背书peer; chaincode升级任何时候，chaincode都可以通过更改其版本来进行升级，这是SignedCDS的一部分;其他部分，例如所有者和实例化策略是可选的。但是，chaincode的名称必需是相同的;否则，它将被视为完全不同的chaincode; 在升级之前，必须将chaincode的新版本安装在需要背书peer上，升级是一个类似于实例化事务的事务;它将chaincode的新版本绑定到channel。其他channel所绑定的旧版本chaincode将会继续运行旧版的chaincode； 换句话说，升级事务只会一次影响 一个channel，即提交事务的channel; 注意:由于chaincode的多个版本可能同时处于活跃状态，所以升级过程不会自动删除旧版本；因此用户必需暂时管理这个版本; 与实例化事务一个微妙的区别; 升级事务是根据当前的chaincode 实例化策略检查的，而不是新策略;这是为了确保当前的实例化策略中指定的现有成员可以升级chaincode; 在升级过程中，调用chaincode Init函数来执行任何与数据 相关的更新或重新初始化它;因此在升级chaincode时必需注意避免重新设置状态; 停止和启动chaincode停止和启动生命周期事务还没有实现。但是，可以通过每个背书人删除chaincode容器和SignedCDS包来手动停止chaincode这是通过peer节点运行的每个主机或虚拟机上删除chaincode的容器来完成的,然后从每个背书peer节点 上删除SignedCDS TODO-为了peer节点删除CDS，首先需要进入peer节点的容器，我们确实需要提供一个能够执行功能的实用程序脚本 12#docker rm -f &lt;container id&gt;rm /var/hyperledger/production/chaincodes/&lt;ccname&gt;:&lt;ccversion&gt; Stop在工作iytkk是有用的,可以控制方式上进行升级，在进行升级之前，可以在所有peer上停止一个chaincode ; CLI(客户端) 官方正在评估为Hyperledger Fabric peer二进制文件分发特定平台的二进制文件的需求; 目前，可以简单地运行dodcker 容器中调用命令; 查看当前的可用的CLI命令，运行的fabric-peer Docker容器中执行以下命令: 12# docker run -it hyperledger/fabric-peer bash# peer chaincode --help 注: 可使用docker exec -it cli (容器名) bash命令进入cli 与下面类似的输出 12345678910111213141516171819202122232425262728293031323334Usage: peer chaincode [command]Available Commands: install Package the specified chaincode into a deployment spec and save it on the peer&apos;s path. instantiate Deploy the specified chaincode to the network. invoke Invoke the specified chaincode. package Package the specified chaincode into a deployment spec. query Query using the specified chaincode. signpackage Sign the specified chaincode package upgrade Upgrade chaincode.Flags: --cafile string Path to file containing PEM-encoded trusted certificate(s) for the ordering endpoint -C, --chainID string The chain on which this command should be executed (default &quot;testchainid&quot;) -c, --ctor string Constructor message for the chaincode in JSON format (default &quot;&#123;&#125;&quot;) -E, --escc string The name of the endorsement system chaincode to be used for this chaincode -l, --lang string Language the chaincode is written in (default &quot;golang&quot;) -n, --name string Name of the chaincode -o, --orderer string Ordering service endpoint -p, --path string Path to chaincode -P, --policy string The endorsement policy associated to this chaincode -t, --tid string Name of a custom ID generation algorithm (hashing and decoding) e.g. sha256base64 --tls Use TLS when communicating with the orderer endpoint -u, --username string Username for chaincode operations when security is enabled -v, --version string Version of the chaincode specified in install/instantiate/upgrade commands -V, --vscc string The name of the verification system chaincode to be used for this chaincodeGlobal Flags: --logging-level string Default logging level and overrides, see core.yaml for full syntax --test.coverprofile string Done (default &quot;coverage.cov&quot;)Use &quot;peer chaincode [command] --help&quot; for more information about a command.2018-03-20 07:55:59.840 UTC [main] main -&gt; INFO 003 Exiting..... 全局flags: –logging-level string默认的日志记录level和overrides test.coverprofile string Done(default “coverage.cov”)-v ,–version使用”peer chaincode [command] -help” 获取更多关于命令的信息;为了方便在脚本化的应用程序中使用，peer命令总是在发生命令失败时生成非零返回代码; chaincode命令的例子: 123456peer chaincode install -n mycc -v 0 -p path/to/my/chaincode/v0peer chaincode instantiate -n mycc -v 0 -c &apos;&#123;&quot;Args&quot;:[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]&#125;&apos; -C mychannelpeer chaincode install -n mycc -v 1 -p path/to/my/chaincode/v1peer chaincode upgrade -n mycc -v 1 -c &apos;&#123;&quot;Args&quot;:[&quot;d&quot;, &quot;e&quot;, &quot;f&quot;]&#125;&apos; -C mychannelpeer chaincode query -C mychannel -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;e&quot;]&#125;&apos;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_CA -C mychannel -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]&#125;&apos; 系统智能合约(System chaincode)系统chaincode具有相同的编程模型，除了它在peer进程中运行，而不是普通的chaincode那样在一个单独的容器中运行; 因此，系统chaincode被构建到peer中可执行文件中，并且不遵循上面描述的相同的生命周期。特别是安装、实例化和升级 并不适用于系统chaincode； 系统chaincode的目的是为了在peer和chaincode之间减少gRPC的通信成本，并权衡管理 的灵活性;例如,系统chaincode只能用peer二进制进行升级。它还必须注册一个固定的参数集，并且没有背书策略或背书策略的功能; 系统chaincode用于Hyperledger Fabric以实现许多系统行为，使它们可以被系统集成所取代或修改; 系统chaincode列表: 123451. LSCC(Lifecycle system chaincode): 生命周期系统chaindoe处理上描述的生命周期请求; 2. CSCC(Configuration system chaincode):配置系统chaincode在peer端处理channel配置; 3. QSCC(Query system chaincode): 查询系统chaincode提供了分类查询api,例如获取块和事务; 4. ESCC(Query system chaincode): 背书系统chaincode通过签署事务提案响应来处理支持; 5. VSCC(Validation system chaincode): 验证系统chaincode处理事务验证,策略和多版本并发控制; 在修改或替换这些系统chaincode时必需注意,特别是LSCC、ESCC和VSCC，因为它们在主事务执行路径 中；值得注意的是，当VSCC在将其提交到账本之前一个块，重要的是，channel中的所有peer节点都要计算相同的验证，以避免账本差异。因此，如果VSCC被修改或替换，就需要特别的处理和维护;]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MariaDB之SELECT语法练习]]></title>
    <url>%2F2018%2F02%2F28%2FMariaDB%E4%B9%8BSELECT%E8%AF%AD%E6%B3%95%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[一 、导入hellodb.sql生成数据库后实现以下操作1# mysql -uroot -h172.16.23.23 -pcento.123 &lt; hellodb.sql 123456789101112mysql&gt; SHOW DATABASES; #可以列出已存在的数据库 +--------------------+| Database |+--------------------+| information_schema || NODE1 || RJYY || hellodb || mysql || performance_schema || test |+--------------------+ 12345678910111213mysql&gt; USE hellodb;mysql&gt; SHOW TABLES; +-------------------+| Tables_in_hellodb |+-------------------+| classes || coc || courses || scores || students || teachers || toc |+-------------------+ 1、 在students表中，查询年龄大于25岁，且为男性的同学的名字和年龄；123456789101112mysql&gt; SELECT Name,Age FROM students WHERE Age &gt;25 AND Gender='M'; +--------------+-----+| Name | Age |+--------------+-----+| Xie Yanke | 53 || Ding Dian | 32 || Yu Yutong | 26 || Shi Qing | 46 || Tian Boguang | 33 || Xu Xian | 27 || Sun Dasheng | 100 |+--------------+-----+ 2、 以ClassID为分组依据，显示每组的平均年龄；123456789101112mysql&gt; SELECT avg(age),ClassID FROM students WHERE ClassID IS NOT NULL GROUP BY ClassID ;+----------+---------+| avg(age) | ClassID |+----------+---------+| 20.5000 | 1 || 36.0000 | 2 || 20.2500 | 3 || 24.7500 | 4 || 46.0000 | 5 || 20.7500 | 6 || 19.6667 | 7 |+----------+---------+ 3、 显示第2题中平均年龄大于30的分组及平均年龄；1234567mysql&gt; SELECT avg(Age),ClassID FROM students WHERE ClassID IS NOT NULL GROUP BY ClassID HAVING avg(Age) &gt; 30;+----------+---------+| avg(Age) | ClassID |+----------+---------+| 36.0000 | 2 || 46.0000 | 5 |+----------+---------+ 4、 显示以L开头的名字的同学的信息；12345678mysql&gt; SELECT * FROM students WHERE Name LIKE 'L%';+-------+-------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID TeacherID |+-------+-------------+-----+--------+---------+-----------+| 8 | Lin Daiyu | 17 | F | 7 | NULL || 14 | Lu Wushuang | 17 | F | 3 | NULL || 17 | Lin Chong | 25 | M | 4 | NULL |+-------+-------------+-----+--------+---------+-----------+ 5、 显示TeacherID非空的同学的相关信息；12345678910mysql&gt; SELECT * FROM students WHERE TeacherID IS NOT NULL; +-------+-------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+-------------+-----+--------+---------+-----------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 || 2 | Shi Potian | 22 | M | 1 | 7 || 3 | Xie Yanke | 53 | M | 2 | 16 || 4 | Ding Dian | 32 | M | 4 | 4 || 5 | Yu Yutong | 26 | M | 3 | 1 |+-------+-------------+-----+--------+---------+-----------+ 6、 以年龄排序后，显示年龄最大的前10位同学的信息；123456789101112131415mysql&gt; SELECT * FROM students ORDER BY Age DESC LIMIT 10;+-------+--------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+--------------+-----+--------+---------+-----------+| 25 | Sun Dasheng | 100 | M | NULL | NULL || 3 | Xie Yanke | 53 | M | 2 | 16 || 6 | Shi Qing | 46 | M | 5 | NULL || 13 | Tian Boguang | 33 | M | 2 | NULL || 4 | Ding Dian | 32 | M | 4 | 4 || 24 | Xu Xian | 27 | M | NULL | NULL || 5 | Yu Yutong | 26 | M | 3 | 1 || 17 | Lin Chong | 25 | M | 4 | NULL || 23 | Ma Chao | 23 | M | 4 | NULL || 18 | Hua Rong | 23 | M | 7 | NULL |+-------+--------------+-----+--------+---------+-----------+ 7、 查询年龄大于等于20岁，小于等于25岁的同学的信息；用三种方法；1234567891011121314151617mysql&gt; SELECT * FROM students WHERE Age &gt;=20 AND Age &lt;=25; mysql&gt; SELECT * FROM students WHERE Age BETWEEN 20 AND 25; mysql&gt; SELECT * FROM students WHERE Age IN (20,21,22,23,24,25);+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 || 2 | Shi Potian | 22 | M | 1 | 7 || 9 | Ren Yingying | 20 | F | 6 | NULL || 11 | Yuan Chengzhi | 23 | M | 6 | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL || 17 | Lin Chong | 25 | M | 4 | NULL || 18 | Hua Rong | 23 | M | 7 | NULL || 21 | Huang Yueying | 22 | F | 6 | NULL || 22 | Xiao Qiao | 20 | F | 1 | NULL || 23 | Ma Chao | 23 | M | 4 | NULL |+-------+---------------+-----+--------+---------+-----------+ 二、 导入hellodb.sql，以下操作在students表上执行1、以ClassID分组，显示每班的同学的人数；12345678910111213mysql&gt; SELECT count(StuID),ClassID FROM students GROUP BY ClassID ; +--------------+---------+ | count(StuID) | ClassID |+--------------+---------+| 2 | NULL || 4 | 1 || 3 | 2 || 4 | 3 || 4 | 4 || 1 | 5 || 4 | 6 || 3 | 7 |+--------------+---------+ 2、以Gender分组，显示其年龄之和；1234567mysql&gt; SELECT sum(Age),Gender FROM students GROUP BY Gender ;+----------+--------+| sum(Age) | Gender |+----------+--------+| 190 | F || 495 | M |+----------+--------+ 3、以ClassID分组，显示其平均年龄大于25的班级；12345678mysql&gt; SELECT avg(Age),ClassID FROM students GROUP BY ClassID HAVING avg(Age) &gt; 25;+----------+---------+| avg(Age) | ClassID |+----------+---------+| 63.5000 | NULL || 36.0000 | 2 || 46.0000 | 5 |+----------+---------+ 4、以Gender分组，显示各组中年龄大于25的学员的年龄之和；123456mysql&gt; SELECT sum(Age),Gender FROM students WHERE Age &gt; 25 GROUP BY Gender ;+----------+--------+| sum(Age) | Gender |+----------+--------+| 317 | M |+----------+--------+ 三、 导入hellodb.sql，完成以下题目：1、显示前5位同学的姓名、课程及成绩；12345678910111213141516171819mysql&gt; SELECT s.Name,courses.Course,scores.Score FROM (select * from students limit 5) AS s LEFT JOIN scores ON scores.StuID = s.StuID LEFT JOIN courses ON scores.CourseID =courses.CourseID;mysql&gt; SELECT s.name,sc.course,sc.score FROM (SELECT * FROM students LIMIT 5 ) AS s LEFT JOIN (SELECT scores.stuid,courses.course,scores.score FROM scores LEFT JOIN courses ON courses.CourseID=scores.CourseID)AS sc ON s.StuId=sc.StuID;+-------------+----------------+-------+| name | course | score |+-------------+----------------+-------+| Shi Zhongyu | Kuihua Baodian | 77 || Shi Zhongyu | Weituo Zhang | 93 || Shi Potian | Kuihua Baodian | 47 || Shi Potian | Daiyu Zanghua | 97 || Xie Yanke | Kuihua Baodian | 88 || Xie Yanke | Weituo Zhang | 75 || Ding Dian | Daiyu Zanghua | 71 || Ding Dian | Kuihua Baodian | 89 || Yu Yutong | Hamo Gong | 39 || Yu Yutong | Dagou Bangfa | 63 |+-------------+----------------+-------+ 2、显示其成绩高于80的同学的名称及课程；1234567891011121314mysql&gt; SELECT Name,Course,Score FROM (students LEFT JOIN scores ON students.StuID=scores.StuID ) LEFT JOIN courses ON courses.CourseID=scores.CourseID WHERE Score &gt; 80; +-------------+----------------+-------+| Name | Course | Score |+-------------+----------------+-------+| Shi Zhongyu | Weituo Zhang | 93 || Shi Potian | Daiyu Zanghua | 97 || Xie Yanke | Kuihua Baodian | 88 || Ding Dian | Kuihua Baodian | 89 || Shi Qing | Hamo Gong | 96 || Xi Ren | Hamo Gong | 86 || Xi Ren | Dagou Bangfa | 83 || Lin Daiyu | Jinshe Jianfa | 93 |+-------------+----------------+-------+ 3、求前8位同学每位同学自己两门课的平均成绩，并按降序排列；1234567891011121314mysql&gt; SELECT Name,avg(Score) FROM (SELECT * FROM students LIMIT 8) AS rj LEFT JOIN scores ASjr ON rj.StuID=jr.StuID GROUP BY Name ORDER BY avg(Score) DESC;+-------------+------------+| Name | avg(Score) |+-------------+------------+| Shi Qing | 96.0000 || Shi Zhongyu | 85.0000 || Xi Ren | 84.5000 || Xie Yanke | 81.5000 || Ding Dian | 80.0000 || Lin Daiyu | 75.0000 || Shi Potian | 72.0000 || Yu Yutong | 51.0000 |+-------------+------------+ 4、显示每门课程课程名称及学习了这门课的同学的个数；123456789101112mysql&gt; SELECT courses.Course,count(rj.StuID) FROM scores AS rj LEFT JOIN courses ON courses.CourseID=rj.CourseID GROUP BY rj.CourseID;+----------------+-----------------+| Course | count(rj.StuID) |+----------------+-----------------+| Hamo Gong | 3 || Kuihua Baodian | 4 || Jinshe Jianfa | 1 || Taiji Quan | 1 || Daiyu Zanghua | 2 || Weituo Zhang | 2 || Dagou Bangfa | 2 |+----------------+-----------------+ 四、思考题1、如何显示其年龄大于平均年龄的同学的名字？12345678910mysql&gt; SELECT Name,Age FROM students WHERE Age &gt; (SELECT avg(Age) FROM students);+--------------+-----+| Name | Age |+--------------+-----+| Xie Yanke | 53 || Ding Dian | 32 || Shi Qing | 46 || Tian Boguang | 33 || Sun Dasheng | 100 |+--------------+-----+ 2、如何显示其学习的课程为第1、2，4或第7门课的同学的名字？123456789101112131415mysql&gt; SELECT rj.Name,scores.CourseID FROM students AS rj LEFT JOIN scores ON scores.StuID = rj.StuID WHERE scores.CourseID IN (1,2,4,7);+-------------+----------+| Name | CourseID |+-------------+----------+| Shi Zhongyu | 2 || Shi Potian | 2 || Xie Yanke | 2 || Ding Dian | 2 || Yu Yutong | 1 || Yu Yutong | 7 || Shi Qing | 1 || Xi Ren | 1 || Xi Ren | 7 || Lin Daiyu | 4 |+-------------+----------+ 3、如何显示其成员数最少为3个的班级的同学中年龄大于同班同学平均年龄的同学？123456789101112131415mysql&gt; SELECT students.name,students.age,tp.classid,tp.vg FROM students,(SELECT classid,COUNT(stuid) AS cs,AVG(age) AS vg FROM students GROUP BY classid HAVING cs &gt;=3) AS tp WHERE students.age&gt;tp.vg AND students.classid=tp.classid;+---------------+-----+---------+---------+| name | age | classid | vg |+---------------+-----+---------+---------+| Shi Potian | 22 | 1 | 20.5000 || Xie Yanke | 53 | 2 | 36.0000 || Ding Dian | 32 | 4 | 24.7500 || Yu Yutong | 26 | 3 | 20.2500 || Yuan Chengzhi | 23 | 6 | 20.7500 || Xu Zhu | 21 | 1 | 20.5000 || Lin Chong | 25 | 4 | 24.7500 || Hua Rong | 23 | 7 | 19.6667 || Huang Yueying | 22 | 6 | 20.7500 |+---------------+-----+---------+---------+ 4、统计各班级中年龄大于全校同学平均年龄的同学。12345678910mysql&gt; SELECT rj.Name,rj.Age FROM students AS rj LEFT JOIN classes AS jr ON rj.ClassID=jr.ClassID WHERE rj.ClassID=jr.ClassID AND Age &gt; (SELECT AVG(Age) FROM students);+--------------+-----+| Name | Age |+--------------+-----+| Xie Yanke | 53 || Ding Dian | 32 || Shi Qing | 46 || Tian Boguang | 33 |+--------------+-----+]]></content>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从头开始了解Hyperledger]]></title>
    <url>%2F2018%2F02%2F15%2Fhyperledger%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[从头开始了解Hyperledger Hyperledger词汇表 Anchor Peer -锚节点 锚节点是通道中能被所有对等节点探测、并能与之进行通信的一种对等节点;通道中的每个成员都有一个(或者多个，以防单点故障) 锚节点 ;允许属于不同成员身份的节点来发现通道中存在的其它节点; Block - 区块 在一个通道上，(区块是)一组有序交易的集合;区块往往通过密码学手段(Hash值)连接到前导区块;区块是一组有序的交易集合，在通道中经过加密码(哈希加密，后与前序区块连接)； Chain - 链 chain就是block之间以hash连接为结构的交易日志。peer从order service接收交易block;并根据背书策和并发冲突标记block上交易是否有效;然后将该block追回到pper文件系统中的hash chain 帐本的链是一个交易区块经过”哈希连接”结构化的交易日志;对等节点从排序服务收到交交易区块;基于背书策略和并发冲突来标注区块的交易为有效或者无效状态;并且将区块追回到等结点文件系统的哈希链中; Chaincode-链码 链码是一个运行在帐本上的软件，它可以对资产过行编码;其中的交易指令(或者叫业务逻辑)也呆以用来修改资产; Channel-通道 通道是构建在”Fabric”网络上的私有区块链，实现了数据的隔离和保密;通道特定的帐本在通道中是与所有对等节点共享的;并且交易方必须通过该通道的正确验证才能与账本进行交互;通道是由一个”配置块”来定义的; Commitment-提交 一个通道中的每个对等节点都会难交易的有序区块，然后将区块提交至该通道上帐本的各个副本;对等节点也会票房每个区块中的每笔交易的状态 是有效或者无效; Concurrency Control Version Check- 并发控制版本检查(CCVC) CCVC是保持通道中各对等节点状态同步的一种方法。对等节点并行的交易；在交易提交到帐本之前，对等节点会检查交易在执行期间读到的数据是否被修改;如果读取的数据在执行和提交之间被改变，就会引发CCVC冲突;该交易就会在帐本中被标记为无效，而且值不会更新到状态数据库; Configuration Block - 配置区块 包含为系统链(排序服务)或通道定义成员和策略的配置数据。对某个通道或整个网络的修改;(比如，成员离开或加入)都将导致生成一个新的配置区块并追回到适当的链上;这个配置区块会包含创始区块的内容加上增量; Consensus - 共识 共识是贯穿整个交易流程的广义术语，其用于产生个对于排序的同意书和确认构成区块的交易集的正确性; Current State -当前状态 ledger的current state表示其chain交易log中所有key的最新值。peer会将处理过的block中的每个交易;对应的修改value提交到ledger和current state。由于current state 表示channel所知的所有最新的k-v;所以current state也被称为World State. Chaincode执行交易proposal就是针对的current state; Dynamic Membership -动态成员 Fabric支持动态添加-移除member、peer 和ordering服务节点，而不会影响整个网络的操作性;当业务关系调整或因各种原因需添加-移除实体时，Dynamic Membership 至关重要； Endorsement-背书 Endorsement是指一个peer执行一个交易并返回YES-NO给生成交易proposal的client app的过程;chaincode具有相应的endorsement policies.其中指定了endorsing peer; Endorsement plolicy - 背书策略 Endorsement policy定义了依赖于特定chaincode执行交易的channel上的peer和响应结果;(endorsements) 的必要组合条件(即反回Yes或NO的条件)。 Endorsement policy可以指定对于某一chaincode;可以对交易背书的最小背书节点或者最小背书节点百分比;背书策略由背书节点基于应用程序和对抵御不良行为的期望水来来组织管理;在install和instantiate Chaincode (deploy tx)时需要指定背书策略; Fabric-ca Fabric-ca是默认的证书管理组件，它向网络成员及其用户颁发基于PKI的证书;CA为每个成员颁发一个根证书(RootCert),为每个授权用户颁发一个注册证书(eCert);为每个注册证书颁发大量交易证书(tCerts); Genesis Block - 初始区块 Genesis Block是初始化区块链网络或channel的配置块，也是链上的每一个区块; Gossip Protocol - Gossip 协议 Gossiop数据传输协议有三项功能 1.管理peer发和channel成员;2.channel上的所有peer间广播帐本数据;3.channel上的所有peer间同步收本数据; Initialize- 初始化 一个初始化chaincode程序的方法; Install -安装 将chaincode放到peer的文件系统的过程; Instantiate - 实例化 启动chaincode容器的过程; Invoke - 调用 用于调用 chaincode内的函数; Chaincode invoke就是一个交易proposal;然后执行模块化的流程(背书、共识、验证、提交);invoke的结构就是一个函数和一个参数数组; Leading Peer - 主导节点 每一个Member在其订阅的channel上可以拥有多个peer；其中一个peer会作为chanel的leading peer 代表该Member与ordering service 通信;ordering service 将block传递给leading peerd， 该peer再将此block分发给同一memer下的其他peer; Ledger - 帐本 Ledger是个channel的chain和由channel中每个peer维护 的world state； Member- 成员 拥有网络唯一根证书的合法独立实体。像peer节点和app client这样的网络组件会链接到一个Member; Membership Service Provider -MSP MSP是指为client和peer提供证书的系统抽象线件。Cient用证书来谁他们的交易;peer用证书认证其交易背书。该接口与系统的交易处理组件密切相关;旨在使已定义的成员身份服务组件以这种方式顺利挺好入而不会修改系统的交易处理组件的核心; Membership Services - 成员服务 成员服务在许可的区块链网络上认证、授权和管理身份 ;在peer和order运行的成员服务的代码者会认证和授权区块链操作;它是基于PKI的MSP实现; fabric-ca组件实现了成员服务，来管理身份。特别的，它处理ECert和TCert的颁发和撤销; ECert是长期的身份任证; TCert是短期的身份凭证，是匿名和不可链接的; Ordering Service -排序服务或共识服务 将交易排序放入block的节点的集合。ordering service 独立于peer流程之外;并以先到先得的方式为网络上所有的channel作交易排序;ordering service 支持可插拔实现，目前默认实现了SOLO和Kafka;ordering service是整个网络的公用binding， 包含每个Member相关的加密材料; Peer -节点 一个网络实体，维护ledger并运行Chaincode容器来对ledger很乖read-write操作;peer由Member拥有和维护; Policy-策略 有背书策略;校验策略;区块提交策略;Chaincode管理策略和网络-通道管理策略; Proposal - 提案 一种针对channel中某peer的背书请求。每个proposal要么是Chaincode instantiate 要么是Chaincode inovke; Query- 查询 对于current state中某个key的value的查询请求; Software Development Kit -SDK SDk为开发人员提供了一个结构化的库环境，用于编写和测试链码应用程序；SDK完全可以通过标准接口实现配置和扩展，像签名的加密算法;日志框架和state存储这样的组件都可以轻松地实现替换;SDK API 使用gRPC进行交易处理，成员服务、节点遍历以及事件处理都是据此与fabric通信;目前SDK支持Node.js Java 和python ; State Database - stateDB 为了从Chainncode中高效的读写,Current state数据礁在stateDB中， 包括levelDB和souchDB; System chain-系统链 包含在系统级定义网络的配置区块。系统链存在于ordering service中;具有包含以下信息的初始配置:MSP信息、策略和信息配置。对整个网络的任何变化;(例如新的Or加入或者添加新的Ordering 节点)将导致新的配置区块被添加到系统链; Transaction- 交易 Caincode的invoke或instantiate操作; Invoke是从ledger中请求read-write set；Instantiate是请求在peer上启动Chaincode容器; 了解Hyperledger FarbicHyperledger Fabric是一个提供 分布式账本方案的平台。Hyperledger Fabric由模块化架构支撑; 并具备极佳的保密性、可伸缩性、灵活性和可扩展平台; Hyperledger Fabirc被设计成支持不同的模块组件直接拔插启动; 并能适应在经济生态系统中错综复杂的和种场景; Hyperledger Fabric提供了一个独特的可伸缩、可扩展的架构，这也是Hyperledger Fabric与其他区块的链解决方案的显著区别;如果正计划部署具备完整审查机制以及开源架构的企业级区块链; Hyperledger Fabric昌一个不错的起点; 区块链分布式账本一个区链网络的核心是一个分布式账本，在这个账本中记录了网络发生的所有交易信息; 区块链账本通常被定义为去中心化，这是因为在整个网络中，每个参与者都保存着一个区块链账本的副本，所有参与者通过协作 共同维护着账本; 去中心化与协作 这两个特点在现实世界的商业货物交易和商务服务中展出现的显著优点; 除了去中心化与协作，区链链的另一个显著特点是信息在只能以”附加”的方式记录在区块链中; 同时使用加密码技术保障了交易一旦被添加进账本中，就无法被篡改。区块链的这种不可篡改性使得信息来源的确认变得异常容易，这是由于参与者可以肯定信息一旦被写入区块链中就几乎不可被 篡改。这也是为什么区块链常常也被称为证明的系统的原因; 智能合约为了持续的进行信息的更新，以及帐本进行管理(写入交易，进行查询等)，区块链网络引入了智能合约来实现对账本的访问和控制; 智能合约不仅仅可用于在区块链网络中打包信息，它们也可以被用于自动的执行由参与者定义的特定交易操作; 例如,买卖双方要以定义一个智能合约，以保证当卖方发货的端口运送到达时，买方支付的货款会自二甲双胍转帐给卖方; 共识保持网络中所有账本交易的同步流程，就是共识。共识保证 了账本只会在交易双方都确认后才进行更新。同时在账本更新时，交易双方能够在在账本中的相同位置 ，更新一个相同的交易信息; ##区块链因何可行 当前的记录系统自从商业数据记录网络系统诞生以来，直到今天的交易网络并不骨发生太大的变化; 在商业网络中的成员进行相互交易时，他们各自维护着自己独立的交易记录。同时，人们交易的物品–无论是16世纪佛兰德的挂毯，还是现代的有价证券–都任然需要在每次卖出交易过程中提供来源信息，以确保卖方拥有所出售端口的所有权; 随着科技的进步，交易流程不断深化发展，经历了从使用用石碑、使用纸质账本、使用硬盘存储器直到使用云计算平台的不同阶段，但流程的底层架构并没有发生任何变化。并不存一个可以统一管理网络参与者身份的系统，确认商品来源十分费劲,常常会耗费数天的时间 明确证券的交易(包含数以万计美元的数量)。人们必需签订合约并手动执行，每一个系统中的数据库都包含着独立 的信息并最终代表一个单点的错误。 在今天的信息和过程共享断裂的方法中，建立一个跨越商业网络的记录系统是不可能的，尽管可见性和信任的需求是明确的; 区块链的不同点 为什么不用”现代”的交易系统来替代这种效率低下的网络？新的商业网络可以具有标准的方法建立身份信息，执行交易，并且存储数据。为什么不建立一个可住的交易链条记录？通过查询这个链条上的所有交易，来确定交易商品来源，并且这个链条上的信息一旦被写入，就无法被再次篡改; 这就是区块链网络。在区块链网络中，每一个参与者都保有一份账本的副本。在区块链网络中，不仅仅是账本信息会被共享，更新账本的流程是共享的。不同于目前的系统–参与者使用私有的程序对私胡的账本进行更新，而区块链系统使用共享的程序对共享的账本进行更新; 通过使用共享账协调整个商业网络，区块链网络能免减少时间、成本以及隐私信息泄露的风险，并且能使用流程更加可信和透明; Hyperledger Fabric2015年，Linux基金会启动了Hyperledger项目，hhsfi是发展跨行业的区块链技术。Hyperledger项目并不仅仅是定义一个单一的区块链标准，它更鼓励能过开源社区的力量协作开发区块链技术 ; Hyperledger Fabric是Hyperledger中的一个区块链项目。与其他区块链技术类似, Hyperledger Fabric包含一个账本，使用智能合约并且是一个通过所有参与者管理 交易的系统; Hyperledger Fabric 与其他区块链系统最大的不同体现在私有和许可。与开放无需许可的网络系统允许未知身份的参与者加入网络不同(需要能过工作量证明协议来保证交易有效并维护网络的安全)，Hyperledger Fabric通过Membership Service Provider(MSP)来登记所有的成员; Hyperledger Fabric也提供了多个可拔插选项。账本数据可被存储为多种格式，共识机制可被接入或者断开，同时支持多种不同的MSP。 Hyperledger Fabric提供了建立 channel的功能，这允许参与者为交易新建一个单独的账本。当网络中的一些参与者是竞争对手时，这个功能变得尤为重要。因为这些参与者并不希望所有的交易信息–比如提供给部分客户的特定价格信息–都对网络中所有参与者公开。只有在同一个channel中的参与者，才会拥有该channel中的账本，而其他不在此channel中的参与者则看不到这个账本; 共享账本Hyperledger Fabric包含一个账本子系统，这个子系统包含两个组件:世界状态(world state) 和交易记录。在Hyperledger Fabric网络中的每一个参与者都拥有一个账本的副本; 世界状态组件描述了账本在特定时间点的状态，它是账本的数据库。交易记录组件记录了产生世界状态当前值的所有交易，它是世界状态的更新历史。那么，账本则是世界状态数据库和交易历史记录的集合; 账本的世界状态存储数据库是可更换的。默认配置下，这是一个key-value存储数据库。交易记录模 块不需要被不接入。只需要记录在区块链网络中曲棍球数据库被 使用时之前和之后的值就可以了; 智能合约Hyperledger Fabric智能合约被称为chaincode，当一个区块链外部的一个应用程序需要访问账本时,就会调用chaincode。大多数情况下，chaincode只会访问账本的数据库组件和世界状态(world sate)(比如查询)，但不会查询交易记录; chaincode可通过多种不同编程语言实现。目前支持chaincode的语言是Go(包含对java的支持)]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Installing and Accessing Mysql Server]]></title>
    <url>%2F2018%2F02%2F09%2FInstalling-and-Accessing-Mysql-Server%2F</url>
    <content type="text"><![CDATA[MariaDB or MySQL1234567891011121314151617181920212223242526272829303132333435363738DBMS: 数据库管理系统，只是一个程序，而非数据RDBMS: 关系型数据库管理系统 C/S: 专有协议 关系模型: 表(行，列) 组成的二维关系 范式:第一范式、第二范式、第三范式 关系运算: 选择 投影 数据库: 表，索引，视图(虚表) SQL: Structure Query Language (结构化查询语言) DDL(数据定义语言),DML(数据操纵语言，操作表中的数据) 编程接口: 存储过程 存储函数 触发器 事件调试器 (Event scheduling) 过程式编辑: 选择、循环三层模型: 物理层(一张表，或者多张表，表现为一个文件) 逻辑层(表，索引，视图，等等) 视图层(最终用户所看到的样子，授权用户所看到的) 做为DBA需要: 设计/创建表 设计/创建索引 设计/创建视图 数据库的导入导出等解决方案: 付费: Oracle ,Sybase ,Infomix(IBM) ,DB2(IBM) 开源: MySQL ,MariaDB ,PostgreSQL , SQLite(是一种嵌入式的解决方案) 目前MySQL已经被Oracle收购 有三成把握的时候，就要争取。不然机会就错过了，但要做好充份准备。 没有谁好谁坏，只要向往自己的理想就好了。 MySQL --&gt; 5.1 --&gt; 5.5 --&gt; 5.6 --&gt; 5.7 MariaDB 插件式存储引擎(支持众多类型的存储引擎) MySQL是否支持事物，则需要查看存储引擎是否支持事物 单进程多线程 连接线程 守护线程 12345678910111213141516MariaDB [mysql]&gt; SHOW ENGINES ;+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| CSV | YES | CSV storage engine | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+10 rows in set (0.00 sec) 1234567891011121314151617181920212223242526272829303132333435363738MySQL配置文件:集中式的配置，能够为mysql的各应用程序提供配置信息 [mysqld] 专用于mysqld应用程序 [mysqld_safe] 线程安全的mysqld专有配置 [mysqld_multi] 多实例共离的mysql [server] 只要有是mysql服务端的都有效的 [mysql] mysql客户端的 [mysqldump] 数据导入导出的 [client] 对于客户端工具的 parameter = value 支持_ - 两种 skip-name-reslove skip_name_reslove 两种方式都是可以的mysql启动时查找路径 /etc/my.cnf --&gt; /etc/mysql/my.cnf --&gt; $MYSQL_HOME/my.cnf --&gt; default-extra-file=/path/to/somdir/my.cnf --&gt; ~/.my.cnf 后找到的，行会覆盖先找到的，于是，越住后的是，越是先生效 安装方法 os vendor: rpm ubuntu最成功的领域在桌面 服务器建议使用CentOS, SUSE,OpenSUSE,Debian等等 Debian 要求技术能力偏高 MySQL: rpm 展开可用，一般安装就用的这种方式 源码，源码安装时需要对代码打布丁，对MySQL订制 安装后的设计: （1）为所有root用户设定密码 mysql&gt; SET PASSWORD mysql&gt; update mysql.user SET password= PASSWORD(&apos;your_pass&apos;) WHERE cluase; mysql&gt; FLUSH PRIVILEGES ; # mysqladmin 用这个命令来修改 (2) 删除所有匿名用户 mysql&gt; DROP USER &apos;&apos;@ &apos;localhost&apos;; 上术两步骤可运行命令: mysql_secure_installation (3) 建议关闭主机名反解功能元数据数据库: mysql user,host 等mysql 客户端工具 mysql]]></content>
      <tags>
        <tag>linux</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 常用命令与技巧]]></title>
    <url>%2F2018%2F02%2F08%2Flinux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[linux 常用命令与技巧 1.检查远程端口是否对bash开放：1echo &gt;/dev/tcp/8.8.8.8/53 &amp;&amp; echo "open" 2.让进程转入后台：1Ctrl + z 3.将进程转到前台：1fg 4.产生随机的十六进制数，其中n是字符数：1openssl rand -hex n 5.在当前shell里执行一个文件里的命令：1source /home/user/file.name 6.截取前5个字符：1$&#123;variable:0:5&#125; 7.SSH debug 模式:1ssh -vvv user@ip_address 8.SSH with pem key:1ssh user@ip_address -i key.pem 9.用wget抓取完整的网站目录结构，存放到本地目录中：1wget -r --no-parent --reject "index.html*" http://hostname/ -P /home/user/dirs 10.一次创建多个目录：1mkdir -p /home/user/&#123;test,test1,test2&#125; 11.列出包括子进程的进程树：1ps axwef 12.创建 war 文件:1jar -cvf name.war file 13.测试硬盘写入速度：1dd if=/dev/zero of=/tmp/output.img bs=8k count=256k; rm -rf /tmp/output.img 14.测试硬盘读取速度：1hdparm -Tt /dev/sda 15.获取文本的md5 hash：1echo -n "text" | md5sum 16.检查xml格式：1xmllint --noout file.xml 17.将tar.gz提取到新目录里：1tar zxvf package.tar.gz -C new_dir 18.使用curl获取HTTP头信息：1curl -I http://www.example.com 19.修改文件或目录的时间戳(YYMMDDhhmm):1touch -t 0812250000 file 20.用wget命令执行ftp下载：1wget -m ftp://username:password@hostname 21.生成随机密码(例子里是16个字符长):1LANG=c &lt; /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c$&#123;1:-16&#125;;echo; 22.快速备份一个文件：1cp some_file_name&#123;,.bkp&#125; 23.访问Windows共享目录：1smbclient -U "DOMAIN\user" //dc.domain.com/share/test/dir 24.执行历史记录里的命令(这里是第100行):1!100 25.解压:123unzip package_name.zip -d dir_nametar xvf package_name.tar.gz -d dir_nametar cvf package_name.tar.gz /path/to/file/ 26.输入多行文字(CTRL + d 退出):1cat &lt; &gt;&gt; test.txt 27.创建空文件或清空一个现有文件：1\&gt; test.txt 28.与Ubuntu NTP server同步时间：1ntpdate ntp.ubuntu.com 29.用netstat显示所有tcp4监听端口：1netstat -lnt4 | awk '&#123;print $4&#125;' | cut -f2 -d: | grep -o '[0-9]*' 30.qcow2镜像文件转换：1qemu-img convert -f qcow2 -O raw precise-server-cloudimg-amd64-disk1.img \precise-server-cloudimg-amd64-disk1.raw 31.重复运行文件，显示其输出（缺省是2秒一次）：12watch ps -efwatch -n1 &quot;df -h&quot; 32.所有用户列表：123getent passwdawk -F: '&#123;print $1&#125;' /etc/passwd cat /etc/passwd | cut -d ':' -f 1 33.Mount root in read/write mode:1mount -o remount,rw / 34.挂载一个目录（这是不能使用链接的情况）:1mount --bind /source /destination 35.动态更新DNS server:1234nsupdate &lt; &lt;EOFupdate add $HOST 86400 A $IPsendEOF 36.递归grep所有目录：1grep -r "some_text" /path/to/dir 37.列出前10个最大的文件：1lsof / | awk '&#123; if($7 &gt; 1048576) print $7/1048576 "MB "$9 &#125;' | sort -n -u | tail 38.显示剩余内存(MB):1free -m | grep cache | awk '/[0-9]/&#123; print $4" MB" &#125;' 39.打开Vim并跳到文件末：1vim + some_file_name 40.Git 克隆指定分支(master):1git clone git@github.com:name/app.git -b master 41.Git 切换到其它分支(develop):1git checkout develop 42.Git 删除分支(myfeature):1git branch -d myfeature 43.Git 删除远程分支1git push origin :branchName 44.Git 将新分支推送到远程服务器：1git push -u origin mynewfeature 45.打印历史记录中最后一次cat命令：1!cat:p 46.运行历史记录里最后一次cat命令：1!cat 47.找出/home/user下所有空子目录:1find /home/user -maxdepth 1 -type d -empty 48.获取test.txt文件中第50-60行内容：1&lt; test.txt sed -n '50,60p' 49.运行最后一个命令(如果最后一个命令是mkdir /root/test, 下面将会运行: sudo mkdir /root/test)：1sudo !! 50.创建临时RAM文件系统 – ramdisk (先创建/tmpram目录):1mount -t tmpfs tmpfs /tmpram -o size=512m 51.Grep whole words:1grep -w "name" test.txt 52.在需要提升权限的情况下往一个文件里追加文本：1echo "some text" | sudo tee -a /path/file 53.列出所有kill signal参数:1kill -l 54.在bash历史记录里禁止记录最后一次会话：1kill -9 $$ 55.扫描网络寻找开放的端口：1nmap -p 8081 172.20.0.0/16 56.设置git email:1git config --global user.email "me@example.com" 57.To sync with master if you have unpublished commits:1git pull --rebase origin master 58.将所有文件名中含有”txt”的文件移入/home/user目录:1find -iname "*txt*" -exec mv -v &#123;&#125; /home/user \; 59.将文件按行并列显示：1paste test.txt test1.txt 60.shell里的进度条:1pv data.log 61.使用netcat将数据发送到Graphite server:12echo "hosts.sampleHost 10 `date +%s`" | nc 192.168.200.2 3000 62.将tabs转换成空格：1expand test.txt &gt; test1.txt 63.Skip bash history:1&lt; space &gt;cmd 64.去之前的工作目录：1cd - 65.拆分大体积的tar.gz文件(每个100MB)，然后合并回去：12split –b 100m /path/to/large/archive /path/to/output/filescat files* &gt; archive 66.使用curl获取HTTP status code:1curl -sL -w "%&#123;http_code&#125;\\n" www.example.com -o /dev/null 67.设置root密码，强化MySQL安全安装:1/usr/bin/mysql_secure_installation 68.当Ctrl + c不好使时:1Ctrl + \ 69.获取文件owner:1stat -c %U file.txt 70.block设备列表：1lsblk -f 71.找出文件名结尾有空格的文件：1find . -type f -exec egrep -l " +$" &#123;&#125; \; 72.找出文件名有tab缩进符的文件1find . -type f -exec egrep -l $'\t' &#123;&#125; \; 73.用”=”打印出横线:全选复制放进笔记1printf '%100s\n' | tr ' ' = 74.当一个文件较大，rm -rf 也无法删除时12echo '' &gt; filenamerm -rf filename 75.统计访问量前5的ip12cat /var/log/nginx/access.log| cut -d " " -f 1 | sort -r | uniq -c | sort -nr | head -n5awk &#123;'print $1'&#125; /var/log/nginx/access.log | sort -r | uniq -c | sort -nr | head -5 76.CPU占用最多的前10个进程：1ps auxw|head -1;ps auxw|sort -rn -k3|head -10 78.内存消耗最多的前10个进程1ps auxw|head -1;ps auxw|sort -rn -k4|head -10 79.虚拟内存使用最多的前10个进程1ps auxw|head -1;ps auxw|sort -rn -k5|head -10 80.将443端口转发到8080端口1sudo iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-ports 8080 1234567mkdir -p /root/configtouch /root/config/postfix-accounts.cfdocker run --rm \ -e MAIL_USER=renjin@ssjinyao.com \ -e MAIL_PASS=centos.123\ -ti tvial/docker-mailserver:latest \ /bin/sh -c &apos;echo &quot;$MAIL_USER|$(doveadm pw -s SHA512-CRYPT -u $MAIL_USER -p $MAIL_PASS)&quot;&apos; &gt;&gt; /root/config/postfix-accounts.cf]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 负载均衡多个nmmp主机]]></title>
    <url>%2F2018%2F02%2F07%2FNginx-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%A4%9A%E4%B8%AAnmmp%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[设计拓扑图 一、Memcache简介cache(缓存系统)12345678910111213141516高性能分布式缓存服务器，缓存所有的“可流式化”数据livejournal旗下Danga Interacive公司 程序=指令+数据指令：程序数据：IO操作文件系统：特征：协议简单基于libevent的事件处理内置内存存储方式memcached 不互通信的分布式由于一台memcached变动时会导致数据无法查询到，客户端使用一致性hash算法一台memcached变动时，数据会丢失。memcached之间不能互相通信，所以不支持冗余。注:memcacched服务重启时，缓存的数据会丢失；CentOS 7 memcached的安装流程；base repository;服务端程序:memcached 程序环境123456配置文件； /etc/sysconfig/memcached主程序:/usr/bin/memcached工具/usr/bin/memcached-toolunitfile /usr/lib/systemd/system/memcached.servicelibmemcached:libmemcached 是一个C/C++对于memcached服务器的客户端库和工具libmemcached-devel:这个包中包涵libmemcached的头文件和库 1234567891011121314151617 Memcached命令详解 memcachedmemcached [options]:-l &lt;ip_addr&gt;:监听的地址-d Run memcahched as a daemon-m &lt;num&gt; 缓存空间最大值-u &lt;username&gt;:进程属主-p &lt;num&gt;:监听的tcp端口，默认为11211-U &lt;num&gt;:监听的udp端口，0表示关闭-M 当缓存满时，禁止对缓存清理-c 最大并发连接数-t &lt;threads&gt;用于指定服务器启动的线程数；每个线程数响应多个请求Slab Allocator:内存分配器预先分配好固定大小（slab class）内存块，每种大小的块（chunk）有1 或多个；相信的slab class的大小差别由增长因子控制;-f&lt;factor&gt;,默认为1.25# vim /etc/sysconfig/memcachedOPITONS=&quot; -f 1.1 -U 0&quot; 可以更改 php连接memcached程序123456php-pecl-memcachephp-pecl-memcachedCluster保持会话的方法session stickysession clustersession server 二、安装配置memcached,php-fpm,nginxnode3 安装memcached123# ansible node3 -m yum -a "name=memcached state=present"# ansible node3 -m command -a "rpm -ql memcached"# ansible node3 -m service -a "name=memcached state=started" node0,1,2安装nginx12345678910# for i in &#123;1..2&#125;; do ansible node$i -m copy -a "src=/root/nginx-1.10.0-1.el7.ngx.x86_64.rpm dest=/root/ " ; done# for i in &#123;1..2&#125; ; do ssh node$i yum -y install /root/nginx-1.10.0-1.el7.ngx.x86_64.rpm ; donenode1,2安装php-fpm mariadb php-pecl-memcached php-memcache php-memcached# for i in &#123;1..2&#125;; do ansible node$i -m yum -a "name=mariadb-server state=present" ; done# for i in &#123;1..2&#125;; do ansible node$i -m yum -a "name=php-fpm state=present" ; done# for i in &#123;1..2&#125;; do ansible node$i -m service -a "name=mariadb enabled=on" ; done# for i in &#123;1..2&#125;; do ansible node$i -m yum -a "name=php-pecl-memcached state=present" ; done# ll /usr/lib64/php/modules/ 安装完 php-peclmemcached 后可以看到 memcached.so-rwxr-xr-x 1 root root 118160 Apr 2 2014 memcached.so-rwxr-xr-x 1 root root 106160 Jun 10 2014 memcache.so 1234567891011# for i in &#123;1..2&#125; ; do ansible node$i -m yum -a "name=php-memcache state=present";done;# for i in &#123;1..2&#125; ; do ansible node$i -m yum -a "name=php-memcached state=present";done;# vim /etc/php.ini # 注这里用的是ansible 所以可以修改或编辑好一个配置文件，然后复制到其它的两个在线的结点[PHP] extension = "/usr/lib64/php/modules/memcache.so" 注：要修改的地方extension = "/usr/lib64/php/modules/memcached.so" 注：要修改的地方session.save_handler = memcached 注:需要修改session.save_path = "tcp://node3:11211 注：需要修改 # for i in &#123;1..2&#125;; do ansible node$i -m copy -a "src=/etc/php.ini dest=/etc/ " ; done# for i in &#123;1..2&#125;; do ansible node$i -m service -a "name=php-fpm state=started " ; done 1234567891011121314151617181920# vim /etc/nginx/conf.d/default.confserver &#123;listen 80;server_name localhost;location / &#123; root /usr/share/nginx/html; index index.html index.htm index.php;&#125;error_page 500 502 503 504 /50x.html;location = /50x.html &#123;root /usr/share/nginx/html;&#125;location ~ \.php$ &#123;root /usr/share/nginx/html;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;fastcgi_param SCRIPT_FILENAME /usr/share/nginx/html$fastcgi_script_name;include fastcgi_params;&#125;&#125; 1234#vim /usr/share/nginx/html/index.php&lt;?phpphpinfo() ;?&gt; 将nignx的配置文件和php的测试页复制到两个结点上1234# for i in &#123;1..2&#125;; do ansible node$i -m copy -a "src=/etc/nginx/conf.d/default.conf dest=/etc/nginx/conf.d/ " ; done# for i in &#123;1..2&#125;; do ansible node$i -m copy -a "src=/usr/share/nginx/html/index.php dest=/usr/share/nginx/html/ " ; done启动两个结点(node1,node2)的nginx# for i in &#123;1..2&#125; ; do ansible node$i -m service -a "name=nginx state=started";done; 在浏览器中输入 http://172.16.23.11/index.php查看两个结点的php是否正常工作，并且查看其index.php中提供的phpinfo(); php配置信息 ，可以查看到memcache 和memcached两项 访问 http://172.16.23.12/index.php 三、在node0结点上配置nginx负载均衡后台两台(node1,node2)主机，为两结点通过php程序测试mariadb注： 由于ansible就在node0上，所以此处直接用系统自身的命令来进行配置，而非远程执行; 把刚刚给node1,node2远程复制的default.conf配置还原还去; 由于node0的nginx无其它将配置文件删了重新安装一下nignx 也行； 负载均衡123456# vim /etc/nginx/nginx.conf# 在http段中加入以下内容upstream mem &#123;server node1:80;server node2:80;&#125; 1234# vim /etc/nginx/conf.d/default.conf# 在每一个location中加入以下内容proxy_pass http://mem;# systemctrl start nginx 此时nginx已经可以负载均衡后面的两台服务器了为node1,node2提供两个php连接mysql的测试页 123456&lt;h1&gt;www.rj.com NODE2&lt;/h1&gt;&lt;?php$link=mysql_connect("localhost","root","centos.123");if(!$link)echo"CNONNECT FILED!";else echo "CAN CNONNECT !";?&gt; 此时访问nginx的负载均衡的结点172.16.23.10后可测试结果如下]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MariaDB之基于openssl的主从复制]]></title>
    <url>%2F2018%2F02%2F07%2FMariaDB%E4%B9%8B%E5%9F%BA%E4%BA%8Eopenssl%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[一、配置openssl1、 在master server(node0)上根CA的搭建(及生成自签名证书)1234567891011121314151617181920212223[root@node0 ~]# cd /etc/pki/CA/[root@node0 CA]# (umask 077;openssl genrsa -out private/cakey.pem 2048)Generating RSA private key, 2048 bit long modulus.................+++..................+++e is 65537 (0x10001)[root@node0 CA]# touch index.txt [root@node0 CA]# echo 01 &gt; serial[root@node0 CA]# openssl req -new -x509 -key private/cakey.pem -out ./cacert.pem -days 3650You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:BJLocality Name (eg, city) [Default City]:BJOrganization Name (eg, company) [Default Company Ltd]:rjOrganizational Unit Name (eg, section) []:rjCommon Name (eg, your name or your server's hostname) []:www.rj.comEmail Address []: 2、为master主机生成密钥，并名为之签名1234567891011121314151617181920212223242526[root@node0 CA]# cd /etc/my.cnf.d/[root@node0 my.cnf.d]# (umask 077;openssl genrsa -out master.key 2048)Generating RSA private key, 2048 bit long modulus...............................................+++................+++e is 65537 (0x10001)[root@node0 my.cnf.d]# openssl req -new -key /etc/my.cnf.d/master.key -out /etc/my.cnf.d/master.csrYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:BJ Locality Name (eg, city) [Default City]:BJOrganization Name (eg, company) [Default Company Ltd]:rjOrganizational Unit Name (eg, section) []:rjCommon Name (eg, your name or your server's hostname) []:www.rj.comEmail Address []:Please enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:An optional company name []: 3、根CA签发master请求1234567891011121314151617181920212223242526272829303132[root@node0 my.cnf.d]# openssl ca -in master.csr -out master.crt -days 3650Using configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature okCertificate Details: Serial Number: 1 (0x1) Validity Not Before: Feb 16 06:55:06 2017 GMT Not After : Feb 14 06:55:06 2027 GMT Subject: countryName = CN stateOrProvinceName = BJ organizationName = rj organizationalUnitName = rj commonName = www.rj.com X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: B4:A1:66:8C:5B:2B:F9:59:9D:F6:4F:F7:35:72:E2:87:9C:A5:95:F9 X509v3 Authority Key Identifier: keyid:71:DD:03:78:51:12:5F:58:C2:1B:53:76:A0:2B:E9:BF:60:D8:67:36Certificate is to be certified until Feb 14 06:55:06 2027 GMT (3650 days)Sign the certificate? [y/n]:y1 out of 1 certificate requests certified, commit? [y/n]yWrite out database with 1 new entriesData Base Updated 4、为slave结点(node1)配置openssl123456789101112131415161718192021222324252627282930313233[root@node1 CA]# cd /etc/my.cnf.d/[root@node1 my.cnf.d]# (umask 077;openssl genrsa -out slave.key 2048)Generating RSA private key, 2048 bit long modulus.............+++......................................................................................................................................................................................................................................................+++e is 65537 (0x10001)[root@node1 my.cnf.d]# openssl req -new -key slave.key -out slave.csrYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:BJLocality Name (eg, city) [Default City]:BJOrganization Name (eg, company) [Default Company Ltd]:rjOrganizational Unit Name (eg, section) []:rjCommon Name (eg, your name or your server's hostname) []:www.rj.comEmail Address []:Please enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:An optional company name []:[root@node1 my.cnf.d]# scp slave.csr node0:/tmpThe authenticity of host 'node0 (172.16.23.10)' can't be established.ECDSA key fingerprint is 2b:98:49:35:5b:78:24:ed:f0:ab:fa:54:b1:8e:df:29.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'node0,172.16.23.10' (ECDSA) to the list of known hosts.root@node0's password: slave.csr 5、为slave结点签发请求123456789101112131415161718192021222324252627282930313233343536[root@node0 my.cnf.d]# mv /etc/pki/CA/serial /root/[root@node0 my.cnf.d]# mv /etc/pki/CA/index.txt /root/[root@node0 my.cnf.d]# touch /etc/pki/CA/index.txt[root@node0 my.cnf.d]# echo 01 &gt; /etc/pki/CA/serial[root@node0 my.cnf.d]# openssl ca -in /tmp/slave.csr -out slave.crt -days 3650Using configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature okCertificate Details: Serial Number: 1 (0x1) Validity Not Before: Feb 16 07:07:14 2017 GMT Not After : Feb 14 07:07:14 2027 GMT Subject: countryName = CN stateOrProvinceName = BJ organizationName = rj organizationalUnitName = rj commonName = www.rj.com X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: A5:FE:11:EB:4D:B5:F1:85:61:E7:18:E3:1D:B7:25:C6:1B:24:97:AF X509v3 Authority Key Identifier: keyid:71:DD:03:78:51:12:5F:58:C2:1B:53:76:A0:2B:E9:BF:60:D8:67:36Certificate is to be certified until Feb 14 07:07:14 2027 GMT (3650 days)Sign the certificate? [y/n]:y1 out of 1 certificate requests certified, commit? [y/n]yWrite out database with 1 new entriesData Base Updated 123[root@node0 my.cnf.d]# scp slave.crt node1:/etc/my.cnf.d/slave.crt 100% 4382 4.3KB/s 00:00 # 此时主从结点的证书都已经准备好 二、配置mariadb主从服务器1、工作拓扑图 2、主服务器配置12345678910111213141516171819[root@node0 ~]# yum -y install mariadb[root@node0 my.cnf.d]# vim /etc/my.cnf将mysqld段中的配置修改为以下内容[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.socksymbolic-links=0innodb-file-per-table = ONskip-name-resolve = ONserver-id = 1 log-bin = master-logsslssl_ca=/etc/my.cnf.d/cacert.pem ssl_cert=/etc/my.cnf.d/master.crtssl_key=/etc/my.cnf.d/master.key [root@node0 my.cnf.d]# cp /etc/pki/CA/cacert.pem .[root@node0 my.cnf.d]# chown mysql.mysql cacert.pem master.*[root@node0 my.cnf.d]# systemctl start mariadb 3、从服务配置123456789101112131415161718[root@node0 ~]# yum -y install mariadb[root@node0 my.cnf.d]# vim /etc/my.cnf将mysqld段中的配置修改为以下内容[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.socksymbolic-links=0skip_name_resolve = ON relay-log = relay-logserver-id = 2 注id号不能与主服务的一样sslssl-ca = /etc/my.cnf.d/cacert.pemssl-cert = /etc/my.cnf.d/slave.crtssl-key = /etc/my.cnf.d/slave.key[root@node0 my.cnf.d]# scp /etc/pki/CA/cacert.pem node1:/etc/my.cnf.d/cacert.pem [root@node1 my.cnf.d]# cd /etc/my.cnf.d/ &amp;&amp; chown mysql.mysql cacert.pem slave.*[root@node1 my.cnf.d]# systemctl start mariadb 4、主服务器授权一个用户可连接mysql拉取二进制文件1MariaDB [(none)]&gt; GRANT REPLICATION SLAVE,REPLICATION CLIENT ON *.* TO 'rj'@'172.16.23.11' IDENTIFIED BY 'centos.123' REQUIRE ssl; 5、配置从服务器连接到主服务器，并拉取数据先查看主结点的二进制日志 123456MariaDB [(none)]&gt; SHOW MASTER STATUS; +-------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+-------------------+----------+--------------+------------------+| master-log.000007 | 342 | | |+-------------------+----------+--------------+------------------+ 123MariaDB [(none)]&gt; CHANGE MASTER TO MASTER_HOST='172.16.23.10', MASTER_USER='rj', MASTER_PASSWORD='centos.123', MASTER_LOG_FILE='master-log.000007', MASTER_LOG_POS=245, MASTER_SSL=1, MASTER_SSL_CA='/etc/my.cnf.d/cacert.pem', MASTER_SSL_CERT='/etc/my.cnf.d/slave.crt', MASTER_SSL_KEY='/etc/my.cnf.d/slave.key';Query OK, 0 rows affected (0.03 sec)查看主从服务器的openssl的是用否用 123456789101112MariaDB [(none)]&gt; SHOW VARIABLES LIKE '%ssl%';+---------------+--------------------------+| Variable_name | Value |+---------------+--------------------------+| have_openssl | YES || have_ssl | YES || ssl_ca | /etc/my.cnf.d/cacert.pem || ssl_capath | || ssl_cert | /etc/my.cnf.d/master.crt || ssl_cipher | || ssl_key | /etc/my.cnf.d/master.key |+---------------+--------------------------+ 123456789101112MariaDB [(none)]&gt; SHOW VARIABLES LIKE '%ssl%';+---------------+--------------------------+| Variable_name | Value |+---------------+--------------------------+| have_openssl | YES || have_ssl | YES || ssl_ca | /etc/my.cnf.d/cacert.pem || ssl_capath | || ssl_cert | /etc/my.cnf.d/slave.crt || ssl_cipher | || ssl_key | /etc/my.cnf.d/slave.key |+---------------+--------------------------+ 6、启用从服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546MariaDB [(none)]&gt; START SLAVE;Query OK, 0 rows affected, 1 warning (0.00 sec)MariaDB [(none)]&gt; SHOW SLAVE STATUS \G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.16.23.10 Master_User: rj Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-log.000007 Read_Master_Log_Pos: 245 Relay_Log_File: relay-log.000003 Relay_Log_Pos: 530 Relay_Master_Log_File: master-log.000007 Slave_IO_Running: Yes 注:IO SQL这两项表示主从同步已经正学进行 Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 245 Relay_Log_Space: 818 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: Yes Master_SSL_CA_File: /etc/my.cnf.d/cacert.pem Master_SSL_CA_Path: Master_SSL_Cert: /etc/my.cnf.d/slave.crt Master_SSL_Cipher: Master_SSL_Key: /etc/my.cnf.d/slave.key Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 11 row in set (0.00 sec) 7、由于从服务器只能读，所以需要开启mariadb的只读1234567MariaDB [(none)]&gt; SHOW VARIABLES LIKE 'read_only';+---------------+-------+| Variable_name | Value |+---------------+-------+| read_only | ON |+---------------+-------+1 row in set (0.00 sec) 12MariaDB [(none)]&gt; SET GLOBAL read_only=ON;Query OK, 0 rows affected (0.00 sec) 8、openssl进行测试1234567891011121314151617[root@node1 my.cnf.d]# mysql -urj -pcentos.123 -h172.16.23.10 --ssl-ca=/etc/my.cnf.d/cacert.pem --ssl-cert=/etc/my.cnf.d/slave.crt --ssl-key=/etc/my.cnf.d/slave.keyWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 7Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || test |+--------------------+2 rows in set (0.00 sec) 9、主从同步测试123456789101112MariaDB [(none)]&gt; CREATE DATABASE node0create;在主服务上创建了一个库Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; SHOW DATABASES; 在从服务器上也可以查看到了+--------------------+| Database |+--------------------+| information_schema || mysql || node0create || performance_schema || test |+--------------------+]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[corosync v2 + pacemaker + crmsh 实现mariadb高可用]]></title>
    <url>%2F2018%2F02%2F07%2Fcorosync-v2-pacemaker-crmsh-%E5%AE%9E%E7%8E%B0mariadb%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[高可用mariadb拓扑图 一、设计前提1、时间同步 # ntpdate 172.16.0.1 或者 # chronyc sources2、所有的主机对应的IP地址解析可以正常工作， 主机名要与命令#uname -n 所得的结果一致 因此，/etc/hosts中的内容为以下内容 123172.16.23.10 node1.rj.com node1 172.16.23.11 node2.rj.com node2 172.16.23.12 node3.rj.com node3 二、环境的建立及安装orosync ,pacemaker ,crmsh三台机器都安装好ansible （对于ansible集群管理工具而言需要双机互信,其中node1当做堡垒机） 安装配置12345678910111213141516# ssh-keygen # for i in &#123;10..12&#125;; do ssh-copy-id -i 172.16.23.$i ; done ; # 此条命令将公钥发送给三台机器，其中包括自己也就是堡垒机# vim /etc/ansible/hosts [mariadb] 172.16.23.10 172.16.23.11 172.16.23.12# ansible mariadb -m ping # 测试三台主机与堡垒机之间的连通性 # vim /etc/hosts 主机名解析配置 172.16.23.10 node1.rj.com node1 172.16.23.11 node2.rj.com node2 172.16.23.12 node3.rj.com node3# ansible mariadb -m command -a "ntpdate 172.16.0.1" 同步三台主机的时间 # ansible mariadb -m yum -a "name=pacemaker,mariadb-server state=present" 在三台主机上安装 mariadb ,corosync 和 pacemaker 注：yum 安装pacemaker 的时候，其corosync也会自动安装上 corosync配置123456789101112131415161718192021222324252627282930313233343536373839404142# vim /etc/corosync/corosync.conf 加入以下信息 totem &#123; version: 2 crypto_cipher: aes256 crypto_hash: sha1 interface &#123; ringnumber: 0 bindnetaddr: 172.16.0.0 mcastaddr: 239.255.23.1 mcastport: 5405 ttl: 1 &#125; logging &#123; fileline: off to_stderr: no to_logfile: yes logfile: /var/log/cluster/corosync.log to_syslog: no debug: off timestamp: on logger_subsys &#123; subsys: QUORUM debug: off &#125; quorum &#123; provider: corosync_votequorum node &#123; ring0_addr: node1.rj.com nodeid:1 &#125; node &#123; ring0_addr: node2.rj.com nodeid:2 &#125; node &#123; ring0_addr: node3.rj.com nodeid:3 &#125; &#125; 123456# corosync-keygen # ansible mariadb -m copy -a "src=/etc/corosync/authkey dest=/etc/corosync/"# ansible mariadb -m copy -a "src=/etc/corosync/corosync.conf dest=/etc/corosync/"# ansible mariadb -m service -a "name=corosync state=persent"# ansible mariadb -m service -a "name=pacemaker state=persent"# tcpdump -i eno16777736 -nn port 5405 抓包分析使用tcpdump抓包工具可以来查看三台主机之间传递的心跳信息 注:mariadb在集群资源的配置中必需是开机自启动的这样corosync才能实别其Unitfile 文件，而不能在配置前启动所以服务一定是关闭的 123456789# ansible mariadb -m service -a "name=mariadb enabled=on"# ansible mariadb -m service -a "name=corosync enabled=on"# ansible mariadb -m service -a "name=pacemaker enabled=on"# mkdir rpm &amp;&amp; cd rpm # wget 172.18.0.1/pub/Sources/7.x86_64/crmsh/crmsh-2.1.4-1.1.x86_64.rpm 下载crmsh及其所依赖的rpm包 # wget 172.18.0.1/pub/Sources/7.x86_64/crmsh/pssh*.rpm# wget 172.18.0.1/pub/Sources/7.x86_64/crmsh/python-passh*.rpm # ansible mariadb -m copy -a "src=/root/rpm dest=/root/"# for i in &#123;1..3&#125;; do ssh node$i yum -y install /root/rpm/*; done 查看corosync引擎是否已经正常启动1234567891011# ansible mariadb -e command -a "grep -e 'Corosync Cluster Engine' -e 'configuration file' /var/log/messages" Feb 13 11:27:35 node1 systemd: Stopped Corosync Cluster Engine.Feb 13 14:08:03 node1 systemd: Starting Corosync Cluster Engine...Feb 13 14:08:04 node1 corosync: Starting Corosync Cluster Engine (corosync): [ OK ]Feb 13 14:08:04 node1 systemd: Started Corosync Cluster Engine.Feb 13 14:28:16 node1 systemd: Mounted NFSD configuration filesystem.Feb 13 14:28:44 node1 smartd[787]: Opened configuration file /etc/smartmontools/smartd.confFeb 13 14:32:12 node1 systemd: Starting Corosync Cluster Engine... Feb 13 14:32:13 node1 corosync: Starting Corosync Cluster Engine (corosync): [ OK ]Feb 13 14:32:13 node1 systemd: Started Corosync Cluster Engine.Feb 13 14:43:03 node1 systemd: Started Corosync Cluster Engine. 查看其成员之间的结点通知信息是否正常1234567891011# ansible mariadb -e command -a "grep TOTEM /var/log/messages"查看启动过程中是否有错误信息产生 # ansible mariadb -e command -a "grep 'ERROR' /var/log/messages"查看pacemaker是否已经正常启动# ansible mariadb -e command -a "grep 'pacemaker' /var/log/messages " 使用以下命令查看结点的状态# crm status Last updated: Mon Feb 13 15:43:08 2017Last change: Mon Feb 13 14:33:58 2017 by hacluster via crmd on node3.rj.comStack: corosync Current DC: node3.rj.com (version 1.1.13-10.el7-44eb2dd) - partition with quorum3 nodes and 0 resources configured Online: [ node1.rj.com node2.rj.com node3.rj.com ] 查看pacemaker 和与corosync所启动的进程12345678910# ansible mariadb -m command -a "ps auxf " | grep pacemakerroot 1720 0.0 1.3 130484 6384 ? Ss 14:33 0:00 /usr/sbin/pacemakerd -fhaclust+ 1729 0.0 2.7 132816 13268 ? Ss 14:33 0:01 \_ /usr/libexec/pacemaker/cibroot 1730 0.0 1.4 133968 6956 ? Ss 14:33 0:00 \_ /usr/libexec/pacemaker/stonithdroot 1731 0.0 0.8 102936 4108 ? Ss 14:33 0:00 \_ /usr/libexec/pacemaker/lrmdhaclust+ 1732 0.0 1.3 124780 6736 ? Ss 14:33 0:00 \_ /usr/libexec/pacemaker/attrdhaclust+ 1733 0.0 0.7 114896 3668 ? Ss 14:33 0:00 \_ /usr/libexec/pacemaker/penginehaclust+ 1734 0.0 1.5 143160 7484 ? Ss 14:33 0:00 \_ /usr/libexec/pacemaker/crmd# ansible marriadb -m command -a "ps auxf" | grep corosync root 1483 0.6 7.9 134848 38436 ? Ssl 14:32 0:28 corosync 三、利用crmsh来配置corosync的IP地址资源及mariadb资源如果想要查看某种类别下的所用资源代理的列表，可以使用类似以下的命令来实现 安装配置1234#crm ra list lsb #crm ra list ocf heartbeat #crm ra list ocf pacemaker #crm ra list ocf stonith 配置vip1 # crm configure property stonith-enabled=false #关闭stonsth设备 1234567891011121314# crm configure primitive DBIP ocf:heartbeat:IPaddr params ip=172.16.23.23 添加vip资源代理 # crm configure verify 查看是否有错误# crm configure commit 用来提交配置信息 # crm configure show 可以用来查看配置信息 node 1: node1.rj.com node 2: node2.rj.com node 3: node3.rj.com primitive DBIP IPaddr \ params ip=172.16.23.23 property cib-bootstrap-options: \ have-watchdog=false \ dc-version=1.1.13-10.el7-44eb2dd \ cluster-infrastructure=corosync \ stonith-enabled=false 1234567891011# crm node standby node1.rj.com 当将node1结点成为备用结点时 # ansible mariadb -m command -a "ip addr list" 查看其vip的变化信息# crm ra info systemd:mairadb 用来查看systemd类型的mariadb资源的语法格式 systemd unit file for mariadb (systemd:mariadb) MariaDB database server Operations' defaults (advisory minimum): start timeout=15 stop timeout=15 status timeout=15 restart timeout=15 monitor timeout=15 interval=15 start-delay=15 vip资源 当node1 # crm node standby node1.rj.com 时 定义mariadbg资源并设定监控123456789101112131415161718192021222324# crm configure primitive MDB systemd:mariadb op start timeout=15s op stop timeout=15s op monitor interval=15s timeout=15s # crm configure group DBservice DBIP MDB# crm configure verify # crm configure commit # crm configure show node 1: node1.rj.com \ attributes standby=on node 2: node2.rj.com \ attributes standby=off node 3: node3.rj.com \ attributes standby=off primitive DBIP IPaddr \ params ip=172.16.23.23 primitive MDB systemd:mariadb \ op start timeout=15s interval=0 \ op stop timeout=15s interval=0 \ op monitor interval=15s timeout=15s group DBservice DBIP MDB property cib-bootstrap-options: \ have-watchdog=false \ dc-version=1.1.13-10.el7-44eb2dd \ cluster-infrastructure=corosync \ stonith-enabled=false \ no-quorum-policy=ignore 为mariadb服务加入数据库资源，并配置远程用户远程接入进行测试 注：此时有一个资源已经启动，但其它的两个mariadb服务启动之后才能进行对数据库的更改 但更改完后旋得再将那两个结点的数据库停止调 node1 node2 node3上执行: # mysql -e &quot;GRANT ALL ON *.* TO &apos;root&apos;@&apos;%.%.%.%&apos; IDENTIFIED BY &apos;centos.123&apos;;&quot; node1 # mysql -e &quot;CREATE DATABASE NODE1&quot; node2 # mysql -e &quot;CREATE DATABASE NODE2&quot; node3 # mysql -e &quot;CREATE DATABASE NODE3&quot; 启用一台测试机进行测试 node1 12# systemctl stop corosync.service pacemaker.service # 当node1的服务停止时 12# systemctl stop corosync.service pacemaker.service # 当node2的服务停止时]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 tomcat 7.0.54 的功能实现及详解]]></title>
    <url>%2F2018%2F02%2F07%2FCentOS-7-tomcat-7-0-54-%E7%9A%84%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%E5%8F%8A%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[一、 jdk 安装配置123456789101112131415161718# yum install java-1.8.0-openjdk-devel (依赖的java-1.8.0-openjdk,java-1.8.0-openjdk,headless也会被安装 )# alternatives -h# vim /etc/profile.d/java.sh # 加入 export JAVA_HOME=/usr# . /etc/profile.d/java.sh # printenv 查看环境变量#用rpm包安装 # wget ftp://172.16.0.1/pub/Sources/7.x86_64/jdk/jdk-8u25-linux-x64.rpm# rpm -ivh jdk-8u25-linux-x64.rpm# rpm -ql jdk1.8.0_25-1.8.0_25-fcs# cd /usr/java/default# vim /etc/profile.d/javad.shJAVA_HOME=/usr/java/latestPATH=$JAVA_HOME/bin:$PATHexport JAVA_HOME PATH# . /etc/profile.d/javad.sh # java -version tomcat:运行于JDK之上，表现为一个独立而完整的java进程，可与用户交互的web服务器使用Java语言编写Tomcat的核心组件:server.xml，其配置的格式为 1234567891011121314151617&lt;Server&gt;&lt;Serivce&gt;&lt;connector/&gt;&lt;connecotr/&gt;...&lt;Engine&gt;&lt;Host&gt;&lt;Context/&gt;&lt;Context/&gt;&lt;/Host&gt;&lt;Host&gt;...&lt;/Host&gt;...&lt;/Engine&gt;&lt;/service&gt;&lt;/Server&gt; 说明： 顶级组件:Server 服务类组件:Service 类 连接类组件:http,https,ajp t 容器类:Engine,Host,Context 被嵌套类:value,logger,realm,loader,manager 集群类组件:listener,cluster,… cluster,… 二、Tomcat安装配置1、安装tomcat:a、二进制格式安装1234567# tar xvf apache-tomcat-VERSION.tar.gz -C /usr/local/ # cd /usr/local/ # ln -sv apache-tomcat-VERSION tomcat #vim /etc/profile.d/tomcat.sh export CATALINA_BASE=/usr/local/tomcat export PATH=$CATALINA_BASE/bin:$PATH# . /etc/profile.d/tomcat.sh b、yum源安装123# yum -y install tomcat-webapps tomcat-docs-webapp tomcat-admin-webapps tomcat tomcat-lib# 安装完后可以使用命令# systemctl start tomcat &amp;&amp; ss -tnl 启动tomcat服务并且查看8080端口是否启用在浏览器中进行测试 http://172.16.254.248:8080/ 2、tomcat程序目录结构 bin:脚本及启动时用到的类 conf:配置文件目录 lib:库文件，java类库 logs:日志文件目录 temp:临时文件目录 webapps:webapp的默认目录 work:工作目录 3、tomcat的配置文件说明 server.xml：主配置文件; web.xml：每个webapp只有部署后才能被访问，它的部署方式通过由web.xml进行定义，其存位置为WEB-INF/目录中，此文件为所有的webapps提供默认配置; context.xml:每个web都可专用的配置文件，它通常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中，此文件为所有的webapps提供默认配置; tomcat-users.xml:用户的账号和文件; catalina.policy:当使用security选项启动tomcat时，用于为tomcat设置安全策略； catalina.propreteis:java物定义文件，用于设定类加载器路径，以及一些与JVM高估相关参数； logging.properties:日志系统相关的配置 ; 4、tomcat-users.xml配置1# vim /etc/tomcat/tomcat-users.xml 在段中加入以五内容 1234&lt;role rolename="manager-gui"/&gt;&lt;user username="centos" password="centos" roles="manager-gui"/&gt;&lt;role rolename="admin-gui"/&gt;&lt;user username="centos" password="centos" roles="admin-gui"/&gt; 重启服务后并重新访问http://172.16.254.248:8080/ 点Server Status、Manager App、 Host Manager时输入用户名centos密码centos进行访问 5、提供一测试类应用，并冷部署；1#mkdir -pv /usr/share/tomcat/webapps/test/&#123;classes,lib,WEB-INF&#125; 12345678910111213# vim /usr/share/tomcat/webapps/test/index.jsp &lt;%@ page language="java" %&gt; &lt;%@ page import="java.util.*" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt; Test Page &lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;% out.println("hellow world");%&gt; &lt;/body&gt; &lt;/html&gt;重新访问http://172.16.254.248:8080/test/时会显示hellow world 6、nginx + tomcat cluster用nginx 反代两台tomcat主机 ，cluster(172.16.254.248[nginx]) ,node1(172.16.251.232[Tomcat A]),node2(172.16.251.74[Tomcat B]) 1234567891011cluster# yum -y install nginx &amp;&amp; systemctl start nginx # vim /etc/nginx/nginx.conf# 在http段中加入upstream tomcat &#123;server 172.16.251.232:8080;server 172.16.251.74:8080;&#125;# vim /etc/nginx/conf.d/default.conf# 在location中加入 proxy_pass http://tomcat/;nod1 # mkdir -pv /usr/share/tomcat/webapps/test/&#123;WEB-INF,classes,lib&#125; 1234567891011121314151617181920# vim /usr/share/tomcat/pwebapps/test/index.jsp &lt;%@ page language="java" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt;&lt;h1&gt;&lt;font color="red"&gt;TomcatA.rj.com&lt;/font&gt;&lt;/h1&gt;&lt;table align="centre" border="1"&gt; &lt;tr&gt;&lt;td&gt;Session ID&lt;/td&gt;&lt;% session.setAttribute("magedu.com","magedu.com"); %&gt;&lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Created on&lt;/td&gt;&lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; &lt;/body&gt;&lt;/html&gt;nod2 # mkdir -pv /usr/share/tomcat/webapps/test/&#123;WEB-INF,classes,lib&#125; 12345678910111213141516171819# vim /usr/share/tomcat/pwebapps/test/index.jsp &lt;%@ page language="java" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt;&lt;h1&gt;&lt;font color="red"&gt;TomcatB.rj.com&lt;/font&gt;&lt;/h1&gt;&lt;table align="centre" border="1"&gt; &lt;tr&gt;&lt;td&gt;Session ID&lt;/td&gt;&lt;% session.setAttribute("magedu.com","magedu.com"); %&gt;&lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Created on&lt;/td&gt;&lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 访问http://172.16.254.248/test/时效果如果下 7、 httpd(proxy_http_module) + tomcat cluster12cluster#systemctl disable nginx &amp;&amp; systemctl stop nginx # yum -y install httpd 1234567891011121314151617181920# vim /etc/httpd/conf.d/tomcat.conf &lt;proxy balancer://tomcat&gt;BalancerMember http://172.16.251.232:8080BalancerMember http://172.16.251.74:8080ProxySet lbmethod=byrequests&lt;/proxy&gt;&lt;VirtualHost *:80&gt;ServerName www.rj.comProxyVia OnProxyRequests OffProxyPreserveHost On&lt;Proxy *&gt;Require all granted&lt;/Proxy&gt;ProxyPass / balancer://tomcat/ProxyPassReverse / balancer://tomcat/&lt;Location /&gt;Require all granted&lt;/Location&gt;&lt;/VirtualHost&gt; 访问http://172.16.254.248/test/时效果如下 启用balancer管理接口 123456cluster# vim /etc/httpd/conf.d/balancer-manager.conf &lt;Location /balancer-manager&gt;Sethandler balancer-manager ProxyPass !Require all granted &lt;/Location&gt; `访问其管理接口http://172.16.254.248/balancer-manager效果如下` 8、 httpd(proxy_ajp_module)+tomcat cluster1# cp /etc/httpd/conf.d/tomcat.conf /etc/httpd/conf.d/tomcat.conf.bak 1234567891011121314151617181920# vim /etc/httpd/conf.d/tomcat.conf &lt;proxy balancer://tomcat&gt;BalancerMember ajp://172.16.251.232:8009BalancerMember ajp://172.16.251.74:8009ProxySet lbmethod=byrequests&lt;/proxy&gt;&lt;VirtualHost *:80&gt;ServerName www.rj.comProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt;Require all granted &lt;/Proxy&gt;ProxyPass / balancer://tomcat/ProxyPassReverse / balancer://tomcat/&lt;Location /&gt;Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt; 访问http://172.16.254.248/test/时效果如下 三、常用组件配置Server:代表tomcat instance, 即表现出一个Java进程：监听在8005端口，只接收“SHUTDOWN”；各server监听的端口不能相同，因此，在同一物理主机启动多个实例时，需要个改其监听端口为不同的端口； service：用于实现将一个或多个connector组件关联至一个engine组件；Connector组件负责接收请求，常见的有三类http/https/ajp:进入tomcat的请求可分为两类； (1)standalone:请求来自于客户端的反代理服务器： nginx –&gt; http connector –&gt; tomcat httpd(proxy_http_module) –&gt; http connector –&gt; tomcat httpd(proxy_ajp_module) –&gt; ajp connecetor –&gt; tomcat 属性： port=”8080” protocol=”HTTP/1.1” connectionTimeout=”20000” address：监听的IP地址；默认为本机所有可用地址； maxThreads：最大并发连接数，默认为150； enableLookups：是否启用DNS查询功能； acceptCount：等待队列的最大长度； secure： sslProtocol： Engine组件：Servlet实例，即servlet引擎，其内部可以一个或多个host组件来定义站点； 通常需要通过defaultHost来定义默认的虚拟主机； 属性： name= defaultHost=”localhost” jvmRoute= Host组件：位于engine内部用于接收请求并进行相应处理的主机或虚拟主机，示例： 123&lt;Host name="localhost" appBase="webapps"unpackWARs="true" autoDeploy="true"&gt;&lt;/Host&gt; 常用属性说明：(1) appBase：此Host的webapps的默认存放目录，指存放非归档的web应用程序的目录或归档的WAR文件目录路径；可以使用基于$CATALINA_BASE变量所定义的路径的相对路径； (2) autoDeploy：在Tomcat处于运行状态时，将某webapp放置于appBase所定义的目录中时，是否自动将其部署至tomcat； 示例： 12&lt;Host name="tc1.magedu.com" appBase="/appdata/webapps" unpackWARs="true" autoDeploy="true"&gt;&lt;/Host&gt; 12# mkdir -pv /appdata/webapps# mkdir -pv /appdata/webapps/ROOT/&#123;lib,classes,WEB-INF&#125; 提供一个测试页即可； 四、tomcat cluster 升级为session cluster，使用deltaManager配置node1,和node2 1node1# vim /etc/tomcat/server.xml 1234567891011121314151617181920212223242526272829303132333435 &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="TomcatA"&gt;&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"channelSendOptions="8"&gt;&lt;Manager className="org.apache.catalina.ha.session.DeltaManager"expireSessionsOnShutdown="false"notifyListenersOnReplication="true"/&gt;&lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt;&lt;Membership className="org.apache.catalina.tribes.membership.McastService"address="228.0.32.4"port="45564"frequency="500"dropTime="3000"/&gt;&lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver"address="192.168.254.130"port="4000"autoBind="100"selectorTimeout="5000"maxThreads="6"/&gt;&lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt;&lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt;&lt;/Sender&gt;&lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt;&lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt;&lt;/Channel&gt;&lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve"filter=""/&gt;&lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt;&lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer"tempDir="/tmp/war-temp/"deployDir="/tmp/war-deploy/"watchDir="/tmp/war-listen/"watchEnabled="false"/&gt;&lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt;&lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt;&lt;/Cluster&gt; 12# scp /etc/tomcat/server.xml 172.16.251.74:/etc/tomcat/server.xml# cp /etc/tomcat/web.xml /var/lib/tomcat/webapps/test/WEB-INF/ 12345678# vim /var/lib/tomcat/webapps/test/WEB-INF/web.xml在 &lt;!-- listings is enabled? [true] --&gt;的后面加入&lt;distributable/&gt;# scp /var/lib/tomcat/webapps/test/WEB-INF/web.xml 172.16.251.74:/var/lib/tomcat/webapps/test/WEB-INF/ node2# vim /etc/tomcat/server.xml 更改 &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="TomcatB"&gt;address="172.16.251.74"node1,2 #systemctl restart tomcat 进入页测试http://172.16.254.248/test/ 五、cluster将会话保存至memcached中node1,2需要的操作将deltaManager的配置还原 123456 # cd /usr/share/tomcat/lib/ # wget ftp://172.16.0.1/pub/Sources/7.x86_64/msm/* &amp;&amp; rm -rf memcached-session-manager-tc8-1.8.3.jar # yum -y install memcached libmemcached # systemctl start memcached # sustemctl enable memcachednode1(tomcat1,memcached1) 12345678910111213141516171819202122232425 # memcached 1配置 # vim /etc/tomcat/server.xml# 修改 &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="rjTomcat1"&gt;在Host段中添加 &lt;Context path="/test" docBase="test" reloadable="true"&gt;&lt;Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"memcachedNodes="n1:172.16.251.232:11211,n2:172.16.251.74:11211"failoverNodes="n1"requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"transcoderFactoryClass="de.javakaffee.web.msm.serializer.javolution.JavolutionTranscoderFactory"/&gt;&lt;/Context&gt;node2(tomcat,memcached2) # memcached 2配置 &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="rjTomcat2"&gt;# 在Host段中添加 &lt;Context path="/test" docBase="test" reloadable="true"&gt;&lt;Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"memcachedNodes="n1:172.16.251.232:11211,n2:172.16.251.74:11211"failoverNodes="n1"requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"transcoderFactoryClass="de.javakaffee.web.msm.serializer.javolution.JavolutionTranscoderFactory"/&gt;&lt;/Context&gt; 关于tomcat memcached session绑定配置详解地址 https://github.com/magro/memcached-session-manager/wiki/SetupAndConfiguration#configure-memcached-session-manager-as--context-manager此时cluster将会话保存于memcached 中 访问http://172.16.254.248/test/效果如下 六、Tomcat的常用优化配置（1）内存空间：12#vim /etc/sysyconfig/tomcat JAVA_OPTS="-server -Xms -Xmx -XX:NewSize= -XX:MaxNewSize= -XX:PermSize= -XX:MaxPermSize=" -server:服务器模型 -Xms:堆内存初始化大小； -Xmx:堆内存空间上限； -XX:NewSize=:新生代空间初始化大小 ； -XX:MaxNewSize=:新生代空间最大值 ； -XX:PermSize=:持久代空间初始化大小； -XX:MaxPermSize=:持久代空间最大值； （2）线程池设置：1&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="200000" redirectPort="8443" /&gt; 常用属性： maxThreads:最大线程数； minSpareThreads:最小空闲线程数； maxSpareThreads:最大空闲线程数； acceptCount:等待队列的最大长度； URIEnconding:URI地址编码格式，建议使用UTF-8； enableLookups:是否启用dns解析，建议禁用； compression:是否启用传输压缩机制，建议”on”; compressionMinSize:启用压缩传输的数据流最小值，单位是字节； compressableMimeType:定义启用压缩功能的MIME类型;text/html,text/xml,text/css,text/javascript; （3）禁用8005端口12&lt;Server port="-1" shutdown="SHUTDOWN"&gt; Server="SOME STRING" （4）隐藏版本信息12&lt;Connector port="8080" protocol="HTTP/1.1" connection Timeout="20000" redirectPort="8443" /&gt;Server="SOME STRING"]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived双主模型的实现]]></title>
    <url>%2F2018%2F02%2F07%2Fkeepalived%E5%8F%8C%E4%B8%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[一、简介 keepalived 简介:是服务器高可用的一个重要软件;它的核心组件有vrrp ，stack， checker ，ipvs，warpper， watch dog ; 它是vrrp协议的实现，原生设计目的为高可用ipvs服务；keepalived能够通过配置文件中定义生成ipvs规则; 并能够对RS的健康状态进行检测；vrrp_script,vrrp_track; 双主模型的实现 简介:双方模型(主/备，备/主)的这里的意思是，一个keepalived配置中;一个虚拟IP地址为主，另一个为备。而在另一个keepalived的配置中;与其它主机则恰恰相反，一个虚拟IP地址为备，另一个为主; 以下为此次双主模型实现的拓扑 二、HA Cluster配置的前提；(1)要点:各节点之间的时间秘需要同步: ntpdate 172.16.0.1 (注此:处可自己在网上找个时间同步服务器) (2)确保iptables及selinux不会阻碍:1#iptables -F &amp;&amp; setenforce 0 ###(3)各节点之间可通过主机名互相通信(对keepalived并非必须): 12345# vim /etc/hosts 172.16.250.140 kpl1172.16.250.158 kpl2 两台keepalived主机都要修改 ###(4)各节点之间root用户可以基于密钥认证的ssh通信 123# ssh-copy-id -i 172.16.250.140# ssh-copy-id -i 172.16.250.158 三、dr集群配置此处使用dr集群类型 首先将dr模型配置好 1234567891011121314151617181920212223242526272829303132333435363738394041424344# vim setkp.sh# !/bin/bash vip=172.16.26.126vip2=172.16.26.127mask=255.255.255.255interface='lo:0'interface2='lo:1'eth='eno16777736:0' case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignoreecho 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announceecho 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announceifconfig $interface $vip netmask $mask broadcast $vip up ifconfig $interface2 $vip2 netmask $mask broadcast $vip2 up route add -host $vip dev $interface route add -host $vip2 dev $interface2;; dstart) ifconfig $eth $vip/32 netmask $mask broadcast $vip up;;dstop)ifconfig $eth down;;stop)ifconfig $interface down ifconfig $interface2 downecho 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignoreecho 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announceecho 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce;; status) ifconfig cat /proc/sys/net/ipv4/conf/all/arp_ignorecat /proc/sys/net/ipv4/conf/lo/arp_ignorecat /proc/sys/net/ipv4/conf/all/arp_announcecat /proc/sys/net/ipv4/conf/lo/arp_announce;; *)echo "Usage: $(basename $0) &#123;dstart|dstop|start|stop&#125;"exit 1 esac RS1、RS2主机中都执行执行此脚本 123456# sh setkp.sh start # sh setkp.sh status 可用来查看当前网络的配置状态 #RS1、RS2主机中安装httpd并启动 # yum -y install httpd &amp;&amp; systemctl start httpd RS1# echo "&lt;h1&gt;RS1&lt;/h1&gt;" &gt; /usr/share/nginx/html/index.html RS2 # echo "&lt;h1&gt;RS2&lt;/h1&gt;" &gt; /usr/share/nginx/html/index.html 四、keepalived配置keepalived,keepalived2 中安装nginx(httpd和nginx都可以,此处用来做为keepalived的本身的提供sorry server)当dr集群的两台节点都停止时，会由keepalived本身来提供一个页面 123456789101112# yum -y install nginx keepalived ipvsadm &amp;&amp; systemctl start nginx # echo "&lt;h1&gt;sorry server keepalived 1 &lt;/h1&gt;" &gt; /usr/share/nginx/html/index.html # echo "&lt;h1&gt;sorry server keepalived 2 &lt;/h2&gt;" &gt; /usr/share/nginx/html/index.html ```bash在一台keepalived主机上进行测试```bash# curl 172.16.251.232&lt;h1&gt;RS1&lt;/h2&gt;# curl 172.16.250.159&lt;h1&gt;RS2&lt;/h1&gt; keepalived,keepalived2 中在 /etc/keepalived/目录下编辑一个脚本来用来在主备变化或服务down掉时发邮件给系统用户 1234567891011121314151617181920212223# vim kmail.sh #!/bin/bashcontact='root@localhost'notify()&#123;mailsubject="$(hostname) to be $1:vip floating"mailbody="$(date +'%F %T'):vrrp transition, $(hostname) change to be $1"echo $mailbody | mail -s "$mailsubject" $contact&#125;case $1 in master )notify master;;backup )notify backup ;;fault )notify fault ;;*)echo "Usage:$(basename $0) &#123;master |backup|fault&#125;";;esac#chmod +x kmail.sh 注:keepalived的两台主机的配置基本相同，当配置模型为主/备模型的时候，主备之间需要修改三个指令 分别为 router_id kpl1 在keepalived2上时需要修改为 router_id kpl2state MASTER 在keepalived2上时需要修改为 state BACKUPpriority 100 在keepalived2上时需要修改为 priority 90 (此处的值比主服务器的小便可以)以下主/备的配置示例 ###先把备的服务器启动 1# tcpdump -i eno33554984 -nn host 224.0.61.61 可使用tcpdump 抓取组播地址 来查看其通过组播方式传递的心跳信息以下的配置文件便是keepavlied双主模型的实现对防火墙打标记keepalived 1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# iptables -t mangle -A PREROUTING -d 172.16.26.126 -p tcp --dport 80 -j MARK --set-mark 3 # iptables -t mangle -A PREROUTING -d 172.16.26.127 -p tcp --dport 80 -j MARK --set-mark 3# vim /etc/keepalived/keepalived.conf! Configuration File for keepalived global_defs &#123; notification_email &#123;root@localhost&#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id kpl1 vrrp_mcast_group4 224.0.61.61&#125;vrrp_instance VI_1 &#123;state MASTERinterface eno33554984virtual_router_id 55priority 100advert_int 1notify_master "/etc/keepalived/kmail.sh master"notify_backup "/etc/keepalived/kmail.sh backup"notify_fault "/etc/keepalived/kmail.sh fault"authentication &#123;auth_type PASSauth_pass zE2kNsRQ&#125;virtual_ipaddress &#123;172.16.26.126 dev eno33554984 label eno33554984:0 &#125;&#125;vrrp_instance VI_2 &#123;state BACKUPinterface eno33554984virtual_router_id 66priority 90advert_int 1notify_master "/etc/keepalived/kmail.sh master"notify_backup "/etc/keepalived/kmail.sh backup"notify_fault "/etc/keepalived/kmail.sh fault"authentication &#123;auth_type PASSauth_pass zE2kfsRQ&#125;virtual_ipaddress &#123;172.16.26.127 dev eno33554984 label eno33554984:1 &#125;&#125;virtual_server fwmark 3 &#123;delay_loop 2lb_algo wrr lb_kind DRnat_mask 255.255.0.0protocol TCPsorry_server 127.0.0.1 80 real_server 172.16.251.232 80 &#123;weight 3HTTP_GET &#123;url &#123; path / status_code 200 &#125;connect_timeout 2nb_get_retry 3delay_before_retry 3&#125;&#125;real_server 172.16.250.159 80 &#123;weight 1HTTP_GET &#123;url &#123; path /status_code 200 u &#125;oconnect_timeout 2enb_get_retry ndelay_before_retry 3&#125;&#125; keepalived 2 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# iptables -t mangle -A PREROUTING -d 172.16.26.126 -p tcp --dport 80 -j MARK --set-mark 3# iptables -t mangle -A PREROUTING -d 172.16.26.127 -p tcp --dport 80 -j MARK --set-mark 3# vim /etc/keepavlied/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; notification_email &#123;root@localhost&#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id kpl2 vrrp_mcast_group4 224.0.61.61&#125;vrrp_instance VI_1 &#123;state BACKUPinterface eno33554984virtual_router_id 55priority 90advert_int 1notify_master "/etc/keepalived/kmail.sh master"notify_backup "/etc/keepalived/kmail.sh backup"notify_fault "/etc/keepalived/kmail.sh fault"authentication &#123;auth_type PASSauth_pass zE2kNsRQ&#125;virtual_ipaddress &#123;172.16.26.126 dev eno33554984 label eno33554984:0 &#125;&#125;vrrp_instance VI_2 &#123;state MASTERinterface eno33554984virtual_router_id 66priority 100advert_int 1notify_master "/etc/keepalived/kmail.sh master"notify_backup "/etc/keepalived/kmail.sh backup"notify_fault "/etc/keepalived/kmail.sh fault"authentication &#123;auth_type PASSauth_pass zE2kfsRQ&#125;virtual_ipaddress &#123;172.16.26.127 dev eno33554984 label eno33554984:1 &#125;&#125;virtual_server fwmark 3 &#123;delay_loop &#123;lb_algo wrrlb_kind DRnat_mask 255.255.0.0protocol TCPsorry_server 127.0.0.1 80real_server 172.16.251.232 80 &#123;weight 3HTTP_GET &#123;url &#123; path / status_code 200 &#125;connect_timeout 2nb_get_retry 3delay_before_retry 3&#125;&#125;real_server 172.16.250.159 80 &#123;weight 1HTTP_GET &#123;url &#123; path / status_code 200 &#125;connect_timeout 2nb_get_retry 3delay_before_retry 3&#125;&#125; 五、测试此时可以测试其访问 当一个keepavlied停止时当RS2停止时当RS1，RS2都停止时 ##六、keepavlied配置指令说明 虚拟路由器段 12345678910111213state MASTER：当前节点在虚拟路由器中的初始状态；interface ETHERCARD: vrrp实际工作的网卡接口virtual_route_id 51 :虚拟路由器ID，范围0-255；priority 100 :当前物理节点在此虚拟路由器中的优先级；advert_int 1:每隔多久发送心跳(通行的时间间隔)auth_type PASS ：选择认证机制 auth_pass 1111 ：密码 八位有效virtual_ipaddress ：定义虚拟IP track_interface ： 定义要监控的接口notify_master &lt;STRING&gt; | &lt;QUOTED-STRING&gt; ：当前节点变为主节点时用STRING脚本通告notfy_backup&lt;STRING&gt; | &lt;QUOTED-STRING&gt; : 当前节点变为主节时用 STRING脚本通告notify_fault&lt;STRING&gt; | &lt;QUOTED-STRING&gt; : 当前节点上不了线时用STRING脚本通告notify&lt;STRING&gt; | &lt;QUOTED-STRING&gt; : 如果三种状态用一个脚本来实现用STRING脚本通告 虚拟服务段 123456789101112131415161718lb_algo rr | wrr|lc|lblc|sh|dh :定义负载均衡调度算法delay_loop&lt;INT&gt;：：定义服务轮询时间间隔bl_kind NAT |DR |TUN ：集群的类型persistence_time_out&lt;INT&gt; ：持久连接时长protocol TCP : 服务协议sorry_server&lt;IPADDR&gt;&lt;PORT&gt;：所有RS均故障时，提供sorry server的服务器；real_server&lt;IPADDR&gt;&lt;PORT&gt;:weight&lt;INT&gt;：权重notify_up&lt;STRING&gt;|&lt;QUOTED-STRING&gt; ： 节点上线通知脚本notify_down &lt;STRING&gt;|&lt;QUOTED-STRNG&gt;：节点离线通知脚本；#HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK ：支持的所以健康状态的检测方式url:健康状态检测时请求的资源的URL delay_before_retry&lt;INT&gt; ：两次尝试之间的时间间隔 connect_timeoute&lt;STRING&gt;：连接的超时时长connect_ip&lt;IP ADDRESS&gt;：向此处指定的地址发测试请求connect_port&lt;PORT&gt;：向此处指定的PORT发测试请求bindto&lt;IP ADDRESS&gt;：指定测试请求报文的源IP bind_port&lt;PORT&gt;： 指定测试请求报文的源PORT]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MariaDB之MHA配置]]></title>
    <url>%2F2018%2F02%2F06%2FMariaDB%E4%B9%8BMHA%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[工作拓扑 一、MHA简明12345678910MHA（Master HA）是一款开源的MySQL的高可用程序，它为MySQL主从复制架构提供了 automating master failover 功能。MHA在监控到master节点故障时，会提升其中 拥有最新数据的slave节点来成为新的master节点。在此期间，MHA会通过于其它从节点 获取额外信息来避免一致性方面的问题。MHA还提供了master节点的在线切换功能，即按 需切换master/slave节点。MHA服务有两咱角色。MHA Mangager(管理节点)和MHA Node(数据节点)： MHA Manager：通常单独部署在一台独立机器上管理多个master/slave集群，每个 master/slave集群称作一个application: MHA node:运行在每台MySQL服务器之上(master/slave/manager),它通过监控 具务解析和清理logs功能来脚本来加快故障转移。 二、MHA 组件12345678910111213141516171819202122232425 MHA会提供诸多工具程序，其常见的如下所示。 Manager节点: masterha_check_ssh:MHA依赖的SSH环境检测工具； masterha_check_repl:MySQL复制环境检测工具； masterha_mamager:MHA服务主程序； masterha_check_status:MHA运行状态探测工具； masterha_master_monitor:MySQL master节点可用性监测工具； masterha_master_swith:master节点切换工具； masterha_conf_host:添加或删除配置的节点； masterha_stop:斗闭MHA服务的工具 ； Node 节点: save_binary_logs:保存和复制Master的二进制日志 ； apply_diff_replay_logs:识别差异的中继日志事件并应用于其它slave; filter_mysqlbinlog:去除不必要的ROLLBACK事件(MHA已不再使用这个工具)； purge_replay_logs:清除中继日志(不会阻塞SQL线程)； 自定义扩展: secondary_check_script:通过多条网络路由检测master的可用性； master_ip_failover_scipt:更新application使用的masterip; shutdown_script：强制关闭master节点； report_scipt:发送报告； init_conf_load_script:加载初始配置参数； master_ip_online_change_scipt:更新master节点ip地址； 三、准备MySQL Replicatin环境123 MHA对MySQL复制环境有特殊要求，例如各节点都要开启二进制日志及中继日志， 各从节点 必须启用其read-only skip_name_resolve innodb_file_per_table=ON 属性， 并关闭relay_log_purge功能等，还有体集事物所必需的同步； 同步主机1234567891011# for i in &#123;0..3&#125; ; do ssh node$i ntpdate 172.16.0.1 ; done # 本实验境共有四个节点，其中角色分配如下；node0 :MHA Manager(172.16.23.10);node1 :MariaDB masternode2 :MariaDB slavenode3 :MariaDB slave # 各节点的/etc/hosts文件配置内容添加如下内容；172.16.23.10 node0 node0.rj.com172.16.23.11 node1 node1.rj.com172.16.23.12 node2 node2.rj.com172.16.23.13 node3 node3.rj.com 初始主节点的master配置1234567node1 # vim /etc/my.cnf innodb_file_per_table=ON # 此项内容与下面一项内容一般在服务器启动时便加上 skip_name_resolve=ON server_id=1 relay_log=relay-bin log-bin=log-bin symbolic-links=0 所有slave节点依赖的配置12345678node(2,3)# vim /etc/my.cnf innodb_file_per_table=ON skip_name_resolve=ON server_id=2 #注 此处的结点到了别的节点中一定要改，各节点的id必需唯一； relay-log=relay-bin log-bin=master-bin relay-log-purge=OFF read-only=ON 按上述要求分别配置好主 从节点之后,按MySQL复制配置架构的配置方式将其配置完成并吂动 master节点和各slave节点，以及各slave节点启动其IO和SQL线程，确保主从复制运行无误 1234567node1 mysql&gt; GRANT REPLICATION SLAVE,REPLICATION CLIENT ON *.* TO 'rj'@'172.16.%.%' IDENTIFIED BY 'centos.123' ;node(2,3) mysql&gt; CHANGE MASTER TO MASTER_HOST='172.16.23.11',MASTER_USER='rj',MASTER_PASSWORD='centos.123',MASTER_LOG_FILE='log-bin.000001',MASTER_LOG_POS=492; mysql&gt; START SLAVE; mysql&gt; SHOW SLAVE STATUS; Slave_IO_Running: Yes Slave_SQL_Running: Yes # 以下两项是否为yes 同时，也可以在主结点上创建个库或表，查看其是否可台实现主从同步； 而后，在所有MySQL节点授权拥有管理权限的用户可在本地网络中有其它节点上远程方问。 当然，此时仅需要且只能在master节点运行类似如下SQL语句即可。 1mysql&gt; GRANT ALL ON *.* to 'rjyy'@'172.16.%.%' IDENTIFIED BY 'centos.123'; 三、安装配置MHA准备基于ssh互信通信环境MHA集群中的各节点彼此之间均需基于ssh互信通信，以实现远程控制及数据管理功能。 简单起见，可在Manager节点生成密钥对，并设置其可远程连接本地主机后，将私钥文件及authorized_keys文件复制给余下的所有结点即可。 下面的的操作在manager（node0）节点操作完成。 1# for i in &#123;0..3&#125; ; do scp -p .ssh/id_rsa .ssh/authorized_keys node$i:/root/.ssh/; done 安装MHA123456789101112131415161718192021222324252627282930313233343536node0 # yum install mha4mysql-manager-0.56-0.el6.noarch.rpm mha4mysql-node-0.56-0.el6.noarch.rpm # for i in &#123;1..3&#125;; do scp mha4mysql-node-0.56-0.el6.noarch.rpm node$i:/root/ ; donenode(1,2,3) # yum -y install mha4mysql-node-0.56-0.el6.noarch.rpm [root@node0 ~]# rpm -ql mha4mysql-manager /usr/bin/masterha_check_repl /usr/bin/masterha_check_ssh /usr/bin/masterha_check_status /usr/bin/masterha_conf_host /usr/bin/masterha_manager /usr/bin/masterha_master_monitor /usr/bin/masterha_master_switch /usr/bin/masterha_secondary_check /usr/bin/masterha_stop 以上为可执行文件，就是上面所列出的命令 /usr/share/man/man1/masterha_check_repl.1.gz /usr/share/man/man1/masterha_check_ssh.1.gz /usr/share/man/man1/masterha_check_status.1.gz /usr/share/man/man1/masterha_conf_host.1.gz /usr/share/man/man1/masterha_manager.1.gz /usr/share/man/man1/masterha_master_monitor.1.gz /usr/share/man/man1/masterha_master_switch.1.gz /usr/share/man/man1/masterha_secondary_check.1.gz /usr/share/man/man1/masterha_stop.1.gz /usr/share/perl5/vendor_perl/MHA/Config.pm /usr/share/perl5/vendor_perl/MHA/DBHelper.pm /usr/share/perl5/vendor_perl/MHA/FileStatus.pm /usr/share/perl5/vendor_perl/MHA/HealthCheck.pm /usr/share/perl5/vendor_perl/MHA/ManagerAdmin.pm /usr/share/perl5/vendor_perl/MHA/ManagerAdminWrapper.pm /usr/share/perl5/vendor_perl/MHA/ManagerConst.pm /usr/share/perl5/vendor_perl/MHA/ManagerUtil.pm /usr/share/perl5/vendor_perl/MHA/MasterFailover.pm /usr/share/perl5/vendor_perl/MHA/MasterMonitor.pm /usr/share/perl5/vendor_perl/MHA/MasterRotate.pm /usr/share/perl5/vendor_perl/MHA/SSHCheck.pm /usr/share/perl5/vendor_perl/MHA/Server.pm /usr/share/perl5/vendor_perl/MHA/ServerManager.pm Manager节点需要为每个监控的master/slave集群提供一个专用的配置文件，而所有的master/salve集群也可共享全局 配置。全局配置文件默认为/etc/masterha_default.cnf,其为可先配置。如果仅监控一组 master/slave集群，也可 直接通过application的配置提供各服务器的默认配置信息。而每个application的配置文件路径为自定义，本示例将使用 /etc/masterha/appl.cnf 12345678910111213141516171819202122# vim /etc/masterha/appl.cnf [server default] user=rjrj password=centos.123 manager_workdir=/data/masterha/app1 manager_log=/data/masterha/app1/manager.log remote_workdir=/data/masterha/app1 ssh_user=root repl_user=rjrj repl_password=centos.123 ping_interval=1 [server1] hostname=172.16.23.11 candidate_master=1 [server2] hostname=172.16.23.12 candidate_master=1 [server3] hostname=172.16.23.13 123456789101112131415161718192021[root@node0 ~]# masterha_check_ssh --conf=/etc/masterha/app1.cnfTue Feb 21 23:13:48 2017 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Tue Feb 21 23:13:48 2017 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Tue Feb 21 23:13:48 2017 - [info] Reading server configuration from /etc/masterha/app1.cnf..Tue Feb 21 23:13:48 2017 - [info] Starting SSH connection tests..Tue Feb 21 23:13:49 2017 - [debug]Tue Feb 21 23:13:48 2017 - [debug] Connecting via SSH from root@172.16.23.11(172.16.23.11:22) to root@172.16.23.12(172.16.23.12:22)..Tue Feb 21 23:13:48 2017 - [debug] ok.Tue Feb 21 23:13:48 2017 - [debug] Connecting via SSH from root@172.16.23.11(172.16.23.11:22) to root@172.16.23.13(172.16.23.13:22)..Tue Feb 21 23:13:48 2017 - [debug] ok.Tue Feb 21 23:13:49 2017 - [debug]Tue Feb 21 23:13:48 2017 - [debug] Connecting via SSH from root@172.16.23.12(172.16.23.12:22) to root@172.16.23.11(172.16.23.11:22)..Tue Feb 21 23:13:49 2017 - [debug] ok.Tue Feb 21 23:13:49 2017 - [debug] Connecting via SSH from root@172.16.23.12(172.16.23.12:22) to root@172.16.23.13(172.16.23.13:22)..Tue Feb 21 23:13:49 2017 - [debug] ok.Tue Feb 21 23:13:50 2017 - [debug]Tue Feb 21 23:13:49 2017 - [debug] Connecting via SSH from root@172.16.23.13(172.16.23.13:22) to root@172.16.23.11(172.16.23.11:22)..Tue Feb 21 23:13:49 2017 - [debug] ok.Tue Feb 21 23:13:49 2017 - [debug] Connecting via SSH from root@172.16.23.13(172.16.23.13:22) to root@172.16.23.12(172.16.23.12:22)..Tue Feb 21 23:13:50 2017 - [debug] ok.Tue Feb 21 23:13:50 2017 - [info] All SSH connection tests passed successfully. 最后显示为successfully表示已经成功了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475[root@node0 ~]# masterha_check_repl --conf=/etc/masterha/app1.cnfWed Feb 22 10:18:40 2017 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Wed Feb 22 10:18:40 2017 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Wed Feb 22 10:18:40 2017 - [info] Reading server configuration from /etc/masterha/app1.cnf..Wed Feb 22 10:18:40 2017 - [info] MHA::MasterMonitor version 0.56.Wed Feb 22 10:18:41 2017 - [info] GTID failover mode = 0Wed Feb 22 10:18:41 2017 - [info] Dead Servers:Wed Feb 22 10:18:41 2017 - [info] Alive Servers:Wed Feb 22 10:18:41 2017 - [info] 172.16.23.11(172.16.23.11:3306)Wed Feb 22 10:18:41 2017 - [info] 172.16.23.12(172.16.23.12:3306)Wed Feb 22 10:18:41 2017 - [info] 172.16.23.13(172.16.23.13:3306)Wed Feb 22 10:18:41 2017 - [info] Alive Slaves:Wed Feb 22 10:18:41 2017 - [info] 172.16.23.12(172.16.23.12:3306) Version=5.5.44-MariaDB-log (oldest major version between slaves) log-bin:enabledWed Feb 22 10:18:41 2017 - [info] Replicating from 172.16.23.11(172.16.23.11:3306)Wed Feb 22 10:18:41 2017 - [info] Primary candidate for the new Master (candidate_master is set)Wed Feb 22 10:18:41 2017 - [info] 172.16.23.13(172.16.23.13:3306) Version=5.5.44-MariaDB-log (oldest major version between slaves) log-bin:enabledWed Feb 22 10:18:41 2017 - [info] Replicating from 172.16.23.11(172.16.23.11:3306)Wed Feb 22 10:18:41 2017 - [info] Current Alive Master: 172.16.23.11(172.16.23.11:3306)Wed Feb 22 10:18:41 2017 - [info] Checking slave configurations..Wed Feb 22 10:18:41 2017 - [info] Checking replication filtering settings..Wed Feb 22 10:18:41 2017 - [info] binlog_do_db= , binlog_ignore_db=Wed Feb 22 10:18:41 2017 - [info] Replication filtering check ok.Wed Feb 22 10:18:41 2017 - [info] GTID (with auto-pos) is not supportedWed Feb 22 10:18:41 2017 - [info] Starting SSH connection tests..Wed Feb 22 10:18:43 2017 - [info] All SSH connection tests passed successfully.Wed Feb 22 10:18:43 2017 - [info] Checking MHA Node version..Wed Feb 22 10:18:48 2017 - [info] Version check ok.Wed Feb 22 10:18:48 2017 - [info] Checking SSH publickey authentication settings on the current master..Wed Feb 22 10:18:48 2017 - [info] HealthCheck: SSH to 172.16.23.11 is reachable.Wed Feb 22 10:18:49 2017 - [info] Master MHA Node version is 0.56.Wed Feb 22 10:18:49 2017 - [info] Checking recovery script configurations on 172.16.23.11(172.16.23.11:3306)..Wed Feb 22 10:18:49 2017 - [info] Executing command: save_binary_logs --command=test --start_pos=4 --binlog_dir=/var/lib/mysql,/var/log/mysql --output_file=/data/masterha/app1/save_binary_logs_test --manager_version=0.56 --start_file=log-bin.000003Wed Feb 22 10:18:49 2017 - [info] Connecting to root@172.16.23.11(172.16.23.11:22).. Creating /data/masterha/app1 if not exists.. Creating directory /data/masterha/app1.. done. ok. Checking output directory is accessible or not.. ok. Binlog found at /var/lib/mysql, up to log-bin.000003Wed Feb 22 10:18:50 2017 - [info] Binlog setting check done.Wed Feb 22 10:18:50 2017 - [info] Checking SSH publickey authentication and checking recovery script configurations on all alive slave servers..Wed Feb 22 10:18:50 2017 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='rjyy' --slave_host=172.16.23.12 --slave_ip=172.16.23.12 --slave_port=3306 --workdir=/data/masterha/app1 --target_version=5.5.44-MariaDB-log --manager_version=0.56 --relay_log_info=/var/lib/mysql/relay-log.info --relay_dir=/var/lib/mysql/ --slave_pass=xxxWed Feb 22 10:18:50 2017 - [info] Connecting to root@172.16.23.12(172.16.23.12:22)..Creating directory /data/masterha/app1.. done. Checking slave recovery environment settings.. Opening /var/lib/mysql/relay-log.info ... ok. Relay log found at /var/lib/mysql, up to relay-bin.000009 Temporary relay log file is /var/lib/mysql/relay-bin.000009 Testing mysql connection and privileges.. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done.Wed Feb 22 10:18:51 2017 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='rjyy' --slave_host=172.16.23.13 --slave_ip=172.16.23.13 --slave_port=3306 --workdir=/data/masterha/app1 --target_version=5.5.44-MariaDB-log --manager_version=0.56 --relay_log_info=/var/lib/mysql/relay-log.info --relay_dir=/var/lib/mysql/ --slave_pass=xxxWed Feb 22 10:18:51 2017 - [info] Connecting to root@172.16.23.13(172.16.23.13:22)..Creating directory /data/masterha/app1.. done. Checking slave recovery environment settings.. Opening /var/lib/mysql/relay-log.info ... ok. Relay log found at /var/lib/mysql, up to relay-bin.000007 Temporary relay log file is /var/lib/mysql/relay-bin.000007 Testing mysql connection and privileges.. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done.Wed Feb 22 10:18:52 2017 - [info] Slaves settings check done.Wed Feb 22 10:18:52 2017 - [info]172.16.23.11(172.16.23.11:3306) (current master) +--172.16.23.12(172.16.23.12:3306) +--172.16.23.13(172.16.23.13:3306)Wed Feb 22 10:18:52 2017 - [info] Checking replication health on 172.16.23.12..Wed Feb 22 10:18:52 2017 - [info] ok.Wed Feb 22 10:18:52 2017 - [info] Checking replication health on 172.16.23.13..Wed Feb 22 10:18:52 2017 - [info] ok.Wed Feb 22 10:18:52 2017 - [warning] master_ip_failover_script is not defined.Wed Feb 22 10:18:52 2017 - [warning] shutdown_script is not defined.Wed Feb 22 10:18:52 2017 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK. 检查管理的MySQL复制集群的连接配置参数是正常的； 12# nohup masterha_manager --conf=/etc/masterha/app1.cnf &gt; /data/master/app1/manager.log 2&gt;&amp;1 &amp; # 让masterha_manager进程工作于后台 四、开始测试123456789101112131415161718192021[root@node1 ~]# systemctl stop mariadb # 让主服务器停掉；[root@node2 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 50Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; SHOW MASTER STATUS;+-------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+-------------------+----------+--------------+------------------+| master-bin.000005 | 245 | | |+-------------------+----------+--------------+------------------+1 row in set (0.00 sec)MariaDB [(none)]&gt; SHOW SLAVE STATUS\G;Empty set (0.00 sec)ERROR: No query specified 此时node2被提升为主服务器 ,node3拉取数据走向node2 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[11:12:41root@node3~]#mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 33Server version: 5.5.44-MariaDB-log MariaDB ServerCopyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; SHOW SLAVE STATUS\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.16.23.12 Master_User: rj Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-bin.000008 Read_Master_Log_Pos: 245 Relay_Log_File: relay-bin.000002 Relay_Log_Pos: 530 Relay_Master_Log_File: master-bin.000008 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 245 Relay_Log_Space: 818 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 21 row in set (0.00 sec)]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 ELK(Elasticsearch Logstash Kibana) 搭建]]></title>
    <url>%2F2018%2F01%2F30%2FCentOS-7-ELK-Elasticsearch-Logstash-Kibana-%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[CentOS 7 ELK(Elasticsearch Logstash Kibana) 搭建 不管是用于记录，监控或者程序的Debug，日志，对于任何系统来说都是一个及其重要的部分;但一般日志的数据量会比较大，并且分散在各个地方。如果管理的服务器或者程序比较少的情况;我们还可以逐一登录到各个服务器去查看，分析。但如果服务器或者程序的数量比较多了;之后这种方法就显得力不从心。基于此，一些集中式的日志系统也就应用而生;目前比较有名成熟的有，Sentry、Splunk(商业)、FaceBook 的Scribe、Apache 的 Chukwa;Cloudera 的 Fluentd、还有ELK 等等; Sentry 与 ELK的对比1、 sentry sentry 是由python开发且开源的日志存储工具，占用内存较小，执行速度较慢，适合少量日志存储;php python等程序可以直接调用sentry url 将日志写入，不支持sentry主动去额外的收集日志;不支持分布式与横向扩展;只能查找错误日志，不支持全局搜索;一般运行在docker中，部署方便。出现问题排查费劲;最底配置1核1G; 2、 ELK ELK即(Elasticsearch[搜索引擎]，Logstash[日志收集]，Kibana [客户端接入的web平台]);ELK 是由JAVA开发且开源的日志存储套件，占用内存较大，执行速度较快，适合大量志日志高并发存储;支持分存式与横向扩展;支持全局搜索，支持正则表达式搜索，支持图形统计, 支持日志json、表格形式;一般运行在系统层面，部署费劲。出现问题易于拆分，排查;最底配置2核4G; 此次部署过程 注: 二进制包Elasticsearch 不能用root用户启动服务 JDK 8 的安装与配置123456789101112131415# useradd elasticsearch# passwd elasticsearch# vim /etc/profile #在最后加入以下内容 export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-0.b14.el7_4.x86_64export JRE_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-0.b14.el7_4.x86_64/jreexport PATH=/usr/share/logstash/bin/:$PATH# source /etc/profile # yum -y install yum -y install java[root@iz8vbap8o8nj8n6yoc05n6z logstash-5.3.0]# java -versionopenjdk version "1.8.0_161"OpenJDK Runtime Environment (build 1.8.0_161-b14)OpenJDK 64-Bit Server VM (build 25.161-b14, mixed mode)[root@iz8vbap8o8nj8n6yoc05n6z logstash-5.3.0]# echo $JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-0.b14.el7_4.x86_64 ElasticSearch 安装与配置1、安装 ElasticSearch 123456789101112131415# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.3.0.zip# unzip elasticsearch-5.3.0.zip# mv elasticsearch-5.3.0 /usr/local/# chown elasticsearch.elasticsearch /usr/local/elasticsearch-5.3.0/ -R# vim /usr/local/elasticsearch-5.3.0/config/elasticsearch.yml #启用变更以下配置cluster.name: transfereasy-elknode.master: truenode.data: truepath.data: /data/elasticDatapath.logs: /data/logsnetwork.host: 0.0.0.0http.port: 9200 2、安装x-pack插件 1# /usr/local/elasticsearch-5.3.0/bin/elasticsearch-plugin install x-pack 3、启动 ElasticSearch 12345678# su - elasticsearch $ /usr/local/elasticsearch-5.3.0/bin/elasticsearch -d$ exit # 服务启动验证# netstat -tnlup | egrep "9200|9300"tcp 0 0 0.0.0.0:9200 0.0.0.0:* LISTEN 14459/java tcp 0 0 0.0.0.0:9300 0.0.0.0:* LISTEN 14459/java 4、api 验证 123456789101112131415# curl http://localhost:9200 -u elastic# 默认用户 elastic 默认密码:changeme&#123; "name" : "RXHIrkw", "cluster_name" : "ssjinyao-elk", "cluster_uuid" : "xxxxxxxxxxxxxxxxxx", "version" : &#123; "number" : "5.3.0", "build_hash" : "3adb13b", "build_date" : "2017-03-23T03:31:50.652Z", "build_snapshot" : false, "lucene_version" : "6.4.1" &#125;, "tagline" : "You Know, for Search"&#125; 5、添加开机启动 1echo "/usr/local/elasticsearch-5.3.0/bin/elasticsearch -d" &gt; /etc/rc.local 6、问题解决 12345678910a、can not run elasticsearch as root # 需新建启动ElasticSearch的用户b、max file descriptors [65535] for elasticsearch process is too low, increase to at least [65536]# vim /etc/sercurity/limits.conf* soft nofile 655350* hard nofile 655350$ su - elasticsearch # 再次合对是否可以打开655350个文件 c、max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] # vim /etc/sysctl.conf 添加以下内容vm.max_map_count=655300# sysctl -p Kibana的安装与配置1、 安装 123456# wget https://artifacts.elastic.co/downloads/kibana/kibana-5.3.0-linux-x86_64.tar.gz # tar -zxf kibana-5.3.0-linux-x86_64.tar.gz# mv kibana-5.3.0-linux-x86_64 /usr/local/# chown elasticsearch.elasticsearch /usr/local/kibana-5.3.0-linux-x86_64/ -R# cd /usr/local/kibana-5.3.0-linux-x86_64/# bin/kibana-plugin install x-pack 2、 配置 12345678# vim /usr/local/kibana-5.3.0-linux-x86_64/config/kibana.yml # 变更以下配置elasticsearch.url: "http://localhost:9200"# su - elasticsearch$ nohup /usr/local/kibana-5.3.0-linux-x86_64/bin/kibana &amp;# exit # netstat -tnlup | grep 5601tcp 0 0 127.0.0.1:5601 0.0.0.0:* LISTEN 14132/node Nginx 的安装与配置12345678910111213141516171819202122232425262728293031323334353637383940# yum install nginx -y # nginx -t # vim /etc/nginx/conf.d/kibana.confserver &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; location / &#123; proxy_pass http://127.0.0.1:5601; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125;# vim /etc/nginx/nginx.conf 注释默认虚拟主机# server &#123;# listen 80 default_server;# listen [::]:80 default_server;# server_name _;# root /usr/share/nginx/html;## # Load configuration files for the default server block.# include /etc/nginx/default.d/*.conf;## location / &#123;# &#125;## error_page 404 /404.html;# location = /40x.html &#123;# &#125;## error_page 500 502 503 504 /50x.html;# location = /50x.html &#123;# &#125;# &#125;# nginx -t # systemctl restart nginx 浏览器访问 http://xxx.ssjinyao.com/ Logstash 的安装与配置 注:由于logstash-5.3的二进制包无法实别系统环境PASH变量，所以这里用rpm包，yum安装 1、 下载并安装Logstash rpm 包 12# wget https://artifacts.elastic.co/downloads/logstash/logstash-6.1.2.rpm# yum -y install logstash-6.1.2.rpm 2、 配置Logstash 收集远程日志 123456789101112131415161718192021222324# vim first-pipeline.confinput &#123; udp &#123; port =&gt; 5959 codec =&gt; json &#125;&#125;filter &#123; grok &#123; match =&gt; &#123; "message" =&gt; "%&#123;COMBINEDAPACHELOG&#125;"&#125; &#125; geoip &#123; source =&gt; "clientip" &#125;&#125;output &#123; #stdout &#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] user =&gt; "elastic" password =&gt; "xxxxxxxxx" &#125;&#125;# logstash -f first-pipeline.conf --path.settings=/etc/logstash/ --config.reload.automatic &amp; beats 的安装与配置 Beats是作为代理在服务器上安装的开源的 data shippers，能将各种不同类型的操作数据;（如， wireData、LogFiles、Metrics、WinEvent）直接发送到 Elasticsearch;或者通过Logstash将其发送到Elasticsearch。我们可以使用它来解析和转换我们需要收集的各种数据; 1、 安装 12# wget https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-5.3.1-x86_64.rpm# yum -y install metricbeat-5.3.1-x86_64.rpm 2、 配置 1234567891011121314151617181920212223242526272829303132# vim /etc/metricbeat/metricbeat.ymlmetricbeat.modules:- module: system metricsets: - cpu - load - core - diskio - filesystem - fsstat - memory - network - process - socket enabled: true period: 10s processes: ['.*']- module: nginx metricsets: ["stubstatus"] enabled: true period: 10s hosts: ["http://127.0.0.1"] server_status_path: "NginxStatus"output.elasticsearch: hosts: ["127.0.0.1:9200"] username: "elastic" password: "changeme"logging.level: debugoutput.elasticsearch: hosts: ["localhost:9200"]# metricbeat.sh -c metricbeat.yml -configtestConfig OK 登录查询日志1、 相看日志源ip区域分布 2、 Nginx 日志格式如下 3、 使用正则搜索 4、 直接写入Logstash的python日志表格式 5、 直接写入Logstash的python日志json格式 远程日志收集1、 filebeat 的安装 1234567891011121314151617181920$ curl -L -O https://download.elastic.co/beats/filebeat/filebeat_1.3.0_amd64.deb$ sudo dpkg -i filebeat_1.3.0_amd64.deb$ sudo vim /etc/filebeat/filebeat.yml filebeat: prospectors: - paths: - /var/log/nginx/*.log - /var/log/cashier/logs/*.log - /var/log/topen/logs/*.log - /var/log/xbasement/logs/*log input_type: log document_type: nginx-access-testapi.transfereasy.com registry_file: /var/lib/filebeat/registryoutput: logstash: hosts: [&quot;xxx.xx.xxx.xx:5959&quot;]shipper:logging: files: 2、 将数据同步到elk 12$ sudo /etc/init.d/filebeat start$ sudo /etc/init.d/filebeat status]]></content>
      <tags>
        <tag>rhca</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 之业务服务监控详解(四)]]></title>
    <url>%2F2018%2F01%2F23%2Fpython-%E4%B9%8B%E4%B8%9A%E5%8A%A1%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E8%AF%A6%E8%A7%A3-%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[实现图文格式的服务器性能报表邮件通过MIMEText 与 MIMEImage类的组合，实现图文邮件格式。另通过MIMEText类再定义Content-Disposition 属性来实现附件的邮件。可以利用这些特性来定质服务器周报。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960➜ test cat email_open.py #!/usr/bin/env python# -*- coding: utf-8 -*-import smtplibfrom email.mime.multipart import MIMEMultipart # 导入MIMEMultipart类 from email.mime.text import MIMEText # 导入MIMEText类 from email.mime.image import MIMEImage # 导入MIMEImae 类HOST = "smtp.139.com" # 定义邮件 stmp 主机SUBJECT = u"业务性能数据报表" # 定义邮件主题TO = "1922006891@qq.com" # 定义邮件收件人FROM = "15822097176@139.com" # 定义邮件发件人def addimg(src,imgid): # 添加片函数，参数1:图片路径,参数2: 图片id fp = open(src, 'rb') # 打开文件 msgImage = MIMEImage(fp.read()) # 创建MIMEImage对象，读取图片内容并作为参数 fp.close() # 关闭文件 msgImage.add_header('Content-ID', imgid) # 指定图片文件的Content-ID,&lt;img&gt; 标签src用到 return msgImage # 返回msgImage 对象msg = MIMEMultipart('related') # 创建MIMEMultipart对象，采用related定义内嵌资源的邮件体#创建MIMEText对象，HTML元素包括表格&lt;stable&gt;及图片&lt;img&gt;msgtext = MIMEText(""" &lt;table width="600" border="0" cellspacing="0" cellpadding="4"&gt; &lt;tr bgcolor="#CECFAD" height="20" style="font-size:14px"&gt; &lt;td colspan=2&gt; * 官网性能数据 &lt;a href="www.ssinyao.com"&gt; 更多&gt;&gt; &lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr bgcolor="#EFEBDE" height="100" style="font-size:13px"&gt; &lt;td&gt; &lt;img src="cid:systemload"&lt;/td&gt;&lt;td&gt; &lt;img src="cid:cpu"&lt;td&gt; &lt;/tr&gt; &lt;tr bgcolor="#EFEBDE" height="100" sytle="font-size:13px"&gt; &lt;td&gt; &lt;img src="cid:eth0"&gt;&lt;/td&gt;&lt;td&gt; &lt;img src="cid:eth1"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;""", "html","utf-8") #&lt;img&gt; 标签的src属性是通过Content-ID 来引用的msg.attach(msgtext) msg.attach(addimg("./systemload.png", "systemload")) msg.attach(addimg("./cpu.png", "cpu")) msg.attach(addimg("./eth0.png", "eth0")) msg.attach(addimg("./eth1.png", "eth1")) msg['Subject'] = SUBJECT # 邮件主题msg['From'] = FROM # 邮件发送人，邮件头部可见msg['TO'] = TO # 邮件收件人，邮件头部可见try: server = smtplib.SMTP() # 创建一个SMTP()对象 server.connect(HOST, "25") # 通过connect方法连接smtp主机 server.starttls() #启动安全传输模式 server.login("15822097176@139.com","xxxxxxxx") # 邮箱帐号登录校验 server.sendmail(FROM, TO, msg.as_string()) #邮件发送 server.quit() # 断开stmp连接 print "邮件发送成功"except Exception, e: print "失败:" +str(e)➜ test ./email_open.py 邮件发送成功 实现的功能如下 同样功能的实现 muttrc + msmtp 发送邮件12345678910111213141516171819# yum -y install msmtp mutt # cat /etc/muttrc et sendmail=&quot;/usr/bin/msmtp&quot;set use_from=yesset realname=&quot;15822097176@139.com&quot;set editor=&quot;vim&quot;# cat /etc/msmtprcaccount defaulthost smtp.139.comport 25from 15822097176@139.comauth logintls offuser 15822097176@139.compassword xxxxxxxx# echo &quot;test&quot; | mutt -s &quot;test&quot; -a /path/to/file]]></content>
      <tags>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 之业务服务监控详解(三)]]></title>
    <url>%2F2018%2F01%2F22%2Fpython-%E4%B9%8B%E4%B8%9A%E5%8A%A1%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E8%AF%A6%E8%A7%A3-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[DNS处理模块dnspython dnspython(https://www.dnspython.org/)是Python实现的一个DNS式具包，它支持几乎所有的记录类型 ，可以用于查询、传输并动态更新ZONE信息， 同时支持TSIG(事务签名)验证消息和EDNS0(扩展DNS)。在系统管理方面，我们可以利用其查询功能来实现DNS服务监控以及解析结果的校验，可以代替nslookup及dig等，轻松做到与现有平台的整合 123456# pip install dnspython # easy_install dnspython # wget http://www.dnspython.org/kits/1.9.4/dnspython-1.9.4.tar.gz# tar -zxvf dnspython-1.9.4.tar.gz# cd dnspython-1.9.4# python setuppy install 模块域名解析方法详解 dnspython 模块提供了大量的DNS处理方法，最常用的方法是域名查询。dnspython提供了一个DNS解析器类–resolver，使用它的uquery方法来实现域名的查询功能。query方法定义如下; 12query(self, qname, rdtype=1, rdclass=1, tcp=False, source=None, raise_on_no_answer=True, source_port=0) 其中，qnae参数为查询的域名。rdtype参数用来指定RR资源的类型，常用的有以下几种: 123456# A 记录，将主机名转换成IP地址: # MX 记录，邮件交换记录，定义邮件服务器的域名； # CNAME记录，指别名记录，实现域名间的映射; # NS记录，标记区域的域名服务器及授权子域; # PTR记录，反向解析，与A记录相反，将IP转换成主机名; # SOA记录，SOA标记，一个起妈授权区的定义; rdclass参数用于指定网络类型，可选的值有IN、CH与HS、其中IN为默认，使用最广泛;tcp参数用于指定查询是否启用TCP协议，默认为False(不启用);source 与source_port 参数作为指定查询源地址与端口;默认值为查询设备IP地址和0。raise_on_no_answer;参当用于指定当查询无应答时是否触发异常。默认为True; 常见解析类型 常见的DNS解析类型包括A、MX、NS、CNAME等。利用dnspython和dns.resolver.query方法可以简单实现这些DNS类型的查询，为后面要实现的功能提供数据来源，比如对一个使用DNS轮循业务的域名进行可用性可用性，需要得到当前的解析结果。 1、实现A记录查询方法 12345678910111213➜ test cat dns_domain.py #!/usr/bin/env python2.7# -*- coding: utf-8 -*-#from dns import resolverimport dns.resolverdomain = raw_input("Please input an domain: ") # 输入域名地址A = dns.resolver.query(domain, 'A') # 指定查询类型为A记录 for i in A.response.answer: # 通过 response.answer 方法获取查询回应信息 for j in i.items: # 遍历回应信息 print j.address➜ test ./dns_domain.py Please input an domain: www.ssjinyao.com47.94.3.76 2、实现MX记录查询方法 12345678910111213141516171819➜ test ./dns_mx.pyPlease input an domain: ^CTraceback (most recent call last): File "./dns_mx.py", line 4, in &lt;module&gt; domain = raw_input("Please input an domain: ")KeyboardInterrupt➜ test cat ./dns_mx.py#!/usr/bin/env python2.7# -*- coding: utf-8 -*-import dns.resolver domain = raw_input("Please input an domain: ")MX = dns.resolver.query(domain, 'MX') # 指定查询类型为MX记录for i in MX: # 遍历回应结果，输出MX记录的preference 及exchanger信息 print 'MX preference =' , i.preference, 'mail exchanger=' , i.exchange➜ test ./dns_mx.pyPlease input an domain: 139.comMX preference = 10 mail exchanger= mx2.mail.139.com.MX preference = 20 mail exchanger= mx3.mail.139.com.MX preference = 5 mail exchanger= mx1.mail.139.com. 3、 实现 NS 记录查询方法源码 1234567891011121314151617181920➜ test cat dns_ns.py #!/usr/bin/env python2.7# -*- coding: utf-8 -*-import dns.resolver domain = raw_input('Please input an domain: ')ns = dns.resolver.query(domain, 'NS') # 指定查询类型为NS记录for i in ns.response.answer: for j in i.items: print j.to_text()➜ test ./dns_ns.py Please input an domain: ssjinyao.comdns30.hichina.com.dns29.hichina.com.➜ test ./dns_ns.pyPlease input an domain: baidu.comns2.baidu.com.ns7.baidu.com.dns.baidu.com.ns3.baidu.com.ns4.baidu.com. 4、 实现CNAME记录查询方法 123456789101112131415➜ test cat dns_cname.py #!/usr/bin/env python2.7# -*- coding: utf-8 -*-import dns.resolver domain = raw_input("Please input an domain: ")cname = dns.resolver.query(domain, 'CNAME') # 指定查询类型为CNAME记录for i in cname.response.answer: # 结果将回应 cname 后的目标域名 for j in i.items: print j.to_text()➜ test ./dns_cname.py Please input an domain: mail.ssjinyao.commail.mxhichina.com.➜ test ./dns_cname.pyPlease input an domain: ll.ssjinyao.comwww.leleol.com. 5、 DNS域名轮循业务监控 大部分的DNS解析都是一个域名对应一个IP地址，但是通过DNS轮循可以做到一个域名对应多个IP从而实现最简单且最高效的负载均衡，不过此方案最大的弊端是目标主机不可以用时，无法被自动剔除，因此做好业务主机的服务可用监控是至关重要的，通过分析当前域名的解析IP再结合服务端口探测来实现自动监控，在域名解析中添加、删除IP时无须对监控脚本进行更改 a、 步骤 12# 实现对域名的解析，获取域名 所有的A记录解析IP列表; # 对IP 列表进行HTTP级别的探测; b、 实现拓扑图 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/env python2.7# -*- coding: utf-8 -*-import dns.resolver import os import httplibiplist = [] # 定义域名IP列表变量appdomain = "www.qqlilin.com" # 定义业务域名def get_iplist(domain=""): # 域名解析函数，解析成功IP将被追加到iplist try: A = dns.resolver.query(domain, 'A') # 解析A记录类型 except Exception, e: print "dns resolver error:" + str(e) return for i in A.response.answer: for j in i.items: iplist.append(j.address) # 追加到iplist return Truedef checkip(ip): checkurl=ip+":80" getcontent="" httplib.socket.setdefaulttimeout(5) # 定义http连接超时间为5秒 conn=httplib.HTTPConnection(checkurl) # 创建http连接对象 try: conn.request("GET", "/", headers = &#123;"Host": appdomain&#125;) # 发起URL请求，添加host 主机头 r=conn.getresponse() getcontent = r.read(15) # 获取URL页面前15个字符，以便做可用性校验 finally: if getcontent=="&lt;!doctype html&gt;": # 监控URL页的内容一般是事先定义好的，比如 "HTTP200" 等 print (getcontent) print ip + " [OK]" else: print ip + " [Error]" # 此处可放告警程序，可以是邮件，短信通知if __name__ == "__main__": if get_iplist(appdomain) and len(iplist) &gt; 0: # 条件:域名解析正确至少返回一个IP for ip in iplist: checkip(ip) else: print "dns resolver error"]]></content>
      <tags>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 之业务服务监控详解(二)]]></title>
    <url>%2F2018%2F01%2F19%2Fpython-%E4%B9%8B%E4%B8%9A%E5%8A%A1%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E8%AF%A6%E8%A7%A3-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[文件/目录差异对比法 当我们进行代码审计或校验备份时，往往需要检查原始与目标目录的一致性;Python的标准库已经自带了满足此需求的模块filecmp;filecmp可以实现文件、目录遍历子目录的差异对比功能;比如报告中输出目录目录比原始多出的文件或子目录;即使文件同名也会判断是否为同一个文件(内容级比对)等;python2.3 或更高版本默认自带fileemp模块,无需额外安装; 模块常用方法说明 filecmp 提供了三个操作方法，分别为cmp（单文件对比）、cmpfiles(多文件对比）dircmp（目录对比) 1234单文件对比，采用filecmp.cmp(f1,f2[,shallow])方法，比较文件名为f1和f2的文件 相同反回True，不相同返回False,shallow默认为True，意思是只根据os.stat()方法 返回的文件基本信息进行对比，比如最后访问时间、修改时间、状态改变时间等 忽略对文件内容的对比。当shallow为False时，则os.stat()与文件内容同时进行校验 1234567891011# 对比文件的差异➜ test echo "good user" &gt; f1 ➜ test echo "good user" &gt; f3➜ test echo "good user2" &gt; f2In [2]: import filecmpIn [3]: filecmp.cmp("/Users/macbookdzsbe/Desktop/MyPython/test/f1","/Users/macbookdzsbe/Desktop/MyPython/test/f3")Out[3]: TrueIn [4]: filecmp.cmp("/Users/macbookdzsbe/Desktop/MyPython/test/f1","/Users/macbookdzsbe/Desktop/MyPython/test/f2")Out[4]: False dir1 与 dir2目录中指定文件清单对比 两目录下文件的 md5 信息如下两目录下文件的 md5 信息如下,其中f1、f2匹配; f3不匹配f4,f5对应的目录中不存在无法比较 123456789101112131415[root@test dir2]# md5sum ../dir1/*1a9dbd408f626389539e9feb1d234df7 ../dir1/f1235dce31eebce0213322102f698bc249 ../dir1/f21a9dbd408f626389539e9feb1d234df7 ../dir1/f3d41d8cd98f00b204e9800998ecf8427e ../dir1/f5[root@test dir2]# md5sum *1a9dbd408f626389539e9feb1d234df7 f1235dce31eebce0213322102f698bc249 f268e51baf228d447b199a75268dd5634b f3764c976782dec989b043d08714ec21a5 f4# 使用cmpfiles 对比的结果如下，符合我们的预期 In [4]: import filecmpIn [5]: filecmp.cmpfiles("/root/test/dir1", "/root/test/dir2",['f1','f2','f3','f4','f5'])Out[5]: (['f1', 'f2'], ['f3'], ['f4', 'f5']) 目录对比，能过dircmp(a,b[,ingore[,hide]]) 类创建一个目录比较对象;其中a和b是参加比较的目录名。ignore代表文件名忽略的列表，并默认为[‘RCS’,’CVS’,’’tags];hide代表隐藏的列表，默认为[os.curdir, os.pardir]。dircmp类可以获得目录比较的详细信息;如只有在a目录中包括的文件、a与b都存在的子目录、匹配的文件等，同时支持递归; dircmp提供了三个输出报的方法123456789101112131415161718# report()，比较当前指定目录中的内容; # report_partial_closure(),比较当前指定目录 及第一级子目录中的内容; # report_full_closure(),递归比较所有指定目录的内容; # 为输出更加详细的比较内容，dircmp类还提供了以下属性; # left, 左目录,如类定义的a; # right, 右目录,如类定义中的b; # left_list, 左目录中的文件及目录列表; # right_list, 右目录中的文件及目录列表; # common, 两边目录共同存在的文件或者目录; # left_only, 只在左目录中的文件或者目录; # right_only, 只在右目录的文件或者目录; # common_dirs, 两边目录都存在的子目录; # common_files, 两边目录都存在的子文件; # common_funny, 两边目录都存在的子目录(不同目录类型或os.stat()记录的错误); # same_files, 匹配相同的文件; # diff_files, 不匹配的文件; # funny_files, 两边目录中都存在，但无法比较的文件; # subdirs, 将common_dirs目录名映身到新的dircmp对象，格式为字典类型; 对比dir1与dir2目录差异1234567891011121314151617181920212223242526[root@test test]# mkdir dir1/&#123;a/&#123;a1,b/&#123;b1,b2,b3&#125;&#125;,f1,f2,f3,f4&#125; -pvmkdir: 已创建目录 "dir1"mkdir: 已创建目录 "dir1/a"mkdir: 已创建目录 "dir1/a/a1"mkdir: 已创建目录 "dir1/a/b"mkdir: 已创建目录 "dir1/a/b/b1"mkdir: 已创建目录 "dir1/a/b/b2"mkdir: 已创建目录 "dir1/a/b/b3"mkdir: 已创建目录 "dir1/f1"mkdir: 已创建目录 "dir1/f2"mkdir: 已创建目录 "dir1/f3"mkdir: 已创建目录 "dir1/f4"[root@test test]# touch dir1/test.py[root@test test]# tree dir1/dir1/├── a│ ├── a1│ └── b│ ├── b1│ ├── b2│ └── b3├── f1├── f2├── f3├── f4└── test.py 123456789101112131415161718192021222324252627282930[root@tf-test test]# mkdir dir2/&#123;a/&#123;a1,b/&#123;b1,b2,b3&#125;&#125;,aa&#123;/aa1&#125;,f1,f2,f3,f5&#125; -pvmkdir: 已创建目录 "dir2"mkdir: 已创建目录 "dir2/a"mkdir: 已创建目录 "dir2/a/a1"mkdir: 已创建目录 "dir2/a/b"mkdir: 已创建目录 "dir2/a/b/b1"mkdir: 已创建目录 "dir2/a/b/b2"mkdir: 已创建目录 "dir2/a/b/b3"mkdir: 已创建目录 "dir2/aa&#123;"mkdir: 已创建目录 "dir2/aa&#123;/aa1&#125;"mkdir: 已创建目录 "dir2/f1"mkdir: 已创建目录 "dir2/f2"mkdir: 已创建目录 "dir2/f3"mkdir: 已创建目录 "dir2/f5"[root@tf-test test]# touch dir2/test.py[root@tf-test test]# tree dir2/dir2/├── a│ ├── a1│ └── b│ ├── b1│ ├── b2│ └── b3├── aa&#123;│ └── aa1&#125;├── f1├── f2├── f3├── f5└── test.py 1234567891011121314151617181920212223242526[root@test test]# cat cmpy.py #!/usr/bin/env python # -*- coding:utf-8 -*- import filecmpa = "/root/test/dir1" # 定义左目录 b = "/root/test/dir2" # 定义右目录 dirobj=filecmp.dircmp(a,b,['test.y']) # 目录比较，忽略test.py文件 #输出对比结果数据报表dirobj.report()dirobj.report_partial_closure()dirobj.report_full_closure() print "left_list:" + str(dirobj.left_list)print "right_list" + str(dirobj.right_list)print "common:" + str(dirobj.common)print "left_only:" + str(dirobj.left_only)print "right_only:" + str(dirobj.right_only)print "common_dirs:" + str(dirobj.common_dirs)print "common_files:" + str(dirobj.common_files)print "common_funny:" + str(dirobj.common_funny)print "same_file:" + str(dirobj.same_files)print "diff_files:" + str(dirobj.diff_files)print "funny_files:" + str(dirobj.funny_files) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455diff /root/test/dir1 /root/test/dir2Only in /root/test/dir1 : ['f4']Only in /root/test/dir2 : ['aa&#123;', 'f5']Identical files : ['test.py']Common subdirectories : ['a', 'f1', 'f2', 'f3']diff /root/test/dir1 /root/test/dir2Only in /root/test/dir1 : ['f4']Only in /root/test/dir2 : ['aa&#123;', 'f5']Identical files : ['test.py']Common subdirectories : ['a', 'f1', 'f2', 'f3']diff /root/test/dir1/a /root/test/dir2/aCommon subdirectories : ['a1', 'b']diff /root/test/dir1/f1 /root/test/dir2/f1diff /root/test/dir1/f2 /root/test/dir2/f2diff /root/test/dir1/f3 /root/test/dir2/f3diff /root/test/dir1 /root/test/dir2Only in /root/test/dir1 : ['f4']Only in /root/test/dir2 : ['aa&#123;', 'f5']Identical files : ['test.py']Common subdirectories : ['a', 'f1', 'f2', 'f3']diff /root/test/dir1/a /root/test/dir2/aCommon subdirectories : ['a1', 'b']diff /root/test/dir1/a/a1 /root/test/dir2/a/a1diff /root/test/dir1/a/b /root/test/dir2/a/bCommon subdirectories : ['b1', 'b2', 'b3']diff /root/test/dir1/a/b/b1 /root/test/dir2/a/b/b1diff /root/test/dir1/a/b/b2 /root/test/dir2/a/b/b2diff /root/test/dir1/a/b/b3 /root/test/dir2/a/b/b3diff /root/test/dir1/f1 /root/test/dir2/f1diff /root/test/dir1/f2 /root/test/dir2/f2diff /root/test/dir1/f3 /root/test/dir2/f3left_list:['a', 'f1', 'f2', 'f3', 'f4', 'test.py']right_list['a', 'aa&#123;', 'f1', 'f2', 'f3', 'f5', 'test.py']common:['a', 'f1', 'f2', 'f3', 'test.py']left_only:['f4']right_only:['aa&#123;', 'f5']common_dirs:['a', 'f1', 'f2', 'f3']common_files:['test.py']common_funny:[]same_file:['test.py']diff_files:[]funny_files:[] 校验源与备份目录差异 有时候我们无法确认备份目录与源目录文件是否保持一致，包括源目录中的新文件或目录;更新文件或目录 有无成功同步，定期进行校验，没有成功则希望有针对性地进行补备份;本未例使用了filecmp模块的left_only、diff_files方法递归获取目录的更新项;再通过shuti.copyfile、 os.makedirs 方法对更新项进行复制，最终保持一致状态; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566➜ test cat dir_contrast.py #!/usr/bin/env python# -*- coding: utf-8 -*-import os, sys import filecmpimport re import shutil import difflibholderlist = []def compareme(dir1,dir2): # 递归获取更新项函数 dircomp=filecmp.dircmp(dir1,dir2) only_in_one=dircomp.left_only # 源目录新文件或目录 diff_in_one=dircomp.diff_files # 不匹配文件，源目录文件已发生变化 dirath=os.path.abspath(dir1) # 定义源目录绝对路径 #将更新文件名或目录追回到holderlist [holderlist.append(os.path.abspath(os.path.join(dir1,x))) for x in only_in_one] [holderlist.append(os.path.abspath(os.path.join(dir1,x))) for x in diff_in_one] if len (dircomp.common_dirs) &gt; 0: # 判断是否存在相同子目录，以便递归 for item in dircomp.common_dirs: #递归子目录 compareme(os.path.abspath(os.path.join(dir1, item)), \ os.path.abspath(os.path.join(dir2,item))) return holderlist def main(): if len(sys.argv) &gt;2: # 要求输入源目录与备份目录 dir1 = sys.argv[1] dir2 = sys.argv[2] else: print "Usage:", sys.argv[0], "datadir backupdir" sys.exit() source_files = compareme(dir1,dir2) dir1 = os.path.abspath(dir1) if not dir2.endswith('/'): dir2=dir2+'/' #备份目录路径加"/"符 dir2=os.path.abspath(dir2) destination_files=[] createdir_bool = False for item in source_files: # 遍历返回的差异文件或目录清单 destination_dir= re.sub(dir1,dir2, item) # 将源目录差异路径清单对应替换成备份目录 destination_files.append(destination_dir) if os.path.isdir(item): # 如果差异路径 为目录且不存在,则在备份目录中创建 if not os.path.exists(destination_dir): os.makedirs(destination_dir) createdir_bool = True #再次调用compareme 函数标记 if createdir_bool: #重新调用compareme函数,重新遍历新创建目录的内容 destination_files = [] source_files=[] source_files=compareme(dir1,dir2) # 调用compareme函数 for item in source_files: #获取目录差异路径清单，对应替换成备分目录 destination_dir = re.sub(dir1,dir2, item) destination_files.append(destination_dir) print "update item:" print source_files #输出更新项列表清单 copy_pair = zip(source_files,destination_files) #将源目录与备份目录文件拆分成无组 for item in copy_pair: if os.path.isfile(item[0]): shutil.copyfile(item[0], item[1])if __name__ == '__main__': main()]]></content>
      <tags>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 之业务服务监控详解(一)]]></title>
    <url>%2F2018%2F01%2F18%2Fpython-%E4%B9%8B%E4%B8%9A%E5%8A%A1%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E8%AF%A6%E8%A7%A3-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[业务服务监控详解 业务服务监控是运维体系中最重要的环节，是保证业务服务质量的关键手段。如何更有效地实现业务服务是每个运维人员应该思考的问题，不同业务场景需定制不同的监控策略。Python在监控方面提供了大量的第三方式具，可以帮助我们快速、有效地开发企业级服务监控平台，为我们的业务保驾护航。 文件内容差异对比方法 通过difflib模块实现文件内容差异比对。difflib作为Python的标准库模块，无需安装，作用是对比文本之间的差异，且支持输出可读性较强的HTML档，与linux下的diff命令相似。 我们可以使用difflib对比代码、配置文件的差别，在版本控制方在是非常有用的。python2.3或者更高版本默认自带difflib模块 两个字符串的差异对比 通过使用difflib模块实现两个字符串的差异对比，然后以版本控制风格进行输出 123456789101112131415161718192021222324252627282930313233343536373839404142434445➜ test cat diff.py #!/usr/bin/env python# -*- coding: utf-8 -*-import difflibtext1 = """text1: This module provides classes and funcitons for compring sequences.including HTML and context and unified diffs. difflib document v7.4add sring """text1_lines = text1.splitlines() #以行进行分隔，以便进行对比 text2 = """text2This module provides classes and functions for Comparing sequences. including HTML and context and unified diffs. difflib document v7.5"""text2_lines = text2.splitlines() d = difflib.Differ()diff = d.compare(text1_lines, text2_lines) # 采用compare方法对字符串进行比较print '\n' .join(list(diff))# 示例结果➜ test python diff.py - text1: + text2- This module provides classes and funcitons for compring sequences.? - ^+ This module provides classes and functions for Comparing sequences. ? + ^ + + including HTML and context and unified diffs. - difflib document v7.4? ^+ difflib document v7.5? ^- add sring ➜ test ``` ## 符号说明 ‘_’ ‘包含在第一个序列行中，但不包含在第二个序列行’‘+’ ‘包含在第二个序列行中，但不包含在第一个序列行’‘’ ‘两个序列行一致’‘?’ ‘标志两个序列行存在增量差异’‘^’ ‘标志出两个序列行存在的差异字符’1234567891011121314## 生成美观的对比HTML格式文档&gt; 采用HtmlDiff()类的make_file() 方法就可以生成美观的HTML文档 ```pythond = difflib.Differ()diff = d.compare(text1_lines, text2_lines)print &apos;\n&apos; .join(list(diff))替换成:d = difflib.HtmlDiff()print d.make_file(text1_lines, text2_lines) 对比Nginx配置文件差异 当我们维护多个Nginx配置时，时常会对比不同版本的配置文件的差异，使用运维人员更加清晰地了解不同版本迭代的更新项，实现的思路是读取两个需对比的配置文件，再以换行符作为分隔符调用 difflib.HtmlDiff() 生成HTML格式的差异文档 12345678910111213141516171819202122232425262728293031323334353637383940414243444546scp diff_nginx.py root@www.ssjinyao.com:/root/diff_nginx.py 100% 1035 1.0KB/s 00:00 ➜ test ssh root@www.ssjinyao.com Last failed login: Thu Jan 18 15:55:31 CST 2018 from 140.205.201.39 on ssh:nottyThere were 48 failed login attempts since the last successful login.Last login: Tue Jan 16 10:06:45 2018 from 111.198.29.81Welcome to Alibaba Cloud Elastic Compute Service ![root@iz2zearhdmowvugecyh820z ~]# vim diff_nginx.py [root@iz2zearhdmowvugecyh820z ~]# python diff_nginx.py /etc/nginx/conf.d/leleol.conf /etc/nginx/conf.d/hexo.conf &gt; /var/www/ssjinyao/diff_nginx.html[root@iz2zearhdmowvugecyh820z ~]# cat diff_nginx.py #!/bin/bash/env python # -*- coding: utf-8 -*-import difflibimport sys try: textfile1 = sys.argv[1] #第一个配置文件路径参数 textfile2 = sys.argv[2] #第二个配置文件路径参数except Exception, e: print "Error:" + str(e) print "Usage: diff_nginx.py filename1 filename2" sys.exit()def readfile(filename): # 文件读取分隔函数 try: fileHandle = open (filename, 'rb' ) text=fileHandle.read() .splitlines() #读取后以行进行分隔 fileHandle.close() return text except IOError as error: print ('Read file Error:' +str(error)) sys.exit() if textfile1 == "" or textfile2 == "": print "Usage: diff_nginx.py filename1 filename2 " sys.exit()text1_lines = readfile(textfile1) #调用readfile函数，获取分隔后的字符串text2_lines = readfile(textfile2) d = difflib.HtmlDiff() #创建HtmlDiff()类对象print d.make_file(text1_lines,text2_lines) #通过make_file方法输出HTML的对比结果https://www.ssjinyao.com/diff_nginx.html]]></content>
      <tags>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python wxpy 模块实现微信通知与告警]]></title>
    <url>%2F2018%2F01%2F16%2Fpython-wxpy-%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E9%80%9A%E7%9F%A5%E4%B8%8E%E5%91%8A%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[python wxpy 模块实现微信通知与告警1、python wxpy的安装 12# pip install wxpy -i "https://pypi.doubanio.com/simple/"# pip install wechat_sender -i "https://pypi.doubanio.com/simple/" 2、 wxpy登录后向文件助手发送一条信息 1234567➜ test cat wechat.py #!/usr/bin/env python2.7# -*- coding: utf-8 -*-from wxpy import *bot = Bot()bot.file_helper.send('hello world')print("ending") 3、wxpy登录后实现与好友/群聊 1234567891011121314151617181920212223242526272829303132333435363738394041424344➜ test cat wechat_friends.py #!/usr/bin/env python2.7# -*- coding: utf-8 -*-import sysimport time reload (sys)sys.setdefaultencoding("utf-8")# 这里要注意中文编码的问题from wxpy import *bot = Bot()# 获取所有好友friends = bot.friends()# 遍历输出好友名称for friend in friends: print(friend)# 找到好友 friend = bot.friends() .search(unicode('有你'))[0]print(friend)friend.send('你在干嘛了?')# 获取所有聊天群 groups = bot.groups()# 遍历输出所有聊天群for group in groups: print(group)# 找到目标群# 搜索聊天群时，要确保将要搜索的群组保存在通讯录中group = bot.groups() .search(unicode("an"))[0]i = 0while i&lt;= 999: group.send("This is bug ！！！") i +=1 time.sleep(0.5) 4、 实现自动对消息处理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950➜ test cat wechat_message.py #!/usr/bin/env python2.7 # -*- coding: utf-8 -*-from wxpy import *import sysreload (sys)sys.setdefaultencoding("utf-8")bot = Bot()# 获取好友 my_friend = bot.friends() .search(unicode('有你真好'))[0]# 搜索信息messages = bot.messages.search(keywords='测试', sender=bot.self)for message in messages: print(message)# 发送文本my_friend.send('hello,yangyang!')# 发送图片my_friend.send_image('yangyang.png')# 发送视频#my_friend.send_video('yangyang.mov')# 发磅文件my_friend.send_file('yangyang.zip')# 以动态的方式发送图片my_friend.send('yangyang.png')# 发送公众号my_friend.send_raw_msg( #名片原始消息类型 raw_type=42, # 注意`ussername` 这里应为微信ID，且被发送的名片必须为自己的好友 raw_content = '&lt;msg username="wxpy_bot" nickname="wxpy 机器人"/&gt;')# 消息接收监听器@bot.register()def print_others(msg): # 输出监听到的消息 print(msg) #回复消息 msg.reply("hello world")embed() 5、 wxpy图灵机器人 123456789101112131415161718192021222324➜ test cat wechat_tulin.py #!/usr/bin/env python2.7# -*- coding: utf-8 -*-from wxpy import *import sysimport timereload (sys)sys.setdefaultencoding("utf-8")bot = Bot() # 获取好友 dear = bot.friends() .search(unicode('有你真好'))[0]# 注册获得个人的图录机器人key填入 tuling = Tuling(api_key='45a3c4xxxxxxxxx043a126a7119363d9fe')# 使用图灵机器人自动与指定好友聊天@bot.register(dear)def reply_my_friend(msg): print(msg) tuling.do_reply(msg)embed()]]></content>
  </entry>
  <entry>
    <title><![CDATA[python 自动化之paramiko]]></title>
    <url>%2F2018%2F01%2F12%2Fpython-%E8%87%AA%E5%8A%A8%E5%8C%96%E4%B9%8Bparamiko%2F</url>
    <content type="text"><![CDATA[简介 paramiko 是基于Python实现的SSH2远程安全连接，支支认证及密钥方式 。可以实现远程命令执行;文件传输、中间SSH代理等功能，相对于Pexpect，封装的层次更高，更贴近SSH协议的功能; paramiko 的安装1、 paramiko 支持pip、 easy_install 或者源安装方式，很方便解决依赖的问题，具体安装命令如下; 12# pip easy_install paramiko# easy_install paramiko 2、 paramiko 依赖第三方的Crypto、Ecdsa包及Python开发包python-devel的支持，源码如下; 1234567891011121314# yum -y install python-devel # wget http://ftp.dlitz.net/pub/dlitz/crypto/pycrypto/pycrypto-2.6.tar.gz# tar -zxvf pycrypto-2.6.tar.gz# cd pycrypto-2.6# python setup.py install# cd ..# wget https://pypi.python.org/packages/source/e/ecdsa/ecdsa-0.10.tar.gz --no-check-certificate # tar -zxvf ecdsa-0.10.tar.gz# cd ecdsa-0.10# python setup.py install # cd ..# git clone https://github.com/paramiko/paramiko.git# cd paramiko# python setup.py install 3、 校验安装结果，导入模块 没有提示异常，则说明该包安装成功; 12345678910111213➜ ~ ipythonPython 2.7.14 (default, Sep 25 2017, 09:53:22) Type "copyright", "credits" or "license" for more information.IPython 5.5.0 -- An enhanced Interactive Python.? -&gt; Introduction and overview of IPython's features.%quickref -&gt; Quick reference.help -&gt; Python's own help system.object? -&gt; Details about 'object', use 'object??' for extra details.In [1]: import paramiko In [2]: 4、使用密码认证方式，通过exec_command()方法执行命令; 1234567891011121314151617181920212223242526272829303132333435➜ test cat paramiko_ssh.py #!/usr/bin/env python # -*- coding: utf-8 -*-import paramikohostname = '192.168.0.78'username = 'root'password = 'paramiko_test*5'paramiko.util.log_to_file('syslogin.log') # 发送paramiko 日志到syslog 文件ssh=paramiko.SSHClient() # 创建一个ssh客户端 client对象ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())ssh.load_system_host_keys()# 获取客户端host_keys，默认 ~/.ssh/known_hosts#ssh.load_system_host_keys(filname='/Users/macbookdzsbe/.ssh/known_hosts') # 获取客户端host_keys，默认 ~/.ssh/known_hosts# ssh.load_host_keys(filename='/root/.ssh/known_hosts')ssh.connect(hostname=hostname,username=username,password=password)# 创建ssh连接stdin,stdout,stderr=ssh.exec_command('netstat -tnlup') #调用远程执行命令方法exec_command# 打印命令执行结果，得到Pyhton列表形，可以使用stdout.readlines()print stdout.read()stdin,stdout,stderr=ssh.exec_command('date')print stdout.readlines()ssh.close # 关闭 ssh 连接➜ test python paramiko_ssh.py Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 885/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1341/master tcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN 18341/mongod tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 1266/mysqld tcp6 0 0 :::22 :::* LISTEN 885/sshd tcp6 0 0 ::1:25 :::* LISTEN 1341/master udp 0 0 127.0.0.1:323 0.0.0.0:* 624/chronyd udp6 0 0 ::1:323 :::* 624/chronyd [u'2018\u5e74 01\u6708 12\u65e5 \u661f\u671f\u4e94 16:50:33 CST\n'] 5、 paramiko 的核组件 paramiko 包含两个核心组件，一个为SSHClient类，另一个为SFTPClient类 6、 SSHClient类 SSHClient类是SSH服务会话的高级表示，该类封装了传输(transport)、通道(channel)及SFTPClient的检验、建立的方法，通常用于执行远程命令 12345# 例 client = SSHClient() client.load_system_host_keys()client.connect('ssh.example.com')stdin, stdout, stderr = client.exec_command('ls -l') SSHClient类方法使用1、 connect 方法 connect 方法实现了远程SSH连接并检验 1234567891011121314# 方法定义connect(self, hostname, port=22, username=None, password=None, pkey=None,key_filename=None, timeout=None, allow_agent=True, look_for_keys=True, compress=False)# 参数说明# hostname (str类型)，连接的目标主机地址；# prot (int 类型)，连接目录主机的端口，默认为22; # username (str 类型), 校验的用户名 (默认为当前的本地用户名); # password (str 类型), 密码用于身份检验或解锁私钥; # pkey (PKey 类型), 私钥方式用于身份难; # key_filename(str or list(str) 类型),一个文件名或者文件名的列表，用于私钥的身份验证;# timeout (float 类型),一个可选 的超时时间(以秒为单位)的TCP连接;# allow_agent (bool 类型)，设置为False时用于禁用连接到SSH代理; # look_for_keys (bool 类型)，设置False时用来禁用在~/.ssh中搜索私钥文件; # compress (bool 类型), 设置为True时打开压缩 2、 exec_command 方法 远程命令执行方法，该命令的输入与输出流为标准输入(stdin)、输出(stdout)、错误(stderr) 12345# 方法定义 exec_command(self, command, bufsize=-1)# 参数说明# command (str 类型), 执行的命令串;# bufsize (int 类型), 文件缓冲区大小，默认为-1（不局限）; 3、loa_syste_host_keys 方法 加载本地公钥校验文件，默认为~/.ssh/known_hosts，非默认路径需要手工指定; 1234load_system_host_keys(self, filename=None)# 参数说明fiename(str类型 ),指定远程主机公钥记录文件; 4、 set_missing_host_key_policy 方法 设置连接的远程主机没有本地主机密钥或HostKeys对象时的策略，目前支持三种分别是 AutoAddPolicy、RejectPolicy(默认),WarnningPolicy，仅限于SSHClient类 123456789# 使用方法如下ssh=paramiko.SSHClient() ssh.set_missing_host_keypolicy(paramiko.AutoAddPolicy)# AutoAddPolicy,自动添加主机名及主机密钥到本地HostKeys对象，并将其保存# 不依赖load_system_host_keys()的配置，即使 ~/.ssh/known_hosts不存在也不产生影响 # RejectPolicy,自动拒绝未知的主机名和密钥，依赖load_system_host_keys()的配置# WarningPolicy,用于记录一个未知的主机密钥的Python警告并接受它，功能上与AutoAddPolicy相似# 但区别在于，未知的主机会有警告 SFTPClient类 SFTPClient 作为一个SFTP客户端对象,根据SSH传输协议的sftp会话，实现远客程文件操作比如文件上传、下载、权限、状态等操作; 1、 from_transport 方法 创建一个已连接通的SFTP客户端通道; 1234567# 方法定义 from_transport(cls, t)# 参数说明t(Transport),一个已经通过验证的传输对象。t = paramiko.Transport(("192.168.0.78", 22))t.connect(username="root",password="paramiko_test*5")sftp =paramiko.SFTPClient.from_transport(t) 2、 put 方法 上传本地文件到远程SFTP服务端; 123456789put(self, localpath, remotepath, callback=None, confirm=True)# 参数说明# localpath (str 类型)，需上传的本地文件(源);# remotepath (str 类型),远程路径(目标); # collback(functioin(int,int))，获取已接收的字字数及总传输字节数，以便回调函数高用,默认为None; # connfirm (bool类型),文件上传完毕后是否调用 stat()方法，以便确认文件的大小。 localpath='/var/log/httpd/access.log'remotepath='/data/bak/log/httpd/access.log'sftp.put(localpath,remotepath) 3、 get方法 从远程SFTP服务端下载文件到本地; 12345678get(self, remotepth, localpath, callbak=None)# 参数说明# remotepath (str类型)，需下载的远程文件 (源文件); # localpath (str类型)，本地路径(目标);# callback(function(int, int)),获取已接收的字节数及总传输字节数，以便回调函数及调用，默认为Noneremotepath='/var/log/httpd/access.og'localpath='/data/bak/log/httpd/access.log'sftp.get(remotepath,localpath) 4、其他方法 12345mkdir，在SFTP服务器端创建目录，如sftp.mkdir("/home/testdir",0700)remove, 删除SFTP服务端创指定目录，如sftp.remove("/home/testdir")rename, 重命名SFTP服务器端文件或目录，如sftp.rename("/home/testdir","/home/test")state, 获取远程SFTP服务器指定文件信息，如sftp.stat("/home/test") listdir, 获取远程SFTP服务器端指定目录列表, 以Python的(List)形式返回, 如sftp.listdir("/home") 5、SFTPClient类应用示例 123456789101112131415161718192021222324#!/usr/bin/env python # -*- coding: utf-8 -*-import paramikoimport osusername = "root"password = "paramiko_test*5"hostname = "10.180.55.118"port = 22try: t = paramiko.Transport((hostname, port)) t.connect(username=username, password=password) sftp =paramiko.SFTPClient.from_transport(t) sftp.put("/tmp/next.vim.log", "/home/root/next.vim.log") #上传文件 sftp.get("/etc/hosts", "/tmp/hosts") #下载文件 sftp.mkdir("/home/testdir",0700) #创建文件 sftp.rmdir("/home/root/test5.sql") #删除目录 sftp.rename("/home/root/test1.sql", "/home/root/test5.sql") #文件重命名 print sftp.stat("/home/root/test5.sql") #打印文件信息 print sftp.listdir("/home/root") # 打印目录列表 t.close();except Exception, e: print str(e)]]></content>
  </entry>
  <entry>
    <title><![CDATA[自习之python基础语法]]></title>
    <url>%2F2018%2F01%2F07%2F%E8%87%AA%E4%B9%A0%E4%B9%8Bpython%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基础语法常量／变量 字面常量 变量变量一个指针，它指向一块内存； 1v = 1 这样就定义了v这个变量 1v2 = v 变量的命名规则1 只能包含字母、数字和下划线2 只能以字母或者下划线开头3 不能是Python解释器的保留字 不能以类似 for if in 来做变量名，加个后缀也可以使用。但不建议这样使用； 运算符跟表达式 算术符1 算术运算符2 逻辑运算符3 比较运算符4 其它运算符 （赋值、成员运算符、身份运算符） 算术运算符1 算术运算符通常只针对数值类型1+1 3 5 3/5 3//5 5%3 2*4 比较运算符1 == 相等2 != 不等于3 &gt; 大于4 &gt;= 大于等于5 &lt; 小于6 &lt;= 小于等于 比较运算，最好是让他的类型是相同的除了 == 和 !=最好类型相同 1float (3)/5 # python2 逻辑运算符 （参与运算的成员只能是bool类型，或者可以隐式转化为bool为类型的类型）True False 123In [1]: True and TrueOut[1]: True# and 需要运算符两边都是True结果才为True 123In [2]: True or FalseOut[2]: True# or 只要运算符两边任意一个为True,结果就是True 123In [3]: not TrueOut[3]: False# not 类似短路的 1234567891011121314151617181920212223In [4]: def add(x,y): ...: print("&#123;0&#125; + &#123;1&#125;".format(x,y)) ...: return x + y ...: In [5]: In [5]: add(1,3)1 + 3Out[5]: 4In [6]: add(1,3) &gt; add(1,2) and add(2,4) &lt; add(3,4)1 + 31 + 22 + 43 + 4Out[6]: TrueIn [7]: add(1,3) &lt; add(1,2) and add(2,4) &lt; add(3,4)1 + 31 + 2Out[7]: False# 总是从左到右的计算，一旦能够斛决定表达式的最终的值，将立刻停止计算 1234567891011In [8]: add(1,3) &gt; add(1,2) or add(2,4) &lt; add(3,4)1 + 31 + 2Out[8]: TrueIn [9]: add(1,3) &lt; add(1,2) or add(2,4) &lt; add(3,4)1 + 31 + 22 + 43 + 4Out[9]: True 12345678910In [10]: left = add(1,3) &lt; add(1,2)1 + 31 + 2In [11]: right = add(2,4) &lt; add(3,4)2 + 43 + 4In [12]: left or rightOut[12]: True 位运算符 12345In [12]: bin(60)Out[12]: '0b111100'In [13]: bin(12)Out[13]: '0b1100' 12345In [14]: 60 &amp; 12Out[14]: 12# 0011 1100# 0000 1100# 0000 1100 12345In [15]: 60 | 12Out[15]: 60# 0011 1100# 0000 1100# 0011 1100 12345In [16]: 60 ^ 12Out[16]: 48# 0011 1100# 0000 1100# 0011 0000 12In [18]: int('0b110000',2)Out[18]: 48 12In [19]: ~60Out[19]: -61 12345In [20]: 60 &gt;&gt;2 Out[20]: 15In [21]: 60 &lt;&lt;2Out[21]: 240 12345678910In [22]: a = 1In [23]: aOut[23]: 1# 左边是一个标实符 右边是一个值（或者可以计算为一个值）# 让这个标实符指向这个值所在的内存In [24]: a = 3+4In [25]: aOut[25]: 7 运算符的优先级 123456789In [26]: 1+2*3Out[26]: 7In [27]: 2 * 3 **2Out[27]: 18In [28]: 2 * 3 &gt; 1+2Out[28]: True# 算术运算符优先级高于比较运算符 123In [29]: 2* 3 &gt; 1+2 and TrueOut[29]: True# 比较运算符的优先级高于逻辑运算符 123In [30]: (2 * 3 &gt; 1+2) and True Out[30]: True# 拿不准的时候加括号，或者我们的代码表现力更清晰的时候 123In [32]: ((2*3) &gt; (1+2)) and TrueOut[32]: True# 表达式由变量/常量 和运算符组成 程序控制结构 顺序分支循环 顺序结构 1234In [33]: a = 0In [34]: a = a+1In [35]: print(a)1 分支结构 单分支12if cond: block 12345678In [36]: if 1 &lt; 2: ...: print ('1 less 2')1 less 2In [37]: if 1 &lt; 2: ...: print ('1 less 2') ...: print ('main block')1 less 2main block 123456789101112131415161718In [39]: bool(0)Out[39]: FalseIn [40]: bool(-0)Out[40]: FalseIn [41]: bool(1)Out[41]: TrueIn [42]: bool(None)Out[42]: FalseIn [43]: bool([])Out[43]: FalseIn [44]: bool('')Out[44]: False# 0\空的内置结构\None bool的结构都是False,非0非空的内置结构都是True 双分支 12345678910111213141516171819202122232425262728293031323334353637383940if cond: true_blockelse: false_blockIn [45]: if 1&lt;2: ...: print ('1&lt;2') ...: else: ...: print ('2&lt;1') ...: 1&lt;2if cond: true_blockelif cond: true_blockelif cond: true_blockelif cond: true_blockelse: false_block In [5]: a = 5In [6]: if a &lt; 0: ...: print ('less 0') ...: elif a &lt; 3: ...: print ('less 3') ...: elif a &lt; 5: ...: print ('less 5') ...: elif a &lt; 7: ...: print ('less 7') ...: else: ...: print ('oops') ...: less 7# 分支结构永远只有一个分支可执行； 循环有while for 两种语句 123456789101112131415161718192021222324252627while cond: block In [8]: while a &lt; 10: ...: print(a) ...: a +=1 # a = a + 1 ...: 0123456789# 通常在while循环中，循环体只需要修改条件，以使得条件为假In [34]: i = 1 In [35]: s =0In [36]: while i &lt;= 100: ...: s +=i ...: i +=1 ...: print (s) ...: 1234567891011121314151617181920212223242526272829303132333435363738394041424344for element in itrator: blockIn [26]: for i in range(5): ...: print (i) ...: 01234In [38]: for i in range(10): ...: if i % 2 == 0: ...: print (i) ...: 02468In [1]: for i in range(10): ...: if i &gt; 3: ...: break ...: print (i) ...: 0123# break 用于提前结束循环；In [3]: for i in range(10): ...: if i == 3: ...: continue ...: print (i) ...: 012456789# continue 用于跳过之后的语句]]></content>
  </entry>
  <entry>
    <title><![CDATA[自习之python环境初准备]]></title>
    <url>%2F2018%2F01%2F07%2F%E8%87%AA%E4%B9%A0%E4%B9%8Bpython%E7%8E%AF%E5%A2%83%E5%88%9D%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[环境准备pyenv 安装Python解释器 管理Python版本 管理Python虚拟环境相当于一个独立的版本,是bash写的一个程序，所以没有依赖； pyenv github地址 1https://github.com/yyuu/pyenv-installer 苹果系统安装pyenv 123456# curl -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash# sudo vim /etc/bashrcexport PATH="/Users/ssjinyao/.pyenv/bin:$PATH"eval "$(pyenv init -)"eval "$(pyenv virtualenv-init -)"# source /etc/bashrc linux系统安装pyenv 12345# curl -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash# vim /etc/profile.d/pyenv.shexport PATH="/Users/ssjinyao/.pyenv/bin:$PATH"eval "$(pyenv init -)"eval "$(pyenv virtualenv-init -)" 安装一个python的依赖（CentOS） 12# yum -y install. gcc make patch gdbm-devel openssl-devel sqlite-devel zlib-devel bzip2-devel readline-devel# 注：在不同的linux系统上安装包的名字不一样 pyenv安装一个python版本 12# pyenv update #用来更新pyenv# pyenv install 3.5.2 切换python 3.5.3 12345bogon:~ ssjinyao$ pyenv local 3.5.2bogon:~ ssjinyao$ pyenv version3.5.2 (set by /Users/ssjinyao/.python-version)bogon:~ ssjinyao$ cat .python-version 3.5.2 切换python到系统版本 123bogon:~ ssjinyao$ pyenv local systembogon:~ ssjinyao$ pyenv versionsystem (set by /Users/ssjinyao/.python-version) 切换全局python变量（希望永远不要执行） 1# pyenv global x.x.x 使用pyenv local 命令local 命令切换当前目录及其子目录的Python版本如何恢复，可以通过删除 ‘.python-version’恢复默认的Python版本 global 命令global命令切换全局默认python版本 12345678910111213141516171819202122232425262728293031323334353637bogon:~ ssjinyao$ pyenv commands--versionactivatecommandscompletionsdeactivatedoctorexecglobalhelphooksinitinstallinstallerlocaloffline-installerprefixrehashrootshellshimsuninstallupdateversionversion-fileversion-file-readversion-file-writeversion-nameversion-originversionsvirtualenvvirtualenv-deletevirtualenv-initvirtualenv-prefixvirtualenvswhencewhich 123456789101112bogon:~ ssjinyao$ pyenv virtualenv 3.5.2 mageduIgnoring indexes: https://pypi.python.org/simpleRequirement already satisfied (use --upgrade to upgrade): setuptools in /Users/ssjinyao/.pyenv/versions/3.5.2/envs/magedu/lib/python3.5/site-packagesRequirement already satisfied (use --upgrade to upgrade): pip in /Users/ssjinyao/.pyenv/versions/3.5.2/envs/magedu/lib/python3.5/site-packages bogon:~ ssjinyao$ pyenv local 3.5.2/envs/magedu (3.5.2/envs/magedu) bogon:~ ssjinyao$ (3.5.2/envs/magedu) bogon:~ ssjinyao$ pyenv local 3.5.2bogon:~ ssjinyao$ bogon:~ ssjinyao$ ls -l ~/.pyenv/versions/ total 8drwxr-xr-x 7 ssjinyao staff 238 11 19 10:30 3.5.2lrwxr-xr-x 1 ssjinyao staff 49 11 19 10:35 magedu -&gt; /Users/ssjinyao/.pyenv/versions/3.5.2/envs/magedu 12345678910bogon:~ ssjinyao$ pyenv versions system* 3.5.2 (set by /Users/ssjinyao/.python-version) 3.5.2/envs/magedu magedubogon:~ ssjinyao$ pyenv uninstall magedupyenv-virtualenv: remove /Users/ssjinyao/.pyenv/versions/3.5.2/envs/magedu? ybogon:~ ssjinyao$ pyenv versions system* 3.5.2 (set by /Users/ssjinyao/.python-version) virtualenv 命令创建虚拟环境 pyenv virtualenv $bash_version $name uninstall 命令卸载某个版本，包括虚拟环境； 选择python版本时，可以这样选择12bogon:~ ssjinyao$ ls ~/.pyenv/versions/3.5.2/envs/magedu/bin/python/Users/ssjinyao/.pyenv/versions/3.5.2/envs/magedu/bin/python vim python插件（jedi）vim python插件包 （maximum-awesome）%]]></content>
  </entry>
  <entry>
    <title><![CDATA[自习之 Linux HA Cluster 2]]></title>
    <url>%2F2018%2F01%2F03%2FLinux-HA-Cluster-2%2F</url>
    <content type="text"><![CDATA[温故而知新123456789101112131415161718192021222324252627282930313233Messaaging Layer: heartbaet v1,v2,v3 corosync v1, v2(votequorum) OpenAISCRM: pacemaker 需要一个配置接口 配置接口:crmsh (由SUSE研发的),由pssh管理工具来实现 pcs (agent c/s ),pcsd来实现 conga(ricci运行在各结点上的进程/luci发送指令到各节点)组成 group,constraint(基于约束) rgmanager(cman) resouce group(资源组): failover domainRA: LSB: /etc/rc.d/init.d systemd: /etc/systemd/system/multi-user.wants 服务开机处于enable状态; OCF:[provider] heartbeat pacemaker linbit 基于内核跨节点的块设备 service stonith 高可用集群的可用方案: heartbeat v1 heartbeat v2 heartbeat v3 + pacemaker X corosync + pacemaker cman + rgmanager corosync + cman + pacemaker keepalived Linux-HA-Cluster 2 Heartbeat集群之间传递心跳的方法1、使用串型线缆2、使用以太网通信3、Unicast 单播，使用udpu，一般在不支持多播的网络中使用的4、Mutlicast 多播/组播, 使用udp5、Broadcast 广播，占用过高的网络资源 1、组播地址: 1234用于标识一个IP组播域:IANA把D类地址留给组播使用:224.0.0.0-239.255.255.255 永久组播地址:224.0.0.0-224.0.0.255临时组播地址:224.0.1.0-238.255.255.255 建议使用临时组播地址本地组播地址:239.0.0.0-239.255.255.255 2、配置以组播方式进行高可用集群通信 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# 在Node1 和 Node2中执行# yum -y install corosync pacemaker# rpm -ql corosync #查看corosync安装完之后所生成的配置文件;/etc/corosync/etc/corosync/corosync.conf.example/etc/corosync/corosync.conf.example.udpu/etc/corosync/corosync.xml.example/etc/corosync/uidgid.d/etc/dbus-1/system.d/corosync-signals.conf/etc/logrotate.d/corosync/etc/sysconfig/corosync/etc/sysconfig/corosync-notifyd/usr/bin/corosync-blackbox/usr/bin/corosync-xmlproc/usr/lib/systemd/system/corosync-notifyd.service/usr/lib/systemd/system/corosync.service/usr/sbin/corosync/usr/sbin/corosync-cfgtool/usr/sbin/corosync-cmapctl/usr/sbin/corosync-cpgtool/usr/sbin/corosync-keygen/usr/sbin/corosync-notifyd/usr/sbin/corosync-quorumtool/usr/share/corosync/usr/share/corosync/corosync/usr/share/corosync/corosync-notifyd/usr/share/corosync/xml2conf.xsl/usr/share/doc/corosync-2.4.0/usr/share/doc/corosync-2.4.0/LICENSE/usr/share/doc/corosync-2.4.0/SECURITY/usr/share/man/man5/corosync.conf.5.gz/usr/share/man/man5/corosync.xml.5.gz/usr/share/man/man5/votequorum.5.gz/usr/share/man/man8/cmap_keys.8.gz/usr/share/man/man8/corosync-blackbox.8.gz/usr/share/man/man8/corosync-cfgtool.8.gz/usr/share/man/man8/corosync-cmapctl.8.gz/usr/share/man/man8/corosync-cpgtool.8.gz/usr/share/man/man8/corosync-keygen.8.gz/usr/share/man/man8/corosync-notifyd.8.gz/usr/share/man/man8/corosync-quorumtool.8.gz/usr/share/man/man8/corosync-xmlproc.8.gz/usr/share/man/man8/corosync.8.gz/usr/share/man/man8/corosync_overview.8.gz/usr/share/snmp/mibs/COROSYNC-MIB.txt/var/lib/corosync/var/log/cluster# rpm -ql pacemaker #查看pacemaker所生成的配置文件;/etc/sysconfig/pacemaker/usr/lib/ocf/resource.d/.isolation/usr/lib/ocf/resource.d/.isolation/docker-wrapper/usr/lib/ocf/resource.d/pacemaker/controld/usr/lib/ocf/resource.d/pacemaker/remote/usr/lib/systemd/system/pacemaker.service/usr/libexec/pacemaker/attrd/usr/libexec/pacemaker/cib/usr/libexec/pacemaker/cibmon/usr/libexec/pacemaker/crmd/usr/libexec/pacemaker/lrmd/usr/libexec/pacemaker/lrmd_internal_ctl/usr/libexec/pacemaker/pengine/usr/libexec/pacemaker/stonith-test/usr/libexec/pacemaker/stonithd/usr/sbin/crm_attribute/usr/sbin/crm_master/usr/sbin/crm_node/usr/sbin/pacemakerd/usr/sbin/stonith_admin/usr/share/doc/pacemaker-1.1.16/usr/share/doc/pacemaker-1.1.16/COPYING/usr/share/doc/pacemaker-1.1.16/ChangeLog/usr/share/licenses/pacemaker-1.1.16/usr/share/licenses/pacemaker-1.1.16/GPLv2/usr/share/man/man7/crmd.7.gz/usr/share/man/man7/ocf_pacemaker_controld.7.gz/usr/share/man/man7/ocf_pacemaker_remote.7.gz/usr/share/man/man7/pengine.7.gz/usr/share/man/man7/stonithd.7.gz/usr/share/man/man8/crm_attribute.8.gz/usr/share/man/man8/crm_master.8.gz/usr/share/man/man8/crm_node.8.gz/usr/share/man/man8/pacemakerd.8.gz/usr/share/man/man8/stonith_admin.8.gz/usr/share/pacemaker/alerts/usr/share/pacemaker/alerts/alert_file.sh.sample/usr/share/pacemaker/alerts/alert_smtp.sh.sample/usr/share/pacemaker/alerts/alert_snmp.sh.sample/var/lib/pacemaker/cib/var/lib/pacemaker/pengine 2、配置corosync 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152# cd /etc/corosync/# cp corosync.conf.example # cp corosync.conf.example corosync.conf# 某些环境中可能不支持组播。这时应该配置Corosync使用单播; # 下面是使用单播的Corosync 配置文件的一部分;totem &#123; #... interface &#123; ringnumber: 0 bindnetaddr: 10.180.22.0 broadcast: yes (1) mcastport: 5405 &#125; interface &#123; ringnumber: 1 bindnetaddr: 10.180.22.0 brodcast: yes mcastport: 5405 &#125; transport: udpu (2)&#125;nodelist&#123; (3) node &#123; ring0_addr: 10.180.22.166 ring1_addr:10.180.55.1 nodedid: 1 &#125; node &#123; ring0_addr: 10.180.22.167 ring1_addr: 10.180.55.2 nodeid: 2 &#125;# 如果将 broadcast 设置为yes,集群心跳将通过广播实现。设置该参数时,不能设置mcastaddr;# transport 配置项决定集群通信方式，要完全禁用组播，应该配置单播传输参数 udpu;# 这要求将所有的节点服务器信息写入nodelist;# 也就是需要在配置HA 集群之前确定节点组成。默认配置是udp。 通信方式类型还支持udpu和iba;# 在nodelist 之下可以为栽一节点设置只与该节点相关的信息，这些设置项只能包含在node之中;# 即只能对属于集群的节点服务器进行设置，而且只应包括那些与默认设置不同的参数;# 每台服务器都必需配置 ring0_addr; # 实验中配置信息如下# Please read the corosync.conf.5 manual pagetotem &#123; version: 2 # crypto_cipher and crypto_hash: Used for mutual node authentication. # If you choose to enable this, then do remember to create a shared # secret with "corosync-keygen". # enabling crypto_cipher, requires also enabling of crypto_hash. crypto_cipher: aes128 crypto_hash: sha1 secauth: on # interface: define at least one interface to communicate # over. If you define more than one interface stanza, you must # also set rrp_mode. interface &#123; # Rings must be consecutively numbered, starting at 0. ringnumber: 0 # This is normally the *network* address of the # interface to bind to. This ensures that you can use # identical instances of this configuration file # across all your cluster nodes, without having to # modify this option. bindnetaddr: 10.180.0.0 # However, if you have multiple physical network # interfaces configured for the same subnet, then the # network address alone is not sufficient to identify # the interface Corosync should bind to. In that case, # configure the *host* address of the interface # instead: # bindnetaddr: 192.168.1.1 # When selecting a multicast address, consider RFC # 2365 (which, among other things, specifies that # 239.255.x.x addresses are left to the discretion of # the network administrator). Do not reuse multicast # addresses across multiple Corosync clusters sharing # the same network. mcastaddr: 239.185.1.31 # Corosync uses the port you specify here for UDP # messaging, and also the immediately preceding # port. Thus if you set this to 5405, Corosync sends # messages over UDP ports 5405 and 5404. mcastport: 5405 # Time-to-live for cluster communication packets. The # number of hops (routers) that this ring will allow # itself to pass. Note that multicast routing must be # specifically enabled on most network routers. ttl: 1 &#125;&#125;nodelist&#123; node &#123; ring0_addr: 10.180.22.166 nodedid: 1 &#125; node &#123; ring0_addr: 10.180.22.167 nodeid: 2 &#125; node &#123; ring0_addr: 10.180.22.168 nodeid: 3 &#125; &#125;logging &#123; # Log the source file and line where messages are being # generated. When in doubt, leave off. Potentially useful for # debugging. fileline: off # Log to standard error. When in doubt, set to no. Useful when # running in the foreground (when invoking "corosync -f") to_stderr: no # Log to a log file. When set to "no", the "logfile" option # must not be set. to_logfile: yes logfile: /var/log/cluster/corosync.log # Log to the system log daemon. When in doubt, set to yes. to_syslog: no # Log debug messages (very verbose). When in doubt, leave off. debug: off # Log messages with time stamps. When in doubt, set to on # (unless you are only logging to syslog, where double # timestamps can be annoying). timestamp: on logger_subsys &#123; subsys: QUORUM debug: off &#125;&#125;quorum &#123; # Enable and configure quorum subsystem (default: off) # see also corosync.conf.5 and votequorum.5 provider: corosync_votequorum&#125;# 生成密钥文件 # corosync-keygen# scp -p authkey coronsync.conf root@node2.ssjinyao.com:/etc/corosync# corosync 启动集群投票系统默认必需需要三人结点;# systemctl start corosync.serivce #这个时候启动是失败的;# systemctl status corosync.serivce #查看corosync的状态信息;# 此时需要开启另一个结点# yum -y install corosync pacemaker # Node1 中执行# scp -p /etc/coronsync.conf /etc/authkey root@node2.ssjinyao.com:/etc/corosync 3、验证结点 123# corosync-cfgtool -s # 验证结点# corosync-cmapctl #查看结点间的信息;# grep -v &apos;^[[:space:]]*#&apos; /etc/corosync.conf # 保存实用的配置示例 4、编辑pacemaker 12345# vim /etc/sysconfig/pacemakerPCMK_logfile= /var/log/pacemaker.log# 各个节点间需要启动pacemaker# systemctl start pacemaker.service# crm_mon # 进行验证 5、 crm 工具的使用简明 12345# crm_node -n # 查看当前节点信息# crm_node -l # 例出集群所有的节点信息# crm_verify -L -V # 但看报错信息# crm shell 的安装与使用，若无rpm包，可在网上找相关的rpm包# yum -y install crmsh pssh python-pssh HA Web Service1234567 vip: 10.180.xx.xxx, ocf:hearbeat:IPaddr httpd: systemd nfs shared storage: ocf:heartbeat:FilesystemHa Cluster 工作模型: A/P: 两节点集群; active/apsslve; without-quorum-policy=(stop|ignore|suicide|freeze) A/A: 12345678# node0 # mkdir -pv /www/htdocs # echo &quot;&lt;h1&gt; Test Page on NFS Server&lt;/h1&gt;&quot; &gt; /www/htdocs/index.html# vim /etc/exports /www/htdocs 10.180.xx.xxx/16(rw)# iptables -L -n # 查看是否有防火墙规则# checkconfig nfs on # systemctl start nfs 123456# node 1 # showmount -e 10.180.xx.xxx# mount -t nfs 10.180.xx.xxx:/www/htdocs /var/www/html # 挂载网络存储NFS # systemctl start httpd # systemctl enable httpd# 此时便可以查看能否可以能否访问到以上的测试信息 123# node 2 # systemctl start httpd # systemctl enabl httpd 123456789101112131415161718192021222324252627282930313233# crm configure crm(live)configure# showcrm(live)# configure property crm(live)# configure property stonith-enabled=falsecrm(live)# configrue verify crm(live)# show crm(live)# configure commitcrm(live)# configure crm(live)configure# primitive webip ocf:heartbeat:IPaddr2 params ip=&quot;10.180.xx.xxx&quot; op monitor interval=30s timeout=20scrm(live)# configure show crm(live)# configure commitcrm(live)# configure edit # 可以打开vim编辑配置文件 crm(live)# configure verifycrm(live)# configure primitive webstore ocf:heartbat:Filesystem params device=&quot;10.180.xx.xxx:/www/htdocs&quot; directory=&quot;/var/www/html&quot; fstype=&quot;nfs&quot; op start timeout=60s op stop timeout=60s op monitor interval=20s timeout=40s crm(live)# configure verifycrm(live)configure# colocation webserver_with_webstore_and_webip inf: webserver ( webip webstore )crm(live)# show xmls # 查看xml格式的配置crm(live)configure# order webstore_afer_webip Mandatory: webip webstorecrm(live)configure# order webserver_after_webstore Manadatory: webstore webserver crm(live)configure# verify crm(live)configure# commit crm(live)configure# location webservice_perf_node1 webip 100: node1.ssjinao.comcrm(live)configure# verify crm(live)configure# commitcrom(live)configure# property default-resource-sticklines = 50# systemctl stop httpd.service # systemctl enable httpd.service # crm_verify -V -L# crm node standby # crm onde online]]></content>
  </entry>
  <entry>
    <title><![CDATA[自习之Linux HA Cluster]]></title>
    <url>%2F2018%2F01%2F01%2FLinux-HA-Cluster%2F</url>
    <content type="text"><![CDATA[Linux HA Cluster一、理论介绍 LB,HA,HP,hadoop 1、LB（负载均衡）: 传输层:lvs应用层:nginx,haproxy,httpd,perlbal,ats,varnish 2、HA(高可用）: vrrp: keepalivedHA Cluster: heartbeat,OpenAIS corosync/pacemaker,cman,RHCS（红帽集群套件）corosync/pacemaker,cman 是从 OpenAIS中独立出来的 3、HA: 123456789故障场景: 硬件故障:设计缺陷，使用过久自然损坏，人为故障 软件故障:设计缺陷，bug,人为误操作 A(可用性)=MTBF[平均无故障时间]/(MTBF[平均无故障时间]+MTTR[平均修复时间]) MTBF:Mean Time Between FailreMTTR:Mean Time To Repair 可用性区间:0&lt;A&lt;1 百分比:90%,95%,99% 通常会用几个9来衡量可用性 12345提供冗余: Messaging Layer (同可用结构间的信息传递层) Resource Manager (在Messaging Layer之上，管理多个资源) Local Resource Manager (在Resource Messaging Layer之上，决定在哪个结点上启动服务) local Resource agent: 四种基本功能(start,stop,restart,status) 12345network partition: 发生了网络分区 隔离： STONITH: shoot the other node on the head (节点级别的隔离) Fence:资源级别的隔离 通过交换机断掉网络，或者通过电源交换机，把服务器的电源停丢 1234集群节点必须大于半数，而非等于 或者加一个仲裁设备 高可用节点，只能有一个节点是工作的状态 但可以在多个节点上，配置出来多个服务，N-M模型 123456failover domain: 故障转移域 fda: node1,node5 fdb: node2,node5 fdc: node3,node5 fdd: node4,node5 1234资源的约束性: 位置约束，资源对节点的倾向性; 排列约束，资源彼此间是否能运行于同一节点的倾向性； 顺序约束，多个资源启动顺序依赖关系； 123456789vote system: 少数服从多数:quorum with quorum:拥有法定票数，( &gt; total/2 ) without quorum:不拥有法定票数 两个节点(偶数个节点): Ping node qdisk failover (资源将要转移出去) failback (资源将要转移回来) 4、Messaging Layer: 12345heartbeat, v1 v2 v3corosync,cman 5、Cluster Resource Manager (CRM): 1234heartbeat v1 haresources (配置接口:配置文件[haresources])heartbeat v2 crm（在每个节点运行一个crmd守护进程（5560/tcp），有命令行接口[crmsh],很大程度上需要编辑xml的配置文件）; GUI;hb_guiheartbeat v3 pacemaker (心跳启读器) （配置接口:crmsh,pcs;GUI: hawk(suse),LCMC,pacemaker-gui)rgmanager （配置文件:cluster.conf,system-config-cluster,conga（webgui）, cman_tool, clustat,） 6、组合方式: 12345678910111213141516heartbeat v1 (haresources)heartbeat v2 (crm)heartbeat v3 + pacemaker heartbeat + pacemakercorosync + pacemaker corosync v1 + pacemaker (plugin) corosync v2 + pacemaker (standalone service)cman + rgmanger CentOS 6 cman + pacemaker CentOS 6 (corosync v1 + cman +pacemaker) RHCS: Red Hat Cluster Suite RHEL5: cman + rgmanager + conga (ricci/luci) RHEL6: cman + rgmanager + conga (ricci/luci) corosync + pacemaker corosync + cman + pacemaker RHEL7: corosync + pacemaker 7、资源代理: 1234567Resource Agent: hearteat legacy: /etc/ha.d/haresources.d/目录下的脚本； LSB: /etc/rc.d/init.d/ 目录下的脚本； OCF: Open Cluster Framework; provider: STONITH设备: Systemctl: 8、资源类型: 12345678910111213141516171819202122232425primitive: 主资源，原始资源:在集群中只能运行一个实例;clone:克隆资源，在集群中可以运行多个实例: 匿名克隆，全局惟一克隆、状态克隆(主动、被动)multi-state(master/slave);克隆资源的特殊实现;多状态资源:group: 组资源: 启动或停止: 资源监视; 相关性;资源属性: priority:优先级; target-role:started,stopped,master 目标角色; is-managed:是否允许群集管理此资源; resource-stickiness: 资源粘性; allow-migrate:是否允许资源迁移;约束:score 位置约束:资源对节点的倾向性； (-oo,+oo) 任何值+无穷大=无穷大 任何值+负无穷大=负无穷大 无穷大+负无穷大=负无穷大 排列约束:资源彼此间是否能运行同一节点的倾向性; (-oo,+oo) 顺序的约束:多个资源启动顺序依赖关系; (-oo,+oo) Mandatory 二、安装配置1、 CentOS 7: corosync v2 + pacemaker corosync v2: vote system pacemaker:独立服务 集群的全生命周期管理工具: pcs: agent(pcsd) crmsh : agentless (pssh) 1# yum info pcs 2、集群配置前提 1234a、时间同步;b、基于当前正在使用的主机名互相访问; c、是否会用到仲裁设备; e、双机互信 3.1安装并启动pcsd 123456789101112# vim /etc/hosts xx.xxx.xx.xxx node1.ssjinyao.comxx.xxx.xx.xxx node2.ssjinyao.com# scp /etc/hosts root@node2.ssjinyao.com:/etc/# date ; ssh root@node2.ssjinyao.com 'date' #查看两个节点服务器时间是否一致# ntpdate date.xxx.com #若服务器时间不同步，则同步服务器的时间Node1 AND Node2# yum install -y pacemaker pcs psmisc policycoreutils-python# 也可以 yum insetall -y pcs # systemctl start pcsd.service # systemctl enable pcsd.service 3.2 各节点统一执行 1234# vim /etc/ansible[ha]node1.ssjinyao.comnode2.ssjinyao.com 1234Node1 AND Node2# ansible ha -m service -a "name=pcsd state=started enabled=yes"# systemctl status pcsd # ansible ha -m shell -a 'echo "xxxxxx" | passwd --stdin hacluster' 1234567891011121314151617# pcs help # pcs cluster --help # pcs cluster auth node1.ssjinyao.com node2.ssjinyao.com -u hacluster # pcs认证通过# pcs cluster setup --name jycluster node1.ssjinyao.com node2.ssjinyao.com# cd /etc/corosync/# cat corosync.conf # 注 totem是专门传递集群间的心跳信息; nodelist 集群中目前存的节点; quorum 法定票数的投票机制; corosync_votequorum; # cd /etc/corosync/ &amp;&amp; cat corosync.conf.example.udpu # 醒看集群配置实例; # vim corosync.conf 修改 logginlogging &#123;to_logfile:yes logfile: /var/log/cluster/corosync.log &#125;# scp corosync.conf node2.ssjinyao.com:/etc/corosync/ 3.3 启动集群 12345678910111213141516171819202122Node1 Or Node2 # pcs cluster start --all # corosync-cfgtool --help 检查各节点通信状态(显示为no faults即为OK):# corosync-cfgtool -s Printing ring status.Local node ID 1 RING ID 0 id = xx.xxx.xx.xxx status = ring 0 active with no faults s同时也可以在node2.ssjinyao.com上查看节点状态 检查集群成员关及Quorum API:# corosync-cmapctl | grep members # pcs staus corosync # pcs staus 查看pcs资源可配置选项有哪些# pcs property list --all查看pcs配置是否存在问题# crm_verify -L -V # pcs property se stonith-enabled=false # pcs property list # crm_verify -L -V 3.4 crmsh 下载并安装 123456# wget crmsh-2.1.4.x86_64.rpm # wget pssh-2.3.1-4.2.x86_64.rpm# wget python-pssh-2.3.1-4.2.x86_64.rpm# yum install -y *rpm 注 crmsh 找一个结点安装就可以，当然两个节点可以都安装 pssh 是并行执行ssh命令 12345678# crm help # crm status # crm 可以直接进入交互式接口 # help start &gt;crm(live)node# configure &gt;crm(live)configure# help &gt;crm(live)configure# show&gt;crm(live)configure# edit 3.5 利用crmsh配置一个web serice: vip:10.180.xxx.xx httpd 123456789101112Node1 AND Node2# yum -y install httpd Node1# echo "&lt;h1&gt;node1.ssjinyao.com&lt;/h1&gt;" &gt; /var/www/html/index.html# systemctl enabled httpd 注:对于CentOS 6 来说必需要禁用 # systemctl stop httpd Node2 # echo "&lt;h1&gt;nodd2.ssjinyao.com&lt;/h1&gt;" &gt; /var/www/html/index.html# systemctl enabled httpd # systemctl stop httpd 测试服务器可以访问后，再将httpd服务停止 12345678910111213141516171819202122232425# crm 或者 # crm ra &gt;crm(live)# ra&gt;crm(live)ra# list systemd&gt;crm(live)ra# list ocf heartbeat &gt;crm(live)ra# info ocf:heartbeat:IPaddr &gt;crm(live)ra# info ocf:heartbeat:IPaddr &gt;crm(live)ra# cd ..&gt;crm(live)# configure &gt;crm(live)configure# primitive webip ocf:heartbeat:IPaddr params ip=10.xxx.xx.xxx&gt;crm(live)# status # ifconfig 可以看到资源已经配置好了 把当前结点变成备用模式&gt;crm(live)node# standby # 软下线&gt;crm(live)node# status&gt;crm(live)# node only&gt;crm(live)# configure &gt;crm(live)configure # primitive webserver systemd:httpd&gt;crm(live)configure # verify&gt;crm(live)configure # commit &gt;crm(live)configure # group&gt;crm(live)configure # grouop webservice webip webserivce &gt;crm(live)configure # verfy&gt;crm(live)configure # commit # crm node standby 注:可以查看web请求的反回内容，与资源定义情况; 12345678910# crm node onlie # crm &gt;crm(live) # configure&gt;crm(live)configure # verify# crm status # systemctl stop pacemaker.service corosync.serivce # crm status 在CentOS 6的情况下，假如将服务器直接关机后，会造成 partition with quorum # crm configure &gt;crm(live)configure # property no-quorum-policy=ignore]]></content>
  </entry>
  <entry>
    <title><![CDATA[python自动化之admin自动切换root]]></title>
    <url>%2F2017%2F12%2F07%2Fpython%E8%87%AA%E5%8A%A8%E5%8C%96%E4%B9%8Badmin%E8%87%AA%E5%8A%A8%E5%88%87%E6%8D%A2root%2F</url>
    <content type="text"><![CDATA[python自动化之admin自动切换root ssh登录系统，如果是非root帐号(普通帐号)登录采取行动，则su切换到root 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#!/usr/env/bin python# -*- coding:utf-8 -*-# des:ssh登录系统，如果是非root帐号(普通帐号)登录采取行动，则su切换到root# python 的SSHV2 protocol协议实现，用于python调用各种ssh功能;import paramiko # python内置时间模块import time #根据用户名密码从普通用户揽权到root用记执行给定命令def ssh_su_root(ip,username,password,root_pwd,cmd):#建立SSHClient对象 myssh = paramiko.SSHClient()#设置自动接收公钥 myssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) try:#使用给定用户名密码尝试连接服务器 myssh.connect(ip, 22, username=username, password=password, timeout=4) except Exception, ex: print str(ex) return # 如果默认root不允许远程登录，提供的是普通用户帐号+root帐号, #则调用invoke_shell,使用交互式shell方式切换同到root帐号，并执行命令。 if username != 'root': print "I am NOT root" ssh = myssh.invoke_shell() time.sleep(0.2) ssh.send('su -\n') buff = '' #循环检测密码输入提示，出现后发送root口令， while not (buff.endswith('Password:') or buff.endswith('密码: ')): #从接收缓存中读入最多9999bytes数据。 resp = ssh.recv(9999) buff += resp ssh.send(root_pwd) ssh.send('\n') buff = '' #循环检测#提示符，出现后执行传入的命令。 while not buff.endwith('# '): resp = ssh.recv(9999) buff += resp ssh.send[cmd] ssh.send('\n') buff ='' #循环检测#提示符，意味着命令执行完成，出现后关闭ssh连接并输出结果。 while not buff.endswith('# '): resp = ssh.recv(9999) buff += resp myssh.close() result = buff print "su root result ---&gt;",result myssh.close() else: #如果提供的是root帐号，则直接调用paramiko exec_command 方法，执行命令。 print "I am root" stdin, stdout, stderr = myssh.exec_command(cmd) stdin,write("Y") print "stdout.readlines() ---&gt;", stdout.readlines() myssh.close()if __name__ == "__main__": cmd = 'date' ip = 'xx.xxx.xx.xxx' username = 'admin' password = 'xxxxxxxxxx' ssh_su_root(ip, username, password, 'xxxxxxxxxxxx', cmd) username = 'root' ssh_su_root(ip, username, password, 'xxxxxxxxxxxx', cmd)]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全加固]]></title>
    <url>%2F2017%2F12%2F03%2F%E5%AE%89%E5%85%A8%E5%8A%A0%E5%9B%BA%2F</url>
    <content type="text"><![CDATA[安全加固安全加固脚本V1 用来做iptables ssh地址白名单限制 openssh-server ssh用户白名单限制 更改登录欢迎信息为警告信息 应用根目录权限最小化 zabbix agent安装配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#!/bin/bash#定义一个函数，程序由前往后执行，次顺序非常重要，一不小心会将自己拒在外面，遇到这种情况让规则失效的处理方式是重启服器，或者从阿里云接接口接入清空规则，可选后者；#注zabbix(xxx.xx.xxx.xx)\xx.xx.xx.xxx主机不加入iptables规则 IP_TABLES () &#123; /sbin/iptables -A INPUT -p tcp --dport 22 -s xxx.xxx.xx.xx -j ACCEPT #首先放行 xxx.xxx.xxx.xxx 我们内网路由地址 /sbin/iptables -A INPUT -p tcp --dport 22 -s xxx.xxx.xx.xx -j ACCEPT #放行备用地址 xxx.xxx.xx.xxx 同时也是我们的zabbix地址 /sbin/iptables -A INPUT -p tcp --dport 22 -s xxx.xxx.xx.xx -j ACCEPT #此服务器为我们闲置的一台服务器 /sbin/iptables -A INPUT -p tcp --dport 22 -j DROP #丢弃所有对22号端口的请求 iptables -vnL #查看防火墙设置&#125;#添加唯一可以登录服务器的用户SSH_INIT () &#123; useradd xxxxxxxx #添加用户 cp -a /etc/skel /home/xxxxxxxx chown -R xxxxxxxx.xxxxxxxx /home/TransferEasyd0--01 usermod -s /bin/bash xxxxxxxx PASS='xxxxxxxxxx' echo "xxxxxxxx:$PASS" | chpasswd #给用户设置密码 echo "AllowUsers xxxxxxxx" &gt;&gt; /etc/ssh/sshd_config #添加白名单到sshd_config中 service ssh restart #重启服务器&#125;#Web根目录权限最小化PY_INIT () &#123;chmod 700 /home/admin/&#125;WEB_INIT () &#123; chown www-data.www-data /var/www/html &amp;&amp; chmod 700 /var/www/html #设置启动用户和用启动组都为www-data用户，设置所有者权限读\写\执行; 所属组0; 其它人0; usermod -s /sbin/nologin www-data #完全禁止www-data用户登录 cat /etc/passwd | grep --color www-data #查看修改登录 ls -ld /var/www/html #查看修改权限&#125;#更改欢迎信息为警告信息MO_TD () &#123; [ -e /etc/.motd.bak ] || cp /etc/motd /etc/.motd.bak cat &lt;&lt;EOF &gt; /etc/motd非xxxxxxxx管理人员请勿登录系统，否则后果自负非xxxxxxxx管理人员请勿登录系统，否则后果自负Non xxxxxxxx administrators are not allowed to log on to the system, otherwise they may be affectedEOF [ -e /etc/update-motd.d/.00-header.bak ] || cp /etc/update-motd.d/00-header /etc/update-motd.d/.00-header.bakcat &lt;&lt;EOF &gt; /etc/update-motd.d/00-header#!/bin/sh[ -r /etc/lsb-release ] &amp;&amp; . /etc/lsb-releaseif [ -z "$DISTRIB_DESCRIPTION" ] &amp;&amp; [ -x /usr/bin/lsb_release ]; then# Fall back to using the very slow lsb_release utilityDISTRIB_DESCRIPTION=$(lsb_release -s -d)fiprintf "xxxxxxxx %s (%s %s %s)\n" "$DISTRIB_DESCRIPTION" "$(uname -o)" "$(uname -r)" "$(uname -m)"EOF [ -e /etc/.lsb-release.bak ] || cp /etc/lsb-release /etc/.lsb-release.bakcat &lt;&lt;EOF &gt; /etc/lsb-release DISTRIB_ID=CentOSDISTRIB_RELEASE=10000DISTRIB_CODENAME=trustyDISTRIB_DESCRIPTION="CentOS 1000"EOF&#125;ZAB_BBIX () &#123; apt-get install zabbix-agent mv /etc/zabbix/zabbix_agentd.conf /etc/zabbix/zabbix_agentd.conf.bak cp /home/admin/zabbix_agentd.conf /etc/zabbix/ cp /home/admin/zabbix_agentd.conf /tmp service zabbix-agent restart &#125;IP_TABLESSSH_INITPY_INITWEB_INITMO_TDZAB_BBIX 对应回滚脚本1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bash#安全加固后，服务器如有问题时的回滚方案；IP_TABLES_F () &#123; iptables -F&#125;SSH_INIT_F () &#123; sed -i 's/AllowUsers xxxxxxxx//g' /etc/ssh/sshd_config userdel xxxxxxxx service ssh restart&#125;WEB_INIT_F () &#123; chmod 700 /var/www/html chown admin.admin /var/www/html usermod -s /sbin/false www-data&#125;PY_INIT_F () &#123; chmod 700 /home/admin&#125;MO_TD_F() &#123; rm -rf /etc/motd mv /etc/.motd.bak /etc/motd rm -rf /etc/update-motd.d/00-header mv /etc/update-motd.d/.00-header.bak /etc/update-motd.d/00-header rm -rf /etc/lsb-release mv /etc/.lsb-release.bak /etc/lsb-release&#125;ZA_BBIX_F () &#123; service zabbix-agent stop apt-get remove zabbix-agent rm -rf /etc/zabbix/&#125;IP_TABLES_FSSH_INIT_FWEB_INIT_FMO_TD_FZA_BBIX_FPY_INIT_F 对无agent探针的RDS网络监控1234567891011121314151617181920212223242526#!/bin/bash#用户RDS通知及报警#作者：任锦#RDS_IP="localhost"RDS_IP="www.xxxxxxxx.com"TOOL_S () &#123; rpm -qa nc &amp;&gt; /dev/null || yum -y install nc&#125;ON_LINE () &#123; DATE=`date | awk '&#123;print $4&#125;' | cut -d":" -f3` echo -e "\n\n" |nc -w 5 $RDS_IP 3306 &amp;&gt; /dev/null || STATP="RDS 服务器已经停止了运行，请您尽快来处理 😰 😰 😰 😰 😰 😰 " #echo $STATP&#125;WEI_XIN () &#123;/bin/weixin --corpid=xxxxxxxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --msg="$STATP" --user=xxx@xxxxxxxxxxx.com --agentid=xxxxxx02 &amp;&gt; /dev/null /bin/weixin --corpid=xxxxxxxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --msg="$STATP" --user=xxx2@xxxxxxxxxxx.com --agentid=xxxxxx02 &amp;&gt; /dev/null /bin/weixin --corpid=xxxxxxxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --msg="$STATP" --user=xxx3@xxxxxxxxxxx.com --agentid=xxxxxx02 &amp;&gt; /dev/null /bin/weixin --corpid=xxxxxxxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --msg="$STATP" --user=xxx4@xxxxxxxxxxx.com --agentid=xxxxxx02 &amp;&gt; /dev/null while sleep 60 ; do TOOL_SON_LINEWEI_XIN done 除线上zabbix多角度的监控网络状态12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/bin/bashHOSTS () &#123; CN='xxx.xxx.xxx.xxx xxx.xxx.xx.xx.xxx xxx.xxx.xxx.xxx.xxx xxx.xxx.xxx.xxx' HK='xxx.xxx.xxx.xxx xxx.xxx.xx.xx.xxx xxx.xxx.xxx.xxx.xxx xxx.xxx.xxx.xxx' XN='xxx.xxx.xxx.xxx xxx.xxx.xx.xx.xxx xxx.xxx.xxx.xxx.xxx xxx.xxx.xxx.xxx'&#125;MESSAGES () &#123; OK_MESSAGES_CN='阿里云xx区域ECS主机网络正常' OK_MESSAGES_HK='阿里云xx区域ECS主机网络正常' OK_MESSAGES_XN='阿里云xx区域ECS主机网络正常' CN_MES='阿里云xx区域ECS主机网络不通！' HK_MES='阿里云xx区域ECS主机网络不通！' XN_MES='阿里云xx区域ECS主机网络不通！' CN_MES_TIME="阿里云xx区域ECS主机网络超时较高，超时时间及丢包率为" HK_MES_TIME="阿里云xx区域ECS主机网络超时较高，超时时间及丢包率为" XN_MES_TIME="阿里云xx区域ECS主机网络超时较高，超时时间及丢包率为"&#125;WEIXIN_E-MAIL_API () &#123;# echo "$1# $2" | mutt -s "Zabbix 报警" xxx@xxxxxxxxxxx.com xxx2.xxxxxxxxxxxx.com xxx3@xxxxxxxxxxx.com/bin/weixin --corpid=xxxxxxxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --msg="$1$2" --user=xxx@xxxxxxxxxxx.com --agentid=xxxxxx02 &amp;&gt; /dev/null /bin/weixin --corpid=xxxxxxxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --msg="$1$2" --user=xxx2@xxxxxxxxxxx.com --agentid=xxxxxx02 &amp;&gt; /dev/null /bin/weixin --corpid=xxxxxxxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --msg="$1$2" --user=xxx3@xxxxxxxxxxx.com --agentid=xxxxxx02 &amp;&gt; /dev/null /bin/weixin --corpid=xxxxxxxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --msg="$1$2" --user=xxx4@xxxxxxxxxxx.com --agentid=xxxxxx02 &amp;&gt; /dev/null &#125;HOSTSMESSAGESfor HOSTS_NET_CN in $CN do STATE_CN=`ping -c 2 -W 1 -S 1 $HOSTS_NET_CN | tail -n 2 | head -n 1 | awk &#123;'print $6'&#125;` TIME_CN=`ping -c 2 -W 1 -S 1 $HOSTS_NET_CN | head -n 3 | tail -n2 | awk &#123;'print $7,$8'&#125;` if ping -c 2 -W 1 -S 1 $HOSTS_NET_CN &amp;&gt; /dev/null ;then echo "$OK_MESSAGES_CN `date` $HOSTS_NET_CN OK" &amp;&gt;&gt; /tmp/$HOSTS_NET_CN else WEIXIN_E-MAIL_API "$CN_MES `date` $HOSTS_NET_CN $CN_MES_TIME $STATE_CN $TIME_CN" "PROBLEM" fi donefor HOSTS_NET_HK in $HK do STATE_HK=`ping -c 2 -W 1 -S 1 $HOSTS_NET_HK | tail -n 2 | head -n 1 | awk &#123;'print $6'&#125;` TIME_HK=`ping -c 2 -W 1 -S 1 $HOSTS_NET_HK | head -n 3 | tail -n2 | awk &#123;'print $7,$8'&#125;` if ping -c 2 -W 1 -S 1 $HOSTS_NET_HK &amp;&gt; /dev/null ; then echo "$OK_MESSAGES_HK `date` $HOSTS_NET_HK OK" &amp;&gt;&gt; /tmp/$HOSTS_NET_HK else WEIXIN_E-MAIL_API "$HK_MES `date` $HOSTS_NET_HK $HK_MES_TIME $STATE_HK $TIME_HK" "PROBLEM" fi donefor HOSTS_NET_XN in $XN do STATE_XN=`ping -c 2 -W 1 -S 1 $HOSTS_NET_XN | tail -n 2 | head -n 1 | awk &#123;'print $6'&#125;` TIME_XN=`ping -c 2 -W 1 -S 1 $HOSTS_NET_XN | head -n 3 | tail -n2 | awk &#123;'print $7,$8'&#125;` if ping -c 2 -W 1 -S 1 $HOSTS_NET_XN &amp;&gt; /dev/null ; then echo "$OK_MESSAGES_XN `date` $HOSTS_NET_XN OK" &amp;&gt;&gt; /tmp/$HOSTS_NET_XN else WEIXIN_E-MAIL_API "$XN_MES `date` $HOSTS_NET_XN $XN_MES_TIME $STATE_XN $TIME_XN" "PROBLEM" fi done 将对应的脚本加入定时计划12crontab -e*/3 * * * * /bin/bash /root/bin/ds.sh 关于/bin/weixin123链接:http://pan.baidu.com/s/1slcAlTb 密码:f3gzweixin接口的调用可以创建一个企业微信来配置一个接口mutt发短信，mutt+msmtp配置使用 删除mongo表中的某一字段1db.screening_sections.remove(&#123;'no':'5a279c19756a7'&#125;)]]></content>
      <tags>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab备份与迁移]]></title>
    <url>%2F2017%2F11%2F22%2Fgitlab%E5%A4%87%E4%BB%BD%E4%B8%8E%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[gitlab的备份与同步gitlab备份12# sudo gitlab-rake gitlab:backup:create# sudo scp -r /var/opt/gitlab/backups/ root@xx.xxx.xx.xxx:/root 由于版本问题，在迁移目标主机安装同样版本123# scp gitlab-ci-multi-runner_1.4.2_amd64.deb gitlab-ce_8.6.2-ce.0_amd64.deb root@xx.xxx.xx.xxx:/root# 若无此版本的备份包时选择以下方式下载链接:http://pan.baidu.com/s/1eS4H6NK 密码:e7i6 迁移目标主机安装与恢复12345678910# dpkg -i /root/gitlab-ci-multi-runner_1.4.2_amd64.deb# dpkg -i /root/gitlab-ce_8.6.2-ce.0_amd64.deb # mv /root/1510889754_gitlab_backup.tar /var/opt/gitlab/backups/# gitlab-rake gitlab:backup:restore BACKUP=1510889754# gitlab-ctl start# vim /etc/gitlab/gitlab.rb unicorn['listen'] = '0.0.0.0' unicorn['port'] = 8080# gitlab-ctl reconfigure# gitlab-ctl start 检查8080端口是否启动12# netstat -tnlup | grep 8080tcp 0 0 0.0.0.0:8080 0.0.0.0:* LISTEN 3290/config.ru 源主机利用bash脚本+定时任务自动备份与同步备份12# 数据同步，首要做的就是双机互信；# ssh-copy-id -i ~/.ssh/id_rsa.pub root@xx.xxx.xx.xxx 123456789101112131415161718192021222324#!/bin/bash#Can Bakup gitlab to xx.xxx.xx.xxxFileBack () &#123; [ -d /var/opt/gitlab/backups/.bak ] || mkdir /var/opt/gitlab/backups/.bak -p mv /var/opt/gitlab/backups/*tar /var/opt/gitlab/backups/.bak/ find /var/opt/gitlab/backups/.bak/ -type f -mtime +7 -exec rm -rf &#123;&#125; \; /usr/bin/gitlab-rake gitlab:backup:create &amp;&gt; /dev/null sleep 240 ssh root@xx.xxx.xx.xxx "[ -d /var/opt/gitlab/backups/.bak ] || mkdir /var/opt/gitlab/backups/.bak -p" ssh root@xx.xxx.xx.xxx "mv /var/opt/gitlab/backups/*tar /var/opt/gitlab/backups/.bak/" ssh root@xx.xxx.xx.xxx "find /var/opt/gitlab/backups/.bak/ -type f -mtime +7 -exec rm -rf &#123;&#125; \;" scp /var/opt/gitlab/backups/*tar root@xx.xxx.xx.xxx:/var/opt/gitlab/backups/&#125;Message () &#123; MESSAGE="gitlab 已备份成功 `ls -l /var/opt/gitlab/backups/` &amp;&amp; `ls -ld /var/opt/gitlab/backups/` gitlab当前主服务器xx.xxx.xx.xxx" MESSAGE_2=`ssh root@xx.xxx.xx.xxx "ls -l /var/opt/gitlab/backups/;ls -ld /var/opt/gitlab/backups/; ifconfig | sed -n '/inet addr/s/^[^:]*:\([0-9.]\&#123;7,15\&#125;\) .*/\1/p' | head -1"` /bin/weixin --corpid=xxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx. --msg="$MESSAGE gitlab当前从服务器$MESSAGE_2" --user=15822097176@139.com --agentid=100000x&#125;FileBack &amp;&amp; Message 12345678910111213141516171819202122#!/bin/bash#Can rolebak gitlabFILE_BAK () &#123;scp /var/opt/gitlab/backups/*tar root@xx.xxx.xx.xxx:/volume1/skill-operation/bakup/gitlab/ssh root@xx.xxx.xx.xxx "find /volume1/skill-operation/bakup/gitlab/ -type f -mtime +7 -exec rm -rf &#123;&#125; \;"&#125;GIT_ROLBAK () &#123;BAKID=`cd /var/opt/gitlab/backups/ &amp;&amp; ls | tr -dc "[:digit:]"`cd /var/opt/gitlab/backups/ &amp;&amp; chmod 666 */usr/bin/gitlab-rake gitlab:backup:restore BACKUP=$BAKID &lt;&lt;EOF &amp;&gt; /dev/nullyesyesEOF&#125;MESSAGE () &#123;/bin/weixin --corpid=xxxxxxxxxxxxx --corpsecret=xxxxxxxxxxxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx --msg="ID 为 $BAKID 的gitlab压缩包恢复完毕" --user=15822097176@139.com --agentid=100000x&#125;FILE_BAKGIT_ROLBAK &amp;&amp; MESSAGE 1234# 定时任务进行实时备份与同步su - rootcrontab -e10 22 * * * /bin/bash /bin/GITLAB_BAK.sh 123su - rootcrontab -e30 22 * * * /bin/bash /bin/GIT_ROL.sh]]></content>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python自动化之fabric]]></title>
    <url>%2F2017%2F11%2F21%2Fpython%E8%87%AA%E5%8A%A8%E5%8C%96%E4%B9%8Bfabric-lnmp%E7%8E%AF%E5%A2%83%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[#lnmp环境的建立 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env pythonfrom fabric.colors import *from fabric.api import *env.user='root'env.roledefs = &#123; #定义业务角色分组 'webservers': [ 'xx.xxx.xx.xxx' ], 'dbservers': ['xx.xxx.xx.xxx']&#125;env.passwords = &#123; 'root@xxx.xx.xx.xxx:22' : 'passwd', 'root@xxx.xx.xx.xxx:22' : 'passwd'&#125;@roles('webservers') #webtask任务函数引用'webservers'角色修饰符def webtask(): print yellow("Install webtask packages class ! ") with settings(warn_only=True): run("yum -y install nginx") run("yum -y install php-fpm php-mysql php-mbstring php-xml php-mcrypt php-gd") run("chkconfig --levels 235 php-fpm on") run("chkconfig --levels 235 nginx on") run("systemctl start php-fpm") run("systemctl start nginx")@roles('dbservers') # dbtask任务函引用'dbservers'角色修饰符def dbtask(): #部署mysql环境 print green("Install mariadb server !") with settings(warn_only=True): run("yum -y install mariadb mariadb-server") run("chkconfig --levels 235 mariadb on") run("systemctl start mariadb")@roles('webservers','dbservers') # publictask任务函数同时引用两个角色修饰符def publictask(): # 部署公共环境，如epel、ntp等 print blue("Install epel ntp !") with settings(warn_only=True): run("rpm -Uvh http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm") run("rpm -y install ntp ntpdate")def deploy(): execute(publictask) execute(webtask) execute(dbtask) 12#vim 底行模式的执行: ! fab -f NGINX_DPL.py deploy 自动部署注:目前代码还有些问题，小心参考 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#!/usr/bin/env python# -*- coding: utf-8 -*-from fabric.api import *from fabric.colors import *from fabric.context_managers import *from fabric.contrib.console import confirmimport time env.user = 'root'env.hosts = ['xx.xxx.xx.xxx','xx.xxx.xx.xxx']env.password = 'test.......'env.project_dev_source = '/var/www/html' #开发机项目主目录env.project_tar_source = '/var/www/releases' #开发机项目压缩包存储目录env.project_pack_name = 'release' # 项目压缩包前缀，文件名为 release.tar.gzenv.deploy_project_root = '/var/www/data' #项目生产环境主目录env.deploy_release_dir = 'release' #项目发布目录，位于主目录下面env.deploy_current_dir = 'current' #对外服务的当前版本软链接env.deploy_version = time.strftime ("%Y%m%d") +"V2" #版本号@runs_once #相当于一个模块def input_versionid(): return prompt ("please input project rollbak version ID:",default="")@task@runs_oncedef tar_source(): print yellow("Creating source package...") with lcd(env.project_dev_source): local("tar -czf %s.tar.gz." % (env.project_tar_source + env.project_pack_name)) print green("Creating source package success!")@taskdef put_packages(): #上传任务函数 print yellow("Start put package...") with settings(warn_only=True): with cd(env.deploy_project_root+env.deploy_release_dir): run("mkdir %s" % (env.deploy_version)) env.deploy_full_path = env.deploy_project_root + env.deploy_release_dir + "/" + env.deploy_version with setting(warn_only=True): result = put(env.project_tar_source + env.project_pack_name + ".tar.gz", env.deploy_full_path) if result.failed and not("put file failed, Continue[Y/N]?"): abort("Aborting file put task!") with cd(env.deploy_full_path): run("tar -zxvf %s.tar.gz" % (env.project_pack_name)) run("rm -rf %s.tar.gz" % (env.project_pack_name)) print green("Put &amp; untar packages success!")@taskdef make_symlink(): #为当前版本目录做软链接 print yellow("update current sylink") env.deploy_full_path = env.deploy_project_root + env.deploy_release_dir + "/" +env.deploy_version with settings(warn_only=True): #删除软链接，重新创建并指定软链接源目录，新版本生效 run("rm -rf %s" % (env.deploy_project_root + env.deploy_current_dir)) run("ls -s %s %s" % (env.deploy_full_path, env.deploy_project_root + env.deploy_current_dir)) print green("make symlink success!")@task def rollback(): #版本回滚任务函数 print yellow("rollback project version") versionid= input_versionid() if versionod=='': abort("Project version ID error,abort!") env.deploy_full_path=env.deploy_project_root + env.deploy_release_dir + "/" +versionid run("rm -f %s" % env.deploy_project_root +env.deploy_current_dir) run("ln -s %s %s" % (env.deploy_full_path, env.deploy_project_root + env.deploy_current_dir))#删除软链接,重新创建并指定软链接源目录，新版本生效 print green("rollback success!")@taskdef go(): tar_source() put_packages() make_symlink()]]></content>
      <tags>
        <tag>linux</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[当我年轻的时候]]></title>
    <url>%2F2017%2F11%2F20%2F%E5%BD%93%E6%88%91%E5%B9%B4%E8%BD%BB%E7%9A%84%E6%97%B6%E5%80%99%2F</url>
    <content type="text"><![CDATA[当我年轻的时候 当我年轻的时候，我的想象力从没有受过限制，我梦想改变这个世界;当我成熟之后，我发现我不能够改变这个世界，我将目光缩短了些，决定只改变我的国家;当我进入暮年以后，我发现我不能够改变我的国家，我最后愿望仅仅是改变一下我的家庭。但是这也不可能;当我现在躺在床上，行将就木时，我突然意识到: 如果一开始我仅仅去改变我自己，然后作为一个榜样;我可能改变我的家庭;在家人的帮助和鼓励下，我可能为国家做一些事情;然而，谁知道呢 ？ 我甚至可能改变这个世界; 他们的好 莎莎姐: 引领自己进入IT行业，提供最新的信息资料让自己在大学学习，提供初到北京经济上的支持。引导就业与学习方向。 海生郭: 推荐就业，帮助学习技术知识。 娜娜: 帮着学习高数，鼓励Linux 发展之路 ，帮着自己排忧解难。 阿狗: 最美的年华鼓励与相伴。 小胖郭: 引领运维入门，相遇直率。 红兵哥: 帮着看房，一起学习专业知识。 不可多得的挚友杨中xin、 梁hao 、 董san 、狗jiang 、勇gang、 海tuan 、 芳mei 、 振xin 火车跑的快，全靠车头带许立宽、 王春兰、崔忘名、雷丽琴、马永亮、王晓春 励志语 有智而性缓者思大智、有才而气和者为大才; 我不能把这个世界让给我所鄙视的人，冬严寒、夏酷暑、春秋亦不死吾心，心有所向，将有所成; 不管走到哪里，都要相信自己的勇敢和毅力，不管遇到什么事情都不要击垮自己的心态; 高中语录12345678烈 火 逝水锦遥赛者奔于道中央，只为尖峰生烈火。观者立于路两傍，求得为此来鼓掌。风吹烈火火似箭，强压烈火火冲天。热血青春度无悔，谁人此生如烈火？不视前方渺我者，无须再品人生味。烈火怒冲人生路，央草留于我芳香。 12345678 堂 弟 逝水锦遥同堂坠地过七秋，伴我同度千百日。堂弟乱入游戏网，悔于当初我沉沦。赛道忙于瞄峰标，专于技艺终不回。游戏人生抛涯底，堂弟基石忙打紧。与其相隔虽遥远，回乡之日挤时间。断落各行千百事，常立天地永不衰。 12345678 淡霞追忆逝水锦遥星划一颗泄万里，光洒暗夜暖一心。双亲似有离别意，子若心弦弦拉紧。今日家和万事兴，天间空留淡霞忆。静观庭台花落去，动听泪雨灌秋田。遥望前程花与锦，追忆淡霞留我情。笑看世间路险义，痛绝此生冬眠人。 12345678910111213141516171819202122232425262728锦遥求佳季 逝水锦遥又是一年冬季 愿同度青春的朋友们外美如花，内秀如竹让我们的心灵山高水阔，天地澄明真正的自己没有左右天气的能力没有力挽狂澜的魄力没有两肋插刀的勇气但却有一颗心有情有义在这个寒冷的冬季里愿同度青春的朋友们如在春天过的美丽如在夏天过的温暖如在秋天过的充实同在冬天过的迷人我有我的自我芬芳我有我的热血内心与朋友同享冬季有寒而降不知寒冷有难同度不感痛苦有泪可落不觉悲凉愿同度青春的朋友一切都好一切都好！ 1234567891011121314151617181920212223242526272829303132333435赤子佳人逝水锦遥看大地山河之秀 品锦瑟年华之盛愿与尔同度四季春赏花夏观瀑秋采红叶冬踏雪闲适的自己浪漫的佳人一闪一星光一锦一人生望前程如海之茫定峰标力求猛进愿与尔同度青春喜听歌怒绽放哀鸣鸟乐乐开怀激扬的热血舞动的青春满月满斜阳落地落芬芳视天长地久之人留余生余世之爱愿与尔同度余生青学习长积蓄年立事业老扶子聚集的烦恼无尽的忧愁共苦共欢乐共涯共此生 123456789101112131415161718192021逝水人生录逝水锦遥曾忆旧时光，千百曲悲歌唱响；时人多思苦楚，无奈哀伤闭双目。回荡人生路，多少次争锋敌对；朝阳冷于寒光，忠于仁义存善良。力挽家幸福，无数尝日夜难眠；双子恐忧父母，有家不和天地乱。停留他人言，听不尽丑闻诽语；关门极力净心，空留锦遥有情人。天不予以我家和，独立其身修自强。自幼至今无健体，唯有一颗傲骨心。家乡如冰无温情，星光照我留暖忆。爱意受冷冰我心，孤友久播关爱种。学习不进技不成，信心百成剩两成。愿寻大学心追求，柔情重返人世间。勿忘朋友情，关怀解难雪送碳。勿忘恩师育，立宽春兰崔忘名。勿忘母亲泪，吸烟喝酒不争气。勿忘锦遥魂，刚毅倔强扬斗志。 1234567醉无温意逝水锦遥哪认吹来布谷鸟，无意牵起家乡情。为得路人一回眸，无力消我家乡愁。晨陪花瓣瓣留露，暗夜无星星点缀。抱负存心志在天，战场一战炮打响。穿肠烈酒无温意，丽人如花酒为愁。 离别后1234567891011121314151617181920逝水人生录 逝水锦遥 曾念旧相识，一面欢快一面愁。时人有梦立大志，各奔前程自拼搏。回荡人生路，多少次日夜相伴。身负你我未来梦，拾起坚强不怕痛。轻拂心中伤，拥抱一时不哭泣。爱忧恨忧不挂心，牵手相伴风雨中。美好终逝往，劳燕分飞可回首？相信技艺不相远，何必急于工作忙。重重思绪绕梦萦，悄然钻入沉寂里。匆匆时光尽逝水，一时低落思过往。吵吵闹闹一三九，快乐和好下一秒。影影相伴不曾怕，信仰不死立心头。言言相随好爱人，杂念停留乱我心。若若欣阳笑归来，无解无思大神在。勿忘往日游，故宫华门似神龟。勿忘淡开放，不晓心思河边乱。勿忘朝日伴，誓言梦想俱痴狂。勿忘别时痛，你我泪别北京南。]]></content>
      <tags>
        <tag>renjin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kvm之快照管理]]></title>
    <url>%2F2017%2F10%2F30%2Fkvm%E4%B9%8B%E5%BF%AB%E7%85%A7%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[kvm之快照管理使用kvm快照，磁盘则必需要使用qcow2的格式123456# qemu-img info centos6.test-x86_64.raw image: centos6.test-x86_64.rawfile format: rawvirtual size: 80G (85899345920 bytes)disk size: 1.2G# 关闭虚拟机并改变磁盘的格式12345678910111213141516171819202122232425262728# virsh list Id 名称 状态---------------------------------------------------- 2 ubuntu-14.4-n1 running 14 ubuntu-14.4-113-pycharm running 16 ubuntu-14.4-n2 running 20 centos-6.8-grafana running 22 centos-6.8-data running 24 centos-6.8-test running# virsh destroy centos-6.8-test域 centos-6.8-test 被删除# virsh list --all Id 名称 状态---------------------------------------------------- 2 ubuntu-14.4-n1 running 14 ubuntu-14.4-113-pycharm running 16 ubuntu-14.4-n2 running 20 centos-6.8-grafana running 22 centos-6.8-data running - centos-6.8-n1 关闭 - centos-6.8-test 关闭 - renjin-scripts 关闭 - ubuntu-14.4-n3 关闭# qemu-img convert -f raw -O qcow2 centos6.test-x86_64.raw centos6.test-x86_64.qcow2# virsh edit centos-6.8-test &lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='qcow2' cache='none'/&gt; &lt;source file='/media/67cbdcec-6419-4571-9632-c605b3e2b910/data/centos6.test-x86_64.qcow2'/&gt; 查看管理快照的命令有哪些12345678910111213# virsh --help | grep snap iface-begin create a snapshot of current interfaces settings, which can be later committed (iface-commit) or restored (iface-rollback) Snapshot (help keyword 'snapshot') snapshot-create Create a snapshot from XML snapshot-create-as Create a snapshot from a set of args snapshot-current Get or set the current snapshot snapshot-delete Delete a domain snapshot snapshot-dumpxml Dump XML for a domain snapshot snapshot-edit edit XML for a snapshot snapshot-info snapshot information snapshot-list List snapshots for a domain snapshot-parent Get the name of the parent of a snapshot snapshot-revert Revert a domain to a snapshot 创建快照123456# virsh snapshot-create centos-6.8-test# virsh snapshot-list centos-6.8-test 名称 Creation Time 状态------------------------------------------------------------ 1509359245 2017-10-30 18:27:25 +0800 shutoff# 其中快照配置文件放到了/var/lib/libvirt/qemu/snapshot/ 快照恢复查看哪些快照需要恢复123456789101112# virsh list --all Id 名称 状态---------------------------------------------------- 2 ubuntu-14.4-n1 running 14 ubuntu-14.4-113-pycharm running 16 ubuntu-14.4-n2 running 20 centos-6.8-grafana running 22 centos-6.8-data running 25 centos-6.8-test running - centos-6.8-n1 关闭 - renjin-scripts 关闭 - ubuntu-14.4-n3 关闭 12345678910# virsh snapshot-list centos-6.8-test 名称 Creation Time 状态------------------------------------------------------------ 1509359245 2017-10-30 18:27:25 +0800 shutoff # virsh destroy centos-6.8-test域 centos-6.8-test 被删除# virsh snapshot-revert centos-6.8-test 1509359245# virsh snapshot-current centos-6.8-test# virsh start centos-6.8-test#至此，已经恢复完成 快照的删除123456# virsh snapshot-list centos-6.8-test 名称 Creation Time 状态------------------------------------------------------------ 1509359245 2017-10-30 18:27:25 +0800 shutoff# virsh snapshot-delete centos-6.8-test 1509359245 补充:在宿主机关机后，启动kvm遇以下问题:123456# virsh start centos-7.2-xxxxxxxx错误：开始域 centos-7.2-xxxxxxx失败错误：Unable to read from monitor: Connection reset by peer# virsh managedsave-remove centos-6.8-grafana# virsh start centos-7.2-xxxxxxxxx 域 centos-7.2-xxxxxxxxx 已开始]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux 系统优化]]></title>
    <url>%2F2017%2F10%2F29%2Flinux-%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[进程调度123456789101112131415161718192021222324252627282930313233343536OS:硬件抽象，虚拟计算机 system call CPU: time slice 获得CPU权限的优先级，有些进程的优先级是可以被提高的调度器(本身也是个程序): CFS Big O O(1) 一个算法的时间复杂度 0-139 0-99 100-139: niceMemory: 虚拟地址空间 PAE：物理地址扩 32bits，寻址的物理空间是4G，4bits是额外引入的，所以被称为PAE技术(64G) 也就是说它的线性地址空间依然为4G MySQL:单进程多线程 可以使用2.7G左右，因此使用PAE技术对MySQL没有技术，因此使用MySQL服务时，建议使用64位的 page frame: 分页技术 物理地址中的内存空间，被划分成了多个页面空间，都被组织成为多个页面形势 从页面到页框完成映射的 一个进程读取数据时，首先需要把数据载入到内存中。遇到经常被调用的数据时，可以配置缓存 如果缓存不断的命中，则说明性能可以不断的提高，将频繁被访问数据放到CPU缓存中 对于CPU来说，CPU的缓存对提高CPU的性能是至关重要的 缓存空间通常是按倍相差的 TLB 转换后元缓存器 page frame: huge page: 使用大页，来提升TLB的命中率 0000 0001 0101 1111 cpu 1,3 两中拆中方法，拿时间换空间，拿空间换时间 较专业的服务器上会有NUMA的结构，非一致内存访问，NUMA结构的前题是，要有多颗CPU 将进程和CPU完成亲和性绑定，进程命中CPU缓存的命中率，将会变的很高 CPU调优操作123456789101112131415161718# 查看当前进和运行在哪颗CPU# ps axo psr,comm,pid# cat /proc/cpuinfo# 定义进程号为 11215的进程绑定在第四颗CPU上# taskset -p -c 3 11215 (为个命令的格式比较诡异) # taskset -p cpu1,cpu2,... pid # vim /boot/grup/grub.conf kernel 行加上 isol = 2,3# cat /proc/interrupts # 通常应该把0号隔离出来，离给内核使用# ls /proc/irq/0/# cat /proc/irq/0/smp_affinity ffffffff,ffffffff 表示任意CPU# echo 1 &gt; /proc/irq/32/smp_affinity# cat /proc/irq/32/smp_affinity# cat # 对于生产来说，越简单，越标准会好# 压榨系统资源，会造成系统不稳定的，不到万不得已，不建议这样做的# nice, renice 经常用到的进程优先级的调整 定义中断 smp affinityy:1234# echo cpunumber ,.. &gt; /proc/irq/#/smp_affinity# 这里使用的cpu应该为isoicpus中定义CPU集合之外的其它CPU# numa,numactl,numad 尽可能把进程绑定在单颗CPU上# 对同一个进程来讲，可能适用的调度器有多个，有其优先级较高的调度来器来调度 12345678910111213141516171819202122232425262728293031# SCHED_FIFO [1-99] chrt -f [1-99] /path/to/program arguments# SCHED_RR chrt -f [1-99] /path/to/program arguments# SCHED_NORMAL (100-139)进程的调度类别: SCHEd_FIFO, SCHED_RR:real-time SCHED_NORMAL, SCHED_OTHER: 100-139 nice,renice (对于已启动的进程使用renice启动)建议使用CPU Utilization工具: htop,dstat,glances,sar w,uptime, vmstat 1 5 # sar -P all 1# iostat -c 1 2 # sysdig/proc,/sysDMA: 直接内存访问CPU跟外部IO设备交互的方式: poll:轮询，忙等待 中断:CPU: 调优 cpu affinity 优先级调整 cgroups,内存: overcommit_memory msg shm 补充nginx 优化加速 给Nginx上 ngx_http_gzip_module 这个模块;用 nginx -V 命令查看 configure arguments 是否有没有的话需要编译加载这个模块 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# vim /usr/local/nginx/nginx.conf# 在 httpd 段中加入以下内容gzip on;#该指令用于开启或关闭gzip模块(on/off)gzip_buffers 16 8k;#设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。16 8k代表以8k为单位，安装原始数据大小以8k为单位的16倍申请内存gzip_comp_level 6;#gzip压缩比，数值范围是1-9，1压缩比最小但处理速度最快，9压缩比最大但处理速度最慢gzip_http_version 1.1;#识别http的协议版本gzip_min_length 256;#设置允许压缩的页面最小字节数，页面字节数从header头得content-length中进行获取。默认值是0，不管页面多大都压缩。这里我设置了为256gzip_proxied any;#这里设置无论header头是怎么样，都是无条件启用压缩gzip_vary on;#在http header中添加Vary: Accept-Encoding ,给代理服务器用的gzip_types text/xml application/xml application/atom+xml application/rss+xml application/xhtml+xml image/svg+xml text/javascript application/javascript application/x-javascript text/x-json application/json application/x-web-app-manifest+json text/css text/plain text/x-component font/opentype font/ttf application/x-font-ttf application/vnd.ms-fontobject image/x-icon;#进行压缩的文件类型,这里特别添加了对字体的文件类型gzip_disable "MSIE [1-6]\.(?!.*SV1)";#禁用IE 6 gzip# vim /etc/nginx/conf.d/ssjinyao.conf # 在虚拟主机server 段中加入以下内容location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|flv|ico)$ &#123; expires 30d; access_log off;&#125;location ~ .*\.(eot|ttf|otf|woff|svg)$ &#123; expires 30d; access_log off;&#125;location ~ .*\.(js|css)?$ &#123; expires 7d; access_log off;&#125;]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker初步使用]]></title>
    <url>%2F2017%2F10%2F27%2Fdocker%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Docker初步使用一、说明 lxc linux container,openvz;容器中各虚拟机只有一个内核，而是多个用户空间;在库中完成虚拟化，比如wine 或者在windows中运行bash;在应用程序的运行级别提供虚拟化，比如jvm;pstree , pid 为1 的进程 这个进程是直接和内核来打交道的;容器之间，和虚拟机之间隔离的技术;容器之间的隔离相对比较困难;NameSpace,（名称空间); 内核级别，环境隔离 PID NameSpace: 用于隔离pid号的 Linux 2.6.24 PID隔离; Network NameSpace : Linux 2.6.29 网络名称空间的隔离 网络设备、网络栈、端口等网络设备隔离; User NameSpace: Linux 用户空间的隔离 Linux 3.8 甚至 3.10之后 用户和用户组资源隔离; IPC NameSpace: 进程间通信技术 Linux 2.6.19 signal 信号量、消息队列和共享内存的隔离; UTS NameSpace: Linux 2.6.19 ， 主机名和域名的隔离； Mount NameSpace: Linux 2.4.19 挂载点（文件系统 ）隔离； API:clone()实现线程系统调用，用来创建新线程; setns()设定一个新的属性,将某(进程|或设备)加入到新的NameSpace中去的; unshare()非共享机制，脱离NameSpace，而关联至新NameSpace; 将NameSpace隔离开来没有问题，而问题在于，恶意用户强行调用资源，一个用户完全可以将系统资源耗尽，cpu占用至100%; 因此带来了另一种机制的出现； CGroup: Linux Control Group,控制组 Linux 2.6.24被收入进内核 内核级别，限制、控制与一个进程组群的资源； 资源：CPU,内存，IO 级别来进行定义 google工程师：2006开始此技术，命令为进程容器而后命令为CGroup 功能： Resource limitation:资源限制； Prioritization:优先级控制； Accounting:审计和统计，主要为计费； Contorl:挂起进程，恢复进程； CGroup 基于单根倒树状结构来实现 在CentOS7 中可以用mount 命令来查看其资源组的隔离技术已经被使用 1234567891011121314151617181920212223242526272829 /sys/fs/cgroup # mount # lssubsys -m ``` ### CGroup的子系统:* blkio:设定块设备的IO限制，而设定的子系统；* cpu:设定CPU的限制；* cpuacct:报告cgroup中所使用的CPU资源；* cpuset:为cgroup中的任务分配 CPU和内存资源 ；* memory:设定内存的使用限制；* devices:控制cgroup中的任务对设备的访问能务；* freezer: 挂起和恢复cgroup中的任务； * net_cls:(classid) ，使用等级级别标识符来标记网络数据包；* tc: 流量整形命令 ；* perf_event:对用户空间中任务，对用户空间产生的进程进行分类；* 使用后使cgrup中的任务可以进行统一的性能测试； * hugetlb:转换后元缓冲区，对HugeTLB子系统进行限制；### CGroup中的术语：* task(任务)：进程或线程；* cgroup:一个独立的资源控制单位，可以包含一个或多个子系统；* subsystem:子系统，* hierarchy:层级* AUFS:UnionFS：* UnionFS：把不同的物理位置的目录合并到同一个目录中。* Another UFS,Alternative UFS,Adanced UFS 几乎完全重写了unix FS ```bash# tc # lssubsys -m Device mapper: linux 2.6内核引入的最重要的技术之一，用于在内核中支持逻辑卷管理的通用设备映射技术； Mapped Device Mapping Table Target Device 在内核空间只能开启一个端，但是可以映射至其它的用户空间 Device mapper: Linux2.6 内核引入的最重要的技术之一，用于在内核 中支持逻辑卷管理的通用设备映射机制； Mapped Device Mapping Table Target Device Docker 2013,GO,Apache 2.0,dotCloudC/S: Docker Client:发起docker相关的请求 Docker Server:窗口运行的节点； Containers 容器 images docker映像文件 –&gt; 存于仓库之中 启动docker容器需要加载镜像文件 –&gt; docker仓库上的镜像加载进来 docker允许我们创建私有仓库 比较难的，如何创建映像文件 dockerfile: namespace cgroup 解决方案 lxc,openvzlxc,linux containerlibcontainerHost OS –&gt; hypervisor –&gt; Guest OSHost OS –&gt; hpervisor –&gt; user space（n个） 核心组件： docker client：docker的客户端工具，是用户使用docker的主要接口，docker client 与docker daemon通信并将结果返回给用户docker deamon:运行于宿主机上，Docker守护进程 ，用户可通过docker client其交互image:镜像文件是只读的；用来创建container,一个镜像可以运行多个container镜像文件可以通Dockerfile文件来创建，可以从docker hub/registry下载； repository 公共仓库:Docker hub/registry私有仓库:docker registry仓库可以存有:nginx image httpd image tomcat imagedocker container: docker的运行实例，容器是一个隔离环境； 另外两个重要组件： docker link: 各docker容器这间能够通信 docker volume: 二、Docker YUM源的安装配置安装使用docker 通过使用epel源来实现， CentOS7 自带的就有了1234567891011121314151617181920212223242526dockerfile 自定义的docker 源 [root@node1 ~]# vim /etc/yum.repos.d/docker.repo [dockerrepo] name=Docker Repository baseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/ gpgcheck=1 gpgkey=https://yum.dockerproject.org/gpg [jin] name=renjin2 baseurl=https://mirrors.aliyun.com/centos/7/os/x86_64/ gpgcheck=0 enabled=1 [extra] name=renjin3 baseurl=https://mirrors.aliyun.com/centos/7/extras/x86_64/ gpgcheck=0 enabled=1 [epel] name=renji4 baseurl=https://mirrors.aliyun.com/epel/7Server/x86_64/ gpgcheck=0 enabled=1 或者可以使用自带的源 https://mirrors.aliyun.com/centos/7.2.1511/extras/x86_64 查看docker版本的详细信息 1234567891011121314151617181920212223[root@node1 ~]# yum info docker-engineLoaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfileInstalled PackagesName : docker-engineArch : x86_64Version : 17.04.0.ceRelease : 1.el7.centosSize : 63 MRepo : installedFrom repo : dockerrepoSummary : The open-source application container engineURL : https://dockerproject.orgLicense : ASL 2.0Description : Docker is an open source project to build, ship and run any application as a : lightweight container. : : Docker containers are both hardware-agnostic and platform-agnostic. This means : they can run anywhere, from your laptop to the largest EC2 compute instance and : everything in between - and they don't require you to use a particular : language, framework or packaging system. That makes them great building blocks : for deploying and scaling web apps, databases, and backend services without : depending on a particular stack or provider. 12[root@node1 ~]# yum -y install docker-engine[root@node1 ~]# systemctl start docker.service 三、Dcoker 的简单测试及使用1234567891011121314151617181920212223242526272829[root@node1 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE[root@node1 ~]# docker search centosNAME DESCRIPTION STARS OFFICIAL AUTOMATEDcentos The official build of CentOS. 3239 [OK] jdeathe/centos-ssh CentOS-6 6.8 x86_64 / CentOS-7 7.3.1611 x8... 63 [OK]jdeathe/centos-ssh-apache-php CentOS-6 6.8 x86_64 - Apache / PHP-FPM / P... 25 [OK]consol/centos-xfce-vnc Centos container with "headless" VNC sessi... 24 [OK]nimmis/java-centos This is docker images of CentOS 7 with dif... 24 [OK]gluster/gluster-centos Official GlusterFS Image [ CentOS-7 + Glu... 18 [OK]million12/centos-supervisor Base CentOS-7 with supervisord launcher, h... 15 [OK]torusware/speedus-centos Always updated official CentOS docker imag... 8 [OK]egyptianbman/docker-centos-nginx-php A simple and highly configurable docker co... 6 [OK]nathonfowlie/centos-jre Latest CentOS image with the JRE pre-insta... 5 [OK]centos/mariadb55-centos7 4 [OK]centos/redis Redis built for CentOS 2 [OK]harisekhon/centos-java Java on CentOS (OpenJDK, tags jre/jdk7-8) 2 [OK]harisekhon/centos-scala Scala + CentOS (OpenJDK tags 2.10-jre7 - 2... 2 [OK]blacklabelops/centos CentOS Base Image! Built and Updates Daily! 1 [OK]darksheer/centos Base Centos Image -- Updated hourly 1 [OK]freenas/centos Simple CentOS Linux interactive container 1 [OK]timhughes/centos Centos with systemd installed and running 1 [OK]januswel/centos yum update-ed CentOS image 0 [OK]kz8s/centos Official CentOS plus epel-release 0 [OK]grayzone/centos auto build for centos. 0 [OK]repositoryjp/centos Docker Image for CentOS. 0 [OK]otagoweb/centos Apache (with PHP7), built on CentOS 7 0 [OK]vcatechnology/centos A CentOS Image which is updated daily 0 [OK]grossws/centos CentOS 6 and 7 base images with gosu and l... 0 [OK] 之所以能搜索出来，是因为别人给我们做了公开的使用123456789101112131415161718192021222324252627[root@node1 ~]# docker search busyboxNAME DESCRIPTION STARS OFFICIAL AUTOMATEDbusybox Busybox base image. 973 [OK] progrium/busybox 65 [OK]radial/busyboxplus Full-chain, Internet enabled, busybox made... 12 [OK]container4armhf/armhf-busybox Automated build of Busybox for armhf devic... 6 [OK]odise/busybox-python 4 [OK]multiarch/busybox multiarch ports of ubuntu-debootstrap 2 [OK]azukiapp/busybox This image is meant to be used as the base... 2 [OK]ofayau/busybox-jvm Prepare busybox to install a 32 bits JVM. 2 [OK]zanner/busybox https://github.com/sergej-kucharev/zanner-... 1 [OK]ofayau/busybox-libc32 Busybox with 32 bits (and 64 bits) libs 1 [OK]elektritter/busybox-teamspeak Leightweight teamspeak3 container based on... 1 [OK]getblank/busybox Docker container busybox for Blank 1 [OK]prom/busybox Prometheus Busybox Docker base images 1 [OK]skomma/busybox-data Docker image suitable for data volume cont... 1 [OK]odise/busybox-curl 1 [OK]jahroots/busybox Busybox containers 0 [OK]ggtools/busybox-ubuntu Busybox ubuntu version with extra goodies 0 [OK]cucy/busybox aouto build busybox 0 [OK]freenas/busybox Simple Busybox interactive Linux container 0 [OK]sdurrheimer/prom-busybox Moved to https://hub.docker.com/r/prom/bus... 0 [OK]jiangshouzhuang/busybox busybox 0 [OK]padcom/busybox-java Oracle Java on BusyBox 0 [OK]futurenda/busybox Mini busybox 0 [OK]hongtao12310/busybox for busybox image based on the gcr.io/goog... 0 [OK]ddn0/busybox fork of official busybox 0 [OK] 12345678910 [root@node1 ~]# docker pull buxybox [root@node1 ~]# docker pull busybox Using default tag: latest latest: Pulling from library/busybox 7520415ce762: Pull complete Digest: sha256:32f093055929dbc23dec4d03e09dfe971f5973a9ca5cf059cbfb644c206aa83f 校验码 Status: Downloaded newer image for busybox:latest[root@node1 ~]# docker pull hub.magedu.com:5000/busybox ##指定到哪台服务器上获取busybox [root@node1 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE busybox latest 00f017a8c2a6 3 weeks ago 1.11MB 123456[root@node1 ~]# docker run -it busybox:latest /bin/sh ##启动一台虚拟机的实例 / # lsbin dev etc home proc root sys tmp usr var[root@node1 ~]# docker ps ##查看正在运行的主机CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7090d8fd9861 busybox:latest "/bin/sh" 2 minutes ago Up 2 minutes boring_archimedes 四、 docker的常用命令总结环境信息相关： info version 12[root@node1 ~]# docker info ##查看docker的环境信息[root@node1 ~]# docker version ##查看docker的版本号 系统维护相关： images inspect build 创建映像文件 commint 基于运行中的容器创建映像文件 pause/unpause ps rm rmi run start/stop/restart top kill 日志信息相关： events history logs Docer hub服务相关 login logout pull push search 基本操作： 获取映像:pull 启动容器:run 1234567891011121314151617181920212223242526272829303132333435 [root@node1 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7090d8fd9861 busybox:latest "/bin/sh" 17 minutes ago Up 17 minutes boring_archimedes [root@node1 ~]# docker kill 7090d8fd9861 7090d8fd9861 [root@node1 ~]# docker ps #结束一个docker进程 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES [root@node1 ~]# docker ps -a #但不会删除容器 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7090d8fd9861 busybox:latest "/bin/sh" 20 minutes ago Exited (137) 3 minutes ago boring_archimedes [root@node1 ~]# docker rm 7090d8fd9861 #此时会删除container 7090d8fd9861 [root@node1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES [root@node1 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2bca1aa3d38d busybox:latest "/bin/sh" 4 minutes ago Up 4 minutes naughty_goldberg[root@node1 ~]# docker docker docker-containerd-ctr dockerd docker-proxy docker-containerd docker-containerd-shim docker-init docker-runc[root@node1 ~]# docker commit 2bca1aa3d38d centos:newuser sha256:08d1d05a6e490c31b0e4e3ffb9532a25bb3d9e8f588b30990338f1ae64b34286[root@node1 ~]# docker docker docker-containerd-ctr dockerd docker-proxy docker-containerd docker-containerd-shim docker-init docker-runc[root@node1 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos newuser 08d1d05a6e49 9 seconds ago 1.11MB busybox latest 00f017a8c2a6 3 weeks ago 1.11MB[root@node1 ~]# docker run -it --rm centos:newuser /bin/sh / # [root@node1 ~]# docker kill fee1da85d418 fee1da85d418[root@node1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES linux Kernel –&gt; libcontainer –&gt; (execdriver、networkdriver)–&gt; Docker Daemon (GraphDB) –&gt; API server –&gt; 用户在docker 之外有个重要存储还需要GraphDB GraphDB也称为图式数据库 Docker应用： 镜像：包含了启动Docker容器所需要的文件系统层给及其内容； 基于UninFS采用分层结构实现; bootfs,rootfs; registry:用于保存镜像的元数据,保存docker镜像层次结构和元数据； reposistory:由具有某个功能的镜像的所有相关版本构建成的集合； index:管理用户的账号、访问权限、镜像及镜像标签等等相关的; graph:从registry中下载的Docker镜像需要保存在本地，此功能即由graph完成； /var/lib/docker/graph; ##与镜像相关的命令： docker images 列出本地的镜像 docker search 搜索 docker pull 下载镜像 docker push 上传镜像 docker login 登录 docker logout 登出 创建镜像：commint,build 删除本地镜像: rmi 容器：也可以想象成一个虚拟机 独立运行的一个或一组应用，以及它们运行的环境 命令： run,kill,stop,start,restart ,log,export,import 启动方法: 通过镜像创建一个新的容器: run 启动一个处于停止状态的容器: start 容器本来就是应用的，当应用结束时，程序也会结束的；123456[root@node1 ~]# docker run busybox:latest /bin/echo "hello world" hello world[root@node1 ~]# docker run -it --name=busybox busybox:latest /bin/sh[root@node1 ~]# docker stop busybox ##正常停止一个容器，相当于正常关机 busybox run命令: –name= Assign a name to the container-i,–interactive=false Keep STDIN open even if not attachedit,-tty=false Alocate a pseudo-TTY–net=default Set the Network for the container 步骤： 检查本地是否存在指定的镜像，不存在则从registry下载；利用镜像启动容器分配一个文件系统，并且在只读的镜像层之外，挂载一个可读写层；从宿主机配置的网桥口中，桥接一个虚拟接口给此容器;从地址池中分配一个地址容器；执行用户指定的应用程序；程序执行完成后，容器即终止；logs命令:获取一个容器的日志，获取其输出信息;对于交互式模式启动的容器，终止可以使用exit 命令或ctrl+d组合键; attach 附加至一个运行中的容器；123456789101112[root@node1 ~]# docker start 31a67d66b2c2[root@node1 ~]# docker attach busybox[root@node1 ~]# docker run busybox:latest /bin/echo "hello world"[root@node1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d35a2673722e busybox:latest "/bin/echo 'hello ..." 13 seconds ago Exited (0) 12 seconds [root@node1 ~]# docker start d35a2673722e d35a2673722e[root@node1 ~]# docker logs cabd0e52f8f8 ##可以查看执行命令后的输出信息 hello world hello world hello world 12345678910111213141516171819202122232425262728293031 / # exit 终止当前容器 或者ctrl +d attach [root@node1 ~]# docker start -i busybox ##启动一个交互式一个接口 [root@node1 ~]# docker start busybox [root@node1 ~]# docker attach busybox ##附加至一个运行中的容器； / # ``` ## Docker Hub * registry有两种* docker hub* private registry```bash # docker login # docker push busybox:latest [root@node2 yum.repos.d]# yum -y install docker-registry 上条命令实质上安装的是另外的一个包 [root@node2 yum.repos.d]# yum -y installdocker-distribution-2.6.0-1.el7.x86_64 [root@node1 yum.repos.d]# systemctl start docker-distribution.service [root@node1 yum.repos.d]# ss -tnl | grep 5000 LISTEN 0 128 :::5000 :::* [root@node1 yum.repos.d]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos newuser 08d1d05a6e49 2 weeks ago 1.11MB centos latest 98d35105a391 5 weeks ago 192MB busybox latest 00f017a8c2a6 6 weeks ago 1.11MB [root@node1 yum.repos.d]# [root@node1 yum.repos.d]# docker tag 08d1d05a6e49 192.168.99.15:5000/centos:1.2.1 给一个镜像打标签 [root@node1 yum.repos.d]# docker push 192.168.99.15:5000/centos:1.2.1]]></content>
  </entry>
  <entry>
    <title><![CDATA[ldirectord+ipvsadm之nat/dr模型的实现]]></title>
    <url>%2F2017%2F10%2F26%2Fldirectord-ipvsadm%E4%B9%8Bnat-dr%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[ldirectord 结合ipvsadm 配置nat,dr模型一、nat模型 drector 1234# wget ftp://172.16.0.1/pub/Sources/7.x86_64/crmsh/ldirectord-3.9.6-0rc1.1.1.x86_64.rpm# yum -y install nginx (同时用于做为sorry主机)# yum -y install ldirectord-3.9.6-0rc1.1.1.x86_64.rpm# echo “sorry, the service is down for maintenance, is recovering” &gt; /usr/share/nginx/html/index.html 主机为两块网卡， 一个是桥接，一个仅主机 (其中仅主机的配置静态地址为192.16.0.5) 开启核心转发功能 1234# echo 1 &gt; /proc/sys/net/ipv4/ip_forward nodeff1# yum -y install httpd # echo “&lt;h1&gt;RS1&lt;/h1&gt;” &gt; /var/www/html/index.html 主机为一块网卡，仅主机（配置静态地址为192.16.0.2）网关指向 192.16.0.51234# route add default gw 192.16.0.5 node2 # yum -y install nginx # echo “&lt;h1&gt;RS2&lt;/h1&gt;” &gt; /var/www/html/index.html 主机为一块网卡，仅主机（配置静态地址为192.16.0.3）网关指向 192.16.0.51# route add default gw 192.16.0.5 directory 此时:可以在drector主机上进行测试，12# curl 192.16.0.2 返回RS1 # curl 192.16.0.3 返回RS2 directory 使用ipvsadm指定调度算法及调度主机；123# ipvsadm -A -t 172.16.250.89:80 -wrr # ipvsadm -a -t 172.16.250.89:80 -r 192.16.0.2:80 -m -w 3 # ipvsadm -a -t 172.16.250.89:80 -r 192.16.0.3:80 -m -w 1 在别的主机中测试结果123456# for i in &#123;1..4&#125; ; do curl 172.16.250.89; done &lt;h1&gt;RS1&lt;/h1&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h1&gt;&lt;h1&gt;RS1&lt;/h1&gt;# 将规则保存 ipvsadm -S &gt; /etc/sysconfig/ipvsadm directory 配置ldirectord 1234567891011121314151617# cp /usr/share/doc/ldirectord-3.9.6/ldirectord.cf /etc/ha.d/ldirectord.cf # vim /etc/ha.d/ldirectord.cf checktimeout=3checkinterval=1fallback=127.0.0.1:80autoreload=yeslogfile=”/var/log/ldirectord.log”quiescent=novirtual=172.16.250.89:80 real=192.16.0.2:80 masq 1real=192.16.0.3:80 masq 3fallback=127.0.0.1:80 masqservice=httpscheduler=wrrprotocol=tcpchecktype=negotiatecheckport=80 注：virtual:172.16.250.89:80 ，后面需要指定端口，否则protocol=tcp指定启动时会报错real=192.16.0.2:80 masq 因为上面配置的为nat模型，所以此处使用masqfallback=172.0.0.1:80 此处便是nginx的sorry server,但所有结点都停掉时，会向用户提供一个sorry server12345678910# systemctl start ldirectord # ipvsadm -Ln 查看结点 在别的主机中测试 #for i in &#123;1..4&#125; ; do curl 172.16.250.89; done &lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h1&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;node1,node2 将两个结点手动停掉# systemctl stop httpd 在测试主机中会返回sorry信息 二、dr 模型 directory ,node1 ,node2 三台主机都是一块网块， 并且网卡都为桥接，且node1,nod2，不需要指定网关编写脚本 123456789101112131415161718192021222324252627282930313233343536373839#vim setkp.sh #!/bin/bash vip=172.16.252.166mask=255.255.255.255interface=’lo:0′eth=’eno16777736:0′ case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignoreecho 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announceecho 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announceifconfig $interface $vip netmask $mask broadcast $vip up route add -host $vip dev $interface ;; dstart) ifconfig $eth $vip/32 netmask $mask broadcast $vip up;;dstop)ifconfig $eth down;;stop)ifconfig $interface down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignoreecho 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announceecho 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce;; status) ifconfig cat /proc/sys/net/ipv4/conf/all/arp_ignorecat /proc/sys/net/ipv4/conf/lo/arp_ignorecat /proc/sys/net/ipv4/conf/all/arp_announcecat /proc/sys/net/ipv4/conf/lo/arp_announce;; *)echo “Usage: $(basename $0) &#123;dstart|dstop|start|stop&#125;”exit 1 esac 在director主机中执行123456789# sh setkp.sh dstart # sh setkp.sh status 查看状态# scp setkp.sh 172.16.251.232:/root# scp setkp.sh 172.16.251.191:/root # ipvsadm -A -t 172.16.252.166:http -s wrr# ipvsadm -a -t 172.16.252.166:http -r 172.16.251.232:http -g -w 1# ipvsadm -a -t 172.16.252.166:http -r 172.16.251.191:http -g -w 3# systemctl start nginx # echo “Sorry Page” &gt; /usr/share/nginx/html/index.html 在node1主机中执行1234# sh setkp.sh start # sh setkp.sh status # systemctl start httpd echo “&lt;h1&gt;NODE1&lt;/h1&gt;” &gt; /var/www/html/index.html 在node2主机中执行1234# sh setkp.sh start# sh setkp.sh status # systemctl start httpd echo “&lt;h2&gt;NODE2&lt;/h2&gt;” &gt; /var/www/html/index.html 在其它主机中进行测试12345#for i in &#123;1..4&#125; ; do curl 172.16.252.166; done &lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt; ldirectord配置 123456789101112131415161718# cat /etc/ha.d/ldirectord.cf | grep -v “^[[:space:]]*#” | grep -v “^[[:space:]]*$” # vim /etc/ha.d/ldirectord.cf checktimeout=3checkinterval=1fallback=127.0.0.1:80autoreload=yeslogfile=”/var/log/ldirectord.log”quiescent=novirtual=172.16.252.166:80real=172.16.251.191:80 gate 1real=172.16.251.232:80 gate 3fallback=127.0.0.1:80 gateservice=httpscheduler=wrrprotocol=tcpchecktype=negotiatecheckport=80# systemctl start ldirectord 在其它主机中进行测试123456789101112# for i in &#123;1..4&#125; ; do curl 172.16.252.166; done &lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;当主机所有结点都停止服务时 （node1,node2）# systemctl stop httpd # for i in &#123;1..4&#125; ; do curl 172.16.252.166; done Sorry PageSorry PageSorry PageSorry Page 借助防火墙标记来分类报文,而后标记定义集群服务，这样不同的服务可以使用一个集群进行调度,并启用持久连接 将两台node结点启动 1# systemctl start httpd 在director主机中配置1234# iptables -t mangle -A PREROUTING -d 172.16.252.166 -p tcp -m multiport –dport 80,443 -j MARK –set-mark 10 为端口打标记 # ipvsadm -A -f 10 -s rr -p 360# ipvsadm -a -f 10 -r 172.16.251.191:0 -g -w 1# ipvsadm -a -f 10 -r 172.16.251.232:0 -g -w 1 在其它主机中进行测试123456# for i in &#123;1..5&#125; ; do curl 172.16.252.166; done &lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt; 在两台node结点上建立https服务123456nod1 # mkdir /etc/httpd/cacert # cd /etc/httpd/cacert # (umask 066;openssl genrsa -out httpd.key 1024)# openssl req -new -key httpd.key -out httpd.crt -days 7200# scp httpd.csr 172.16.252.162:/root 在director主机中生成自签证书12345678# echo 01 &gt; /etc/pki/CA/serial# touch /etc/pki/CA/index.txt # cd /etc/pki/CA/# (umask 077; openssl genrsa -out /etc/pki/CA/private/cakey.pem 2048)# openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 7300 -out /etc/pki/CA/cacert.pem# openssl ca -in /root/httpd.csr -out /tmp/httpd.crt# scp /tmp/httpd.crt 172.16.251.232:/root# scp /etc/pki/CA/cacert.pem 172.16.250.69:/root 123456789node2 # mkdir /etc/httpd/cacertnode1 # cd /etc/httpd/cacert/ &amp;&amp; scp * 172.16.251.191:/etc/httpd/cacert/ nod1,node1 # vim /etc/httpd/conf.d/ssl.conf 修改 : SSLCertificateFile /etc/httpd/cacert/httpd.crtSSLCertificateKeyFile /etc/httpd/cacert/httpd.key # systemctl restart httpd 在其它主机中进行测试:12# vim /etc/hosts 加入 : 172.16.252.166 www.rj.com 测试https与http的持久连接123456789# for i in &#123;1..4&#125; ;do curl –cacert /root/cacert.pem https://www.rj.com &amp;&amp; curl http://www.rj.com ; done &lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt; 在 ldirectord 中实现123456789101112131415161718driector # vim /etc/ha.d/ldirectord.cf checktimeout=3checkinterval=1fallback=127.0.0.1:80autoreload=yeslogfile=”/var/log/ldirectord.log”quiescent=novirtual=10real=172.16.251.191:80 gate 1real=172.16.251.232:80 gate 3fallback=127.0.0.1:80 gateservice=httpscheduler=wrrchecktype=negotiatecheckport=80# systemctl start ldirectord# ipvsadm -Ln 在其它主机中进行测试123456789# for i in &#123;1..4&#125; ;do curl –cacert /root/cacert.pem https://www.rj.com &amp;&amp; curl http://www.rj.com ; done &lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS2&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;&lt;h1&gt;RS1&lt;/h2&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[笔记之--bash基础特性]]></title>
    <url>%2F2017%2F10%2F19%2F%E7%AC%94%E8%AE%B0%E4%B9%8B-bash%E5%9F%BA%E7%A1%80%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[bash 基础特性命令模式systemctl set-default multi-user.target 图形模式systemctl set-default graphical.target ipython安装使用12345678910111213# python ipython # tar -xvf pip-8.1.2.tar.gz# tar -xvf setuptools-28.2.0.tar.gz# tar -xvf ipython-5.1.0# cd 到其各个目录中 python setup.py build &amp;&amp; pyton setup.py install # pip install traitlets# pip install pygments# pip install simplegeneric# pip install --upgrade setuptools pi# pip unistall ipython# pip uninstall ipython# pip install ipython# pip install jupyter 123jupyter-notebook --ip 0.0.0.0 --port 46 启动jupyter jupyter-nbconvert --to html filename.ipynbipython nbconvert --to python &lt;YourNotebook&gt;.ipynb 历史记录的使用格式 1export HISTTIMEFORMAT=&quot;`whoami`:%F%T&quot; 定义历史命令的格式 HISTSIZE=1000000 定义命令的数量 12345678# rmdir [OPTION]...DIRECTORY... -p:删除某录后，如果其父目录为空，则一并删除之 -v:显示过程# mkdir -pv /tmp/x&#123;y1/&#123;a,b&#125;,y2&#125;# mkdir -v &#123;a,b&#125;_&#123;c,d&#125;# mkdir -pv /tmp/mysysroot/&#123;bin,sbin,etc/sysconfig/network-scripts,usr/ &#123;bin,sbin,local/&#123;bin,sbin,etc,lib&#125;,lib,lib64&#125;,var/&#123;cache,log,run&#125;&#125;# tree -L level指定显示层级 bash的基础特性：命令的执行状态结果 命令执行的状态结果 bash通过状态返回值来输出此结果 成功0 失败1-255 命令执行完成之后，其状态返回值保存在bash的特殊变量$?中 命令正常执行时，有的还回有命令返回值 根据命令及其功能不同，结果各不相同 引用命令的执行结果；$(COMMAND)或COMMAND 1mkdir $(date +%H-%M-%S) bash 快捷键 12345ctrl +a ：跳转到命令行首ctrl +e ：跳转到命令行尾ctrl +u ：删除行首到光标所在处之间的所有字符ctrl +k ：删除光标所在处到行尾的所有字符ctrl +l ：清屏，相当于clear 文件查看类命令：cat,tac,head,tail,more,less 分屏查看命令：more less more命令 more FILE 特点：翻屏至文件尾后自动退出 less命令 less FILE head命令 查看文件的前n行： head [options] FILE -n # or -# tail命令： 查看文件的后n行：tail [options] FILE -n # or -# 注 -f ：output appended data as the file grows 查看内容后不退出，用来查看文件内的新增内容 stat /tmp/functions 用来显示文件的状态stat FILE… 文件：两类数据 元数所：metadata 据数：data时间戳 access time modify time change time touch 摸一个不存在的文件时，会创建空文件 touch - change file timestamps touch [OPTION]…FILE… -c:指定的文件不存在时不予创建； -a:仅修改access time; -m:仅修改modify time; -t STAMP [[CC]YY]MMDDhhmm[-ss]. bash基础特性 globbing:文件名通配(整体文件名匹配，而非部分) *：匹配任意长度的任意字符 pa*所有以pa开头的文件 pa pa pa ?：匹配任意单个字符 pa? paa ??pa p?a p?a? []:匹配指定范围内的任意单个字符 有几种特殊格式 [ a-z],[A-Z],[a-z,0-9] pa[0-9][0-9],2[0-9][0-9] nmtui NetworkManager root用户不一直是管理员，原因：管理员是可以更改的 tty命令查看终端类型：物理终端，伪终端，pts 虚拟终端tty 图形终端 1234567891011# echo $SHELL# cat /etc/shells# type pwd builtin(内置) 内置命令在/bin/bash 中# type ls 别名# hashed(外置命令)# hash 显示命令缓存，作用提高系统查找命令的速度# hash -d tty 指定删除 （注：指定别名时直接删除别名）# hash -r 全清空# hash -l 显示缓存# hash -p /usr/bin/tty newtty 给缓存的命令起一个别名# hash -t 查看命令对应路径 alias eg ce7 grep 有别名 alias grep=’grep –color=auto’ 而ce6的grep没有alias 别名要想生效要定义到 .bashrc中别名比内部优先级高，内部命令比外部命令优先级高alias 内部 外部 hashed 比PATH中定义的要高 which -a cat 强置搜索cat所在的所有目录（注，如果命令有多个的话） which –skip-alias ls 查找ls所在目录时，跳过别名 unalias 取消别名 -a 取消所有别名 同样只对当前终端生效 注：bash自身是一个外部的命令 查找内部命令的时候man 文档打开的相当于 man bash 注：直接键入help时候，可以直接列出所有的内部命令 enalbe -n pwd 临时禁用pwd命令 -a 启用 echo $[RANDOMM%80] 随机数的生成 注pwd 有外部命令 注只要是能只接man查到的命令，它都有外部命令 注PS1=\e[31m \e[0m用来截止颜色 PS1=’\033[31m[\u@\h\W]\$\033[0m’ ascii 7 位 2^7=128字符 unicode（他可以把世界全部的文字都录入进来） 表 utf-8就是其中的一种 bc计算器 ibase=8 指定进制为八 ibase=16 指定进制为16 obase=8 指定输出为八进制 总结：alias nano bc enable (管理内部命令) -n hash -d -r -l type help which man unalias whereis 查看命令比which 更详细 hostname 查看主机名 仅对当前用户生效： ~/.bashrc 对所有用户生交： /etc/bashrc中 使用vmare 前期要有快照 可将vmware 下的文件复制出来 source 和 . 是等价的 eg source .bashrc . .bashrc (注中间有空格) 123假如有别名之后，要用它的真实名 /bin/grep root /etc/passwd\grep root /etc/passwd&apos;grep&apos; root /etc/passwd 命令 选项 参数ls -la 短格式 –all短格式区别：短格式可以简写连在一起而短的不能还有的不须要 - eg : ps apwd;ls;hostname 多个命令可以用;隔开命令太过长时可加\ls -l (意思为list)-rw——-. 1 root root 1537 Oct 4 01:52 anaconda-ks.cfg什么时候修改的 d b(block) l s(sock) c（chararter）-p (pip) 注在本机内部的两个程序通信时借助于socket文件 硬盘IDE SCSI SATA SAS (用于服务器面)/dev/hd(IDE) /dev/sd(除IDE之外的) /dev/vd(虚拟的)lsblk 显示块文件随机访问：可以直接去访问那个文件c (c………………hararter) 须要顺序访问 ll /dev/zerodf 可查看分区的利用率mount 挂载，映射/dev/sda1 ==mount==&gt; (映射到) /boot (C:) 挂载点把一个设备mount dir(挂载点)dd if（输入文件）=/dev/zero of=f1 count=1hexdump -v -C f1 可查看二进制文件od 也可以cat 用于看文本/dev/null（空）系统黑洞dd if=/dev/sda of=/dev/nullnano /etc/DIR_COLORS 可更改系统文件的颜色ctrl +D 正常退出（退出当前进程） ctrl +C 强行退出date -u 其它区的时间 123456[11:54:27root@clu~]# cal 9 1752 September 1752 Su Mo Tu We Th Fr Sa 1 2 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 注：cd /misc/cd df ？？？？？screen -S （session）renjin 创建会话 screen -x 加入会话 exit 退出 ctrl +a,d 剥离当前会话screen -ls显示当前会话 screen -r 还原会话补screen -S some_name -X quitmount /dev/sr0 /mnt/yum mount /dev/cdrom /mnt/yum步骤 当前机器 screen -S renjin 另一台机器screen -x renjinecho -n 不换行-e 可开启\特性（\a发声\c不换行\n强制再换行\t tab \b退格x\r光标移到行首，但不换行\033[43(背景色);33m \033[0m \HH 十六进投影 \e “\x#”打印ascii \onnn八进制asciic &lt; echo ‘只任字符串（强）’ eg echo -e “a\nb”echo 命令和引用都能实别echo “处于中间状态（弱）”命令调用另一个命令，被调用的命令用的反向单引号touch `date +%F`.log touch `hostname`.txt $() 与是等价的linux ls 列出的顺序尊重ascii码的顺序 大写字母在小写字母前 Aa Bbtouch f{a,b,c}.{txt,log} touch f{a,b,c}.{txt,log}echo {000（初始数，定义了位的0）..30（0到30）..2(每次递增2)}echo {a-z}]]></content>
  </entry>
  <entry>
    <title><![CDATA[GIT简单使用及服务器日常错误处理]]></title>
    <url>%2F2017%2F10%2F18%2FGIT%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[git 简单使用 gitlab 新建项目gitlab 本地新建地址 http://10.180.55.111:8088/dashboard/projects/ 点击 New Project —&gt; RenJin / You project name —&gt; Create Project 终端中的配置 1234# git config --global user.name &quot;Jin.Ren&quot;# git config --global user.emal &quot;renjin@transfereasy.com&quot;查看本机的密钥，添加至gitlab中# cat ~/.ssh/id_rsa.pub 复制密钥至 gitlab 点击左下脚的用户名 —&gt; Profile Settings –&gt;SSH Keys —&gt; (key) —&gt; Add key git本地新项目上传 12345678# mkdir deplay-test# git init # vim secruity.sh# vim rolbask.sh # chmod +x *.sh# git commit -m &quot;security scripts&quot;# git remote add origin git@10.180.55.111:Jin.Ren/deplay-test.git# git push -u origin master git上传已经存在的repository 123# cd old-deplay # git remote add origin git@10.180.55.111:Jin.Ren/deplay-test.git# git push -u origin master git 上传已经存在的repository 1234# git checkout -b seq# git branch # git checkout master 可以切换回master分支 补充mysql数据的导入导出 1# mysqldump -uuser -ppasswd -hhost --databases data &gt; /tmp/database.sql mongo生产报错总结 python 记入mongo时会报错 2.x 与 3.x 使用的加密方式不同ubuntu升级mongo2.x到3.x 1234567891011121314151617181920212223242526272829# sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 7F0CEB10# echo &quot;deb http://repo.mongodb.org/apt/ubuntu &quot;$(lsb_release -sc)&quot;/mongodb-org/3.0 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.0.list# sudo apt-get update# sudo apt-get install -y mongodb-org=3.0.1 mongodb-org-server=3.0.1 mongodb-org-shell=3.0.1 mongodb-org-mongos=3.0.1 mongodb-org-tools=3.0.1# su - root -c &quot;echo &apos;never&apos; &gt; /sys/kernel/mm/transparent_hugepage/enabled&quot;# su - root -c &quot;echo &apos;never&apos; &gt; /sys/kernel/mm/transparent_hugepage/defrag&quot;# sudo /etc/init.d/mongodb start# mogon #此处便可以看到版本号了# mogodb默认是没有密码的，需要在配置文件中将认证开启（但在此之前配置好用户有名和密码）# mogon&#123; user: &quot;&lt;name&gt;&quot;, pwd: &quot;&lt;cleartext password&gt;&quot;, customData: &#123; &lt;any information&gt; &#125;, # 任意的数据,一般是用于描述用户管理员的信息 roles: [ &#123; role: &quot;&lt;role&gt;&quot;, db: &quot;&lt;database&gt;&quot; &#125; | &quot;&lt;role&gt;&quot;, # 如果是role就是直接指定了角色,并作用于当前的数据库 ... ] # roles是必传项,但是可以指定空数组,为空就是不指定任何权限&#125;use products # mongoDB的权限设置是以库为单位的,必选要先选择库db.createUser( &#123; &quot;user&quot; : &quot;accountAdmin01&quot;, &quot;pwd&quot;: &quot;cleartext password&quot;, &quot;customData&quot; : &#123; employeeId: 12345 &#125;, &quot;roles&quot; : [ &#123; role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; &#125;, &#123; role: &quot;readAnyDatabase&quot;, db: &quot;admin&quot; &#125;, &quot;readWrite&quot; ] &#125;,&#123; w: &quot;majority&quot; , wtimeout: 5000 &#125; ) # readWrite 适用于products库,clusterAdmin与readAnyDatabase角色适用于admin库 mac测试环境多版本php添加mongo报错 php.h file not fond12# cp -r /Library/Developer/Command LineTools/SDKs/MacOSX10.12.sdk/usr/i nclude /Applications/MAMP/bin/php/ph p5.6.10/ # brew install pcre # sudo ./pecl install mongodb nginx 重写443全局生效的两种方式在server中新开起一个000-http2https.conf虚拟主机123456789101112server &#123; listen 80; server_name _; return 301 https://$HOST$request_uri;&#125;#server &#123;# listen 80;# server_name test.com;# rewrite ^(.*)$ https://$host$1 permanent; # #&#125; nginx 临时返回一个值或一个地址123456789 location /rjyy &#123; return &apos;https://rjyy.ssjinyao.com&apos; ;&#125; location /nene &#123; return &apos;https://nene.ssjinyao.com&apos; ;&#125; location /sange.html &#123; return 200 &apos;&lt;h1&gt;mei tou nao a&lt;/h1&gt;&apos; ;&#125; ssh不能key登录123查看.ssh 与 authorized_keys的权限查看/etc/ssh配置问题AuthorizedKeysFile %h/.ssh/authorized_keys 允许HTTP上传文件，并设定大小12345vim /etc/php.inifile_uploads = on; 是否允许通过HTTP上传文件的开关。默认为ON即是开;upload_tmp_dir; 文件上传至服务器上存储临时文件的地方，如果没指定就会用系统默认的临时文件夹;post_max_filesize = 8m; 允许上传文件大小的最大值。默认为2M; post_max_size 8m; 指通过表单POST给PHP的所能接收的最大值，包括表单里的所有值。默认为8M; gitlab-ci 持续化发布平台123456789# gitlab-ci 认证是一坑，版本不兼容的话一直会认证失败的,gitlab-ci 与gilab 可以不在同一台服务器; # 但是可以堡垒机放在同一台服务器上;# apt-get install gitlab-ci-multi-runner=1.10.2# gitlab-ci-multi-runner registerhttp://xxx.xx.xxx.xxx:8080/ci如果是建立公共runner，则需要以root登录gitlab --&gt; root --&gt; Admin Area --&gt; Ruuners -&gt; 可以查看到变红的koen deployshellshell 便可以添加上了 在指定分支中添加.gitlab-ci.yml ，如test分支 123456789before_script: - cd /xxxxx/xxxx/deploy_cijob: only: - test tags: - inner script: - /usr/bin/fab -f xx-deploy.py xxxxxx:test,0 关于python 部署的坑12345678910# 项目目录 /root/text/# 需要执行的代码 /root/text/poor/fober.py# config 配置文件 /root/text/config/config.py共两种解决方式1. 添加v.pth 在ENV中 # virtualenv /root/text/ENV# vim /root/text/ENV/lib/python2.7/site-packages/v.pth/root/text2. 在调用config前，定义好目录# sys.path.append(&apos;/root/text/&apos;)]]></content>
  </entry>
</search>
